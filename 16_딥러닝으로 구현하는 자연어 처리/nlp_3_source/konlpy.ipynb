{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 품사 태깅(tag) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "형태소의 뜻과 문맥을 고려하여 그것에 마크업을 하는 일입니다. \n",
    "\n",
    "예를 들어: 가방에 들어가신다 -> 가방/NNG + 에/JKM + 들어가/VV + 시/EPH + ㄴ다/EFN\n",
    "\n",
    "한국어 품사 태그 비교표 링크: https://docs.google.com/spreadsheets/d/1OGAjUvalBuX-oZvZ_-9tEfYD2gQe7hTGsgUpiiBSXI8/edit#gid=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 형태소 분석기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hannanum - KAIST 말뭉치를 이용해 생성된 사전\n",
    "\n",
    "Kkma - 세종 말뭉치를 이용해 생성된 사전 (꼬꼬마)\n",
    "\n",
    "Mecab - 세종 말뭉치로 만들어진 CSV형태의 사전\n",
    "\n",
    "Komoran- Java로 쓰여진 오픈소스 한글 형태소 분석기\n",
    "\n",
    "Twitter(Okt) - 오픈소스 한글 형태소 분석기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[('롯데마트', 'ncn'), ('의', 'jcm')], [('롯데마트의', 'ncn')], [('롯데마트', 'nqq'), ('의', 'jcm')], [('롯데마트의', 'nqq')]], [[('흑마늘', 'ncn')], [('흑마늘', 'nqq')]], [[('양념', 'ncn')]], [[('치킨', 'ncn'), ('이', 'jcc')], [('치킨', 'ncn'), ('이', 'jcs')], [('치킨', 'ncn'), ('이', 'ncn')]], [[('논란', 'ncpa'), ('이', 'jcc')], [('논란', 'ncpa'), ('이', 'jcs')], [('논란', 'ncpa'), ('이', 'ncn')]], [[('되', 'nbu'), ('고', 'jcj')], [('되', 'nbu'), ('이', 'jp'), ('고', 'ecc')], [('되', 'nbu'), ('이', 'jp'), ('고', 'ecs')], [('되', 'nbu'), ('이', 'jp'), ('고', 'ecx')], [('되', 'paa'), ('고', 'ecc')], [('되', 'paa'), ('고', 'ecs')], [('되', 'paa'), ('고', 'ecx')], [('되', 'pvg'), ('고', 'ecc')], [('되', 'pvg'), ('고', 'ecs')], [('되', 'pvg'), ('고', 'ecx')], [('되', 'px'), ('고', 'ecc')], [('되', 'px'), ('고', 'ecs')], [('되', 'px'), ('고', 'ecx')]], [[('있', 'paa'), ('다', 'ef')], [('있', 'px'), ('다', 'ef')]], [[('.', 'sf')], [('.', 'sy')]]]\n",
      "['롯데마트', '의', '흑마늘', '양념', '치킨', '이', '논란', '이', '되', '고', '있', '다', '.']\n",
      "['다람쥐', '쳇바퀴', '타고파']\n",
      "[('웃', 'P'), ('으면', 'E'), ('더', 'M'), ('행복', 'N'), ('하', 'X'), ('ㅂ니다', 'E'), ('!', 'S')]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Hannanum\n",
    "hannanum = Hannanum() \n",
    " \n",
    "hannanum.analyze  #구(Phrase) 분석\n",
    "hannanum.morphs   #형태소 분석\n",
    "hannanum.nouns    #명사 분석\n",
    "hannanum.pos      #형태소 분석 태깅\n",
    " \n",
    "# 사용예시\n",
    "print(hannanum.analyze(u'롯데마트의 흑마늘 양념 치킨이 논란이 되고 있다.'))\n",
    "\n",
    "print(hannanum.morphs(u'롯데마트의 흑마늘 양념 치킨이 논란이 되고 있다.'))\n",
    " \n",
    "print(hannanum.nouns(u'다람쥐 헌 쳇바퀴에 타고파'))\n",
    " \n",
    "print(hannanum.pos(u'웃으면 더 행복합니다!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['공부', '를', '하', '면', '하', 'ㄹ수록', '모르', '는', '것', '이', '많', '다는', '것', '을', '알', '게', '되', 'ㅂ니다', '.']\n",
      "['대학', '통계학', '이산', '이산수학', '수학', '등']\n",
      "[('다', 'MAG'), ('까먹', 'VV'), ('어', 'ECD'), ('버리', 'VXV'), ('었', 'EPT'), ('네요', 'EFN'), ('?', 'SF'), ('ㅋㅋ', 'EMO')]\n",
      "['그래도 계속 공부합니다.', '재밌으니까!']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Kkma\n",
    "kkma = Kkma()\n",
    " \n",
    "kkma.morphs         #형태소 분석\n",
    "kkma.nouns          #명사 분석\n",
    "kkma.pos            #형태소 분석 태깅\n",
    "kkma.sentences      #문장 분석\n",
    " \n",
    "# 사용예시\n",
    "print(kkma.morphs(u'공부를 하면할수록 모르는게 많다는 것을 알게 됩니다.'))\n",
    "\n",
    "print(kkma.nouns(u'대학에서 DB, 통계학, 이산수학 등을 배웠지만...'))\n",
    " \n",
    "print(kkma.pos(u'다 까먹어버렸네요?ㅋㅋ'))\n",
    " \n",
    "print(kkma.sentences(u'그래도 계속 공부합니다. 재밌으니까!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['우왕', '코', '모란', '도', '오픈', '소스', '가', '되', '었', '어요']\n",
      "['오픈', '소스', '관심', '개발자']\n",
      "[('혹시', 'MAG'), ('바람과 함께 사라지다', 'NNP'), ('보', 'VV'), ('았', 'EP'), ('어', 'EF'), ('?', 'SF')]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Komoran\n",
    "komoran = Komoran(userdic='/tmp/dic.txt')\n",
    " \n",
    "komoran.morphs    #형태소 분석\n",
    "komoran.nouns     #명사 분석\n",
    "komoran.pos       #형태소 분석 태깅\n",
    " \n",
    "# 사용예시\n",
    "print(komoran.morphs(u'우왕 코모란도 오픈소스가 되었어요'))\n",
    " \n",
    "print(komoran.nouns(u'오픈소스에 관심 많은 멋진 개발자님들!'))\n",
    " \n",
    "print(komoran.pos(u'혹시 바람과 함께 사라지다 봤어?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['단독', '입찰', '보다', '복수', '입찰', '의', '경우']\n",
      "['항공기', '체계', '종합', '개발', '경험']\n",
      "['날카로운 분석', '날카로운 분석과 신뢰감', '날카로운 분석과 신뢰감 있는 진행', '분석', '신뢰', '진행']\n",
      "[('이', 'Determiner'), ('것', 'Noun'), ('도', 'Josa'), ('되나욬', 'Noun'), ('ㅋㅋ', 'KoreanParticle')]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    " \n",
    "okt.morphs     #형태소 분석\n",
    "okt.nouns      #명사 분석\n",
    "okt.phrases    #구(Phrase) 분석\n",
    "okt.pos        #형태소 분석 태깅\n",
    " \n",
    "# 사용예시\n",
    "print(okt.morphs(u'단독입찰보다 복수입찰의 경우'))\n",
    " \n",
    "print(okt.nouns(u'유일하게 항공기 체계 종합개발 경험을 갖고 있는 KAI는'))\n",
    " \n",
    "print(okt.phrases(u'날카로운 분석과 신뢰감 있는 진행으로'))\n",
    " \n",
    "print(okt.pos(u'이것도 되나욬ㅋㅋ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hanna\t1\t3.5953609943389893\n",
      "[('대', 'M')]\n",
      "Kkma\t1\t9.272657871246338\n",
      "[('대', 'NNG')]\n",
      "Komor\t1\t4.146404266357422\n",
      "[('대', 'NNB')]\n",
      "Uhoh, Install MeCab in order to use it: http://konlpy.org/en/latest/install/\n",
      "Mecab\t1\t0.0\n",
      "[]\n",
      "Okt\t1\t4.157790660858154\n",
      "[('대', 'Verb')]\n",
      "Twitt\t1\t0.003989219665527344\n",
      "[('대', 'Verb')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jikim\\anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hanna\t10\t1.7694134712219238\n",
      "[('대한민국헌법', 'N'), ('유구', 'N')]\n",
      "Kkma\t10\t0.15259337425231934\n",
      "[('대한민국', 'NNG'), ('헌법', 'NNG'), ('유구', 'XR')]\n",
      "Komor\t10\t1.6071555614471436\n",
      "[('대한민국', 'NNP'), ('헌법', 'NNP'), ('유구', 'NNP')]\n",
      "Uhoh, Install MeCab in order to use it: http://konlpy.org/en/latest/install/\n",
      "Mecab\t10\t0.0009987354278564453\n",
      "[]\n",
      "Okt\t10\t0.028920650482177734\n",
      "[('대한민국', 'Noun'), ('헌법', 'Noun'), ('\\n\\n', 'Foreign'), ('유구', 'Noun')]\n",
      "Twitt\t10\t0.013962984085083008\n",
      "[('대한민국', 'Noun'), ('헌법', 'Noun'), ('\\n\\n', 'Foreign'), ('유구', 'Noun')]\n",
      "Hanna\t100\t0.9177322387695312\n",
      "[('대한민국헌법', 'N'), ('유구', 'N'), ('하', 'X'), ('ㄴ', 'E'), ('역사', 'N')]\n",
      "Kkma\t100\t0.4727363586425781\n",
      "[('대한민국', 'NNG'), ('헌법', 'NNG'), ('유구', 'NNG'), ('하', 'XSV'), ('ㄴ', 'ETD')]\n",
      "Komor\t100\t1.5554828643798828\n",
      "[('대한민국', 'NNP'), ('헌법', 'NNP'), ('유구', 'XR'), ('하', 'XSA'), ('ㄴ', 'ETM')]\n",
      "Uhoh, Install MeCab in order to use it: http://konlpy.org/en/latest/install/\n",
      "Mecab\t100\t0.0009982585906982422\n",
      "[]\n",
      "Okt\t100\t0.05186104774475098\n",
      "[('대한민국', 'Noun'),\n",
      " ('헌법', 'Noun'),\n",
      " ('\\n\\n', 'Foreign'),\n",
      " ('유구', 'Noun'),\n",
      " ('한', 'Josa')]\n",
      "Twitt\t100\t0.021942138671875\n",
      "[('대한민국', 'Noun'),\n",
      " ('헌법', 'Noun'),\n",
      " ('\\n\\n', 'Foreign'),\n",
      " ('유구', 'Noun'),\n",
      " ('한', 'Josa')]\n",
      "Hanna\t1000\t1.7483270168304443\n",
      "[('대한민국헌법', 'N'), ('유구', 'N'), ('하', 'X'), ('ㄴ', 'E'), ('역사', 'N')]\n",
      "Kkma\t1000\t1.1845595836639404\n",
      "[('대한민국', 'NNG'), ('헌법', 'NNG'), ('유구', 'NNG'), ('하', 'XSV'), ('ㄴ', 'ETD')]\n",
      "Komor\t1000\t0.9841465950012207\n",
      "[('대한민국', 'NNP'), ('헌법', 'NNP'), ('유구', 'XR'), ('하', 'XSA'), ('ㄴ', 'ETM')]\n",
      "Uhoh, Install MeCab in order to use it: http://konlpy.org/en/latest/install/\n",
      "Mecab\t1000\t0.0019948482513427734\n",
      "[]\n",
      "Okt\t1000\t0.10372233390808105\n",
      "[('대한민국', 'Noun'),\n",
      " ('헌법', 'Noun'),\n",
      " ('\\n\\n', 'Foreign'),\n",
      " ('유구', 'Noun'),\n",
      " ('한', 'Josa')]\n",
      "Twitt\t1000\t0.4797179698944092\n",
      "[('대한민국', 'Noun'),\n",
      " ('헌법', 'Noun'),\n",
      " ('\\n\\n', 'Foreign'),\n",
      " ('유구', 'Noun'),\n",
      " ('한', 'Josa')]\n",
      "Hanna\t10000\t2.289877414703369\n",
      "[('대한민국헌법', 'N'), ('유구', 'N'), ('하', 'X'), ('ㄴ', 'E'), ('역사', 'N')]\n",
      "Kkma\t10000\t2.708808422088623\n",
      "[('대한민국', 'NNG'), ('헌법', 'NNG'), ('유구', 'NNG'), ('하', 'XSV'), ('ㄴ', 'ETD')]\n",
      "Komor\t10000\t2.3164689540863037\n",
      "[('대한민국', 'NNP'), ('헌법', 'NNP'), ('유구', 'XR'), ('하', 'XSA'), ('ㄴ', 'ETM')]\n",
      "Uhoh, Install MeCab in order to use it: http://konlpy.org/en/latest/install/\n",
      "Mecab\t10000\t0.0009970664978027344\n",
      "[]\n",
      "Okt\t10000\t1.356389045715332\n",
      "[('대한민국', 'Noun'),\n",
      " ('헌법', 'Noun'),\n",
      " ('\\n\\n', 'Foreign'),\n",
      " ('유구', 'Noun'),\n",
      " ('한', 'Josa')]\n",
      "Twitt\t10000\t0.6771891117095947\n",
      "[('대한민국', 'Noun'),\n",
      " ('헌법', 'Noun'),\n",
      " ('\\n\\n', 'Foreign'),\n",
      " ('유구', 'Noun'),\n",
      " ('한', 'Josa')]\n",
      "Hanna\t100000\t8.168427228927612\n",
      "[('대한민국헌법', 'N'), ('유구', 'N'), ('하', 'X'), ('ㄴ', 'E'), ('역사', 'N')]\n",
      "Kkma\t100000\t29.785685062408447\n",
      "[('대한민국', 'NNG'), ('헌법', 'NNG'), ('유구', 'NNG'), ('하', 'XSV'), ('ㄴ', 'ETD')]\n",
      "Komor\t100000\t4.352652549743652\n",
      "[('대한민국', 'NNP'), ('헌법', 'NNP'), ('유구', 'XR'), ('하', 'XSA'), ('ㄴ', 'ETM')]\n",
      "Uhoh, Install MeCab in order to use it: http://konlpy.org/en/latest/install/\n",
      "Mecab\t100000\t0.006949186325073242\n",
      "[]\n",
      "Okt\t100000\t2.9095001220703125\n",
      "[('대한민국', 'Noun'),\n",
      " ('헌법', 'Noun'),\n",
      " ('\\n\\n', 'Foreign'),\n",
      " ('유구', 'Noun'),\n",
      " ('한', 'Josa')]\n",
      "Twitt\t100000\t2.8903141021728516\n",
      "[('대한민국', 'Noun'),\n",
      " ('헌법', 'Noun'),\n",
      " ('\\n\\n', 'Foreign'),\n",
      " ('유구', 'Noun'),\n",
      " ('한', 'Josa')]\n",
      "\n",
      "아버지가방에들어가신다\n",
      "Hannanum\n",
      "[('아버지가방에들어가', 'N'), ('이', 'J'), ('시ㄴ다', 'E')]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"map\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1ac6f0d578a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# Accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeasure_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtaggers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m''\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-1ac6f0d578a5>\u001b[0m in \u001b[0;36mmeasure_accuracy\u001b[1;34m(taggers, text)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtagging\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtagger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mpprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtagger\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m' / '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate list (not \"map\") to list"
     ]
    }
   ],
   "source": [
    "#! /usr/bin/python2.7\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from time import time\n",
    "\n",
    "from konlpy import tag\n",
    "from konlpy.corpus import kolaw\n",
    "from konlpy.utils import pprint\n",
    "\n",
    "\n",
    "def tagging(tagger, text):\n",
    "    r = []\n",
    "    try:\n",
    "        r = getattr(tag, tagger)().pos(text)\n",
    "    except Exception as e:\n",
    "        print(\"Uhoh,\", e)\n",
    "    return r\n",
    "\n",
    "\n",
    "def measure_time(taggers, mult=6):\n",
    "    doc = kolaw.open('constitution.txt').read()*6\n",
    "    data = [['n'] + taggers]\n",
    "    for i in range(mult):\n",
    "        doclen = 10**i\n",
    "        times = [time()]\n",
    "        diffs = [doclen]\n",
    "        for tagger in taggers:\n",
    "            r = tagging(tagger, doc[:doclen])\n",
    "            times.append(time())\n",
    "            diffs.append(times[-1] - times[-2])\n",
    "            print('%s\\t%s\\t%s' % (tagger[:5], doclen, diffs[-1]))\n",
    "            pprint(r[:5])\n",
    "        data.append(diffs)\n",
    "        print\n",
    "    return data\n",
    "\n",
    "\n",
    "def measure_accuracy(taggers, text):\n",
    "    print('\\n%s' % text)\n",
    "    result = []\n",
    "    for tagger in taggers:\n",
    "        print (tagger)\n",
    "        r = tagging(tagger, text)\n",
    "        pprint(r)\n",
    "        result.append([tagger] + map(lambda s: ' / '.join(s), r))\n",
    "    return result\n",
    "\n",
    "\n",
    "def plot(result):\n",
    "\n",
    "    from matplotlib import pylab as pl\n",
    "    import scipy as sp\n",
    "\n",
    "    if not result:\n",
    "        result = sp.loadtxt('morph.csv', delimiter=',', skiprows=1).T\n",
    "\n",
    "    x, y = result[0], result[1:]\n",
    "\n",
    "    for i in y:\n",
    "        pl.plot(x, i)\n",
    "\n",
    "    pl.xlabel('Number of characters')\n",
    "    pl.ylabel('Time (sec)')\n",
    "    pl.xscale('log')\n",
    "    pl.grid(True)\n",
    "    pl.savefig(\"images/time.png\")\n",
    "    pl.show()\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "\n",
    "    PLOT = False\n",
    "    MULT = 6\n",
    "\n",
    "    examples = [u'아버지가방에들어가신다',  # 띄어쓰기\n",
    "            u'나는 밥을 먹는다', u'하늘을 나는 자동차', # 중의성 해소\n",
    "            u'아이폰 기다리다 지쳐 애플공홈에서 언락폰질러버렸다 6+ 128기가실버ㅋ'] # 속어\n",
    "\n",
    "    taggers = [t for t in dir(tag) if t[0].isupper()]\n",
    "\n",
    "    # Time\n",
    "    data = measure_time(taggers, mult=MULT)\n",
    "\n",
    "    # Accuracy\n",
    "    for i, example in enumerate(examples):\n",
    "        result = measure_accuracy(taggers, example)\n",
    "        result = map(lambda *row: [i or '' for i in row], *result)\n",
    "\n",
    "    # Plot\n",
    "    if PLOT:\n",
    "        plot(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
