{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 75)\n",
      "(90, 75)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "sys.path.append(os.pardir)\n",
    "from common.util import im2col\n",
    "\n",
    "x1 = np.random.rand(1, 3, 7, 7)\n",
    "col1 = im2col( x1, 5, 5, stride=1, pad=0)\n",
    "print(col1.shape)\n",
    "\n",
    "x2 = np.random.rand(10, 3, 7, 7)\n",
    "col2 = im2col( x2, 5, 5, stride=1, pad=0)\n",
    "print(col2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 3, 3)\n",
      "[[[[0 1 2]\n",
      "   [3 4 5]\n",
      "   [6 7 8]]]]\n",
      "[[[[0 1]\n",
      "   [3 4]]]]\n",
      "(4, 4)\n",
      "[[0. 1. 3. 4.]\n",
      " [1. 2. 4. 5.]\n",
      " [3. 4. 6. 7.]\n",
      " [4. 5. 7. 8.]]\n"
     ]
    }
   ],
   "source": [
    "input_data = np.arange(9).reshape(1, 1, 3, 3)\n",
    "pad=0\n",
    "img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "print(img.shape)\n",
    "print(img)\n",
    "print(img[:, :, 0:2, 0:2])\n",
    "col = np.zeros((1, 1, 2, 2, 2, 2))\n",
    "for y in range(2):\n",
    "    y_max = y + 1*2\n",
    "    for x in range(2):\n",
    "        x_max = x + 1*2\n",
    "        col[:, :, y, x, :, :] = img[:, :, y:y_max:1, x:x_max:1]\n",
    "col = col.transpose(0, 4, 5, 1, 2, 3).reshape(1*2*2, -1)\n",
    "print(col.shape)\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 2, 2, 2, 2)\n",
      "[[[[[[0. 0.]\n",
      "     [0. 0.]]\n",
      "\n",
      "    [[0. 0.]\n",
      "     [0. 0.]]]\n",
      "\n",
      "\n",
      "   [[[0. 0.]\n",
      "     [0. 0.]]\n",
      "\n",
      "    [[0. 0.]\n",
      "     [0. 0.]]]]]]\n"
     ]
    }
   ],
   "source": [
    "col = np.zeros((1, 1, 2, 2, 2, 2))\n",
    "print(col.shape)\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "    N, C, H, W = input_data.shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "\n",
    "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
    "\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
    "\n",
    "#     print(col)\n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3)\n",
    "#     print(col)\n",
    "    col = col.reshape(N*out_h*out_w, -1)\n",
    "    \n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\n",
    "    N, C, H, W = input_shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w)\n",
    "#     print(col)\n",
    "    col = col.transpose(0, 3, 4, 5, 1, 2)\n",
    "#     print(col)\n",
    "\n",
    "    img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
    "\n",
    "    return img[:, :, pad:H + pad, pad:W + pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 3. 4.]\n",
      " [1. 2. 4. 5.]\n",
      " [3. 4. 6. 7.]\n",
      " [4. 5. 7. 8.]]\n",
      "[[[[ 0.  2.  2.]\n",
      "   [ 6. 16. 10.]\n",
      "   [ 6. 14.  8.]]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "img = np.arange(9).reshape(1,1,3,3)\n",
    "col = im2col(img,2,2)\n",
    "print(col)\n",
    "dx = col2im(col, img.shape, 2, 2)\n",
    "print(dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀링 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        self.x = None\n",
    "        self.arg_max = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "\n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        print(col)\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "        print(col)\n",
    "        arg_max = np.argmax(col, axis=1)\n",
    "#         print(arg_max)\n",
    "        out = np.max(col, axis=1)\n",
    "#         print(out)\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "#         print(out)\n",
    "        self.x = x\n",
    "        self.arg_max = arg_max\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout = dout.transpose(0, 2, 3, 1)\n",
    "        \n",
    "        pool_size = self.pool_h * self.pool_w\n",
    "        dmax = np.zeros((dout.size, pool_size))\n",
    "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n",
    "        dmax = dmax.reshape(dout.shape + (pool_size,)) \n",
    "        print('dmax', dmax)\n",
    "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
    "        print('dcol', dcol)\n",
    "        dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        \n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[15 14  6  2]\n",
      "   [ 8 18 16  3]\n",
      "   [11  5  2 13]\n",
      "   [ 6  6 19  9]]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "img = np.random.randint(1, 20, size=(1,1,4,4))\n",
    "print(img)\n",
    "\n",
    "pool = Pooling(2, 2, 2)\n",
    "x = pool.forward(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0  1  2  3]\n",
      "   [ 4  5  6  7]\n",
      "   [ 8  9 10 11]\n",
      "   [12 13 14 15]]\n",
      "\n",
      "  [[16 17 18 19]\n",
      "   [20 21 22 23]\n",
      "   [24 25 26 27]\n",
      "   [28 29 30 31]]]]\n",
      "[[[[ 5.  7.]\n",
      "   [13. 15.]]\n",
      "\n",
      "  [[21. 23.]\n",
      "   [29. 31.]]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = np.arange(32).reshape(1,2,4,4)\n",
    "print(img)\n",
    "pool = Pooling(2, 2, 2)\n",
    "x = pool.forward(img)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0  1  2  3]\n",
      "   [ 4  5  6  7]\n",
      "   [ 8  9 10 11]\n",
      "   [12 13 14 15]]\n",
      "\n",
      "  [[16 17 18 19]\n",
      "   [20 21 22 23]\n",
      "   [24 25 26 27]\n",
      "   [28 29 30 31]]]\n",
      "\n",
      "\n",
      " [[[32 33 34 35]\n",
      "   [36 37 38 39]\n",
      "   [40 41 42 43]\n",
      "   [44 45 46 47]]\n",
      "\n",
      "  [[48 49 50 51]\n",
      "   [52 53 54 55]\n",
      "   [56 57 58 59]\n",
      "   [60 61 62 63]]]]\n",
      "[[[[ 5.  7.]\n",
      "   [13. 15.]]\n",
      "\n",
      "  [[21. 23.]\n",
      "   [29. 31.]]]\n",
      "\n",
      "\n",
      " [[[37. 39.]\n",
      "   [45. 47.]]\n",
      "\n",
      "  [[53. 55.]\n",
      "   [61. 63.]]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = np.arange(64).reshape(2,2,4,4)\n",
    "print(img)\n",
    "pool = Pooling(2, 2, 2)\n",
    "x = pool.forward(img)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n",
      "[1 1 2 2]\n",
      "(1, 2, 2, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "b = np.zeros((4,4))\n",
    "a = np.array([[1,1],[2,2]])\n",
    "print(len(a))\n",
    "print(a.size)\n",
    "\n",
    "a = a.reshape(1,2,2,1)\n",
    "print(a.flatten())\n",
    "\n",
    "b = b.reshape( a.shape + (4,) ) \n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀링  연산 테스트 : 채널이 1인 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[18. 19.]\n",
      "   [13. 19.]]]]\n",
      "dmax [[[[[0. 1. 0. 0.]]\n",
      "\n",
      "   [[0. 0. 0. 1.]]]\n",
      "\n",
      "\n",
      "  [[[0. 0. 2. 0.]]\n",
      "\n",
      "   [[0. 0. 2. 0.]]]]]\n",
      "dcol [[0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 2. 0.]\n",
      " [0. 0. 2. 0.]]\n",
      "[[[[0. 1. 0. 0.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [2. 0. 2. 0.]]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "img = np.array([[ [[13,18, 6, 2],\n",
    "                   [14,16,12,19],\n",
    "                   [ 9, 4, 7, 7],\n",
    "                   [13, 9,19,10]] ]])\n",
    "\n",
    "pool = Pooling(2, 2, 2)\n",
    "x = pool.forward(img)\n",
    "print(x)\n",
    "\n",
    "dout = np.array([[ [[1,1],\n",
    "                    [2,2]] ]])\n",
    "\n",
    "\n",
    "dx = pool.backward(dout)\n",
    "print(dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀링  연산 테스트 : 채널이 2인 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 4, 4)\n",
      "[[13. 18. 14. 16. 13. 10. 14. 16.]\n",
      " [ 6.  2. 12. 19.  6.  2. 12.  9.]\n",
      " [ 9.  4. 13.  9.  9. 14.  8.  9.]\n",
      " [ 7.  7. 19. 10.  7.  7. 19. 20.]]\n",
      "[[13. 18. 14. 16.]\n",
      " [13. 10. 14. 16.]\n",
      " [ 6.  2. 12. 19.]\n",
      " [ 6.  2. 12.  9.]\n",
      " [ 9.  4. 13.  9.]\n",
      " [ 9. 14.  8.  9.]\n",
      " [ 7.  7. 19. 10.]\n",
      " [ 7.  7. 19. 20.]]\n",
      "[[[[18. 19.]\n",
      "   [13. 19.]]\n",
      "\n",
      "  [[16. 12.]\n",
      "   [14. 20.]]]]\n",
      "dmax [[[[[0. 1. 0. 0.]\n",
      "    [0. 0. 0. 3.]]\n",
      "\n",
      "   [[0. 0. 0. 1.]\n",
      "    [0. 0. 3. 0.]]]\n",
      "\n",
      "\n",
      "  [[[0. 0. 2. 0.]\n",
      "    [0. 4. 0. 0.]]\n",
      "\n",
      "   [[0. 0. 2. 0.]\n",
      "    [0. 0. 0. 4.]]]]]\n",
      "dcol [[0. 1. 0. 0. 0. 0. 0. 3.]\n",
      " [0. 0. 0. 1. 0. 0. 3. 0.]\n",
      " [0. 0. 2. 0. 0. 4. 0. 0.]\n",
      " [0. 0. 2. 0. 0. 0. 0. 4.]]\n",
      "[[[[0. 1. 0. 0.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [2. 0. 2. 0.]]\n",
      "\n",
      "  [[0. 0. 0. 0.]\n",
      "   [0. 3. 3. 0.]\n",
      "   [0. 4. 0. 0.]\n",
      "   [0. 0. 0. 4.]]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# (1,2,4,4)\n",
    "\n",
    "img = np.array([[ [[13,18, 6, 2],\n",
    "                   [14,16,12,19],\n",
    "                   [ 9, 4, 7, 7],\n",
    "                   [13, 9,19,10]],\n",
    "                  [[13,10, 6, 2],\n",
    "                   [14,16,12, 9],\n",
    "                   [ 9,14, 7, 7],\n",
    "                   [ 8, 9,19,20]]]])\n",
    "\n",
    "print(img.shape)\n",
    "pool = Pooling(2, 2, 2)\n",
    "x = pool.forward(img)\n",
    "print(x)\n",
    "\n",
    "dout = np.array([[ [[1,1],\n",
    "                    [2,2]],\n",
    "                   [[3,3],\n",
    "                    [4,4]]\n",
    "                 ]])\n",
    "\n",
    "\n",
    "dx = pool.backward(dout)\n",
    "print(dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from simple_convnet import SimpleConvNet\n",
    "from matplotlib.image import imread\n",
    "from common.layers import Convolution\n",
    "\n",
    "def filter_show(filters, nx=4, show_num=16):\n",
    "    \"\"\"\n",
    "    c.f. https://gist.github.com/aidiary/07d530d5e08011832b12#file-draw_weight-py\n",
    "    \"\"\"\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(show_num / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(show_num):\n",
    "        ax = fig.add_subplot(4, 4, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "\n",
    "# 학습된 가중치\n",
    "network.load_params(\"params.pkl\")\n",
    "\n",
    "filter_show(network.params['W1'], 16)\n",
    "\n",
    "img = imread('../dataset/cactus_gray.png')\n",
    "img = img.reshape(1, 1, *img.shape)\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "w_idx = 1\n",
    "\n",
    "for i in range(16):\n",
    "    w = network.params['W1'][i]\n",
    "    b = 0  # network.params['b1'][i]\n",
    "\n",
    "    w = w.reshape(1, *w.shape)\n",
    "    #b = b.reshape(1, *b.shape)\n",
    "    conv_layer = Convolution(w, b) \n",
    "    out = conv_layer.forward(img)\n",
    "    out = out.reshape(out.shape[2], out.shape[3])\n",
    "    \n",
    "    ax = fig.add_subplot(4, 4, i+1, xticks=[], yticks=[])\n",
    "    ax.imshow(out, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 5.080283264748344e-07\n",
      "b1 1.448947443282632e-06\n",
      "W2 3.8109693837087724e-11\n",
      "b2 4.729897866212127e-09\n",
      "W3 2.1656877008921265e-10\n",
      "b3 1.7990195529116182e-07\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from simple_convnet import SimpleConvNet\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,10, 10), \n",
    "                        conv_param = {'filter_num':10, 'filter_size':3, 'pad':0, 'stride':1},\n",
    "                        hidden_size=10, output_size=10, weight_init_std=0.01)\n",
    "\n",
    "X = np.random.rand(100).reshape((1, 1, 10, 10))\n",
    "T = np.array([1]).reshape((1,1))\n",
    "\n",
    "grad_num = network.numerical_gradient(X, T)\n",
    "grad = network.gradient(X, T)\n",
    "\n",
    "for key, val in grad_num.items():\n",
    "    print(key, np.abs(grad_num[key] - grad[key]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "\n",
    "class SimpleConvNet:\n",
    "    \"\"\"단순한 합성곱 신경망\n",
    "    \n",
    "    conv - relu - pool - affine - relu - affine - softmax\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_size : 입력 크기（MNIST의 경우엔 784）\n",
    "    hidden_size_list : 각 은닉층의 뉴런 수를 담은 리스트（e.g. [100, 100, 100]）\n",
    "    output_size : 출력 크기（MNIST의 경우엔 10）\n",
    "    activation : 활성화 함수 - 'relu' 혹은 'sigmoid'\n",
    "    weight_init_std : 가중치의 표준편차 지정（e.g. 0.01）\n",
    "        'relu'나 'he'로 지정하면 'He 초깃값'으로 설정\n",
    "        'sigmoid'나 'xavier'로 지정하면 'Xavier 초깃값'으로 설정\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        \"\"\"손실 함수를 구한다.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "        \"\"\"\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다（수치미분）.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        loss_w = lambda w: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        for idx in (1, 2, 3):\n",
    "            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n",
    "            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다(오차역전파법).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    "        \n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n",
    "            self.layers[key].W = self.params['W' + str(i+1)]\n",
    "            self.layers[key].b = self.params['b' + str(i+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2992385257989927\n",
      "=== epoch:1, train acc:0.103, test acc:0.109 ===\n",
      "train loss:2.2976492968889595\n",
      "train loss:2.294529319528135\n",
      "train loss:2.2872119427965223\n",
      "train loss:2.2789876944379794\n",
      "train loss:2.2681210670460588\n",
      "train loss:2.2540400176036473\n",
      "train loss:2.2333410971538314\n",
      "train loss:2.2204299586163563\n",
      "train loss:2.1879572874178543\n",
      "train loss:2.1779493277364126\n",
      "train loss:2.110886826338491\n",
      "train loss:2.0782036188699506\n",
      "train loss:2.037183316092976\n",
      "train loss:2.0096722698518525\n",
      "train loss:1.9019766631508173\n",
      "train loss:1.881545274592184\n",
      "train loss:1.7714601889191959\n",
      "train loss:1.722138949921664\n",
      "train loss:1.6877070789393418\n",
      "train loss:1.5647323875890335\n",
      "train loss:1.4939948886020122\n",
      "train loss:1.4038041821343452\n",
      "train loss:1.3843492581611077\n",
      "train loss:1.341463795684202\n",
      "train loss:1.1862617576824364\n",
      "train loss:1.0607739752101073\n",
      "train loss:1.0575332409594325\n",
      "train loss:1.0610739081191396\n",
      "train loss:0.9096768913799032\n",
      "train loss:0.9801480422080264\n",
      "train loss:0.8286405363277161\n",
      "train loss:0.7802714946849971\n",
      "train loss:0.9278747840598516\n",
      "train loss:0.7608647062824971\n",
      "train loss:0.849952000679867\n",
      "train loss:0.8946924088070523\n",
      "train loss:0.5911872825488049\n",
      "train loss:0.6665738302211244\n",
      "train loss:0.6963592473129014\n",
      "train loss:0.7340339374940676\n",
      "train loss:0.7387931257707693\n",
      "train loss:0.634781592269841\n",
      "train loss:0.515446210589471\n",
      "train loss:0.6164459794178724\n",
      "train loss:0.6150149128715792\n",
      "train loss:0.6273109143874539\n",
      "train loss:0.5740986223236353\n",
      "train loss:0.553086709348986\n",
      "train loss:0.5374616082138922\n",
      "train loss:0.5627927517207653\n",
      "train loss:0.48849521198340035\n",
      "train loss:0.466742116394419\n",
      "train loss:0.5856823637151987\n",
      "train loss:0.568706062014686\n",
      "train loss:0.4335977618227513\n",
      "train loss:0.40514542460783026\n",
      "train loss:0.6317747207575498\n",
      "train loss:0.5040718929991236\n",
      "train loss:0.4639804257538343\n",
      "train loss:0.5194027203453571\n",
      "train loss:0.4613874039891109\n",
      "train loss:0.4221759523334959\n",
      "train loss:0.47013869539200476\n",
      "train loss:0.5261753457077961\n",
      "train loss:0.4766328393352759\n",
      "train loss:0.5407837093402903\n",
      "train loss:0.4121421753585573\n",
      "train loss:0.4397656520137672\n",
      "train loss:0.5470113919053644\n",
      "train loss:0.3522541868400634\n",
      "train loss:0.6201680074241137\n",
      "train loss:0.4771235804375253\n",
      "train loss:0.3291110502156113\n",
      "train loss:0.39240138725082846\n",
      "train loss:0.4957313273634636\n",
      "train loss:0.6093569763317483\n",
      "train loss:0.3469264713831617\n",
      "train loss:0.30102372773257174\n",
      "train loss:0.35494523265197253\n",
      "train loss:0.2251013281869427\n",
      "train loss:0.5266681519835226\n",
      "train loss:0.4941219858282121\n",
      "train loss:0.3847593580606655\n",
      "train loss:0.42588411053014674\n",
      "train loss:0.3965580622919366\n",
      "train loss:0.3772993756268213\n",
      "train loss:0.3298714483924289\n",
      "train loss:0.5404916120987857\n",
      "train loss:0.4331097698931433\n",
      "train loss:0.48061853066273097\n",
      "train loss:0.4208921944738098\n",
      "train loss:0.5475273510669194\n",
      "train loss:0.4822191225288456\n",
      "train loss:0.5999740256090454\n",
      "train loss:0.4400914350267072\n",
      "train loss:0.5585584985683244\n",
      "train loss:0.3956691880128643\n",
      "train loss:0.5727848949960093\n",
      "train loss:0.3025461715021556\n",
      "train loss:0.31220590981691276\n",
      "train loss:0.4413472933819033\n",
      "train loss:0.5860809564939912\n",
      "train loss:0.3228170437869629\n",
      "train loss:0.524607232251968\n",
      "train loss:0.2959127437244197\n",
      "train loss:0.4126948230064944\n",
      "train loss:0.33674071143155154\n",
      "train loss:0.30140301583126683\n",
      "train loss:0.33252604330418195\n",
      "train loss:0.27470027217609067\n",
      "train loss:0.300289247223437\n",
      "train loss:0.4628676827758737\n",
      "train loss:0.553276631518532\n",
      "train loss:0.34109744470276965\n",
      "train loss:0.2681196907942755\n",
      "train loss:0.4160079631929463\n",
      "train loss:0.23189066790782845\n",
      "train loss:0.4360449045655722\n",
      "train loss:0.2816790600585718\n",
      "train loss:0.2892035958107302\n",
      "train loss:0.401805352615853\n",
      "train loss:0.30646267171762154\n",
      "train loss:0.3216765296956738\n",
      "train loss:0.2437931645271182\n",
      "train loss:0.4317645629450525\n",
      "train loss:0.3683061328413133\n",
      "train loss:0.4717362152194057\n",
      "train loss:0.33278693406208815\n",
      "train loss:0.4284667714552716\n",
      "train loss:0.3601586117534739\n",
      "train loss:0.262225105135791\n",
      "train loss:0.44128965138354337\n",
      "train loss:0.2834039407151192\n",
      "train loss:0.3028787526914044\n",
      "train loss:0.38965456873829885\n",
      "train loss:0.25524303254722946\n",
      "train loss:0.1914642168332906\n",
      "train loss:0.29711174167287807\n",
      "train loss:0.2365698085909929\n",
      "train loss:0.29048502516693825\n",
      "train loss:0.2768427217177958\n",
      "train loss:0.3533394652825924\n",
      "train loss:0.44413414128662043\n",
      "train loss:0.4801567725635678\n",
      "train loss:0.4183924252497066\n",
      "train loss:0.41173989637887226\n",
      "train loss:0.2703570555979756\n",
      "train loss:0.4209016605479265\n",
      "train loss:0.23134562668611955\n",
      "train loss:0.4340064272307675\n",
      "train loss:0.30769543123983284\n",
      "train loss:0.5431323572767542\n",
      "train loss:0.30919028827366085\n",
      "train loss:0.45624798019601487\n",
      "train loss:0.24513823066703178\n",
      "train loss:0.3822526623162388\n",
      "train loss:0.45312884090185274\n",
      "train loss:0.26646472726873777\n",
      "train loss:0.3226582910144486\n",
      "train loss:0.39688657638422725\n",
      "train loss:0.21141538621686584\n",
      "train loss:0.21004175891912413\n",
      "train loss:0.2250077267315968\n",
      "train loss:0.30967086982782766\n",
      "train loss:0.6003332632575991\n",
      "train loss:0.3841596730158176\n",
      "train loss:0.3239185149910581\n",
      "train loss:0.3249267979878389\n",
      "train loss:0.16170684794403695\n",
      "train loss:0.27661354814548184\n",
      "train loss:0.27516017539583665\n",
      "train loss:0.46200116840843897\n",
      "train loss:0.30866430574609593\n",
      "train loss:0.35678109498578814\n",
      "train loss:0.1870815905334923\n",
      "train loss:0.15581734847201387\n",
      "train loss:0.4820485084466909\n",
      "train loss:0.3228441389343412\n",
      "train loss:0.3135906600806256\n",
      "train loss:0.3364001478257168\n",
      "train loss:0.40835055128387315\n",
      "train loss:0.21054770799792713\n",
      "train loss:0.2567718742317993\n",
      "train loss:0.327505916570723\n",
      "train loss:0.2605964721127591\n",
      "train loss:0.280319021630283\n",
      "train loss:0.35653567551009474\n",
      "train loss:0.2689812607447626\n",
      "train loss:0.3046319368274773\n",
      "train loss:0.30305253019483297\n",
      "train loss:0.17572577374688458\n",
      "train loss:0.15954673152464965\n",
      "train loss:0.31244199581657944\n",
      "train loss:0.3068115933787189\n",
      "train loss:0.2672725544038508\n",
      "train loss:0.23973669179838517\n",
      "train loss:0.21750590403432124\n",
      "train loss:0.3353979991864109\n",
      "train loss:0.23486958643199388\n",
      "train loss:0.5328809433438798\n",
      "train loss:0.2934597747819316\n",
      "train loss:0.14562298905251145\n",
      "train loss:0.382401571787098\n",
      "train loss:0.40112750954904774\n",
      "train loss:0.3219943864158216\n",
      "train loss:0.19541760479791648\n",
      "train loss:0.31679695153258974\n",
      "train loss:0.20485813207010622\n",
      "train loss:0.19276072841466566\n",
      "train loss:0.20148552424578667\n",
      "train loss:0.32999323218177556\n",
      "train loss:0.2904590603246725\n",
      "train loss:0.30002137896801473\n",
      "train loss:0.17644166486478136\n",
      "train loss:0.1945960404849611\n",
      "train loss:0.3263220757100923\n",
      "train loss:0.27949867198642525\n",
      "train loss:0.2617785961566003\n",
      "train loss:0.1395027162912877\n",
      "train loss:0.25470633209206744\n",
      "train loss:0.24417623356559864\n",
      "train loss:0.28919356990150397\n",
      "train loss:0.19657211407466668\n",
      "train loss:0.20001882049997147\n",
      "train loss:0.20076425541290882\n",
      "train loss:0.24574528776957055\n",
      "train loss:0.17833515021059626\n",
      "train loss:0.21611097830993922\n",
      "train loss:0.23127932028442819\n",
      "train loss:0.2710102497136077\n",
      "train loss:0.25382462417709634\n",
      "train loss:0.21651511794789782\n",
      "train loss:0.34897712229195466\n",
      "train loss:0.34642822159708947\n",
      "train loss:0.23338587622233065\n",
      "train loss:0.1438996319640925\n",
      "train loss:0.16843377961531167\n",
      "train loss:0.3351087001329079\n",
      "train loss:0.1645644046613584\n",
      "train loss:0.253899496678569\n",
      "train loss:0.32208826340416385\n",
      "train loss:0.3889249804307881\n",
      "train loss:0.2106960451238983\n",
      "train loss:0.2685997254717446\n",
      "train loss:0.16556310496879964\n",
      "train loss:0.26963090720407584\n",
      "train loss:0.2268811513144788\n",
      "train loss:0.3311325493049835\n",
      "train loss:0.3443707682001202\n",
      "train loss:0.4447435517941461\n",
      "train loss:0.31190959026627857\n",
      "train loss:0.1801795135809763\n",
      "train loss:0.2409734709072136\n",
      "train loss:0.2743631392712478\n",
      "train loss:0.2832172431235444\n",
      "train loss:0.17532348220582214\n",
      "train loss:0.295864533989602\n",
      "train loss:0.18712451388839793\n",
      "train loss:0.29563303449858686\n",
      "train loss:0.18207730771313574\n",
      "train loss:0.18890761981594356\n",
      "train loss:0.2878339179080539\n",
      "train loss:0.2762195707694329\n",
      "train loss:0.22699695280606544\n",
      "train loss:0.1558744423604729\n",
      "train loss:0.15741575031086208\n",
      "train loss:0.4031457978943776\n",
      "train loss:0.15205077275206377\n",
      "train loss:0.20816953754838782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.3759239345513794\n",
      "train loss:0.3664798678631901\n",
      "train loss:0.17574071081803466\n",
      "train loss:0.24765009025340604\n",
      "train loss:0.19786161422978832\n",
      "train loss:0.234584395962185\n",
      "train loss:0.2510778997991901\n",
      "train loss:0.24320862686846723\n",
      "train loss:0.12500635847571412\n",
      "train loss:0.2827995355123948\n",
      "train loss:0.1783331562965529\n",
      "train loss:0.18791253525598428\n",
      "train loss:0.20621236539978763\n",
      "train loss:0.14076282725295353\n",
      "train loss:0.18996402388931152\n",
      "train loss:0.23949381664946479\n",
      "train loss:0.2615297781408988\n",
      "train loss:0.33324917893798905\n",
      "train loss:0.32744194463399084\n",
      "train loss:0.30359603968129695\n",
      "train loss:0.21603106920068002\n",
      "train loss:0.1475436701261329\n",
      "train loss:0.25709081125787897\n",
      "train loss:0.20771589797345003\n",
      "train loss:0.1715763766833806\n",
      "train loss:0.11448521659032705\n",
      "train loss:0.29247926330735174\n",
      "train loss:0.1694271509843652\n",
      "train loss:0.1467054170676211\n",
      "train loss:0.24037577266895\n",
      "train loss:0.20376190373361813\n",
      "train loss:0.20851921528045522\n",
      "train loss:0.2431964365881991\n",
      "train loss:0.18695196025998226\n",
      "train loss:0.3070789903327666\n",
      "train loss:0.16873403523428734\n",
      "train loss:0.1452450932062151\n",
      "train loss:0.2523172545640724\n",
      "train loss:0.16131615336543043\n",
      "train loss:0.2876156992149114\n",
      "train loss:0.26968793652262774\n",
      "train loss:0.17074209418213487\n",
      "train loss:0.2500221376240825\n",
      "train loss:0.23987746574633328\n",
      "train loss:0.27326063082062474\n",
      "train loss:0.24084408433938392\n",
      "train loss:0.1472480335135646\n",
      "train loss:0.16217945022472757\n",
      "train loss:0.21209302904645028\n",
      "train loss:0.15425730176743752\n",
      "train loss:0.22121132624571158\n",
      "train loss:0.23330654000462903\n",
      "train loss:0.13335540970899554\n",
      "train loss:0.2562553721768006\n",
      "train loss:0.1007181704338938\n",
      "train loss:0.35413580630753777\n",
      "train loss:0.31665318344940524\n",
      "train loss:0.1917344705616642\n",
      "train loss:0.20348495186646037\n",
      "train loss:0.3024632664353458\n",
      "train loss:0.17940957492081025\n",
      "train loss:0.26635374675316187\n",
      "train loss:0.3636659937176025\n",
      "train loss:0.2611705480863342\n",
      "train loss:0.1711642503939095\n",
      "train loss:0.18333092878075147\n",
      "train loss:0.17213626765309875\n",
      "train loss:0.21264236066301392\n",
      "train loss:0.17304151044353686\n",
      "train loss:0.22113601886786036\n",
      "train loss:0.1980988509550713\n",
      "train loss:0.16262918567349044\n",
      "train loss:0.14983985807866684\n",
      "train loss:0.17989745690972278\n",
      "train loss:0.15175504156560524\n",
      "train loss:0.09808047007712042\n",
      "train loss:0.19556784529273355\n",
      "train loss:0.27601389270055793\n",
      "train loss:0.09229807275130089\n",
      "train loss:0.150898617529761\n",
      "train loss:0.11236148648021238\n",
      "train loss:0.11027813726686377\n",
      "train loss:0.22416136736212103\n",
      "train loss:0.16206427961708442\n",
      "train loss:0.126350589271445\n",
      "train loss:0.19161029214313172\n",
      "train loss:0.07822651535276105\n",
      "train loss:0.11862379685073941\n",
      "train loss:0.20156730676574391\n",
      "train loss:0.1959260985174337\n",
      "train loss:0.12426155834022026\n",
      "train loss:0.1609266030005675\n",
      "train loss:0.10487377061577924\n",
      "train loss:0.2549854645900494\n",
      "train loss:0.27833022449895306\n",
      "train loss:0.1219755347559656\n",
      "train loss:0.24888762330537734\n",
      "train loss:0.13391601700527983\n",
      "train loss:0.10175743555868898\n",
      "train loss:0.31403011972559136\n",
      "train loss:0.2786411858298876\n",
      "train loss:0.3104730956424219\n",
      "train loss:0.13348366744696982\n",
      "train loss:0.14237453748327383\n",
      "train loss:0.17098034218508495\n",
      "train loss:0.102504187878809\n",
      "train loss:0.17477997963017214\n",
      "train loss:0.12852207815286032\n",
      "train loss:0.20886389263598562\n",
      "train loss:0.15704673510814549\n",
      "train loss:0.12082331681029129\n",
      "train loss:0.1368381759036434\n",
      "train loss:0.1938606368595773\n",
      "train loss:0.14372626279522918\n",
      "train loss:0.1794517840064658\n",
      "train loss:0.20029201488952936\n",
      "train loss:0.21348555435303965\n",
      "train loss:0.19785052965291608\n",
      "train loss:0.22511270788515614\n",
      "train loss:0.23142783969957262\n",
      "train loss:0.22761141142514923\n",
      "train loss:0.12612500796803328\n",
      "train loss:0.1581183726028428\n",
      "train loss:0.13412550957827635\n",
      "train loss:0.16046269511849828\n",
      "train loss:0.11833898489399357\n",
      "train loss:0.13650876659628244\n",
      "train loss:0.21836424501288562\n",
      "train loss:0.17165534997253196\n",
      "train loss:0.21587919140938797\n",
      "train loss:0.14483852237483688\n",
      "train loss:0.1303888699064985\n",
      "train loss:0.15906759859990427\n",
      "train loss:0.1393213482901029\n",
      "train loss:0.131303078628074\n",
      "train loss:0.14983342230622287\n",
      "train loss:0.12438401052747192\n",
      "train loss:0.11200509747422725\n",
      "train loss:0.1892179873366193\n",
      "train loss:0.15247965893148008\n",
      "train loss:0.0680468905213133\n",
      "train loss:0.19931352855529125\n",
      "train loss:0.19152224871317727\n",
      "train loss:0.10867704291933986\n",
      "train loss:0.16917407535476559\n",
      "train loss:0.17799720968861388\n",
      "train loss:0.1442624982208276\n",
      "train loss:0.11651163444182065\n",
      "train loss:0.18251724116472445\n",
      "train loss:0.13849704952908184\n",
      "train loss:0.1372195190407969\n",
      "train loss:0.11862206152553158\n",
      "train loss:0.1221711106216365\n",
      "train loss:0.12777890015570711\n",
      "train loss:0.1406582663547581\n",
      "train loss:0.13173524243318852\n",
      "train loss:0.14440302256177018\n",
      "train loss:0.16877300135156187\n",
      "train loss:0.07978259096410772\n",
      "train loss:0.10114499523536372\n",
      "train loss:0.26278515866590657\n",
      "train loss:0.1848199331455487\n",
      "train loss:0.11082196821398643\n",
      "train loss:0.11035539466861687\n",
      "train loss:0.22545631759935708\n",
      "train loss:0.2276330623058772\n",
      "train loss:0.1941923010219334\n",
      "train loss:0.2351217082107109\n",
      "train loss:0.16259928015507336\n",
      "train loss:0.1972447903675608\n",
      "train loss:0.13213467897921968\n",
      "train loss:0.17392174719767917\n",
      "train loss:0.19465304166284167\n",
      "train loss:0.1145794647606745\n",
      "train loss:0.19927017096140218\n",
      "train loss:0.18999937490377028\n",
      "train loss:0.09847690636602813\n",
      "train loss:0.20721549324703264\n",
      "train loss:0.1854643428154499\n",
      "train loss:0.17115929117976478\n",
      "train loss:0.18251604292102716\n",
      "train loss:0.10865592631182029\n",
      "train loss:0.15611402289312148\n",
      "train loss:0.16022132031284703\n",
      "train loss:0.1630076658335097\n",
      "train loss:0.17890502991006196\n",
      "train loss:0.11806709255520723\n",
      "train loss:0.05043586464739925\n",
      "train loss:0.08828589525248756\n",
      "train loss:0.09944008117786225\n",
      "train loss:0.10075760039056285\n",
      "train loss:0.10495085196080238\n",
      "train loss:0.15160037063078602\n",
      "train loss:0.12222863327116537\n",
      "train loss:0.2867049104919883\n",
      "train loss:0.10315068097805684\n",
      "train loss:0.16723364776277339\n",
      "train loss:0.20649162465106424\n",
      "train loss:0.10519300748759335\n",
      "train loss:0.11463461714427015\n",
      "train loss:0.3133362628711805\n",
      "train loss:0.19469055270823232\n",
      "train loss:0.13758475793867758\n",
      "train loss:0.18515244636004577\n",
      "train loss:0.12482857776668028\n",
      "train loss:0.1534106153594934\n",
      "train loss:0.1411521342416963\n",
      "train loss:0.21279666983311477\n",
      "train loss:0.20865182719488795\n",
      "train loss:0.13417910472862643\n",
      "train loss:0.11685406725649466\n",
      "train loss:0.1455403173045829\n",
      "train loss:0.1186085360597369\n",
      "train loss:0.27270000228211017\n",
      "train loss:0.1392357233315054\n",
      "train loss:0.13495756900207337\n",
      "train loss:0.15891049530156426\n",
      "train loss:0.1141896455590264\n",
      "train loss:0.19513295539394868\n",
      "train loss:0.170221361496051\n",
      "train loss:0.127370191207105\n",
      "train loss:0.09288100123184297\n",
      "train loss:0.1920400562196994\n",
      "train loss:0.09432566200423238\n",
      "train loss:0.13964290025650342\n",
      "train loss:0.16443611105798742\n",
      "train loss:0.18035032743285048\n",
      "train loss:0.2513841818405164\n",
      "train loss:0.1559581772405632\n",
      "train loss:0.19825210460437975\n",
      "train loss:0.1934281704518103\n",
      "train loss:0.06615619238253301\n",
      "train loss:0.12884934733459302\n",
      "train loss:0.2244139170549971\n",
      "train loss:0.11714629826723423\n",
      "train loss:0.11344097560138483\n",
      "train loss:0.21890907141153906\n",
      "train loss:0.1402352879220753\n",
      "train loss:0.18486406617039752\n",
      "train loss:0.09325719918552884\n",
      "train loss:0.15271541547600717\n",
      "train loss:0.12702596608060288\n",
      "train loss:0.0970489881168784\n",
      "train loss:0.19017765358970196\n",
      "train loss:0.1384435104095692\n",
      "train loss:0.11159427988464672\n",
      "train loss:0.245595197753985\n",
      "train loss:0.13174397923246858\n",
      "train loss:0.1369844164409151\n",
      "train loss:0.05386012269157106\n",
      "train loss:0.12534657421539813\n",
      "train loss:0.14156003663160946\n",
      "train loss:0.1311533988893124\n",
      "train loss:0.13549660967723529\n",
      "train loss:0.08882750490836015\n",
      "train loss:0.13522172145527378\n",
      "train loss:0.22815665200062604\n",
      "train loss:0.1895354835271115\n",
      "train loss:0.19398525314180518\n",
      "train loss:0.13765608807007668\n",
      "train loss:0.13703733022503106\n",
      "train loss:0.0731898324302327\n",
      "train loss:0.1598828275883675\n",
      "train loss:0.15551329570340844\n",
      "train loss:0.1307273984462629\n",
      "train loss:0.14829791942380627\n",
      "train loss:0.14697641067638115\n",
      "train loss:0.11593425430286367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.12068572999006116\n",
      "train loss:0.12461626907121082\n",
      "train loss:0.15577178797053753\n",
      "train loss:0.11282181240590333\n",
      "train loss:0.107173637167072\n",
      "train loss:0.2563463006646311\n",
      "train loss:0.10399285280630118\n",
      "train loss:0.09966783110324401\n",
      "train loss:0.1465374241922505\n",
      "train loss:0.1293000782078129\n",
      "train loss:0.24665917862883333\n",
      "train loss:0.16873628297425572\n",
      "train loss:0.11340079713118549\n",
      "train loss:0.20713717820034042\n",
      "train loss:0.11193655803813235\n",
      "train loss:0.1142089710913089\n",
      "train loss:0.14040379862010957\n",
      "train loss:0.0982805766418849\n",
      "train loss:0.08807782402116915\n",
      "train loss:0.2108002953338589\n",
      "train loss:0.14541851796358224\n",
      "train loss:0.13910908241012043\n",
      "train loss:0.16922073437700985\n",
      "train loss:0.03470848466694633\n",
      "train loss:0.36124483447395334\n",
      "train loss:0.10980299512314907\n",
      "train loss:0.2134010014468814\n",
      "train loss:0.08156861538579786\n",
      "train loss:0.17330220107331215\n",
      "train loss:0.09667140999020471\n",
      "train loss:0.17603290672073058\n",
      "train loss:0.08645308258877972\n",
      "train loss:0.16985025608228654\n",
      "train loss:0.0670786607776156\n",
      "train loss:0.16725257181276654\n",
      "train loss:0.10067317542372418\n",
      "train loss:0.03963793159438886\n",
      "train loss:0.050173570719826976\n",
      "train loss:0.2091527346463188\n",
      "train loss:0.07998487695989744\n",
      "train loss:0.11812978884085586\n",
      "train loss:0.10102639334032731\n",
      "train loss:0.09147283529964238\n",
      "train loss:0.23915400174248916\n",
      "train loss:0.12400248865963732\n",
      "train loss:0.1329307359052537\n",
      "train loss:0.12900309327257214\n",
      "train loss:0.13861662094890317\n",
      "train loss:0.10053524406724139\n",
      "train loss:0.060979043446640714\n",
      "train loss:0.055839947469054796\n",
      "train loss:0.18248707670422282\n",
      "train loss:0.13290923805416402\n",
      "train loss:0.1337244993106329\n",
      "train loss:0.08445523366827425\n",
      "train loss:0.14698180686574222\n",
      "train loss:0.13667889171918524\n",
      "train loss:0.21285727776897553\n",
      "train loss:0.31128111961551985\n",
      "train loss:0.07030386179173961\n",
      "train loss:0.058478470510330845\n",
      "train loss:0.08667086221266881\n",
      "train loss:0.15765187271865594\n",
      "=== epoch:2, train acc:0.965, test acc:0.964 ===\n",
      "train loss:0.17883280274703003\n",
      "train loss:0.16669160341559786\n",
      "train loss:0.19488389327811337\n",
      "train loss:0.2017549581662755\n",
      "train loss:0.15116862146369542\n",
      "train loss:0.08951103069274806\n",
      "train loss:0.07821860655665212\n",
      "train loss:0.16144659183919519\n",
      "train loss:0.07200358607477968\n",
      "train loss:0.10414181707002067\n",
      "train loss:0.1450723651932566\n",
      "train loss:0.13967248420019454\n",
      "train loss:0.06676496686046074\n",
      "train loss:0.14498656738007581\n",
      "train loss:0.17150891650648087\n",
      "train loss:0.20229491557976315\n",
      "train loss:0.13591178109552654\n",
      "train loss:0.05951761746187009\n",
      "train loss:0.05813338755223514\n",
      "train loss:0.05940926589800755\n",
      "train loss:0.12134522160077432\n",
      "train loss:0.12181155488019872\n",
      "train loss:0.1753925552531984\n",
      "train loss:0.1544804939602584\n",
      "train loss:0.06453049381791387\n",
      "train loss:0.12361163934751414\n",
      "train loss:0.04889865088029491\n",
      "train loss:0.08839998876690888\n",
      "train loss:0.14763965891894595\n",
      "train loss:0.16587233300634988\n",
      "train loss:0.09575024427363311\n",
      "train loss:0.15955959636633257\n",
      "train loss:0.0964286705850344\n",
      "train loss:0.10382775373627724\n",
      "train loss:0.059284249821406974\n",
      "train loss:0.0762001301792679\n",
      "train loss:0.05159922789868193\n",
      "train loss:0.09785975867088088\n",
      "train loss:0.05096110150646291\n",
      "train loss:0.11385143789547553\n",
      "train loss:0.06580297728507764\n",
      "train loss:0.07851122307136177\n",
      "train loss:0.0775565112625369\n",
      "train loss:0.06483608846429069\n",
      "train loss:0.05567827718029035\n",
      "train loss:0.10958175795640468\n",
      "train loss:0.24655741622660204\n",
      "train loss:0.0532786376979207\n",
      "train loss:0.06369098947684185\n",
      "train loss:0.0914791182423428\n",
      "train loss:0.11332457674762868\n",
      "train loss:0.2442381616601638\n",
      "train loss:0.1617392697971224\n",
      "train loss:0.16203853859289544\n",
      "train loss:0.05371658822482316\n",
      "train loss:0.08826706322776876\n",
      "train loss:0.10903036571215843\n",
      "train loss:0.09573111797069615\n",
      "train loss:0.06235490660599761\n",
      "train loss:0.06698498944146404\n",
      "train loss:0.09180615516364973\n",
      "train loss:0.20667062495097976\n",
      "train loss:0.1418680981401022\n",
      "train loss:0.1733019825154578\n",
      "train loss:0.2437551726754837\n",
      "train loss:0.03126807135868962\n",
      "train loss:0.092718740696534\n",
      "train loss:0.07394674693344785\n",
      "train loss:0.1059573854838406\n",
      "train loss:0.07986801106879562\n",
      "train loss:0.09461113279132308\n",
      "train loss:0.059160303489308286\n",
      "train loss:0.08511920316352127\n",
      "train loss:0.06320202730941682\n",
      "train loss:0.19360652380209967\n",
      "train loss:0.0643275362972844\n",
      "train loss:0.15042883308281307\n",
      "train loss:0.11693556770062274\n",
      "train loss:0.06593555945660884\n",
      "train loss:0.11436696504558583\n",
      "train loss:0.2189552735464342\n",
      "train loss:0.06975997171827032\n",
      "train loss:0.11369990303161921\n",
      "train loss:0.13746878838154952\n",
      "train loss:0.1453093737989467\n",
      "train loss:0.14853527418746537\n",
      "train loss:0.12998351374670972\n",
      "train loss:0.058933725209208344\n",
      "train loss:0.04179908757009088\n",
      "train loss:0.11258960010203842\n",
      "train loss:0.04119935364479156\n",
      "train loss:0.14157100058530322\n",
      "train loss:0.07547158145016811\n",
      "train loss:0.09503840693344934\n",
      "train loss:0.07132997252617457\n",
      "train loss:0.09452715213409583\n",
      "train loss:0.06809427622561123\n",
      "train loss:0.1069673663270388\n",
      "train loss:0.04659087039889353\n",
      "train loss:0.03651675277392317\n",
      "train loss:0.10447530841669718\n",
      "train loss:0.036326148492958205\n",
      "train loss:0.08862797379194555\n",
      "train loss:0.10724991743918835\n",
      "train loss:0.09780260033867377\n",
      "train loss:0.06625563359089223\n",
      "train loss:0.15045456005354718\n",
      "train loss:0.16151957763041402\n",
      "train loss:0.03162481801121281\n",
      "train loss:0.1757555582145616\n",
      "train loss:0.06115669881199483\n",
      "train loss:0.13763388893995587\n",
      "train loss:0.10998711085631449\n",
      "train loss:0.11169058097178722\n",
      "train loss:0.06987153374227166\n",
      "train loss:0.06156385800058283\n",
      "train loss:0.07038707447302076\n",
      "train loss:0.14507631113793312\n",
      "train loss:0.11554074653601026\n",
      "train loss:0.14658243046494066\n",
      "train loss:0.12122440851452092\n",
      "train loss:0.0392897252579485\n",
      "train loss:0.07748996702367675\n",
      "train loss:0.06733555537136947\n",
      "train loss:0.148676598485359\n",
      "train loss:0.1608014415549476\n",
      "train loss:0.06588767191076952\n",
      "train loss:0.19769256938320612\n",
      "train loss:0.07159307001724527\n",
      "train loss:0.08325633360081452\n",
      "train loss:0.06057960509211797\n",
      "train loss:0.0759424748179288\n",
      "train loss:0.02649901379647351\n",
      "train loss:0.14833164898672258\n",
      "train loss:0.12422874040543434\n",
      "train loss:0.11511732688732927\n",
      "train loss:0.15981942008176872\n",
      "train loss:0.10036062596263896\n",
      "train loss:0.0586723907526747\n",
      "train loss:0.055648115527572505\n",
      "train loss:0.05235627414732287\n",
      "train loss:0.12158410943604389\n",
      "train loss:0.2036505559883708\n",
      "train loss:0.16020230712919062\n",
      "train loss:0.02860604423116136\n",
      "train loss:0.054505561208337244\n",
      "train loss:0.055708213583718746\n",
      "train loss:0.08662388164085597\n",
      "train loss:0.051195503637957746\n",
      "train loss:0.04336469023800813\n",
      "train loss:0.0843244807254599\n",
      "train loss:0.051646497170687936\n",
      "train loss:0.08024182432695458\n",
      "train loss:0.1103157520715187\n",
      "train loss:0.1347893941748106\n",
      "train loss:0.11186330445838893\n",
      "train loss:0.1534821810143065\n",
      "train loss:0.037164342849673605\n",
      "train loss:0.08242269267040603\n",
      "train loss:0.13119337993060898\n",
      "train loss:0.11722579146429632\n",
      "train loss:0.05215169208785185\n",
      "train loss:0.0877096988845639\n",
      "train loss:0.13303295519000533\n",
      "train loss:0.07677354473486038\n",
      "train loss:0.04929692102141775\n",
      "train loss:0.13618582222643522\n",
      "train loss:0.04865499336951173\n",
      "train loss:0.08266374917578165\n",
      "train loss:0.06425134285702788\n",
      "train loss:0.17507655934383254\n",
      "train loss:0.07665484144511966\n",
      "train loss:0.08943187237358213\n",
      "train loss:0.09747099166180818\n",
      "train loss:0.07914803322450382\n",
      "train loss:0.14109373300363662\n",
      "train loss:0.08604460559187181\n",
      "train loss:0.06186682093628417\n",
      "train loss:0.06348297689347106\n",
      "train loss:0.06088750379371078\n",
      "train loss:0.1469664191552028\n",
      "train loss:0.05990476582341778\n",
      "train loss:0.09310438577488461\n",
      "train loss:0.11151723688796913\n",
      "train loss:0.19193502133998194\n",
      "train loss:0.12845852535144478\n",
      "train loss:0.08321762516060155\n",
      "train loss:0.16382189678969492\n",
      "train loss:0.12454631085639441\n",
      "train loss:0.07682363592880898\n",
      "train loss:0.08225391710902605\n",
      "train loss:0.06169261904173947\n",
      "train loss:0.06338228797293764\n",
      "train loss:0.08020441408417486\n",
      "train loss:0.061956035664874134\n",
      "train loss:0.07716218484142855\n",
      "train loss:0.10648118417526979\n",
      "train loss:0.12891971547983283\n",
      "train loss:0.034140077089253866\n",
      "train loss:0.1488308138139623\n",
      "train loss:0.15183900893488572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.03332790685715985\n",
      "train loss:0.10244093882222378\n",
      "train loss:0.13529231570608902\n",
      "train loss:0.07102297116967395\n",
      "train loss:0.13717324679269224\n",
      "train loss:0.050943921515316994\n",
      "train loss:0.04785229887630794\n",
      "train loss:0.05093497318419157\n",
      "train loss:0.13038065363104562\n",
      "train loss:0.08384567497725973\n",
      "train loss:0.1444964187846838\n",
      "train loss:0.03355133265478239\n",
      "train loss:0.12090252921429856\n",
      "train loss:0.12336538002734466\n",
      "train loss:0.03181654904819641\n",
      "train loss:0.0539787373973727\n",
      "train loss:0.1657598414076419\n",
      "train loss:0.1537930206657256\n",
      "train loss:0.05065664793886333\n",
      "train loss:0.08357261675094022\n",
      "train loss:0.036198701461690484\n",
      "train loss:0.029658265859351877\n",
      "train loss:0.10096449983342895\n",
      "train loss:0.07700834634580507\n",
      "train loss:0.10063920943821347\n",
      "train loss:0.061668167955416714\n",
      "train loss:0.04951581802049453\n",
      "train loss:0.12253014411671082\n",
      "train loss:0.03162687364954492\n",
      "train loss:0.13398927487745285\n",
      "train loss:0.07644219027161765\n",
      "train loss:0.059954869675233634\n",
      "train loss:0.10687589292081531\n",
      "train loss:0.09625914309322539\n",
      "train loss:0.20236931440755504\n",
      "train loss:0.09875420453999725\n",
      "train loss:0.04485519379912378\n",
      "train loss:0.06627473531450165\n",
      "train loss:0.020475525500797124\n",
      "train loss:0.13419903135097994\n",
      "train loss:0.039394608363240005\n",
      "train loss:0.07711416113989038\n",
      "train loss:0.047958061252788974\n",
      "train loss:0.05375561148795072\n",
      "train loss:0.054019350086104055\n",
      "train loss:0.12735100700665727\n",
      "train loss:0.09675572730453191\n",
      "train loss:0.03132220836367056\n",
      "train loss:0.07781071604607585\n",
      "train loss:0.05605136037329042\n",
      "train loss:0.06457130056438237\n",
      "train loss:0.13416927754869074\n",
      "train loss:0.06424087939018629\n",
      "train loss:0.08378998357253603\n",
      "train loss:0.08510452376410395\n",
      "train loss:0.09359602450828819\n",
      "train loss:0.12487852440859033\n",
      "train loss:0.0765901235366397\n",
      "train loss:0.040049074106391594\n",
      "train loss:0.062018584638711294\n",
      "train loss:0.0928773060875549\n",
      "train loss:0.03400605103187179\n",
      "train loss:0.06631340338043185\n",
      "train loss:0.18133427025143284\n",
      "train loss:0.07970119104124714\n",
      "train loss:0.03594929192526161\n",
      "train loss:0.10111860411061889\n",
      "train loss:0.06619466917955721\n",
      "train loss:0.06481486096713517\n",
      "train loss:0.04196565943111751\n",
      "train loss:0.10864386656402125\n",
      "train loss:0.0857767659641214\n",
      "train loss:0.05061317160147513\n",
      "train loss:0.07500238642813323\n",
      "train loss:0.06372504804784596\n",
      "train loss:0.08182071374599893\n",
      "train loss:0.052024120804448584\n",
      "train loss:0.05870921534009703\n",
      "train loss:0.04719844897132169\n",
      "train loss:0.08534807404468106\n",
      "train loss:0.1284538501616045\n",
      "train loss:0.06876690975030264\n",
      "train loss:0.06457178031830177\n",
      "train loss:0.08821582530603278\n",
      "train loss:0.09106367400957119\n",
      "train loss:0.13820622887879477\n",
      "train loss:0.16017127351470525\n",
      "train loss:0.04279534455337716\n",
      "train loss:0.1484824740455962\n",
      "train loss:0.07247331861856803\n",
      "train loss:0.09875718550590572\n",
      "train loss:0.04295864868549316\n",
      "train loss:0.04760899811524026\n",
      "train loss:0.08086780335275184\n",
      "train loss:0.06681797618641201\n",
      "train loss:0.03253095342604157\n",
      "train loss:0.08995923455200198\n",
      "train loss:0.0721383213005034\n",
      "train loss:0.12722111535499667\n",
      "train loss:0.04167825877050204\n",
      "train loss:0.03510475568072677\n",
      "train loss:0.06557484753374088\n",
      "train loss:0.03668014618696076\n",
      "train loss:0.021449680349879444\n",
      "train loss:0.07964367554482162\n",
      "train loss:0.06486413862778283\n",
      "train loss:0.02315335294501583\n",
      "train loss:0.05226306372186105\n",
      "train loss:0.01881314827884494\n",
      "train loss:0.08470824183097292\n",
      "train loss:0.06146345428590065\n",
      "train loss:0.11405525058844981\n",
      "train loss:0.07785640910810558\n",
      "train loss:0.11987056261621358\n",
      "train loss:0.0398936455250585\n",
      "train loss:0.07259188353776543\n",
      "train loss:0.05866554523465685\n",
      "train loss:0.08487268030128352\n",
      "train loss:0.03707863445393092\n",
      "train loss:0.052256606172829526\n",
      "train loss:0.018232863985872257\n",
      "train loss:0.03709377299494149\n",
      "train loss:0.06492701649437542\n",
      "train loss:0.15511178751479662\n",
      "train loss:0.03663277633879636\n",
      "train loss:0.10195846791778067\n",
      "train loss:0.04743876013208134\n",
      "train loss:0.07073778028190668\n",
      "train loss:0.06541729417668224\n",
      "train loss:0.07868099647085253\n",
      "train loss:0.05978148704272148\n",
      "train loss:0.12214422743798485\n",
      "train loss:0.04842626650276337\n",
      "train loss:0.07264595928118436\n",
      "train loss:0.05114932985317145\n",
      "train loss:0.06618395900632384\n",
      "train loss:0.13495943291185378\n",
      "train loss:0.07064984207754695\n",
      "train loss:0.10821010040429625\n",
      "train loss:0.12518575674344767\n",
      "train loss:0.05175516893778485\n",
      "train loss:0.0510913626281274\n",
      "train loss:0.048467797356149894\n",
      "train loss:0.06589619314736059\n",
      "train loss:0.08751438421526697\n",
      "train loss:0.05997077723894726\n",
      "train loss:0.07534345739122228\n",
      "train loss:0.10163921433737284\n",
      "train loss:0.0733919884629506\n",
      "train loss:0.1464696060366177\n",
      "train loss:0.10252579004167206\n",
      "train loss:0.06524570644354871\n",
      "train loss:0.042917173142290696\n",
      "train loss:0.05237370130667401\n",
      "train loss:0.03405561980366866\n",
      "train loss:0.054945854377937205\n",
      "train loss:0.218150928352903\n",
      "train loss:0.05034753436350857\n",
      "train loss:0.09580570866108706\n",
      "train loss:0.06755058442097464\n",
      "train loss:0.04637571118331303\n",
      "train loss:0.17001788429493161\n",
      "train loss:0.04601179561810137\n",
      "train loss:0.038459032642511395\n",
      "train loss:0.05442359369839867\n",
      "train loss:0.09992160040405564\n",
      "train loss:0.09343387851247158\n",
      "train loss:0.026879087871884966\n",
      "train loss:0.13041302904087415\n",
      "train loss:0.10181715580483967\n",
      "train loss:0.037987264797280935\n",
      "train loss:0.05457438212027066\n",
      "train loss:0.17434852806467951\n",
      "train loss:0.05630458702249305\n",
      "train loss:0.04927693658944271\n",
      "train loss:0.08833569189587942\n",
      "train loss:0.09237967980761684\n",
      "train loss:0.1386214534388416\n",
      "train loss:0.07737734063864009\n",
      "train loss:0.12180849863566945\n",
      "train loss:0.12628786224838862\n",
      "train loss:0.10051682629576639\n",
      "train loss:0.059735068140799014\n",
      "train loss:0.053774559246613104\n",
      "train loss:0.05965668093079049\n",
      "train loss:0.07268439602573058\n",
      "train loss:0.046780703292259106\n",
      "train loss:0.03477777200320598\n",
      "train loss:0.057898793010798595\n",
      "train loss:0.05884252776911251\n",
      "train loss:0.07569784160735234\n",
      "train loss:0.11217726967240103\n",
      "train loss:0.10090279842876917\n",
      "train loss:0.045041986980483145\n",
      "train loss:0.03143609379391528\n",
      "train loss:0.019150207106446784\n",
      "train loss:0.07575966306865994\n",
      "train loss:0.09202583694901564\n",
      "train loss:0.05152020725078154\n",
      "train loss:0.1080020929248347\n",
      "train loss:0.02939544333006177\n",
      "train loss:0.044170605196979566\n",
      "train loss:0.05025181380980335\n",
      "train loss:0.03328129956052472\n",
      "train loss:0.023311328880759163\n",
      "train loss:0.03396027448367371\n",
      "train loss:0.12739693657950504\n",
      "train loss:0.03435606007226475\n",
      "train loss:0.16816177502953203\n",
      "train loss:0.09131255464232815\n",
      "train loss:0.06881155768738002\n",
      "train loss:0.07227632804503724\n",
      "train loss:0.04597167260563467\n",
      "train loss:0.12638468747198733\n",
      "train loss:0.03945483982343496\n",
      "train loss:0.08777038488790226\n",
      "train loss:0.02179575179877162\n",
      "train loss:0.07024906635804767\n",
      "train loss:0.054334163447166156\n",
      "train loss:0.09600032025720852\n",
      "train loss:0.06438621240815916\n",
      "train loss:0.061487541718136675\n",
      "train loss:0.2088624229004936\n",
      "train loss:0.10196173119692883\n",
      "train loss:0.08208854127950428\n",
      "train loss:0.060426738499036584\n",
      "train loss:0.027120906384437725\n",
      "train loss:0.05520941426153374\n",
      "train loss:0.06107129378067294\n",
      "train loss:0.03206104922172952\n",
      "train loss:0.08085762194801316\n",
      "train loss:0.0610449105680533\n",
      "train loss:0.02521497287409462\n",
      "train loss:0.11178486758750175\n",
      "train loss:0.03675866396661805\n",
      "train loss:0.0397844979430786\n",
      "train loss:0.03936575639119423\n",
      "train loss:0.0417475344515782\n",
      "train loss:0.0689092684097134\n",
      "train loss:0.12207273341388587\n",
      "train loss:0.03410464285809616\n",
      "train loss:0.08793125160032123\n",
      "train loss:0.12040941330335013\n",
      "train loss:0.07036042328961384\n",
      "train loss:0.0662095192545401\n",
      "train loss:0.09952624796780418\n",
      "train loss:0.04491579574200397\n",
      "train loss:0.0503443448964018\n",
      "train loss:0.050827300256690286\n",
      "train loss:0.08972801733250431\n",
      "train loss:0.03357308736213404\n",
      "train loss:0.03082029873261967\n",
      "train loss:0.10160676423448542\n",
      "train loss:0.08491853177946262\n",
      "train loss:0.07958532609456415\n",
      "train loss:0.017987000485544757\n",
      "train loss:0.23647459718256134\n",
      "train loss:0.07464753340618603\n",
      "train loss:0.07265186671523863\n",
      "train loss:0.05376674049847319\n",
      "train loss:0.08652712707743516\n",
      "train loss:0.03613570600965121\n",
      "train loss:0.05590630415979986\n",
      "train loss:0.025204295522369927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.06188470745016866\n",
      "train loss:0.0533663382427614\n",
      "train loss:0.09382335156222915\n",
      "train loss:0.15541839638207383\n",
      "train loss:0.023862339405459884\n",
      "train loss:0.09591367289407657\n",
      "train loss:0.04130341327543228\n",
      "train loss:0.022424045556730606\n",
      "train loss:0.05044029042680474\n",
      "train loss:0.0972777610223419\n",
      "train loss:0.049017283351674525\n",
      "train loss:0.07325867673990842\n",
      "train loss:0.05137516622684487\n",
      "train loss:0.08675405086600259\n",
      "train loss:0.03859989280095029\n",
      "train loss:0.05517874119831522\n",
      "train loss:0.05973801115298068\n",
      "train loss:0.053056054860027665\n",
      "train loss:0.0976233292217156\n",
      "train loss:0.048647890615092455\n",
      "train loss:0.06824955944785494\n",
      "train loss:0.08293132240332729\n",
      "train loss:0.05054132316418368\n",
      "train loss:0.07238000458107996\n",
      "train loss:0.03844919128064013\n",
      "train loss:0.11073137737868566\n",
      "train loss:0.07682590073031755\n",
      "train loss:0.04451001572934788\n",
      "train loss:0.02117707446021179\n",
      "train loss:0.010903206725169283\n",
      "train loss:0.06823653772636354\n",
      "train loss:0.04540179582104965\n",
      "train loss:0.022528547397481467\n",
      "train loss:0.03457794773232497\n",
      "train loss:0.021971517539816562\n",
      "train loss:0.15678315816542882\n",
      "train loss:0.126202397976272\n",
      "train loss:0.13301199028254407\n",
      "train loss:0.06810780349862236\n",
      "train loss:0.20443845046618123\n",
      "train loss:0.10879741951919053\n",
      "train loss:0.03858896627666481\n",
      "train loss:0.039537750376350295\n",
      "train loss:0.02986444366013239\n",
      "train loss:0.048905357859348506\n",
      "train loss:0.026694544354400603\n",
      "train loss:0.05832002543160142\n",
      "train loss:0.02527796902524936\n",
      "train loss:0.1099788212535181\n",
      "train loss:0.13434394619007192\n",
      "train loss:0.06702011480455097\n",
      "train loss:0.04705109801949452\n",
      "train loss:0.05860926426082558\n",
      "train loss:0.07996155132277777\n",
      "train loss:0.08156401425782406\n",
      "train loss:0.06497908933478237\n",
      "train loss:0.04468458272738837\n",
      "train loss:0.11758181361361722\n",
      "train loss:0.11319912886213018\n",
      "train loss:0.013741542343590889\n",
      "train loss:0.03413486190423528\n",
      "train loss:0.10910956456099169\n",
      "train loss:0.03529108134812342\n",
      "train loss:0.05054287075984977\n",
      "train loss:0.03289407489493606\n",
      "train loss:0.04412987646097163\n",
      "train loss:0.11336105038234123\n",
      "train loss:0.012830292971988656\n",
      "train loss:0.06186563669605012\n",
      "train loss:0.08069932493062094\n",
      "train loss:0.08328286010575033\n",
      "train loss:0.11150884952040055\n",
      "train loss:0.07822848337835278\n",
      "train loss:0.06335313458024082\n",
      "train loss:0.10462548772166269\n",
      "train loss:0.030042040343155163\n",
      "train loss:0.05504998468789239\n",
      "train loss:0.037153362397941134\n",
      "train loss:0.036520911451388284\n",
      "train loss:0.032976252681219065\n",
      "train loss:0.08704391184092275\n",
      "train loss:0.032554867931668646\n",
      "train loss:0.08229392663082216\n",
      "train loss:0.056985148392360185\n",
      "train loss:0.06340806259301014\n",
      "train loss:0.08727044609749321\n",
      "train loss:0.15125330817638194\n",
      "train loss:0.07886708248007576\n",
      "train loss:0.033846215847761554\n",
      "train loss:0.05248483934633084\n",
      "train loss:0.04908041016053251\n",
      "train loss:0.035040701144125795\n",
      "train loss:0.023739695228121006\n",
      "train loss:0.038982967440630234\n",
      "train loss:0.04152137915492226\n",
      "train loss:0.0297631221446504\n",
      "train loss:0.039434472852679904\n",
      "train loss:0.03751995430817928\n",
      "train loss:0.0704083377255373\n",
      "train loss:0.07216483747066155\n",
      "train loss:0.07410792359268514\n",
      "train loss:0.030707571944578942\n",
      "train loss:0.040952546107231945\n",
      "train loss:0.022954402598638714\n",
      "train loss:0.12066298464538713\n",
      "train loss:0.04054874778461022\n",
      "train loss:0.04537873834098236\n",
      "train loss:0.04129070678372912\n",
      "train loss:0.0466412686905712\n",
      "train loss:0.037040425289684056\n",
      "train loss:0.05822916525282928\n",
      "train loss:0.07286772334037238\n",
      "train loss:0.02305825841201801\n",
      "train loss:0.058558719358763216\n",
      "train loss:0.030465080819540146\n",
      "train loss:0.048696370326048205\n",
      "train loss:0.037730508249143584\n",
      "train loss:0.041295673990177785\n",
      "train loss:0.12034382981448843\n",
      "train loss:0.058724509614718805\n",
      "train loss:0.019458277995938147\n",
      "train loss:0.13036731743185956\n",
      "train loss:0.030058020890913716\n",
      "train loss:0.07457222816494259\n",
      "train loss:0.03346333680736625\n",
      "train loss:0.10640353143776445\n",
      "train loss:0.11118153979761793\n",
      "train loss:0.04504195203048214\n",
      "train loss:0.08473218515589431\n",
      "train loss:0.03497386305599547\n",
      "train loss:0.03023191727999235\n",
      "train loss:0.04532956941659017\n",
      "train loss:0.042505279721022804\n",
      "train loss:0.09806935446413995\n",
      "train loss:0.0442314627136199\n",
      "=== epoch:3, train acc:0.977, test acc:0.978 ===\n",
      "train loss:0.06768316981729579\n",
      "train loss:0.02998865364850743\n",
      "train loss:0.061067490385114685\n",
      "train loss:0.06126594792711115\n",
      "train loss:0.07509578584406619\n",
      "train loss:0.015523186313400137\n",
      "train loss:0.08541064009131291\n",
      "train loss:0.055505122594740997\n",
      "train loss:0.06482645637614173\n",
      "train loss:0.04959495776950606\n",
      "train loss:0.11756928687259931\n",
      "train loss:0.034839440764897235\n",
      "train loss:0.017696604431841446\n",
      "train loss:0.10304309750073898\n",
      "train loss:0.06796053815550746\n",
      "train loss:0.07470683993383918\n",
      "train loss:0.10967463065564936\n",
      "train loss:0.09062682825888378\n",
      "train loss:0.022339351044577876\n",
      "train loss:0.05952033627291204\n",
      "train loss:0.03219567453307518\n",
      "train loss:0.07382421003831803\n",
      "train loss:0.056920387225748215\n",
      "train loss:0.10857246175293099\n",
      "train loss:0.06424133288871196\n",
      "train loss:0.06829351177463085\n",
      "train loss:0.03222254484314201\n",
      "train loss:0.06782085683889133\n",
      "train loss:0.10573418117218765\n",
      "train loss:0.03739331542091732\n",
      "train loss:0.024434174672396117\n",
      "train loss:0.05175489436374359\n",
      "train loss:0.1563171341983617\n",
      "train loss:0.09460730196205747\n",
      "train loss:0.1041589263297861\n",
      "train loss:0.1396292877947287\n",
      "train loss:0.045090649325721\n",
      "train loss:0.05867720641040115\n",
      "train loss:0.04690878128828685\n",
      "train loss:0.03754812289168781\n",
      "train loss:0.11945151216852354\n",
      "train loss:0.015272586797782397\n",
      "train loss:0.05544622135286653\n",
      "train loss:0.06987081857709486\n",
      "train loss:0.029780403159478244\n",
      "train loss:0.043617783599860516\n",
      "train loss:0.04997921044371595\n",
      "train loss:0.014603462627906261\n",
      "train loss:0.12134444687581304\n",
      "train loss:0.1215870695515788\n",
      "train loss:0.04540180918467382\n",
      "train loss:0.14718059912138837\n",
      "train loss:0.06991356098243572\n",
      "train loss:0.014621982945416062\n",
      "train loss:0.04618849848051952\n",
      "train loss:0.07771767316286528\n",
      "train loss:0.0850324818002123\n",
      "train loss:0.07192890539778098\n",
      "train loss:0.09007534513139183\n",
      "train loss:0.14068619573487062\n",
      "train loss:0.032062338888542215\n",
      "train loss:0.05235783279974613\n",
      "train loss:0.08143125715450653\n",
      "train loss:0.03149276960729283\n",
      "train loss:0.04471735028869598\n",
      "train loss:0.05462720354722473\n",
      "train loss:0.02413213482083194\n",
      "train loss:0.07192176207887917\n",
      "train loss:0.09490704157506595\n",
      "train loss:0.03737917054820638\n",
      "train loss:0.02385831088840852\n",
      "train loss:0.087376740519178\n",
      "train loss:0.02916115007703983\n",
      "train loss:0.02231567413590515\n",
      "train loss:0.007801338690160607\n",
      "train loss:0.09740763873920402\n",
      "train loss:0.044410427844587666\n",
      "train loss:0.10699104493657671\n",
      "train loss:0.06921518173368135\n",
      "train loss:0.06617787726710449\n",
      "train loss:0.0738052087276583\n",
      "train loss:0.04321727841168944\n",
      "train loss:0.08912530799020484\n",
      "train loss:0.05317846784215921\n",
      "train loss:0.010074482007296442\n",
      "train loss:0.07709498308686648\n",
      "train loss:0.019085065227305895\n",
      "train loss:0.0501000184607527\n",
      "train loss:0.02918656028347409\n",
      "train loss:0.0421297509263841\n",
      "train loss:0.04660358149582673\n",
      "train loss:0.08823194632935392\n",
      "train loss:0.09104212644759699\n",
      "train loss:0.04759733549090261\n",
      "train loss:0.07553448568336735\n",
      "train loss:0.051704401099337854\n",
      "train loss:0.04974668396242699\n",
      "train loss:0.12905571285243275\n",
      "train loss:0.03085373154126403\n",
      "train loss:0.042472636402332536\n",
      "train loss:0.0382137992628734\n",
      "train loss:0.03407341543335494\n",
      "train loss:0.09631957974442397\n",
      "train loss:0.08253601747694635\n",
      "train loss:0.02691145859125308\n",
      "train loss:0.09470351493051908\n",
      "train loss:0.039733128975026254\n",
      "train loss:0.0289883102932644\n",
      "train loss:0.013414744723773995\n",
      "train loss:0.07129633606362815\n",
      "train loss:0.14990037028566008\n",
      "train loss:0.047421541028182475\n",
      "train loss:0.08800468054649205\n",
      "train loss:0.020349398947982437\n",
      "train loss:0.1097939905089303\n",
      "train loss:0.046396221287575076\n",
      "train loss:0.06168377126738819\n",
      "train loss:0.08485659571600893\n",
      "train loss:0.05093164230805416\n",
      "train loss:0.017269223434386374\n",
      "train loss:0.03477691849875646\n",
      "train loss:0.05836782956573086\n",
      "train loss:0.16436269270818485\n",
      "train loss:0.05018210272645243\n",
      "train loss:0.049497614464753543\n",
      "train loss:0.07640873807744433\n",
      "train loss:0.050275034177312126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.031053314001833116\n",
      "train loss:0.0346950783641672\n",
      "train loss:0.06114929076245608\n",
      "train loss:0.04418176812964524\n",
      "train loss:0.02879547565299978\n",
      "train loss:0.06200561998687801\n",
      "train loss:0.09912402135543477\n",
      "train loss:0.02808751620443652\n",
      "train loss:0.07753679164653426\n",
      "train loss:0.030199877962310114\n",
      "train loss:0.09234020003328178\n",
      "train loss:0.026250263663392143\n",
      "train loss:0.04976694821378916\n",
      "train loss:0.06898521968124065\n",
      "train loss:0.13823746495095457\n",
      "train loss:0.03292988749468679\n",
      "train loss:0.03829675100659858\n",
      "train loss:0.18443024728173374\n",
      "train loss:0.027400078476231694\n",
      "train loss:0.02571767115600703\n",
      "train loss:0.05569642137568105\n",
      "train loss:0.12758160230527418\n",
      "train loss:0.07200607778664361\n",
      "train loss:0.02195778027328164\n",
      "train loss:0.09250407917005495\n",
      "train loss:0.034672717235478\n",
      "train loss:0.04628870656988452\n",
      "train loss:0.0681251459362871\n",
      "train loss:0.14823860083112927\n",
      "train loss:0.10153832485387264\n",
      "train loss:0.018583716991330913\n",
      "train loss:0.05000345905575926\n",
      "train loss:0.047878960864328385\n",
      "train loss:0.09871223158993024\n",
      "train loss:0.06213062822681144\n",
      "train loss:0.04633753003951879\n",
      "train loss:0.07902152280105029\n",
      "train loss:0.047375354160035237\n",
      "train loss:0.033501576379513634\n",
      "train loss:0.022774956765230617\n",
      "train loss:0.04267818394450704\n",
      "train loss:0.027131956090576278\n",
      "train loss:0.0531193443339487\n",
      "train loss:0.05769666376177527\n",
      "train loss:0.08013367319196116\n",
      "train loss:0.06267116703417058\n",
      "train loss:0.05921718017151582\n",
      "train loss:0.04504054969270751\n",
      "train loss:0.022151403364557027\n",
      "train loss:0.07332175638799587\n",
      "train loss:0.06312417826559719\n",
      "train loss:0.0684281611797416\n",
      "train loss:0.01306647661762405\n",
      "train loss:0.014353058870915503\n",
      "train loss:0.0300829892398121\n",
      "train loss:0.028795986386492264\n",
      "train loss:0.007930004651461053\n",
      "train loss:0.038624773162826885\n",
      "train loss:0.0687771491929815\n",
      "train loss:0.06456712657993748\n",
      "train loss:0.0321919954581779\n",
      "train loss:0.0394681564000368\n",
      "train loss:0.0194282344772361\n",
      "train loss:0.07069400031601192\n",
      "train loss:0.05007175369604786\n",
      "train loss:0.06845203448516042\n",
      "train loss:0.11262250393321277\n",
      "train loss:0.14955745660333175\n",
      "train loss:0.03611070203736681\n",
      "train loss:0.01737803198169267\n",
      "train loss:0.02663656470946839\n",
      "train loss:0.019823531435686013\n",
      "train loss:0.01719158097002788\n",
      "train loss:0.05188754120985409\n",
      "train loss:0.053424479059939654\n",
      "train loss:0.04503156715984035\n",
      "train loss:0.047489570501155924\n",
      "train loss:0.039406475672459966\n",
      "train loss:0.07085838326394678\n",
      "train loss:0.018796400710456674\n",
      "train loss:0.03834803565907851\n",
      "train loss:0.052408062012947315\n",
      "train loss:0.0683951279521718\n",
      "train loss:0.07914599485138726\n",
      "train loss:0.0522800347044928\n",
      "train loss:0.035919417132404693\n",
      "train loss:0.029814126327917415\n",
      "train loss:0.03559815486377168\n",
      "train loss:0.09232756168563946\n",
      "train loss:0.02667103973839397\n",
      "train loss:0.013922655789827452\n",
      "train loss:0.0778048648489691\n",
      "train loss:0.025258837612179327\n",
      "train loss:0.05410535300996508\n",
      "train loss:0.0387876559131322\n",
      "train loss:0.08085468277500248\n",
      "train loss:0.02795205911884654\n",
      "train loss:0.07135251521191405\n",
      "train loss:0.04130067381050005\n",
      "train loss:0.04732091803356931\n",
      "train loss:0.043815316480503894\n",
      "train loss:0.06671671712957296\n",
      "train loss:0.011380690667877266\n",
      "train loss:0.09945148644887039\n",
      "train loss:0.016223444726567077\n",
      "train loss:0.031925580383525894\n",
      "train loss:0.015677331813780438\n",
      "train loss:0.06827339862881857\n",
      "train loss:0.06217525882412197\n",
      "train loss:0.0397713986098325\n",
      "train loss:0.04043619818792038\n",
      "train loss:0.07183523752746906\n",
      "train loss:0.03250172547756456\n",
      "train loss:0.049071319304452896\n",
      "train loss:0.036756288893209796\n",
      "train loss:0.01739293332253544\n",
      "train loss:0.015102291348301393\n",
      "train loss:0.026245448796359597\n",
      "train loss:0.05854162026890305\n",
      "train loss:0.06844643787875437\n",
      "train loss:0.10844044301821862\n",
      "train loss:0.022094512568143227\n",
      "train loss:0.12236919789530827\n",
      "train loss:0.013904087724231401\n",
      "train loss:0.014926286713720337\n",
      "train loss:0.04687124787654197\n",
      "train loss:0.06058871937456233\n",
      "train loss:0.008879148030108683\n",
      "train loss:0.02676787847872662\n",
      "train loss:0.03438292149144647\n",
      "train loss:0.08117629382428976\n",
      "train loss:0.018646862026372755\n",
      "train loss:0.11080049487714583\n",
      "train loss:0.015819174357046516\n",
      "train loss:0.03628227542120257\n",
      "train loss:0.03422095506144249\n",
      "train loss:0.059232855007998075\n",
      "train loss:0.08157172784766276\n",
      "train loss:0.017344229363589106\n",
      "train loss:0.02058823656220746\n",
      "train loss:0.08186354508001832\n",
      "train loss:0.06667023924109501\n",
      "train loss:0.05347205387507275\n",
      "train loss:0.04360401819580988\n",
      "train loss:0.02977195288127583\n",
      "train loss:0.025210072239223637\n",
      "train loss:0.014077063561892911\n",
      "train loss:0.034877933093112955\n",
      "train loss:0.09236150317950333\n",
      "train loss:0.02475422359725872\n",
      "train loss:0.042814527214759056\n",
      "train loss:0.0659758061333899\n",
      "train loss:0.02577957036436541\n",
      "train loss:0.019115429457411112\n",
      "train loss:0.08836939687509565\n",
      "train loss:0.038082536787107685\n",
      "train loss:0.027651351001214266\n",
      "train loss:0.03520556995375307\n",
      "train loss:0.021281831730097237\n",
      "train loss:0.024649007669162098\n",
      "train loss:0.010635456028180647\n",
      "train loss:0.03788912591344103\n",
      "train loss:0.06263386249064794\n",
      "train loss:0.03850759988837083\n",
      "train loss:0.01369398390550091\n",
      "train loss:0.016056698446069363\n",
      "train loss:0.017379286016613305\n",
      "train loss:0.06602394843193134\n",
      "train loss:0.11381238829846438\n",
      "train loss:0.039919677149539694\n",
      "train loss:0.025447806495856925\n",
      "train loss:0.02321371113644579\n",
      "train loss:0.04094061786001948\n",
      "train loss:0.03426041051625531\n",
      "train loss:0.03391829177704981\n",
      "train loss:0.043241762630657654\n",
      "train loss:0.03145557241764112\n",
      "train loss:0.07301020150283569\n",
      "train loss:0.0726950142857616\n",
      "train loss:0.04152526209491106\n",
      "train loss:0.072944299427737\n",
      "train loss:0.02898246595577099\n",
      "train loss:0.06778128232768496\n",
      "train loss:0.028280667916171263\n",
      "train loss:0.053941055954000824\n",
      "train loss:0.1949670000703457\n",
      "train loss:0.029268665321745407\n",
      "train loss:0.054129633343804\n",
      "train loss:0.05434065857026565\n",
      "train loss:0.034746247860373836\n",
      "train loss:0.08391063016153388\n",
      "train loss:0.037445843219064814\n",
      "train loss:0.09366690080108903\n",
      "train loss:0.03259597337127281\n",
      "train loss:0.09943177794592602\n",
      "train loss:0.05822279177954287\n",
      "train loss:0.06065278597412676\n",
      "train loss:0.05132489252314509\n",
      "train loss:0.06496576302000218\n",
      "train loss:0.07665756709811139\n",
      "train loss:0.017196280150352763\n",
      "train loss:0.02869568782753607\n",
      "train loss:0.09542289846537381\n",
      "train loss:0.05424959161094564\n",
      "train loss:0.03215642347869864\n",
      "train loss:0.03379323312465608\n",
      "train loss:0.02789816865892484\n",
      "train loss:0.01457971936834322\n",
      "train loss:0.028976147752848225\n",
      "train loss:0.03797149856679935\n",
      "train loss:0.04505002716408622\n",
      "train loss:0.07353749791439773\n",
      "train loss:0.07766742133257841\n",
      "train loss:0.044806532700214285\n",
      "train loss:0.03782628489557464\n",
      "train loss:0.007847749571049344\n",
      "train loss:0.045350333967502064\n",
      "train loss:0.0222293827714569\n",
      "train loss:0.02091445392379427\n",
      "train loss:0.00804029782645257\n",
      "train loss:0.013517558230627693\n",
      "train loss:0.0752640949224918\n",
      "train loss:0.022963037769214552\n",
      "train loss:0.05362942035296077\n",
      "train loss:0.015853392038772562\n",
      "train loss:0.05350251010008386\n",
      "train loss:0.01730959644400803\n",
      "train loss:0.03967773438826399\n",
      "train loss:0.04766291877863933\n",
      "train loss:0.05265292600857857\n",
      "train loss:0.021437085060173132\n",
      "train loss:0.035025435823281124\n",
      "train loss:0.02494815202649321\n",
      "train loss:0.03279857840703828\n",
      "train loss:0.02122025505692238\n",
      "train loss:0.02075343014961571\n",
      "train loss:0.036070764707922594\n",
      "train loss:0.047485085612898464\n",
      "train loss:0.12713143040550615\n",
      "train loss:0.04826707375720747\n",
      "train loss:0.025364236579131005\n",
      "train loss:0.00580248177130699\n",
      "train loss:0.10839407438815757\n",
      "train loss:0.010893435840210419\n",
      "train loss:0.06856796868044174\n",
      "train loss:0.018504198785092206\n",
      "train loss:0.04387064954155969\n",
      "train loss:0.0879639169540008\n",
      "train loss:0.04704514837318279\n",
      "train loss:0.01269083034271252\n",
      "train loss:0.02224009598192086\n",
      "train loss:0.019437875211375712\n",
      "train loss:0.08928016018568054\n",
      "train loss:0.05200820885531542\n",
      "train loss:0.05932934702877532\n",
      "train loss:0.05387894291422006\n",
      "train loss:0.07902477399908486\n",
      "train loss:0.01600667882526385\n",
      "train loss:0.03473853650382409\n",
      "train loss:0.0402507498806954\n",
      "train loss:0.046528813500370386\n",
      "train loss:0.014410825489157307\n",
      "train loss:0.0850597963609454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.07688440916206311\n",
      "train loss:0.03308786750612292\n",
      "train loss:0.013665647998499602\n",
      "train loss:0.04591775692131099\n",
      "train loss:0.062133655856019\n",
      "train loss:0.04696082829757679\n",
      "train loss:0.058327786069256676\n",
      "train loss:0.04248056998161468\n",
      "train loss:0.03271734374785085\n",
      "train loss:0.02717253435058677\n",
      "train loss:0.012097895537390484\n",
      "train loss:0.032420893721957784\n",
      "train loss:0.056216657769849805\n",
      "train loss:0.04400108612100423\n",
      "train loss:0.04397881362724904\n",
      "train loss:0.02361380177546863\n",
      "train loss:0.012225375670823968\n",
      "train loss:0.014224533473360364\n",
      "train loss:0.016645221237874153\n",
      "train loss:0.07452682440261435\n",
      "train loss:0.08002909740884094\n",
      "train loss:0.06466264121452302\n",
      "train loss:0.06968736951376686\n",
      "train loss:0.06116656707348571\n",
      "train loss:0.09678630911376042\n",
      "train loss:0.02182996344146325\n",
      "train loss:0.016451079549463607\n",
      "train loss:0.021020043430041442\n",
      "train loss:0.021423174778734507\n",
      "train loss:0.061895645086465195\n",
      "train loss:0.15629184920038358\n",
      "train loss:0.046609788165158594\n",
      "train loss:0.029325060644615535\n",
      "train loss:0.026364724929465493\n",
      "train loss:0.01737779879613891\n",
      "train loss:0.06488868407674707\n",
      "train loss:0.07186488096592589\n",
      "train loss:0.02834918455085851\n",
      "train loss:0.017516961205355272\n",
      "train loss:0.020002307670430434\n",
      "train loss:0.07335687988102958\n",
      "train loss:0.02556518261434093\n",
      "train loss:0.0394705308035937\n",
      "train loss:0.030600924776754242\n",
      "train loss:0.03636169480062463\n",
      "train loss:0.061823523838190286\n",
      "train loss:0.07860369545115653\n",
      "train loss:0.007502056449964651\n",
      "train loss:0.0157416534564895\n",
      "train loss:0.007158662542047199\n",
      "train loss:0.028818723381315144\n",
      "train loss:0.02544186506144519\n",
      "train loss:0.013507439198230083\n",
      "train loss:0.006670840206165646\n",
      "train loss:0.042658353591891435\n",
      "train loss:0.03883352631070387\n",
      "train loss:0.009317181560370152\n",
      "train loss:0.09845564191396684\n",
      "train loss:0.039385551756379804\n",
      "train loss:0.0670291239667061\n",
      "train loss:0.0734959150315314\n",
      "train loss:0.08459729054777558\n",
      "train loss:0.024096736350853548\n",
      "train loss:0.04022490196369354\n",
      "train loss:0.02699870166967354\n",
      "train loss:0.11383467172534871\n",
      "train loss:0.07081237602356726\n",
      "train loss:0.051006953661637836\n",
      "train loss:0.013487638341665633\n",
      "train loss:0.045653503176241096\n",
      "train loss:0.04051433225067101\n",
      "train loss:0.08124534252549957\n",
      "train loss:0.05138080179424073\n",
      "train loss:0.027288570406341757\n",
      "train loss:0.05605965870018023\n",
      "train loss:0.04760160395983774\n",
      "train loss:0.06431255896108948\n",
      "train loss:0.04830934993601842\n",
      "train loss:0.025546058848015675\n",
      "train loss:0.07064096366251034\n",
      "train loss:0.0244773011022422\n",
      "train loss:0.027355509531978062\n",
      "train loss:0.04146274034921234\n",
      "train loss:0.018068928084472902\n",
      "train loss:0.07226025923015013\n",
      "train loss:0.07110475212342075\n",
      "train loss:0.02289434806298611\n",
      "train loss:0.06119162985897368\n",
      "train loss:0.019413570774255994\n",
      "train loss:0.02704654526080587\n",
      "train loss:0.016784154402292376\n",
      "train loss:0.05386912047269284\n",
      "train loss:0.039128954339467774\n",
      "train loss:0.07443107574974275\n",
      "train loss:0.025159660169086287\n",
      "train loss:0.01145170925979636\n",
      "train loss:0.04845914271728766\n",
      "train loss:0.10090729148287708\n",
      "train loss:0.015413769263075437\n",
      "train loss:0.05669964570443056\n",
      "train loss:0.008144170845473095\n",
      "train loss:0.03452788892437438\n",
      "train loss:0.0854980281770174\n",
      "train loss:0.06436941216636406\n",
      "train loss:0.009308414552115262\n",
      "train loss:0.08408882808270046\n",
      "train loss:0.051839810290691506\n",
      "train loss:0.03351665338317357\n",
      "train loss:0.02359241559391336\n",
      "train loss:0.014948353287156413\n",
      "train loss:0.10685388769380756\n",
      "train loss:0.010433004375607392\n",
      "train loss:0.01456629209205598\n",
      "train loss:0.05929865843681451\n",
      "train loss:0.08886133691628537\n",
      "train loss:0.009966326231398032\n",
      "train loss:0.028409844010730018\n",
      "train loss:0.05314955569898091\n",
      "train loss:0.02894475289918176\n",
      "train loss:0.03014675969778706\n",
      "train loss:0.11370895457048676\n",
      "train loss:0.025934287321937206\n",
      "train loss:0.006908750989191839\n",
      "train loss:0.040663782297183045\n",
      "train loss:0.020777987530831626\n",
      "train loss:0.05192106822464743\n",
      "train loss:0.033486100478818226\n",
      "train loss:0.07600552563414677\n",
      "train loss:0.05845840697928687\n",
      "train loss:0.036262329605060845\n",
      "train loss:0.04626479409705806\n",
      "train loss:0.029963256716015133\n",
      "train loss:0.03188458087220424\n",
      "train loss:0.01844158494574998\n",
      "train loss:0.012993194271892373\n",
      "train loss:0.0374710625825798\n",
      "train loss:0.08736313614341906\n",
      "train loss:0.17106970681478426\n",
      "train loss:0.024419443749619622\n",
      "train loss:0.053875527484018734\n",
      "train loss:0.06482755859879914\n",
      "train loss:0.029209005917474298\n",
      "train loss:0.0642187708872\n",
      "train loss:0.055988899687386705\n",
      "train loss:0.049221068330600574\n",
      "train loss:0.031477909405326014\n",
      "train loss:0.02317204827720599\n",
      "train loss:0.057743800462204654\n",
      "train loss:0.02101167776251962\n",
      "train loss:0.021159072085713135\n",
      "train loss:0.016334575470790966\n",
      "train loss:0.012363392043607866\n",
      "train loss:0.022791306549868856\n",
      "train loss:0.050388020335757976\n",
      "train loss:0.012975368312896052\n",
      "train loss:0.03589350438328643\n",
      "train loss:0.01645333845259233\n",
      "train loss:0.15142146367392273\n",
      "train loss:0.056924138707086236\n",
      "train loss:0.06304079352242614\n",
      "train loss:0.011512228669666502\n",
      "train loss:0.012166071906450058\n",
      "train loss:0.06577687948440407\n",
      "train loss:0.06342278905932636\n",
      "train loss:0.04571342646545734\n",
      "train loss:0.035004521343025334\n",
      "train loss:0.05506806939476663\n",
      "train loss:0.01681860148419802\n",
      "train loss:0.025198358170108973\n",
      "train loss:0.0326534706261597\n",
      "train loss:0.019067291737505765\n",
      "train loss:0.006671780299706462\n",
      "train loss:0.028272547885793795\n",
      "train loss:0.02101153998923635\n",
      "train loss:0.09118461178039626\n",
      "train loss:0.04595952762633502\n",
      "train loss:0.023611917648536474\n",
      "train loss:0.07518998470426724\n",
      "train loss:0.04267689118809488\n",
      "train loss:0.09069096081513706\n",
      "train loss:0.06437893150058142\n",
      "train loss:0.030301333182187015\n",
      "train loss:0.031188931928084775\n",
      "train loss:0.09114861321514774\n",
      "train loss:0.03554569448397321\n",
      "train loss:0.06951520214570911\n",
      "train loss:0.03500330311218998\n",
      "train loss:0.07607838465398219\n",
      "train loss:0.024928831438788907\n",
      "train loss:0.04845450489460432\n",
      "train loss:0.024703692603495746\n",
      "train loss:0.06709464075551279\n",
      "train loss:0.045367707838340196\n",
      "train loss:0.04671361007854105\n",
      "train loss:0.02238171135349492\n",
      "train loss:0.03494284506598268\n",
      "train loss:0.011564820190288663\n",
      "train loss:0.0406508085960201\n",
      "train loss:0.03333681057972738\n",
      "train loss:0.03203833280384586\n",
      "train loss:0.054400342804110796\n",
      "train loss:0.026303857357542905\n",
      "train loss:0.010522868789765234\n",
      "train loss:0.007803680779322186\n",
      "train loss:0.025449040844167034\n",
      "train loss:0.09196396274846935\n",
      "train loss:0.0412331599367193\n",
      "train loss:0.049303989993542865\n",
      "train loss:0.02898824737127586\n",
      "train loss:0.02124116132786065\n",
      "=== epoch:4, train acc:0.984, test acc:0.983 ===\n",
      "train loss:0.06765896979435147\n",
      "train loss:0.04337976739379107\n",
      "train loss:0.03472681396353716\n",
      "train loss:0.06310013782483262\n",
      "train loss:0.06696454585329148\n",
      "train loss:0.03295972217463019\n",
      "train loss:0.047896735998398804\n",
      "train loss:0.02271586833256407\n",
      "train loss:0.037784908707145806\n",
      "train loss:0.01980731092348497\n",
      "train loss:0.0804187470398203\n",
      "train loss:0.026118638852668484\n",
      "train loss:0.08445807537337384\n",
      "train loss:0.02119636830781927\n",
      "train loss:0.011237079788772112\n",
      "train loss:0.09513923745404529\n",
      "train loss:0.025846355341681386\n",
      "train loss:0.07589094147577673\n",
      "train loss:0.04275910754453584\n",
      "train loss:0.013495293295089715\n",
      "train loss:0.06013313260556677\n",
      "train loss:0.02918678907477564\n",
      "train loss:0.04277908010070184\n",
      "train loss:0.027611832272714708\n",
      "train loss:0.0386330929836282\n",
      "train loss:0.044880267800683556\n",
      "train loss:0.06150310024850971\n",
      "train loss:0.0235932343244499\n",
      "train loss:0.08508972001394964\n",
      "train loss:0.019492267727590912\n",
      "train loss:0.0075670003427551116\n",
      "train loss:0.03276163797342628\n",
      "train loss:0.14002622516878022\n",
      "train loss:0.04877471303760594\n",
      "train loss:0.03139212454882426\n",
      "train loss:0.03213951086462148\n",
      "train loss:0.04985965841409735\n",
      "train loss:0.0712294255846342\n",
      "train loss:0.013805797940721938\n",
      "train loss:0.03294078005769789\n",
      "train loss:0.10046222865620592\n",
      "train loss:0.038906849943687455\n",
      "train loss:0.04680957102546575\n",
      "train loss:0.11503202689535899\n",
      "train loss:0.1804228561380493\n",
      "train loss:0.04336137391365049\n",
      "train loss:0.030121550506456908\n",
      "train loss:0.03611229431145975\n",
      "train loss:0.06839142684456746\n",
      "train loss:0.054608447530406466\n",
      "train loss:0.056767927589037814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.04630528049491718\n",
      "train loss:0.026002619372822108\n",
      "train loss:0.056723989043721584\n",
      "train loss:0.014774609616621281\n",
      "train loss:0.021515002652372918\n",
      "train loss:0.06473179816126319\n",
      "train loss:0.06645531582630651\n",
      "train loss:0.013848004087916739\n",
      "train loss:0.007376258740694784\n",
      "train loss:0.06514771168229909\n",
      "train loss:0.041638096885083416\n",
      "train loss:0.026286120150901898\n",
      "train loss:0.02501794024161817\n",
      "train loss:0.0235934534259868\n",
      "train loss:0.03956044106800122\n",
      "train loss:0.07175501507711977\n",
      "train loss:0.03664621251128497\n",
      "train loss:0.02425247802352203\n",
      "train loss:0.028976975869282627\n",
      "train loss:0.006229067525378088\n",
      "train loss:0.02282151447955553\n",
      "train loss:0.021371285977680055\n",
      "train loss:0.03276891385654229\n",
      "train loss:0.055269884146990876\n",
      "train loss:0.009191295499124834\n",
      "train loss:0.01699648292437344\n",
      "train loss:0.012624343981345829\n",
      "train loss:0.022778336388797022\n",
      "train loss:0.04763207007323463\n",
      "train loss:0.0064121939347798525\n",
      "train loss:0.0874834113747763\n",
      "train loss:0.04754376665875862\n",
      "train loss:0.03506762673705319\n",
      "train loss:0.033434979527612416\n",
      "train loss:0.017783225507587642\n",
      "train loss:0.029451421777090415\n",
      "train loss:0.01965979954676084\n",
      "train loss:0.06229485794928156\n",
      "train loss:0.005885810429571616\n",
      "train loss:0.02740196744263977\n",
      "train loss:0.020357001399933933\n",
      "train loss:0.005036770341671176\n",
      "train loss:0.04663163425816923\n",
      "train loss:0.02708527353604803\n",
      "train loss:0.015979477825116235\n",
      "train loss:0.05529106609094873\n",
      "train loss:0.01973261499811277\n",
      "train loss:0.01895502094688593\n",
      "train loss:0.021826300446538265\n",
      "train loss:0.029293447737077396\n",
      "train loss:0.007504805667578287\n",
      "train loss:0.020070057857601343\n",
      "train loss:0.027901498664139414\n",
      "train loss:0.048537678952905026\n",
      "train loss:0.0285910417122366\n",
      "train loss:0.01034110871820117\n",
      "train loss:0.022630768132135666\n",
      "train loss:0.02511041349627749\n",
      "train loss:0.06410474694730936\n",
      "train loss:0.05116171181537402\n",
      "train loss:0.02566429348993447\n",
      "train loss:0.04851299476386763\n",
      "train loss:0.02471966601085536\n",
      "train loss:0.03434880566472445\n",
      "train loss:0.013692754241216822\n",
      "train loss:0.047356961572647106\n",
      "train loss:0.04446338849367005\n",
      "train loss:0.07618188166164946\n",
      "train loss:0.06640385213696283\n",
      "train loss:0.04910196934313712\n",
      "train loss:0.07391133297888629\n",
      "train loss:0.10834554639794908\n",
      "train loss:0.07717826260765809\n",
      "train loss:0.024363329125263063\n",
      "train loss:0.014617146622149503\n",
      "train loss:0.011847761090991907\n",
      "train loss:0.014190669666487288\n",
      "train loss:0.010291150309566668\n",
      "train loss:0.05214246526737623\n",
      "train loss:0.017758958387401512\n",
      "train loss:0.07628275318743248\n",
      "train loss:0.00902671129034856\n",
      "train loss:0.12991833585819118\n",
      "train loss:0.05000913234869828\n",
      "train loss:0.016352124861083287\n",
      "train loss:0.03178145988616323\n",
      "train loss:0.06756009208507834\n",
      "train loss:0.027824446600104837\n",
      "train loss:0.016879608676614265\n",
      "train loss:0.021531397975008023\n",
      "train loss:0.060605709842177495\n",
      "train loss:0.08235666506966632\n",
      "train loss:0.04782613108243731\n",
      "train loss:0.017876322467442224\n",
      "train loss:0.018544324041661377\n",
      "train loss:0.0437499710585555\n",
      "train loss:0.00880188803540844\n",
      "train loss:0.01518477429458318\n",
      "train loss:0.016238560308815913\n",
      "train loss:0.07673150198050654\n",
      "train loss:0.01680141147613004\n",
      "train loss:0.008729162832511978\n",
      "train loss:0.029587010146952156\n",
      "train loss:0.053586842581946736\n",
      "train loss:0.023851097005192542\n",
      "train loss:0.049459722190762126\n",
      "train loss:0.011798399621470737\n",
      "train loss:0.011629548602055586\n",
      "train loss:0.04142166023600827\n",
      "train loss:0.040861135310730816\n",
      "train loss:0.02889243225893211\n",
      "train loss:0.0655351567147169\n",
      "train loss:0.026541001360696835\n",
      "train loss:0.05632681812910545\n",
      "train loss:0.007486492501008543\n",
      "train loss:0.014119620999309225\n",
      "train loss:0.04200938981594879\n",
      "train loss:0.020062760757121604\n",
      "train loss:0.04893299968405232\n",
      "train loss:0.09304865351737618\n",
      "train loss:0.021113904786674964\n",
      "train loss:0.013006300468233017\n",
      "train loss:0.027288778421349864\n",
      "train loss:0.03029324102412455\n",
      "train loss:0.01306044700846642\n",
      "train loss:0.12055136202730277\n",
      "train loss:0.021612975158434713\n",
      "train loss:0.09496108895241014\n",
      "train loss:0.013276249399964935\n",
      "train loss:0.008976989951630304\n",
      "train loss:0.005985397571472115\n",
      "train loss:0.05519319206692296\n",
      "train loss:0.042959679203947554\n",
      "train loss:0.008674703529621727\n",
      "train loss:0.1126810256163531\n",
      "train loss:0.06956178468782363\n",
      "train loss:0.05039267652637361\n",
      "train loss:0.05965095131214421\n",
      "train loss:0.053071619638096104\n",
      "train loss:0.01975804768312102\n",
      "train loss:0.05949430062866762\n",
      "train loss:0.004184506557599488\n",
      "train loss:0.017450302517173638\n",
      "train loss:0.02073647944463835\n",
      "train loss:0.0287911455934069\n",
      "train loss:0.04292850437253246\n",
      "train loss:0.0698604045396798\n",
      "train loss:0.03065568124975729\n",
      "train loss:0.050168202452000585\n",
      "train loss:0.03148329081146177\n",
      "train loss:0.05254440657772531\n",
      "train loss:0.0426772292073054\n",
      "train loss:0.07094903272253274\n",
      "train loss:0.010116237858912048\n",
      "train loss:0.031201510336891416\n",
      "train loss:0.030676011591028313\n",
      "train loss:0.048003291919549974\n",
      "train loss:0.06633569152384786\n",
      "train loss:0.005307407263957687\n",
      "train loss:0.010670149161069828\n",
      "train loss:0.019785602979907727\n",
      "train loss:0.00788917949901854\n",
      "train loss:0.01877923330106921\n",
      "train loss:0.06955052417829904\n",
      "train loss:0.03449616666571584\n",
      "train loss:0.026542331609240175\n",
      "train loss:0.01895867432307525\n",
      "train loss:0.028325280428959303\n",
      "train loss:0.02184453105323099\n",
      "train loss:0.014984418693898825\n",
      "train loss:0.03153977563414335\n",
      "train loss:0.06961219269264092\n",
      "train loss:0.040253208442034706\n",
      "train loss:0.011182073545916448\n",
      "train loss:0.08329952398056915\n",
      "train loss:0.05389963899248924\n",
      "train loss:0.08944574844143874\n",
      "train loss:0.05066639872577906\n",
      "train loss:0.048860828805714365\n",
      "train loss:0.023913284175834177\n",
      "train loss:0.07077956281642515\n",
      "train loss:0.03235862304258322\n",
      "train loss:0.0448255320489814\n",
      "train loss:0.09274941211826143\n",
      "train loss:0.00381475091973296\n",
      "train loss:0.024654235248995002\n",
      "train loss:0.020410585254987366\n",
      "train loss:0.08600759055978119\n",
      "train loss:0.10717865271032612\n",
      "train loss:0.025958126479866794\n",
      "train loss:0.01468067188752426\n",
      "train loss:0.010033443178410982\n",
      "train loss:0.020506852882207074\n",
      "train loss:0.040297541953789005\n",
      "train loss:0.03812352677703343\n",
      "train loss:0.00920350873144338\n",
      "train loss:0.024740548373551993\n",
      "train loss:0.00838321283935189\n",
      "train loss:0.06923242845930548\n",
      "train loss:0.03695070227074686\n",
      "train loss:0.02906706183198859\n",
      "train loss:0.0354811310477416\n",
      "train loss:0.02233638027529437\n",
      "train loss:0.02224214426059173\n",
      "train loss:0.032817459456575486\n",
      "train loss:0.07580490089361908\n",
      "train loss:0.02751004840972492\n",
      "train loss:0.03772845844445183\n",
      "train loss:0.016642216816812723\n",
      "train loss:0.03723020467580076\n",
      "train loss:0.02722616722610955\n",
      "train loss:0.029902191444561906\n",
      "train loss:0.060983673893052294\n",
      "train loss:0.05926283636925702\n",
      "train loss:0.02569467800413979\n",
      "train loss:0.03388557498054462\n",
      "train loss:0.02141284507458328\n",
      "train loss:0.07730036333450468\n",
      "train loss:0.09730698640124812\n",
      "train loss:0.02665874267502238\n",
      "train loss:0.007666685844723087\n",
      "train loss:0.02075016771995715\n",
      "train loss:0.017673372455809026\n",
      "train loss:0.054454428499034986\n",
      "train loss:0.058123079005403595\n",
      "train loss:0.014767155254760076\n",
      "train loss:0.04515484072056583\n",
      "train loss:0.017263924912094372\n",
      "train loss:0.03331297830515126\n",
      "train loss:0.014074266469124743\n",
      "train loss:0.03198495574603726\n",
      "train loss:0.02377525524247299\n",
      "train loss:0.10591195883568646\n",
      "train loss:0.02099028668402543\n",
      "train loss:0.018885808176956613\n",
      "train loss:0.03125057192816196\n",
      "train loss:0.1177821697307122\n",
      "train loss:0.01196277582780585\n",
      "train loss:0.005626391535976541\n",
      "train loss:0.037910844266971014\n",
      "train loss:0.1764116617478792\n",
      "train loss:0.029447981548390713\n",
      "train loss:0.013660770465337447\n",
      "train loss:0.038385269056333916\n",
      "train loss:0.00819553045744121\n",
      "train loss:0.008402630914509802\n",
      "train loss:0.012886377344350023\n",
      "train loss:0.016168046203826673\n",
      "train loss:0.02318508574880147\n",
      "train loss:0.05744051870545089\n",
      "train loss:0.024422845897703573\n",
      "train loss:0.044541318361583225\n",
      "train loss:0.052659974020150366\n",
      "train loss:0.048977196330587384\n",
      "train loss:0.012146438034791561\n",
      "train loss:0.058759048360250025\n",
      "train loss:0.022872519300719218\n",
      "train loss:0.03112159892651113\n",
      "train loss:0.020021811371544115\n",
      "train loss:0.026550960658517742\n",
      "train loss:0.012514663762767555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.018797922693220004\n",
      "train loss:0.020538007896414415\n",
      "train loss:0.01910572295017943\n",
      "train loss:0.037480558622697446\n",
      "train loss:0.010339892685502722\n",
      "train loss:0.018911420236644202\n",
      "train loss:0.03206948613722055\n",
      "train loss:0.083007614893756\n",
      "train loss:0.027521765338753626\n",
      "train loss:0.032987889327483616\n",
      "train loss:0.0181670096297041\n",
      "train loss:0.043817940843854465\n",
      "train loss:0.051380200638513805\n",
      "train loss:0.03744233395151657\n",
      "train loss:0.053057221149305\n",
      "train loss:0.009176004299425803\n",
      "train loss:0.03448765550735225\n",
      "train loss:0.06857747321782019\n",
      "train loss:0.007446124789415956\n",
      "train loss:0.016552402109688814\n",
      "train loss:0.052227934131597174\n",
      "train loss:0.027759852360735117\n",
      "train loss:0.020361384155055392\n",
      "train loss:0.03555437545367313\n",
      "train loss:0.02848320313615796\n",
      "train loss:0.04862194524396335\n",
      "train loss:0.03414578291969752\n",
      "train loss:0.013803380100273942\n",
      "train loss:0.04839226403072487\n",
      "train loss:0.03374372579720715\n",
      "train loss:0.04941631699633347\n",
      "train loss:0.02114978013230346\n",
      "train loss:0.04747812505566523\n",
      "train loss:0.046518590792594815\n",
      "train loss:0.01382078394420017\n",
      "train loss:0.0545465708955722\n",
      "train loss:0.021216139193228057\n",
      "train loss:0.046886370609140346\n",
      "train loss:0.03135459847698478\n",
      "train loss:0.016071146680494124\n",
      "train loss:0.009831652578418238\n",
      "train loss:0.024401537075243257\n",
      "train loss:0.024697643722621315\n",
      "train loss:0.025087008008970058\n",
      "train loss:0.12552653325117458\n",
      "train loss:0.1357608077141893\n",
      "train loss:0.020460788665920465\n",
      "train loss:0.012297460812670177\n",
      "train loss:0.025423559257156222\n",
      "train loss:0.010006176102477265\n",
      "train loss:0.017056506396985933\n",
      "train loss:0.02869189724829671\n",
      "train loss:0.009422789810019462\n",
      "train loss:0.014028256892324096\n",
      "train loss:0.016656590412286128\n",
      "train loss:0.03500140023011447\n",
      "train loss:0.06948563495631305\n",
      "train loss:0.02627047743019654\n",
      "train loss:0.022159609996516515\n",
      "train loss:0.03767737491269508\n",
      "train loss:0.026047153871094818\n",
      "train loss:0.09325169674869853\n",
      "train loss:0.09343146633594014\n",
      "train loss:0.07770814468048477\n",
      "train loss:0.023856414486356125\n",
      "train loss:0.03455455556509148\n",
      "train loss:0.03717230488996566\n",
      "train loss:0.01226905473851108\n",
      "train loss:0.045565822126477515\n",
      "train loss:0.017070622334865223\n",
      "train loss:0.02162332022070227\n",
      "train loss:0.04200687524916703\n",
      "train loss:0.023006504143059398\n",
      "train loss:0.026998907052161805\n",
      "train loss:0.04475790061091414\n",
      "train loss:0.010328679465855629\n",
      "train loss:0.020465705879921536\n",
      "train loss:0.01590702798918572\n",
      "train loss:0.013789092815510839\n",
      "train loss:0.06475577605958756\n",
      "train loss:0.013465002660479716\n",
      "train loss:0.020615675803422356\n",
      "train loss:0.047517094276752464\n",
      "train loss:0.01961173279663505\n",
      "train loss:0.014373518268657896\n",
      "train loss:0.021487377705068433\n",
      "train loss:0.020679816673237955\n",
      "train loss:0.03473189396796332\n",
      "train loss:0.0458498344060268\n",
      "train loss:0.02976133532780428\n",
      "train loss:0.010044413017034024\n",
      "train loss:0.03729334358097377\n",
      "train loss:0.03189815746282703\n",
      "train loss:0.017266378605521514\n",
      "train loss:0.051583696926610446\n",
      "train loss:0.03360635063144843\n",
      "train loss:0.026490593727751328\n",
      "train loss:0.060869795170024686\n",
      "train loss:0.024229063305823622\n",
      "train loss:0.02851496410372986\n",
      "train loss:0.012594593843600323\n",
      "train loss:0.04919855369493196\n",
      "train loss:0.05683966867503341\n",
      "train loss:0.02188619471334868\n",
      "train loss:0.013804320663880744\n",
      "train loss:0.018355284972832144\n",
      "train loss:0.08554454833131428\n",
      "train loss:0.023315025646802136\n",
      "train loss:0.03035898458883244\n",
      "train loss:0.014003202630473287\n",
      "train loss:0.015033142097818917\n",
      "train loss:0.016974074962532934\n",
      "train loss:0.016900863466132232\n",
      "train loss:0.007401553735839067\n",
      "train loss:0.08210768144175605\n",
      "train loss:0.02232623677660661\n",
      "train loss:0.01646854286101612\n",
      "train loss:0.014723154145709882\n",
      "train loss:0.0046001769038833094\n",
      "train loss:0.004644076460809894\n",
      "train loss:0.01683416990991879\n",
      "train loss:0.009650252193760785\n",
      "train loss:0.01722695299159284\n",
      "train loss:0.09377416244660403\n",
      "train loss:0.04225609677634691\n",
      "train loss:0.005829160740262994\n",
      "train loss:0.017453969722776182\n",
      "train loss:0.013018367152974351\n",
      "train loss:0.008401672030386977\n",
      "train loss:0.08711512547917223\n",
      "train loss:0.05674135269122355\n",
      "train loss:0.00952761366085052\n",
      "train loss:0.007604029431956682\n",
      "train loss:0.049126483342538815\n",
      "train loss:0.005968164391481261\n",
      "train loss:0.012238207739704434\n",
      "train loss:0.010824990344467472\n",
      "train loss:0.01870477576939522\n",
      "train loss:0.08497482835585135\n",
      "train loss:0.033086642565175906\n",
      "train loss:0.02949310642067301\n",
      "train loss:0.007127449578439058\n",
      "train loss:0.02706345185222111\n",
      "train loss:0.028865331018120045\n",
      "train loss:0.01927235559140098\n",
      "train loss:0.009461705879575882\n",
      "train loss:0.03381636034811654\n",
      "train loss:0.01806254698793034\n",
      "train loss:0.015454546657803946\n",
      "train loss:0.021903383143246823\n",
      "train loss:0.01866355185648434\n",
      "train loss:0.015432982529425902\n",
      "train loss:0.033302089402944254\n",
      "train loss:0.00890984606707231\n",
      "train loss:0.02317364624256774\n",
      "train loss:0.03628991726760075\n",
      "train loss:0.026746458929998922\n",
      "train loss:0.015394219939441907\n",
      "train loss:0.004899680999677914\n",
      "train loss:0.06365523204302\n",
      "train loss:0.009071751060564529\n",
      "train loss:0.029478832658915474\n",
      "train loss:0.012854665469407134\n",
      "train loss:0.04244989635683611\n",
      "train loss:0.07620906962479361\n",
      "train loss:0.044308738270627514\n",
      "train loss:0.015410256289183305\n",
      "train loss:0.019211041119683928\n",
      "train loss:0.031738406412142456\n",
      "train loss:0.05888520122248635\n",
      "train loss:0.02968129183432084\n",
      "train loss:0.05240066691341819\n",
      "train loss:0.06530253489718486\n",
      "train loss:0.01225298433943103\n",
      "train loss:0.05250475761141085\n",
      "train loss:0.012523137581435142\n",
      "train loss:0.00899332926418602\n",
      "train loss:0.041733479222667035\n",
      "train loss:0.041818633633869985\n",
      "train loss:0.01627743892081139\n",
      "train loss:0.03973014984641501\n",
      "train loss:0.035393250730107836\n",
      "train loss:0.013339277801188239\n",
      "train loss:0.020051307850014178\n",
      "train loss:0.027864289653248428\n",
      "train loss:0.023431742312134327\n",
      "train loss:0.0417668350969829\n",
      "train loss:0.041439960713797165\n",
      "train loss:0.05255817272426436\n",
      "train loss:0.042469335577977885\n",
      "train loss:0.010882341596862698\n",
      "train loss:0.039449307420486766\n",
      "train loss:0.06492302480496154\n",
      "train loss:0.03437932114246889\n",
      "train loss:0.037964263168492565\n",
      "train loss:0.030469554422816496\n",
      "train loss:0.012703082893992185\n",
      "train loss:0.007009334665779724\n",
      "train loss:0.01550650506695059\n",
      "train loss:0.007904690698143006\n",
      "train loss:0.02646962304332645\n",
      "train loss:0.013941507618494746\n",
      "train loss:0.022873865644008298\n",
      "train loss:0.026707619162803238\n",
      "train loss:0.015613723380289617\n",
      "train loss:0.02392313660006359\n",
      "train loss:0.00602011730994752\n",
      "train loss:0.01065423070603547\n",
      "train loss:0.008885807444239327\n",
      "train loss:0.012435951946814254\n",
      "train loss:0.0044393076560100934\n",
      "train loss:0.017660202247049315\n",
      "train loss:0.017806628299323966\n",
      "train loss:0.013461027609105313\n",
      "train loss:0.013726613024926592\n",
      "train loss:0.030723539504696938\n",
      "train loss:0.00816615308649937\n",
      "train loss:0.010932173257994593\n",
      "train loss:0.020198405017341783\n",
      "train loss:0.010284500923180668\n",
      "train loss:0.0062262541512224\n",
      "train loss:0.007616820430009564\n",
      "train loss:0.014207712957604125\n",
      "train loss:0.016952445593923667\n",
      "train loss:0.00988959489250504\n",
      "train loss:0.05409964110953622\n",
      "train loss:0.031244982971840987\n",
      "train loss:0.02221735920416519\n",
      "train loss:0.04249783892894963\n",
      "train loss:0.04240446765607089\n",
      "train loss:0.02603632417732617\n",
      "train loss:0.01542718809037655\n",
      "train loss:0.005837474332238443\n",
      "train loss:0.060169355514306314\n",
      "train loss:0.003565667340800259\n",
      "train loss:0.0736996258187396\n",
      "train loss:0.006613468466806561\n",
      "train loss:0.006120303168075673\n",
      "train loss:0.04352630538365501\n",
      "train loss:0.008967297182571549\n",
      "train loss:0.009887885617477617\n",
      "train loss:0.05478979451519754\n",
      "train loss:0.014529745744204849\n",
      "train loss:0.009158093521525358\n",
      "train loss:0.020882654521093186\n",
      "train loss:0.02899607912024914\n",
      "train loss:0.1619543419330833\n",
      "train loss:0.03618765093147521\n",
      "train loss:0.04696831926104987\n",
      "train loss:0.07286427919481912\n",
      "train loss:0.018781892191030266\n",
      "train loss:0.004293746311549797\n",
      "train loss:0.0043382055885101975\n",
      "train loss:0.031516574636128045\n",
      "train loss:0.017206721126195854\n",
      "train loss:0.03570765631266644\n",
      "train loss:0.01894657986332921\n",
      "train loss:0.03576909723486002\n",
      "train loss:0.007594523997614222\n",
      "train loss:0.027462582833557646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0837284335985073\n",
      "train loss:0.018122004854153273\n",
      "train loss:0.005472604126418966\n",
      "train loss:0.021487552269874085\n",
      "train loss:0.05416659477788891\n",
      "train loss:0.008840700313164576\n",
      "train loss:0.044803350486726054\n",
      "train loss:0.022512462350763526\n",
      "train loss:0.01744974246531079\n",
      "train loss:0.06427400529186325\n",
      "train loss:0.019774603202870177\n",
      "train loss:0.12454661463246293\n",
      "train loss:0.06907501897406887\n",
      "train loss:0.011529212378933373\n",
      "train loss:0.03228887525982328\n",
      "train loss:0.03731695698243437\n",
      "train loss:0.10980025251630651\n",
      "train loss:0.033748015784340696\n",
      "train loss:0.0071148368962345035\n",
      "train loss:0.036057463176191795\n",
      "train loss:0.009307147573456995\n",
      "train loss:0.06269463939221874\n",
      "train loss:0.016851237311490755\n",
      "train loss:0.026576502864812824\n",
      "train loss:0.09489625781803498\n",
      "train loss:0.004978373721400924\n",
      "train loss:0.07130256020617015\n",
      "train loss:0.012362519421452712\n",
      "=== epoch:5, train acc:0.989, test acc:0.985 ===\n",
      "train loss:0.015441280773288263\n",
      "train loss:0.04412789777836145\n",
      "train loss:0.01619384264346805\n",
      "train loss:0.007021242808529081\n",
      "train loss:0.02554064134260349\n",
      "train loss:0.02310729843154488\n",
      "train loss:0.01800877814667257\n",
      "train loss:0.020931094907733483\n",
      "train loss:0.008361210161120557\n",
      "train loss:0.013263005124607687\n",
      "train loss:0.00848761910783259\n",
      "train loss:0.06129152361322555\n",
      "train loss:0.06861525003871866\n",
      "train loss:0.025478688328660133\n",
      "train loss:0.007573540191176545\n",
      "train loss:0.011458926236371864\n",
      "train loss:0.007847858344952493\n",
      "train loss:0.00723919793711288\n",
      "train loss:0.051423044469431314\n",
      "train loss:0.031050521063902353\n",
      "train loss:0.025666683378225957\n",
      "train loss:0.024917278783508266\n",
      "train loss:0.024214033436928354\n",
      "train loss:0.010271757357480588\n",
      "train loss:0.03534092735455305\n",
      "train loss:0.031689501739331216\n",
      "train loss:0.025295570728538865\n",
      "train loss:0.03583552281988869\n",
      "train loss:0.008199727824157297\n",
      "train loss:0.08547576570589097\n",
      "train loss:0.04731664431316185\n",
      "train loss:0.008708903866629952\n",
      "train loss:0.024721904717148472\n",
      "train loss:0.009202904562271045\n",
      "train loss:0.011536687981407924\n",
      "train loss:0.024942182784973444\n",
      "train loss:0.017216144713997156\n",
      "train loss:0.039925895062385364\n",
      "train loss:0.014554108358912137\n",
      "train loss:0.028139693023603495\n",
      "train loss:0.018267124470832324\n",
      "train loss:0.0083011054882066\n",
      "train loss:0.015337111358448832\n",
      "train loss:0.030331128646291238\n",
      "train loss:0.008014723438527304\n",
      "train loss:0.05019574476032642\n",
      "train loss:0.022975346334916612\n",
      "train loss:0.010654159786988906\n",
      "train loss:0.0032739338791070226\n",
      "train loss:0.014911854719691477\n",
      "train loss:0.025926797917855505\n",
      "train loss:0.01050883086268471\n",
      "train loss:0.0076605255999602495\n",
      "train loss:0.009434566922645365\n",
      "train loss:0.12733237896022784\n",
      "train loss:0.057937208586605546\n",
      "train loss:0.025588101037792806\n",
      "train loss:0.006663416029637865\n",
      "train loss:0.08512826684726772\n",
      "train loss:0.013169581634565452\n",
      "train loss:0.020677200005714057\n",
      "train loss:0.025384231849342336\n",
      "train loss:0.013661636818559421\n",
      "train loss:0.004703760764955639\n",
      "train loss:0.06510681133438288\n",
      "train loss:0.0029436699703406692\n",
      "train loss:0.020823710012176554\n",
      "train loss:0.020594205670107966\n",
      "train loss:0.02165961929361593\n",
      "train loss:0.012363181731317134\n",
      "train loss:0.01121008344293961\n",
      "train loss:0.03677067285753822\n",
      "train loss:0.01922649671428979\n",
      "train loss:0.012335251890108902\n",
      "train loss:0.045453870915553286\n",
      "train loss:0.014509298345542791\n",
      "train loss:0.07135818215220538\n",
      "train loss:0.007154843615982762\n",
      "train loss:0.01901355841159642\n",
      "train loss:0.009925177362500216\n",
      "train loss:0.012157594046154052\n",
      "train loss:0.026923490407839132\n",
      "train loss:0.015781566386248\n",
      "train loss:0.02875545078057684\n",
      "train loss:0.012780862305873537\n",
      "train loss:0.06830251903491417\n",
      "train loss:0.013463504530140929\n",
      "train loss:0.02075037117949461\n",
      "train loss:0.02682035395191348\n",
      "train loss:0.024191802626352454\n",
      "train loss:0.04591542082646726\n",
      "train loss:0.016830892312210903\n",
      "train loss:0.054310856112590865\n",
      "train loss:0.00649304545137843\n",
      "train loss:0.02308641585020297\n",
      "train loss:0.008997363974360932\n",
      "train loss:0.01587484192260506\n",
      "train loss:0.05308869763942627\n",
      "train loss:0.04130800032676702\n",
      "train loss:0.035983320809600386\n",
      "train loss:0.028927820211695095\n",
      "train loss:0.015582525343433129\n",
      "train loss:0.018682457819716346\n",
      "train loss:0.03432287816730548\n",
      "train loss:0.021803406634623764\n",
      "train loss:0.020017922872631808\n",
      "train loss:0.010205540945041804\n",
      "train loss:0.00749373213362664\n",
      "train loss:0.03603005408358518\n",
      "train loss:0.008235707310687696\n",
      "train loss:0.0036078210483508743\n",
      "train loss:0.023490396597213904\n",
      "train loss:0.03343171048276419\n",
      "train loss:0.03550109366114157\n",
      "train loss:0.08023478741293902\n",
      "train loss:0.030968771148364386\n",
      "train loss:0.01011052498171149\n",
      "train loss:0.01966212183633735\n",
      "train loss:0.009416886705378104\n",
      "train loss:0.03987559813296695\n",
      "train loss:0.06038976519183948\n",
      "train loss:0.008915692092121355\n",
      "train loss:0.03998892531650116\n",
      "train loss:0.02557559048521727\n",
      "train loss:0.02572984852933253\n",
      "train loss:0.025079542759135945\n",
      "train loss:0.06195824081644153\n",
      "train loss:0.006242298753487267\n",
      "train loss:0.03257304603805843\n",
      "train loss:0.006275306812846696\n",
      "train loss:0.030581508422347203\n",
      "train loss:0.016312405175742187\n",
      "train loss:0.007972155898272125\n",
      "train loss:0.0036766900464737544\n",
      "train loss:0.010231119564053277\n",
      "train loss:0.02240688465755411\n",
      "train loss:0.03965725913996265\n",
      "train loss:0.01252111006212629\n",
      "train loss:0.02321801041258004\n",
      "train loss:0.02618986431168389\n",
      "train loss:0.014127179049596806\n",
      "train loss:0.017360277122739798\n",
      "train loss:0.026994725326771607\n",
      "train loss:0.012420808377958122\n",
      "train loss:0.05825014273216476\n",
      "train loss:0.0350904177203672\n",
      "train loss:0.024250602853623678\n",
      "train loss:0.020514438066186996\n",
      "train loss:0.016528736950000063\n",
      "train loss:0.007442906306556608\n",
      "train loss:0.04263521866604484\n",
      "train loss:0.006420541856532676\n",
      "train loss:0.04956611625127853\n",
      "train loss:0.024730234745294757\n",
      "train loss:0.04769038076937741\n",
      "train loss:0.015655846573406282\n",
      "train loss:0.011431816356533309\n",
      "train loss:0.06532769969327676\n",
      "train loss:0.0637925613624265\n",
      "train loss:0.02609986853272138\n",
      "train loss:0.011202395353780592\n",
      "train loss:0.02279991832100178\n",
      "train loss:0.04679690770404792\n",
      "train loss:0.08541891010853372\n",
      "train loss:0.029395378578895164\n",
      "train loss:0.036202128555488634\n",
      "train loss:0.013223995280450944\n",
      "train loss:0.01485473842132936\n",
      "train loss:0.025540662202675674\n",
      "train loss:0.0663768457104376\n",
      "train loss:0.026189850367668542\n",
      "train loss:0.03494719750237259\n",
      "train loss:0.01841472371601471\n",
      "train loss:0.004147608372793747\n",
      "train loss:0.006976046074286469\n",
      "train loss:0.016403778380862346\n",
      "train loss:0.009840335675236494\n",
      "train loss:0.010650283292678104\n",
      "train loss:0.060324272617002156\n",
      "train loss:0.006432685209523988\n",
      "train loss:0.029382456307081792\n",
      "train loss:0.012361464734586144\n",
      "train loss:0.03413519730689235\n",
      "train loss:0.026715553813870977\n",
      "train loss:0.023786853551195968\n",
      "train loss:0.09976765429983607\n",
      "train loss:0.02191687606303607\n",
      "train loss:0.03540305431088502\n",
      "train loss:0.009325883572423407\n",
      "train loss:0.00875787152173907\n",
      "train loss:0.013541700054237509\n",
      "train loss:0.00616656910097816\n",
      "train loss:0.00935145892256768\n",
      "train loss:0.011653373731136767\n",
      "train loss:0.0059524944055132055\n",
      "train loss:0.02543261986939227\n",
      "train loss:0.08987493541393668\n",
      "train loss:0.041249137082135325\n",
      "train loss:0.018608684942829194\n",
      "train loss:0.002646635712999418\n",
      "train loss:0.04938509870692227\n",
      "train loss:0.009892279626326512\n",
      "train loss:0.00342416519248615\n",
      "train loss:0.023998423626381396\n",
      "train loss:0.015603924716111345\n",
      "train loss:0.017198919050730007\n",
      "train loss:0.039569280278932334\n",
      "train loss:0.01317897424360761\n",
      "train loss:0.014154087694195176\n",
      "train loss:0.038705714177669236\n",
      "train loss:0.04895467170060317\n",
      "train loss:0.05159796415916701\n",
      "train loss:0.07347144385706167\n",
      "train loss:0.012412222103711885\n",
      "train loss:0.007789125860931143\n",
      "train loss:0.017886728629431123\n",
      "train loss:0.07182601738012888\n",
      "train loss:0.05945342108045509\n",
      "train loss:0.04830046090247563\n",
      "train loss:0.01063559776664595\n",
      "train loss:0.054922588065616035\n",
      "train loss:0.04200367137559145\n",
      "train loss:0.02550971497872616\n",
      "train loss:0.013027954600615854\n",
      "train loss:0.02010610239424936\n",
      "train loss:0.022234147543656976\n",
      "train loss:0.007174780054538938\n",
      "train loss:0.01748986847821768\n",
      "train loss:0.035098772849177534\n",
      "train loss:0.018195551892593777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.02302449921346686\n",
      "train loss:0.0030640966855658884\n",
      "train loss:0.030107523426612805\n",
      "train loss:0.0038920913333133655\n",
      "train loss:0.026383763213897272\n",
      "train loss:0.031769173789083414\n",
      "train loss:0.007326570219329887\n",
      "train loss:0.013293668859111856\n",
      "train loss:0.028221727155258884\n",
      "train loss:0.08265821138571072\n",
      "train loss:0.03160766352617162\n",
      "train loss:0.012058859538043833\n",
      "train loss:0.02339060481038134\n",
      "train loss:0.027844304131205214\n",
      "train loss:0.003164360570016622\n",
      "train loss:0.007321623088159353\n",
      "train loss:0.019459584465427913\n",
      "train loss:0.03671188679245181\n",
      "train loss:0.030468420973178315\n",
      "train loss:0.04316554588726206\n",
      "train loss:0.011268842837692776\n",
      "train loss:0.018603738968810977\n",
      "train loss:0.016396233402426914\n",
      "train loss:0.011703922771005704\n",
      "train loss:0.053309024798324146\n",
      "train loss:0.0050446589410364975\n",
      "train loss:0.023860222195000676\n",
      "train loss:0.008464990677696599\n",
      "train loss:0.01383153859572903\n",
      "train loss:0.01825764751213128\n",
      "train loss:0.023995808227578554\n",
      "train loss:0.029294027303762054\n",
      "train loss:0.019258836277115828\n",
      "train loss:0.024519100793453662\n",
      "train loss:0.01572029181386105\n",
      "train loss:0.01500431806612811\n",
      "train loss:0.013718887072528461\n",
      "train loss:0.02386285035273256\n",
      "train loss:0.015581679556394583\n",
      "train loss:0.006112336051942075\n",
      "train loss:0.01599774770813001\n",
      "train loss:0.010003818407991256\n",
      "train loss:0.013225974086874925\n",
      "train loss:0.02809056704040781\n",
      "train loss:0.016067461272969746\n",
      "train loss:0.029463948158584375\n",
      "train loss:0.015289872016937916\n",
      "train loss:0.021958526977524765\n",
      "train loss:0.0051769794898874\n",
      "train loss:0.00827456961766714\n",
      "train loss:0.028736178354718523\n",
      "train loss:0.019306487525051843\n",
      "train loss:0.06618917836539741\n",
      "train loss:0.017705995554356185\n",
      "train loss:0.015042074967689698\n",
      "train loss:0.02061023251617536\n",
      "train loss:0.09440715667402054\n",
      "train loss:0.03953623257220566\n",
      "train loss:0.008342179172053803\n",
      "train loss:0.004333979881927783\n",
      "train loss:0.10224525249958666\n",
      "train loss:0.008392512133011292\n",
      "train loss:0.054033682073424266\n",
      "train loss:0.054504965610545526\n",
      "train loss:0.013427253315576468\n",
      "train loss:0.016036339813532037\n",
      "train loss:0.01928070206217414\n",
      "train loss:0.011890091052468273\n",
      "train loss:0.009984389642053953\n",
      "train loss:0.013216399560174065\n",
      "train loss:0.06519672646773685\n",
      "train loss:0.021121860641223046\n",
      "train loss:0.007971882683896753\n",
      "train loss:0.05204456649124874\n",
      "train loss:0.025228311267465768\n",
      "train loss:0.016281098605240633\n",
      "train loss:0.010072478402202722\n",
      "train loss:0.010940532686074115\n",
      "train loss:0.08258021569376721\n",
      "train loss:0.017841326774912486\n",
      "train loss:0.035700936556638994\n",
      "train loss:0.0186393619522087\n",
      "train loss:0.008441670950797741\n",
      "train loss:0.02338900456862525\n",
      "train loss:0.017396611844791427\n",
      "train loss:0.029343729173752376\n",
      "train loss:0.014740611589820459\n",
      "train loss:0.01993888689572569\n",
      "train loss:0.018382548600447267\n",
      "train loss:0.025063038379448406\n",
      "train loss:0.022564861474727933\n",
      "train loss:0.05540445084939545\n",
      "train loss:0.026490254772426378\n",
      "train loss:0.030783424629421824\n",
      "train loss:0.005564919091306175\n",
      "train loss:0.005372446703910136\n",
      "train loss:0.022556678961567475\n",
      "train loss:0.007797229977444934\n",
      "train loss:0.008103055820841221\n",
      "train loss:0.07038779197018825\n",
      "train loss:0.015196688114666936\n",
      "train loss:0.01153498497225045\n",
      "train loss:0.01988131629397524\n",
      "train loss:0.004268124901018701\n",
      "train loss:0.01655271401781486\n",
      "train loss:0.02995894098724676\n",
      "train loss:0.003607422782711365\n",
      "train loss:0.0071456861983683366\n",
      "train loss:0.011595059778158945\n",
      "train loss:0.034696873873682095\n",
      "train loss:0.023097541649081673\n",
      "train loss:0.01293202165192039\n",
      "train loss:0.01487762074086355\n",
      "train loss:0.004179632878990691\n",
      "train loss:0.06891421200928717\n",
      "train loss:0.058909275046149664\n",
      "train loss:0.004739281425239229\n",
      "train loss:0.024209489373906143\n",
      "train loss:0.015234673216579066\n",
      "train loss:0.005695128402651368\n",
      "train loss:0.003982944048673628\n",
      "train loss:0.012740927889704299\n",
      "train loss:0.019232812544107393\n",
      "train loss:0.06075674158176207\n",
      "train loss:0.030532394282230334\n",
      "train loss:0.01499394300117778\n",
      "train loss:0.004119814025081576\n",
      "train loss:0.005982915101173567\n",
      "train loss:0.02551866520331679\n",
      "train loss:0.032151488381677605\n",
      "train loss:0.023640985407481538\n",
      "train loss:0.026530677777280274\n",
      "train loss:0.025969307268052307\n",
      "train loss:0.0018512449949975238\n",
      "train loss:0.015382990388684663\n",
      "train loss:0.02004799352872812\n",
      "train loss:0.04376528202585847\n",
      "train loss:0.010382675204820533\n",
      "train loss:0.2053309164046414\n",
      "train loss:0.05523693064257541\n",
      "train loss:0.05667672823438855\n",
      "train loss:0.017374520178951868\n",
      "train loss:0.005399366562463791\n",
      "train loss:0.014020026367825787\n",
      "train loss:0.015994699203730995\n",
      "train loss:0.023293400612745475\n",
      "train loss:0.020791805762138505\n",
      "train loss:0.010252662884007412\n",
      "train loss:0.017201049888853875\n",
      "train loss:0.03603265948074244\n",
      "train loss:0.021384011587424086\n",
      "train loss:0.043249635618704346\n",
      "train loss:0.007911510108201274\n",
      "train loss:0.00594613563607583\n",
      "train loss:0.011201573391254356\n",
      "train loss:0.01804849693086833\n",
      "train loss:0.01167631155826666\n",
      "train loss:0.028660198412868446\n",
      "train loss:0.00855096887149831\n",
      "train loss:0.005197400977877651\n",
      "train loss:0.01244714616872948\n",
      "train loss:0.031744156227585224\n",
      "train loss:0.041297958507381965\n",
      "train loss:0.01736499647309629\n",
      "train loss:0.00836409612873736\n",
      "train loss:0.0015852541862787712\n",
      "train loss:0.03303934145504235\n",
      "train loss:0.012422191919607563\n",
      "train loss:0.011968686488586944\n",
      "train loss:0.014390691864598085\n",
      "train loss:0.057328860238114156\n",
      "train loss:0.0035091227450704436\n",
      "train loss:0.00429118936933484\n",
      "train loss:0.024253565736545836\n",
      "train loss:0.003331290581380417\n",
      "train loss:0.009696741946755015\n",
      "train loss:0.04742059100151209\n",
      "train loss:0.015541834471955854\n",
      "train loss:0.04431925402095957\n",
      "train loss:0.10908559851396232\n",
      "train loss:0.012372669351375931\n",
      "train loss:0.008900149419307229\n",
      "train loss:0.013092547662781282\n",
      "train loss:0.00738584142248297\n",
      "train loss:0.012227601881332904\n",
      "train loss:0.05012629907215933\n",
      "train loss:0.025879788709444396\n",
      "train loss:0.019605178091023488\n",
      "train loss:0.07470772974831266\n",
      "train loss:0.07780842743160947\n",
      "train loss:0.049065317690037864\n",
      "train loss:0.023141402619145622\n",
      "train loss:0.009870084853284899\n",
      "train loss:0.015820403396466235\n",
      "train loss:0.010718195877992642\n",
      "train loss:0.016565882512703065\n",
      "train loss:0.009621698819438805\n",
      "train loss:0.013337354203590777\n",
      "train loss:0.05796949001351322\n",
      "train loss:0.0026720317468845478\n",
      "train loss:0.01683409669079361\n",
      "train loss:0.013513902210974392\n",
      "train loss:0.00847671805362936\n",
      "train loss:0.03702822336244562\n",
      "train loss:0.021568390921664345\n",
      "train loss:0.05135225770811578\n",
      "train loss:0.020714687142074677\n",
      "train loss:0.005403493081310419\n",
      "train loss:0.011882395024755198\n",
      "train loss:0.031366784246084405\n",
      "train loss:0.016271708018357183\n",
      "train loss:0.014686122217605877\n",
      "train loss:0.017789348985912893\n",
      "train loss:0.014221527747039733\n",
      "train loss:0.025717237465251765\n",
      "train loss:0.011219084221271271\n",
      "train loss:0.039827737808601535\n",
      "train loss:0.007330508490222411\n",
      "train loss:0.025592774994535453\n",
      "train loss:0.0027395003520985744\n",
      "train loss:0.04101845210657964\n",
      "train loss:0.022774133150049072\n",
      "train loss:0.016440720655504778\n",
      "train loss:0.07551260627942588\n",
      "train loss:0.01253384917803669\n",
      "train loss:0.00962791801656702\n",
      "train loss:0.027212923990149872\n",
      "train loss:0.04083785002695128\n",
      "train loss:0.02902515794955176\n",
      "train loss:0.02536474742843563\n",
      "train loss:0.0316151934452968\n",
      "train loss:0.026657827042747148\n",
      "train loss:0.009363309388468716\n",
      "train loss:0.02431315909969828\n",
      "train loss:0.01321096866565586\n",
      "train loss:0.023192292877887023\n",
      "train loss:0.020508025568915268\n",
      "train loss:0.03003161629341546\n",
      "train loss:0.016582246073714606\n",
      "train loss:0.0046245110926955105\n",
      "train loss:0.003896372772104716\n",
      "train loss:0.015672233026625352\n",
      "train loss:0.027365987402457506\n",
      "train loss:0.02103680318610719\n",
      "train loss:0.012571125844298599\n",
      "train loss:0.029332510807096125\n",
      "train loss:0.012235454410295428\n",
      "train loss:0.018564878041519482\n",
      "train loss:0.037433541391329574\n",
      "train loss:0.0038144332901176143\n",
      "train loss:0.06611805938968097\n",
      "train loss:0.007746992940423965\n",
      "train loss:0.03591436062321189\n",
      "train loss:0.04074713929160006\n",
      "train loss:0.013765242695489777\n",
      "train loss:0.0055499431770433885\n",
      "train loss:0.01567985857366604\n",
      "train loss:0.004705214112023085\n",
      "train loss:0.035062788983719596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0022856114931950715\n",
      "train loss:0.00405620275653925\n",
      "train loss:0.008578923814355967\n",
      "train loss:0.010231906420558348\n",
      "train loss:0.03543424071865922\n",
      "train loss:0.01190945076075266\n",
      "train loss:0.046314249878404115\n",
      "train loss:0.02312020976437866\n",
      "train loss:0.014308791103484519\n",
      "train loss:0.02050294669523023\n",
      "train loss:0.018281456252352547\n",
      "train loss:0.039184791917052895\n",
      "train loss:0.007525040918299583\n",
      "train loss:0.019401476541092467\n",
      "train loss:0.06382276495146343\n",
      "train loss:0.06688235397962641\n",
      "train loss:0.027306751093617434\n",
      "train loss:0.019136244941451542\n",
      "train loss:0.013750613280453747\n",
      "train loss:0.02120804311471861\n",
      "train loss:0.003915163744697234\n",
      "train loss:0.015255110423780225\n",
      "train loss:0.008051059165482467\n",
      "train loss:0.013885039364869598\n",
      "train loss:0.025054353060769096\n",
      "train loss:0.011241799813690166\n",
      "train loss:0.01922191724680084\n",
      "train loss:0.02559696584048949\n",
      "train loss:0.01945241748116561\n",
      "train loss:0.037118020204309224\n",
      "train loss:0.0034046990546871673\n",
      "train loss:0.003109659543057102\n",
      "train loss:0.020207371111445625\n",
      "train loss:0.004537098869714806\n",
      "train loss:0.05228739065953687\n",
      "train loss:0.05834200239940385\n",
      "train loss:0.004467518782771854\n",
      "train loss:0.051004467100398326\n",
      "train loss:0.0026836031402250847\n",
      "train loss:0.016879962085296348\n",
      "train loss:0.014297353971621298\n",
      "train loss:0.01746363699474733\n",
      "train loss:0.023374391737984876\n",
      "train loss:0.09201895708085636\n",
      "train loss:0.006757454253768206\n",
      "train loss:0.05750266359927943\n",
      "train loss:0.014513878716482426\n",
      "train loss:0.0035288211620148014\n",
      "train loss:0.02293357670558441\n",
      "train loss:0.10897923278455\n",
      "train loss:0.010539057716366205\n",
      "train loss:0.013432741634885566\n",
      "train loss:0.034838043018043996\n",
      "train loss:0.016435600248460094\n",
      "train loss:0.04433720998184236\n",
      "train loss:0.01775723084298156\n",
      "train loss:0.06804532613970359\n",
      "train loss:0.0072816670812240825\n",
      "train loss:0.009934390253346902\n",
      "train loss:0.005780759713070769\n",
      "train loss:0.010770677913743499\n",
      "train loss:0.010222827821419945\n",
      "train loss:0.02004644815219698\n",
      "train loss:0.06713618898391424\n",
      "train loss:0.04482890625637509\n",
      "train loss:0.015588320069829499\n",
      "train loss:0.003785290495294737\n",
      "train loss:0.011473054502748152\n",
      "train loss:0.009957729610238004\n",
      "train loss:0.08510975875744563\n",
      "train loss:0.01467935554097118\n",
      "train loss:0.01309107647460845\n",
      "train loss:0.13340942845489662\n",
      "train loss:0.01672793354206973\n",
      "train loss:0.007662515213702784\n",
      "train loss:0.005962365628277305\n",
      "train loss:0.009816205739541329\n",
      "train loss:0.001751456690340427\n",
      "train loss:0.04936817002166802\n",
      "train loss:0.01382200308402712\n",
      "train loss:0.040515730829593616\n",
      "train loss:0.006615313557938032\n",
      "train loss:0.017218414858825245\n",
      "train loss:0.011584081044800068\n",
      "train loss:0.010154516594089377\n",
      "train loss:0.015235239430915377\n",
      "train loss:0.030109308586958056\n",
      "train loss:0.010143789463020076\n",
      "train loss:0.009376757932479931\n",
      "train loss:0.012518661710861108\n",
      "train loss:0.007974960882757913\n",
      "train loss:0.010493772462256747\n",
      "train loss:0.004653208785194775\n",
      "train loss:0.011957160723740885\n",
      "train loss:0.021826185442128172\n",
      "train loss:0.061411597748515005\n",
      "train loss:0.014615684275322238\n",
      "train loss:0.028239113770574736\n",
      "train loss:0.0328891621775954\n",
      "train loss:0.06694787173720712\n",
      "train loss:0.01697150043391305\n",
      "train loss:0.004279237321679932\n",
      "train loss:0.026307543181045678\n",
      "train loss:0.018449629984565067\n",
      "train loss:0.07596248604851975\n",
      "train loss:0.019842880643009073\n",
      "train loss:0.03966660975746843\n",
      "train loss:0.03288261298186699\n",
      "train loss:0.003798248264439959\n",
      "train loss:0.005915471575650535\n",
      "train loss:0.017942654549296513\n",
      "=== epoch:6, train acc:0.988, test acc:0.981 ===\n",
      "train loss:0.005518421436009971\n",
      "train loss:0.006869384795595641\n",
      "train loss:0.002541125582848628\n",
      "train loss:0.00490692291586969\n",
      "train loss:0.00273016445657354\n",
      "train loss:0.022540269444164714\n",
      "train loss:0.046879704081717016\n",
      "train loss:0.009042008880507579\n",
      "train loss:0.09525517012876904\n",
      "train loss:0.05062643061217449\n",
      "train loss:0.03303450469757863\n",
      "train loss:0.056228257456534515\n",
      "train loss:0.003937689844397709\n",
      "train loss:0.04135588107912349\n",
      "train loss:0.061762422976628685\n",
      "train loss:0.01620511568658102\n",
      "train loss:0.016079061771150358\n",
      "train loss:0.032868282563116226\n",
      "train loss:0.016295338859694565\n",
      "train loss:0.0355394717010673\n",
      "train loss:0.03786439020216441\n",
      "train loss:0.003810221043202413\n",
      "train loss:0.019792726309383533\n",
      "train loss:0.035548404370745156\n",
      "train loss:0.011521529968543833\n",
      "train loss:0.014815047029920085\n",
      "train loss:0.01571641115922407\n",
      "train loss:0.05676754096183143\n",
      "train loss:0.014739863924098812\n",
      "train loss:0.00755504746387883\n",
      "train loss:0.009814383121728327\n",
      "train loss:0.010711214934925573\n",
      "train loss:0.026361050540125427\n",
      "train loss:0.008624121002073645\n",
      "train loss:0.017115917874397608\n",
      "train loss:0.029366726095031367\n",
      "train loss:0.017919631832192296\n",
      "train loss:0.010974361682627392\n",
      "train loss:0.011214755100934299\n",
      "train loss:0.023956730492922112\n",
      "train loss:0.005561055053630021\n",
      "train loss:0.007078945578610796\n",
      "train loss:0.0018260210621148438\n",
      "train loss:0.012694041164613692\n",
      "train loss:0.009907920310477847\n",
      "train loss:0.031557266038119244\n",
      "train loss:0.011472842480014034\n",
      "train loss:0.009848659031307995\n",
      "train loss:0.0032978340969538745\n",
      "train loss:0.021826119691685842\n",
      "train loss:0.012551035865539533\n",
      "train loss:0.037890781216233876\n",
      "train loss:0.0034060678949848584\n",
      "train loss:0.013089312439403951\n",
      "train loss:0.012742443818790559\n",
      "train loss:0.006239883353377469\n",
      "train loss:0.04034127878958973\n",
      "train loss:0.005831499888541299\n",
      "train loss:0.006027123525730506\n",
      "train loss:0.005709487855391152\n",
      "train loss:0.030352866963699578\n",
      "train loss:0.03093505104162348\n",
      "train loss:0.0065091059915552175\n",
      "train loss:0.014555698207669793\n",
      "train loss:0.03949477559439224\n",
      "train loss:0.03278574300759606\n",
      "train loss:0.0060855032799858495\n",
      "train loss:0.03180730104641781\n",
      "train loss:0.002293010363706613\n",
      "train loss:0.005240175658116317\n",
      "train loss:0.023903274631234758\n",
      "train loss:0.019037601845924353\n",
      "train loss:0.045830369305342004\n",
      "train loss:0.007185937671735921\n",
      "train loss:0.016080903793654275\n",
      "train loss:0.03077228913562051\n",
      "train loss:0.006936478556240161\n",
      "train loss:0.012077803094676327\n",
      "train loss:0.05059449963531614\n",
      "train loss:0.002033073797995677\n",
      "train loss:0.03314049146598312\n",
      "train loss:0.0043026646724762556\n",
      "train loss:0.02507608254615376\n",
      "train loss:0.04685949482284724\n",
      "train loss:0.009470346482341862\n",
      "train loss:0.07283544522112036\n",
      "train loss:0.004871729471129278\n",
      "train loss:0.010733706580392355\n",
      "train loss:0.009033622496328495\n",
      "train loss:0.007930864584075601\n",
      "train loss:0.012090478749983402\n",
      "train loss:0.043300486212162044\n",
      "train loss:0.014422898014901972\n",
      "train loss:0.013213910901960342\n",
      "train loss:0.007450235008692985\n",
      "train loss:0.017895692338866242\n",
      "train loss:0.05954785483040838\n",
      "train loss:0.03668672477819555\n",
      "train loss:0.002988773223728107\n",
      "train loss:0.11786580498008338\n",
      "train loss:0.0034856539506723867\n",
      "train loss:0.006479965997133333\n",
      "train loss:0.01809074465297034\n",
      "train loss:0.0057165601080447935\n",
      "train loss:0.007889776534492195\n",
      "train loss:0.009016864364646255\n",
      "train loss:0.025615556206094747\n",
      "train loss:0.014218641815748143\n",
      "train loss:0.0015579965137301048\n",
      "train loss:0.01965459863640136\n",
      "train loss:0.007426924072788964\n",
      "train loss:0.010470140745433105\n",
      "train loss:0.0072526617255947124\n",
      "train loss:0.021066202070885876\n",
      "train loss:0.005095569138828399\n",
      "train loss:0.0571300811827444\n",
      "train loss:0.011650964242191532\n",
      "train loss:0.00478324563266977\n",
      "train loss:0.005959226856519158\n",
      "train loss:0.012216141776792177\n",
      "train loss:0.054416862473488765\n",
      "train loss:0.011675003394336338\n",
      "train loss:0.019420962442943564\n",
      "train loss:0.07869457182675607\n",
      "train loss:0.02716785591437389\n",
      "train loss:0.02836651185663032\n",
      "train loss:0.010979599602148376\n",
      "train loss:0.036062123752582304\n",
      "train loss:0.012196749904079707\n",
      "train loss:0.012503390155167892\n",
      "train loss:0.02023711689706571\n",
      "train loss:0.029376951684437352\n",
      "train loss:0.006747056421277942\n",
      "train loss:0.030547319176455395\n",
      "train loss:0.00732085753051066\n",
      "train loss:0.012251100231365579\n",
      "train loss:0.003711402988127148\n",
      "train loss:0.005152634950391313\n",
      "train loss:0.05253926792170156\n",
      "train loss:0.02208436829737335\n",
      "train loss:0.01807837066400991\n",
      "train loss:0.004434607949774158\n",
      "train loss:0.010852298899559716\n",
      "train loss:0.014309909204100118\n",
      "train loss:0.008185156374540883\n",
      "train loss:0.021650356181690353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.009684005977867002\n",
      "train loss:0.022617018967945494\n",
      "train loss:0.06538055510888523\n",
      "train loss:0.007023179251328795\n",
      "train loss:0.06628330101898544\n",
      "train loss:0.0030511433067772274\n",
      "train loss:0.005513613805811291\n",
      "train loss:0.026383741264892725\n",
      "train loss:0.008804141974168437\n",
      "train loss:0.08143775179788436\n",
      "train loss:0.005403263029498562\n",
      "train loss:0.003612077302623582\n",
      "train loss:0.014556525741085586\n",
      "train loss:0.009904149695081053\n",
      "train loss:0.03844397759338792\n",
      "train loss:0.01674077658924162\n",
      "train loss:0.009287877855308477\n",
      "train loss:0.007321623026071455\n",
      "train loss:0.023715426216772428\n",
      "train loss:0.023262445668775854\n",
      "train loss:0.007509946668051775\n",
      "train loss:0.0022600753740479734\n",
      "train loss:0.008465647556994365\n",
      "train loss:0.010412174564787414\n",
      "train loss:0.02409819495055075\n",
      "train loss:0.017877240679772043\n",
      "train loss:0.046656510887057745\n",
      "train loss:0.008693441570118868\n",
      "train loss:0.00866162074594429\n",
      "train loss:0.0017667039052586782\n",
      "train loss:0.010733688374598703\n",
      "train loss:0.019170761419038077\n",
      "train loss:0.012559448920000094\n",
      "train loss:0.045667136472484555\n",
      "train loss:0.003909229972229975\n",
      "train loss:0.021799644573995514\n",
      "train loss:0.006646087142649573\n",
      "train loss:0.003582660609461392\n",
      "train loss:0.03887278973728128\n",
      "train loss:0.019028340716425146\n",
      "train loss:0.00612691771526142\n",
      "train loss:0.015431445766670604\n",
      "train loss:0.014964135054213542\n",
      "train loss:0.012268774340360111\n",
      "train loss:0.010221472824485357\n",
      "train loss:0.0013338454519162706\n",
      "train loss:0.005461341625248586\n",
      "train loss:0.014379205797952741\n",
      "train loss:0.009837190258324158\n",
      "train loss:0.004519682150372399\n",
      "train loss:0.007932592397066772\n",
      "train loss:0.024095925186371235\n",
      "train loss:0.008439405934353803\n",
      "train loss:0.025785660408348524\n",
      "train loss:0.014118991204993627\n",
      "train loss:0.006335991165103536\n",
      "train loss:0.014941315392357388\n",
      "train loss:0.011710140344325326\n",
      "train loss:0.07120003761936823\n",
      "train loss:0.007072370302608443\n",
      "train loss:0.010479385933103949\n",
      "train loss:0.033294790483211295\n",
      "train loss:0.03253791669892613\n",
      "train loss:0.032549485810899455\n",
      "train loss:0.018938401606132624\n",
      "train loss:0.007560321568924522\n",
      "train loss:0.007871631858199793\n",
      "train loss:0.033708612766142204\n",
      "train loss:0.005801282394746593\n",
      "train loss:0.01082616311009842\n",
      "train loss:0.013579013488311038\n",
      "train loss:0.01571133307895546\n",
      "train loss:0.008954053589972163\n",
      "train loss:0.035075611281469306\n",
      "train loss:0.028244049961932163\n",
      "train loss:0.03122463426270146\n",
      "train loss:0.001328533811732243\n",
      "train loss:0.030514014442932114\n",
      "train loss:0.012630319786655606\n",
      "train loss:0.018965885549289418\n",
      "train loss:0.003917504382439608\n",
      "train loss:0.011194716633155927\n",
      "train loss:0.010748878917947647\n",
      "train loss:0.008798132948991429\n",
      "train loss:0.011097253676980643\n",
      "train loss:0.009530193900022162\n",
      "train loss:0.006046463816706243\n",
      "train loss:0.01401001091442139\n",
      "train loss:0.003701106095489348\n",
      "train loss:0.02301417417540037\n",
      "train loss:0.004963808035891406\n",
      "train loss:0.003974833253297234\n",
      "train loss:0.00956635699279717\n",
      "train loss:0.0049616476009274576\n",
      "train loss:0.01241523964790526\n",
      "train loss:0.013129041872689737\n",
      "train loss:0.009731878036206622\n",
      "train loss:0.018988318218772\n",
      "train loss:0.02490669108215278\n",
      "train loss:0.010034028602345669\n",
      "train loss:0.08536884264108636\n",
      "train loss:0.014001681257275012\n",
      "train loss:0.008007116712117023\n",
      "train loss:0.007800339541357932\n",
      "train loss:0.0032689179883824996\n",
      "train loss:0.011727956571962836\n",
      "train loss:0.03759115873290164\n",
      "train loss:0.001921316083797381\n",
      "train loss:0.013271279861377334\n",
      "train loss:0.014171539636971396\n",
      "train loss:0.026070737941995766\n",
      "train loss:0.10633090409573837\n",
      "train loss:0.03318107860566775\n",
      "train loss:0.010004081053678678\n",
      "train loss:0.007256912010873791\n",
      "train loss:0.010873471524884801\n",
      "train loss:0.018345903815560168\n",
      "train loss:0.007404617001490293\n",
      "train loss:0.012038100408745266\n",
      "train loss:0.03852466915071587\n",
      "train loss:0.014301290608593817\n",
      "train loss:0.023097329158015777\n",
      "train loss:0.0037620517107176577\n",
      "train loss:0.003914834010013488\n",
      "train loss:0.03291296187698901\n",
      "train loss:0.00926341584073372\n",
      "train loss:0.06344068818560408\n",
      "train loss:0.0040761700498853064\n",
      "train loss:0.005180557437587716\n",
      "train loss:0.024405965310724188\n",
      "train loss:0.0016144953137900986\n",
      "train loss:0.0642564848245757\n",
      "train loss:0.05673709588521904\n",
      "train loss:0.004318255484755503\n",
      "train loss:0.03495719007300671\n",
      "train loss:0.020424920862225297\n",
      "train loss:0.06387510777922328\n",
      "train loss:0.011618915706189791\n",
      "train loss:0.04516603149158139\n",
      "train loss:0.01983963087820868\n",
      "train loss:0.050861599704255786\n",
      "train loss:0.024501442987332474\n",
      "train loss:0.01565476393224302\n",
      "train loss:0.004754335636509286\n",
      "train loss:0.022609126543350157\n",
      "train loss:0.009375391852043068\n",
      "train loss:0.0025651928174055027\n",
      "train loss:0.006583906558324477\n",
      "train loss:0.0057364196789460075\n",
      "train loss:0.007010128482791261\n",
      "train loss:0.020580330541479598\n",
      "train loss:0.008737343754177023\n",
      "train loss:0.014309134803838395\n",
      "train loss:0.018496939216744956\n",
      "train loss:0.009277076648525916\n",
      "train loss:0.002412900776373755\n",
      "train loss:0.0026495891402836588\n",
      "train loss:0.01395238654945087\n",
      "train loss:0.007023153729162004\n",
      "train loss:0.026906602324902162\n",
      "train loss:0.038598484930587616\n",
      "train loss:0.00785555408431661\n",
      "train loss:0.006717753569286558\n",
      "train loss:0.033738931695978025\n",
      "train loss:0.16810679920785176\n",
      "train loss:0.027504150852034767\n",
      "train loss:0.011549889464915268\n",
      "train loss:0.01619663599298848\n",
      "train loss:0.02113977943049246\n",
      "train loss:0.05668464445917747\n",
      "train loss:0.021108802012708497\n",
      "train loss:0.014604189866488817\n",
      "train loss:0.006957831946976517\n",
      "train loss:0.010844175285606432\n",
      "train loss:0.004854571526943474\n",
      "train loss:0.011513403260210622\n",
      "train loss:0.0478498996880406\n",
      "train loss:0.024779032387883104\n",
      "train loss:0.0049112836085159275\n",
      "train loss:0.031552997762398845\n",
      "train loss:0.009063040343460494\n",
      "train loss:0.026231336204703797\n",
      "train loss:0.009259722789239942\n",
      "train loss:0.0073642151018611015\n",
      "train loss:0.04332759237301409\n",
      "train loss:0.012860833585410392\n",
      "train loss:0.01686796168376816\n",
      "train loss:0.01171402690182894\n",
      "train loss:0.013086262483386653\n",
      "train loss:0.054255183530019985\n",
      "train loss:0.024167448126311664\n",
      "train loss:0.005887751015990337\n",
      "train loss:0.030912759263217154\n",
      "train loss:0.05293477851721873\n",
      "train loss:0.012130583509305818\n",
      "train loss:0.05779871851251975\n",
      "train loss:0.01850273857164922\n",
      "train loss:0.02347376257733372\n",
      "train loss:0.026513094083590677\n",
      "train loss:0.016429211294741383\n",
      "train loss:0.027821312665298113\n",
      "train loss:0.03948995035239217\n",
      "train loss:0.01136291127416452\n",
      "train loss:0.013892421352638556\n",
      "train loss:0.012686822943612463\n",
      "train loss:0.021557358073594917\n",
      "train loss:0.016774700995725863\n",
      "train loss:0.025655596108751063\n",
      "train loss:0.10266455064877839\n",
      "train loss:0.018454003059578485\n",
      "train loss:0.04973328110716456\n",
      "train loss:0.011436598829517634\n",
      "train loss:0.01534061328227695\n",
      "train loss:0.011659834510710634\n",
      "train loss:0.00951671469626059\n",
      "train loss:0.007799837946420065\n",
      "train loss:0.015101964398496249\n",
      "train loss:0.019949658668445173\n",
      "train loss:0.028534180149234967\n",
      "train loss:0.013103370705024826\n",
      "train loss:0.0017493232478462404\n",
      "train loss:0.008923886533043948\n",
      "train loss:0.008463181800056925\n",
      "train loss:0.012957632779015304\n",
      "train loss:0.0053178583119848745\n",
      "train loss:0.008017477778679519\n",
      "train loss:0.0024833353001144677\n",
      "train loss:0.018519684687447566\n",
      "train loss:0.00683920645495912\n",
      "train loss:0.012831640994003326\n",
      "train loss:0.019025434495502973\n",
      "train loss:0.014833316457289653\n",
      "train loss:0.016449858304917055\n",
      "train loss:0.012540498078435798\n",
      "train loss:0.0172117887679144\n",
      "train loss:0.0035392507349285805\n",
      "train loss:0.004992647958934557\n",
      "train loss:0.04315886220045801\n",
      "train loss:0.02123210215024558\n",
      "train loss:0.014487671464923954\n",
      "train loss:0.004350537189366331\n",
      "train loss:0.007975507885130568\n",
      "train loss:0.010587433317579033\n",
      "train loss:0.0028626523004886316\n",
      "train loss:0.09548622392667312\n",
      "train loss:0.02647402553185947\n",
      "train loss:0.034452818962697196\n",
      "train loss:0.016610460839965212\n",
      "train loss:0.04775878061081353\n",
      "train loss:0.011938835164152924\n",
      "train loss:0.011561547375257896\n",
      "train loss:0.01860536081621269\n",
      "train loss:0.016396623887856853\n",
      "train loss:0.02164473985168493\n",
      "train loss:0.010848669104275893\n",
      "train loss:0.005204489680419998\n",
      "train loss:0.047882276379976954\n",
      "train loss:0.012979297541009998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.043716452372139926\n",
      "train loss:0.019395218776895685\n",
      "train loss:0.010920865088657045\n",
      "train loss:0.0026659649419346417\n",
      "train loss:0.012016938093353254\n",
      "train loss:0.011227281790015498\n",
      "train loss:0.03135785105704279\n",
      "train loss:0.010254077631292609\n",
      "train loss:0.02153412753238958\n",
      "train loss:0.009412179509206475\n",
      "train loss:0.012836493678600134\n",
      "train loss:0.024557307337776196\n",
      "train loss:0.010259308868526806\n",
      "train loss:0.0021414640677404548\n",
      "train loss:0.014149993445957014\n",
      "train loss:0.0025658927081646226\n",
      "train loss:0.007283058528018286\n",
      "train loss:0.014959542963024286\n",
      "train loss:0.009589608738254872\n",
      "train loss:0.013794536971335848\n",
      "train loss:0.0028152290168572806\n",
      "train loss:0.0007640341719841443\n",
      "train loss:0.012112437856589784\n",
      "train loss:0.015775137300765896\n",
      "train loss:0.10934935220978163\n",
      "train loss:0.012937389504584477\n",
      "train loss:0.04510234042142346\n",
      "train loss:0.018209794338946605\n",
      "train loss:0.05010523254093337\n",
      "train loss:0.01146417801462263\n",
      "train loss:0.0073063983273442545\n",
      "train loss:0.061491494459741745\n",
      "train loss:0.008902048296700436\n",
      "train loss:0.019467990352166654\n",
      "train loss:0.043617525577235534\n",
      "train loss:0.009701975494154724\n",
      "train loss:0.011372758449725816\n",
      "train loss:0.11272752225613214\n",
      "train loss:0.013255065254751947\n",
      "train loss:0.018343317678403883\n",
      "train loss:0.010793498495341908\n",
      "train loss:0.008691083782534036\n",
      "train loss:0.012211807775155587\n",
      "train loss:0.020711358297943062\n",
      "train loss:0.024827892057906108\n",
      "train loss:0.007282044545780203\n",
      "train loss:0.012360707829163809\n",
      "train loss:0.011193996396714045\n",
      "train loss:0.013068003440973171\n",
      "train loss:0.012873285314690333\n",
      "train loss:0.005531393828062786\n",
      "train loss:0.0024023104116570105\n",
      "train loss:0.012564566094383563\n",
      "train loss:0.07350736279025423\n",
      "train loss:0.005160867023574113\n",
      "train loss:0.007599119985462196\n",
      "train loss:0.03702481422310362\n",
      "train loss:0.0021971233156803296\n",
      "train loss:0.014939870874138143\n",
      "train loss:0.034749784610793165\n",
      "train loss:0.01229824929395126\n",
      "train loss:0.021852393595921515\n",
      "train loss:0.05076092341424594\n",
      "train loss:0.028436523977823255\n",
      "train loss:0.022909757849108467\n",
      "train loss:0.00912473409486415\n",
      "train loss:0.010741028516792707\n",
      "train loss:0.012007769384673992\n",
      "train loss:0.015414122233178342\n",
      "train loss:0.004083309852015651\n",
      "train loss:0.019498175209937598\n",
      "train loss:0.040356839022971824\n",
      "train loss:0.0016089731079237239\n",
      "train loss:0.031907463816227916\n",
      "train loss:0.007703823135107035\n",
      "train loss:0.036290476535098946\n",
      "train loss:0.01337929279852716\n",
      "train loss:0.01038195843781351\n",
      "train loss:0.0457413141924293\n",
      "train loss:0.015244518256403447\n",
      "train loss:0.0036305409251573095\n",
      "train loss:0.06702895776642291\n",
      "train loss:0.009087219465293946\n",
      "train loss:0.0033765259600110247\n",
      "train loss:0.014189790272104605\n",
      "train loss:0.009849114658370225\n",
      "train loss:0.01361342717094512\n",
      "train loss:0.04730181332597447\n",
      "train loss:0.13054071013688093\n",
      "train loss:0.009920660207879428\n",
      "train loss:0.01662434759755503\n",
      "train loss:0.024157788135504885\n",
      "train loss:0.008612854551481936\n",
      "train loss:0.008578853002102654\n",
      "train loss:0.00825612033182991\n",
      "train loss:0.013969283285153818\n",
      "train loss:0.06278569470995583\n",
      "train loss:0.053896969792130794\n",
      "train loss:0.030220533613612748\n",
      "train loss:0.001041281167251641\n",
      "train loss:0.010964521155030195\n",
      "train loss:0.005670267639667623\n",
      "train loss:0.010423298480435814\n",
      "train loss:0.009178926461713702\n",
      "train loss:0.04685225906672984\n",
      "train loss:0.058872231134327935\n",
      "train loss:0.0055918068048268444\n",
      "train loss:0.012856707048883533\n",
      "train loss:0.002459841808068792\n",
      "train loss:0.009782320760746848\n",
      "train loss:0.01075342259798768\n",
      "train loss:0.024628705826875995\n",
      "train loss:0.021278512605542418\n",
      "train loss:0.013924641004693617\n",
      "train loss:0.004991634605794439\n",
      "train loss:0.026320231173805834\n",
      "train loss:0.02439886496554299\n",
      "train loss:0.01609994571766833\n",
      "train loss:0.003520417805033833\n",
      "train loss:0.00447438893685\n",
      "train loss:0.008929086031849625\n",
      "train loss:0.023452225719886546\n",
      "train loss:0.008925724486857049\n",
      "train loss:0.0020121218300148277\n",
      "train loss:0.006287075785438006\n",
      "train loss:0.03303603006245899\n",
      "train loss:0.0011401884878447864\n",
      "train loss:0.006462549581580761\n",
      "train loss:0.00909468922582537\n",
      "train loss:0.018323481065107738\n",
      "train loss:0.02201161932813264\n",
      "train loss:0.042830778468256205\n",
      "train loss:0.004004785824009844\n",
      "train loss:0.02842780879890434\n",
      "train loss:0.017955198253677026\n",
      "train loss:0.08463142781442519\n",
      "train loss:0.03766664171869631\n",
      "train loss:0.05849829816407382\n",
      "train loss:0.021176252899221034\n",
      "train loss:0.013374775593641417\n",
      "train loss:0.004030232976552052\n",
      "train loss:0.005108466330073096\n",
      "train loss:0.017164783337604572\n",
      "train loss:0.006436964827714824\n",
      "train loss:0.011045148624138506\n",
      "train loss:0.00523060793059486\n",
      "train loss:0.00962146072780949\n",
      "train loss:0.010344801748014564\n",
      "train loss:0.004970700514414086\n",
      "train loss:0.0047319222715981706\n",
      "train loss:0.0065064051592947526\n",
      "train loss:0.04099883075077242\n",
      "train loss:0.036515642780572274\n",
      "train loss:0.03237367763789879\n",
      "train loss:0.003396919552351351\n",
      "train loss:0.028169646705327914\n",
      "train loss:0.02149452975208434\n",
      "train loss:0.009079188772944606\n",
      "train loss:0.007180398405153058\n",
      "train loss:0.004876236819988046\n",
      "train loss:0.016938832442177622\n",
      "train loss:0.005436413629358031\n",
      "train loss:0.00421315537126546\n",
      "train loss:0.006980371571734077\n",
      "train loss:0.06943766238869865\n",
      "train loss:0.012791933255358955\n",
      "train loss:0.024877425991220673\n",
      "train loss:0.010324058124727595\n",
      "train loss:0.0416375314924849\n",
      "train loss:0.005679265260607338\n",
      "train loss:0.006795050764013539\n",
      "train loss:0.004249561024073059\n",
      "train loss:0.007856276464091932\n",
      "train loss:0.05550006732200946\n",
      "train loss:0.03210853960222728\n",
      "train loss:0.013274839075597596\n",
      "train loss:0.04154237349859839\n",
      "train loss:0.009804087985991656\n",
      "train loss:0.039556302398284386\n",
      "train loss:0.023276275817724006\n",
      "train loss:0.014443288551809055\n",
      "train loss:0.027001023337666855\n",
      "train loss:0.002416953134775583\n",
      "train loss:0.0031697594072342015\n",
      "train loss:0.006908664633363988\n",
      "train loss:0.00974865566417348\n",
      "train loss:0.006913895081174376\n",
      "train loss:0.011774752913484603\n",
      "train loss:0.008834764996093118\n",
      "train loss:0.03253367104169406\n",
      "train loss:0.029859541557831753\n",
      "train loss:0.01301502966447652\n",
      "train loss:0.022045819910790555\n",
      "train loss:0.008937460014959334\n",
      "train loss:0.007955842015933284\n",
      "train loss:0.044513138361340784\n",
      "=== epoch:7, train acc:0.985, test acc:0.983 ===\n",
      "train loss:0.010221718803335998\n",
      "train loss:0.006616016230669188\n",
      "train loss:0.014916321858375638\n",
      "train loss:0.04137809197079917\n",
      "train loss:0.01880491232125923\n",
      "train loss:0.008916193994756724\n",
      "train loss:0.013982677277950755\n",
      "train loss:0.013140843491416487\n",
      "train loss:0.025952844427718745\n",
      "train loss:0.015997749629125497\n",
      "train loss:0.03430698972802908\n",
      "train loss:0.0028614617851205355\n",
      "train loss:0.005585949974595716\n",
      "train loss:0.013052075918550423\n",
      "train loss:0.005783333314227684\n",
      "train loss:0.013010240554998179\n",
      "train loss:0.015645554130940067\n",
      "train loss:0.015931611891330737\n",
      "train loss:0.005658806254752819\n",
      "train loss:0.005207250377631897\n",
      "train loss:0.019481092407527812\n",
      "train loss:0.01562770945198029\n",
      "train loss:0.027503842632119236\n",
      "train loss:0.027093853410288134\n",
      "train loss:0.002862932356542254\n",
      "train loss:0.006549651227523707\n",
      "train loss:0.027285614803162703\n",
      "train loss:0.004807607811856774\n",
      "train loss:0.0347691109399776\n",
      "train loss:0.0774588791992765\n",
      "train loss:0.011201215638451244\n",
      "train loss:0.022482681265323278\n",
      "train loss:0.043236327506395715\n",
      "train loss:0.00820592804691961\n",
      "train loss:0.009615051929412066\n",
      "train loss:0.007844385600646809\n",
      "train loss:0.043218695758975974\n",
      "train loss:0.0042864401568018\n",
      "train loss:0.014233527569384324\n",
      "train loss:0.003400314615505971\n",
      "train loss:0.0032877440623878284\n",
      "train loss:0.06707555176457315\n",
      "train loss:0.007403515148206848\n",
      "train loss:0.009840916562563888\n",
      "train loss:0.015997379441193546\n",
      "train loss:0.00835371757943636\n",
      "train loss:0.0028779368940670905\n",
      "train loss:0.005215277162186882\n",
      "train loss:0.015302170698609074\n",
      "train loss:0.029557922685071198\n",
      "train loss:0.007323638166854768\n",
      "train loss:0.0017637850356099758\n",
      "train loss:0.003334400709685775\n",
      "train loss:0.0020385336445447664\n",
      "train loss:0.011123848009442503\n",
      "train loss:0.005509490168502596\n",
      "train loss:0.019701288826622868\n",
      "train loss:0.029485124144906453\n",
      "train loss:0.006246916089234994\n",
      "train loss:0.005805659507810151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00947483069715675\n",
      "train loss:0.12358543067729229\n",
      "train loss:0.009338982457463512\n",
      "train loss:0.012309420498111371\n",
      "train loss:0.018657094576600045\n",
      "train loss:0.013449761885109504\n",
      "train loss:0.010565474168895868\n",
      "train loss:0.004884392590665503\n",
      "train loss:0.0014789186082710055\n",
      "train loss:0.0419488195403866\n",
      "train loss:0.031486724184161326\n",
      "train loss:0.015936654518030228\n",
      "train loss:0.00572196626978984\n",
      "train loss:0.022483331070608695\n",
      "train loss:0.039252598958673966\n",
      "train loss:0.015328689840885827\n",
      "train loss:0.01152810746985208\n",
      "train loss:0.006547468808483559\n",
      "train loss:0.010741336019087945\n",
      "train loss:0.006395071864405174\n",
      "train loss:0.0026143547312144823\n",
      "train loss:0.030711017345586473\n",
      "train loss:0.028237953352859783\n",
      "train loss:0.008377571638962612\n",
      "train loss:0.06040661309727079\n",
      "train loss:0.014091829066926756\n",
      "train loss:0.013056544999790415\n",
      "train loss:0.007484320297850584\n",
      "train loss:0.011925207592692073\n",
      "train loss:0.0016485864126629419\n",
      "train loss:0.034898691078925424\n",
      "train loss:0.005186559983257382\n",
      "train loss:0.04394535157555577\n",
      "train loss:0.010588795255789636\n",
      "train loss:0.013590028576446452\n",
      "train loss:0.03410564437670528\n",
      "train loss:0.03659361458381277\n",
      "train loss:0.006354091638301355\n",
      "train loss:0.013072455806337546\n",
      "train loss:0.014071642117351586\n",
      "train loss:0.01238121855691958\n",
      "train loss:0.013019993421789208\n",
      "train loss:0.002312681564862551\n",
      "train loss:0.00300247103971231\n",
      "train loss:0.03556029270806347\n",
      "train loss:0.005017155615225143\n",
      "train loss:0.030282404636852927\n",
      "train loss:0.0028706787770829663\n",
      "train loss:0.01876989780525973\n",
      "train loss:0.009723250308549584\n",
      "train loss:0.006135137322673543\n",
      "train loss:0.007598796744632288\n",
      "train loss:0.006358290884185226\n",
      "train loss:0.036730801243125645\n",
      "train loss:0.03103984719127903\n",
      "train loss:0.007684713219722552\n",
      "train loss:0.005073538022647466\n",
      "train loss:0.022000636416421075\n",
      "train loss:0.008635778242828032\n",
      "train loss:0.0016794498903811635\n",
      "train loss:0.1214138203331317\n",
      "train loss:0.015836116524972414\n",
      "train loss:0.009887684332662091\n",
      "train loss:0.0419994622336003\n",
      "train loss:0.029329289053120933\n",
      "train loss:0.055466158987802494\n",
      "train loss:0.02888488033144814\n",
      "train loss:0.0018647700443363935\n",
      "train loss:0.0007675566571071685\n",
      "train loss:0.07790590396262438\n",
      "train loss:0.009312835794282772\n",
      "train loss:0.00822467459577511\n",
      "train loss:0.011424246533780831\n",
      "train loss:0.0035634878367258745\n",
      "train loss:0.01734255950146623\n",
      "train loss:0.003876620190505056\n",
      "train loss:0.017467569256280784\n",
      "train loss:0.0030815511747908876\n",
      "train loss:0.006031662139928391\n",
      "train loss:0.03260572712298631\n",
      "train loss:0.0021643880743812704\n",
      "train loss:0.009410211789541262\n",
      "train loss:0.001678146531118483\n",
      "train loss:0.008840884398402405\n",
      "train loss:0.029862800370601798\n",
      "train loss:0.011793911927296405\n",
      "train loss:0.013387136994795337\n",
      "train loss:0.013471760982862943\n",
      "train loss:0.17812016326949487\n",
      "train loss:0.011595953486108953\n",
      "train loss:0.009468248313759343\n",
      "train loss:0.15222587440121219\n",
      "train loss:0.03194446162998135\n",
      "train loss:0.022293887190767206\n",
      "train loss:0.022487968767185288\n",
      "train loss:0.02728025074260693\n",
      "train loss:0.005151784607117177\n",
      "train loss:0.015937333929201155\n",
      "train loss:0.005167994854721504\n",
      "train loss:0.010468313056124844\n",
      "train loss:0.006395063937765089\n",
      "train loss:0.02179476840952389\n",
      "train loss:0.033938083883283364\n",
      "train loss:0.011790347591538726\n",
      "train loss:0.014164828342318634\n",
      "train loss:0.01737925769436262\n",
      "train loss:0.015096505450796643\n",
      "train loss:0.008668595959796377\n",
      "train loss:0.05547599954864875\n",
      "train loss:0.08209982069430653\n",
      "train loss:0.005946110055028213\n",
      "train loss:0.005869062599278674\n",
      "train loss:0.005324280602514038\n",
      "train loss:0.009413728908291431\n",
      "train loss:0.004328151504255665\n",
      "train loss:0.007695897590463685\n",
      "train loss:0.008283773268258706\n",
      "train loss:0.026334531166106276\n",
      "train loss:0.005814047863567394\n",
      "train loss:0.05142264009888974\n",
      "train loss:0.06345713252545952\n",
      "train loss:0.009114745309519558\n",
      "train loss:0.005259709220681839\n",
      "train loss:0.02004753160722469\n",
      "train loss:0.008821436487612733\n",
      "train loss:0.004904706690223237\n",
      "train loss:0.007801711732566655\n",
      "train loss:0.014007687125863208\n",
      "train loss:0.016201146902501698\n",
      "train loss:0.00860923269913754\n",
      "train loss:0.006376298156887689\n",
      "train loss:0.01194648262761815\n",
      "train loss:0.01649314746533714\n",
      "train loss:0.010321404551879026\n",
      "train loss:0.02627990520631567\n",
      "train loss:0.021752577526012028\n",
      "train loss:0.07815774045318367\n",
      "train loss:0.02330660367717273\n",
      "train loss:0.00731813046647379\n",
      "train loss:0.0057786871239812855\n",
      "train loss:0.007149868601997991\n",
      "train loss:0.010708771201689607\n",
      "train loss:0.0030791492244064767\n",
      "train loss:0.00644697476849597\n",
      "train loss:0.017316357501629357\n",
      "train loss:0.013922021144908005\n",
      "train loss:0.009604209096079949\n",
      "train loss:0.005213195177190412\n",
      "train loss:0.0023975497871862187\n",
      "train loss:0.004202646772610157\n",
      "train loss:0.017168831847308826\n",
      "train loss:0.01098380084284628\n",
      "train loss:0.0019252301768724748\n",
      "train loss:0.05613962347761179\n",
      "train loss:0.009830846518825032\n",
      "train loss:0.014811620697602114\n",
      "train loss:0.005994683173808662\n",
      "train loss:0.004276738962521523\n",
      "train loss:0.01014574556485555\n",
      "train loss:0.012670023636482376\n",
      "train loss:0.017576440541656566\n",
      "train loss:0.0384239941978553\n",
      "train loss:0.004155006413323204\n",
      "train loss:0.00511208525475711\n",
      "train loss:0.018391795095780965\n",
      "train loss:0.006171856754930637\n",
      "train loss:0.019459586111717296\n",
      "train loss:0.002324407655296002\n",
      "train loss:0.01443273723973742\n",
      "train loss:0.005045999506702244\n",
      "train loss:0.005996392317943815\n",
      "train loss:0.003372454321712487\n",
      "train loss:0.005085705014950518\n",
      "train loss:0.014533600885323367\n",
      "train loss:0.01888411733662433\n",
      "train loss:0.004868726095962269\n",
      "train loss:0.004295799842644307\n",
      "train loss:0.004846425204001821\n",
      "train loss:0.026989426694796422\n",
      "train loss:0.020116673517262477\n",
      "train loss:0.0039793309785961265\n",
      "train loss:0.06141172124282741\n",
      "train loss:0.0031985873701150963\n",
      "train loss:0.03125381881023542\n",
      "train loss:0.0024602218105381247\n",
      "train loss:0.024701785778756747\n",
      "train loss:0.011473661453030238\n",
      "train loss:0.020647165947557795\n",
      "train loss:0.0866640800191711\n",
      "train loss:0.030411962624393572\n",
      "train loss:0.010945437504988385\n",
      "train loss:0.026423812893957836\n",
      "train loss:0.011741787694510168\n",
      "train loss:0.021690974785960528\n",
      "train loss:0.035677346298533245\n",
      "train loss:0.03844911391918294\n",
      "train loss:0.008012540577057813\n",
      "train loss:0.022322202201659213\n",
      "train loss:0.0034674256957194114\n",
      "train loss:0.010165814059731553\n",
      "train loss:0.010723402754980866\n",
      "train loss:0.018220352236426263\n",
      "train loss:0.03511229520820095\n",
      "train loss:0.02553403406398174\n",
      "train loss:0.04230146657991818\n",
      "train loss:0.01823668377930498\n",
      "train loss:0.029954445686286378\n",
      "train loss:0.06892303047036544\n",
      "train loss:0.007016339304236694\n",
      "train loss:0.0039221483569307795\n",
      "train loss:0.023621759234406632\n",
      "train loss:0.024079088943043697\n",
      "train loss:0.009043418207309226\n",
      "train loss:0.005774091704929339\n",
      "train loss:0.019930693207057898\n",
      "train loss:0.003604959996553917\n",
      "train loss:0.04707936386789858\n",
      "train loss:0.034321830508058454\n",
      "train loss:0.00492182743195524\n",
      "train loss:0.04482903442712836\n",
      "train loss:0.0077685033960272366\n",
      "train loss:0.007346108111026336\n",
      "train loss:0.003542514643150329\n",
      "train loss:0.009908466375448212\n",
      "train loss:0.004166858213425781\n",
      "train loss:0.01518585098992296\n",
      "train loss:0.010125384104478307\n",
      "train loss:0.009217197946164527\n",
      "train loss:0.004496156326641821\n",
      "train loss:0.010736604729823651\n",
      "train loss:0.08852703182157821\n",
      "train loss:0.027368066422249822\n",
      "train loss:0.006471756774335901\n",
      "train loss:0.0072418224895691085\n",
      "train loss:0.0019881218377571824\n",
      "train loss:0.004155596181395455\n",
      "train loss:0.01945626060512745\n",
      "train loss:0.009310530327157356\n",
      "train loss:0.01760084729704716\n",
      "train loss:0.006747080242427451\n",
      "train loss:0.013259845659997698\n",
      "train loss:0.03330975348517681\n",
      "train loss:0.006236178816175782\n",
      "train loss:0.008410342293111203\n",
      "train loss:0.023772109543188057\n",
      "train loss:0.004355021546260535\n",
      "train loss:0.0189130439701849\n",
      "train loss:0.011680481475274411\n",
      "train loss:0.0055109937739946805\n",
      "train loss:0.026390238001491047\n",
      "train loss:0.017011338668353936\n",
      "train loss:0.03130024821830523\n",
      "train loss:0.01054943103371441\n",
      "train loss:0.029757867116509452\n",
      "train loss:0.004324987306883056\n",
      "train loss:0.005364398857783016\n",
      "train loss:0.010645947391453041\n",
      "train loss:0.018681780240221692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.013650234629021853\n",
      "train loss:0.006400068709353399\n",
      "train loss:0.001361374205243386\n",
      "train loss:0.035367630262119754\n",
      "train loss:0.004724931233648523\n",
      "train loss:0.005283955104225192\n",
      "train loss:0.0027950765426355733\n",
      "train loss:0.008365657575191851\n",
      "train loss:0.0019108160560180527\n",
      "train loss:0.035612862887332855\n",
      "train loss:0.010903195230070883\n",
      "train loss:0.0049498374382623365\n",
      "train loss:0.004552963016624531\n",
      "train loss:0.01105964936608105\n",
      "train loss:0.006515305185196628\n",
      "train loss:0.003678246066077952\n",
      "train loss:0.046776244040281946\n",
      "train loss:0.010138079512375466\n",
      "train loss:0.0043104334959067694\n",
      "train loss:0.003601057667858129\n",
      "train loss:0.09247856263169908\n",
      "train loss:0.03943134387495531\n",
      "train loss:0.004835287339579455\n",
      "train loss:0.019101300522615567\n",
      "train loss:0.004397722132999682\n",
      "train loss:0.00572700480047866\n",
      "train loss:0.00600645829268895\n",
      "train loss:0.0061931751568597105\n",
      "train loss:0.011854009514168899\n",
      "train loss:0.05586750761346354\n",
      "train loss:0.0356516820481921\n",
      "train loss:0.02232302706078411\n",
      "train loss:0.01079807147081965\n",
      "train loss:0.032755628423901416\n",
      "train loss:0.007455446564534722\n",
      "train loss:0.009446790847910108\n",
      "train loss:0.018923410202265248\n",
      "train loss:0.07836851795550834\n",
      "train loss:0.026970018985466006\n",
      "train loss:0.0034420873713930456\n",
      "train loss:0.014526514772046958\n",
      "train loss:0.008351628090558512\n",
      "train loss:0.004476672811406847\n",
      "train loss:0.0039708774649105496\n",
      "train loss:0.0010918417404066293\n",
      "train loss:0.021717855295081044\n",
      "train loss:0.010072018235222073\n",
      "train loss:0.015461992083032722\n",
      "train loss:0.030750486351587853\n",
      "train loss:0.017229787186016796\n",
      "train loss:0.002895417358578395\n",
      "train loss:0.06859426954115586\n",
      "train loss:0.005769824715808816\n",
      "train loss:0.017348144378672842\n",
      "train loss:0.005098317169194861\n",
      "train loss:0.009868892890599133\n",
      "train loss:0.01797194275739558\n",
      "train loss:0.0015927804911983472\n",
      "train loss:0.005331554044963184\n",
      "train loss:0.002669606073269203\n",
      "train loss:0.01309331200180976\n",
      "train loss:0.004972568138491273\n",
      "train loss:0.005292914226271508\n",
      "train loss:0.008359870103480856\n",
      "train loss:0.0045807542540637165\n",
      "train loss:0.014176435979193007\n",
      "train loss:0.0015247432408504171\n",
      "train loss:0.010188335744710614\n",
      "train loss:0.0224774847569283\n",
      "train loss:0.01608511939709862\n",
      "train loss:0.0863012734799874\n",
      "train loss:0.014950699906723043\n",
      "train loss:0.009570865788333056\n",
      "train loss:0.007860790650350091\n",
      "train loss:0.001495643186485105\n",
      "train loss:0.006853281434110301\n",
      "train loss:0.006388039738968487\n",
      "train loss:0.014000815244442124\n",
      "train loss:0.011364697234660335\n",
      "train loss:0.01763307160860742\n",
      "train loss:0.045288276334648776\n",
      "train loss:0.004487361187147722\n",
      "train loss:0.003520768108090492\n",
      "train loss:0.010779638749561497\n",
      "train loss:0.02092469182404176\n",
      "train loss:0.009204443303190714\n",
      "train loss:0.007689862429269836\n",
      "train loss:0.023249955344959914\n",
      "train loss:0.009139466644888586\n",
      "train loss:0.0024295667850332335\n",
      "train loss:0.04974119436734842\n",
      "train loss:0.01933163610208391\n",
      "train loss:0.005666970487580502\n",
      "train loss:0.009616632112401918\n",
      "train loss:0.012041462840686213\n",
      "train loss:0.005775530037932847\n",
      "train loss:0.018650880139283725\n",
      "train loss:0.003468248473119186\n",
      "train loss:0.0037683757091555303\n",
      "train loss:0.008499570787065439\n",
      "train loss:0.009865694460770222\n",
      "train loss:0.0030570196050007468\n",
      "train loss:0.01277923548194527\n",
      "train loss:0.01666338505749096\n",
      "train loss:0.003991264595352723\n",
      "train loss:0.01147406795757102\n",
      "train loss:0.04151367161389623\n",
      "train loss:0.022584967924809917\n",
      "train loss:0.005129833440688084\n",
      "train loss:0.016709638609231733\n",
      "train loss:0.010555102181838272\n",
      "train loss:0.030120513993899704\n",
      "train loss:0.014677466194043594\n",
      "train loss:0.004853122355562549\n",
      "train loss:0.02273113614687153\n",
      "train loss:0.006226091754185668\n",
      "train loss:0.040482166818056706\n",
      "train loss:0.001518333231119288\n",
      "train loss:0.024064626133197126\n",
      "train loss:0.007894804199736219\n",
      "train loss:0.0029139540436853946\n",
      "train loss:0.027582451548283392\n",
      "train loss:0.008775152423054447\n",
      "train loss:0.019607450504440366\n",
      "train loss:0.005693407524329786\n",
      "train loss:0.03658458750740212\n",
      "train loss:0.014638373096760606\n",
      "train loss:0.0031586440453398455\n",
      "train loss:0.06307698085975427\n",
      "train loss:0.006489331995302102\n",
      "train loss:0.0033439137444171113\n",
      "train loss:0.02078281771586485\n",
      "train loss:0.003979804770146715\n",
      "train loss:0.003140952135763675\n",
      "train loss:0.015370668113310957\n",
      "train loss:0.00514906703567748\n",
      "train loss:0.014907784230398659\n",
      "train loss:0.008422986910663004\n",
      "train loss:0.00471947731673099\n",
      "train loss:0.010083357219669098\n",
      "train loss:0.004576831883006538\n",
      "train loss:0.006826614747084063\n",
      "train loss:0.013848431979231902\n",
      "train loss:0.007317070777785088\n",
      "train loss:0.0022132426413330984\n",
      "train loss:0.005122176573087472\n",
      "train loss:0.007275517758316063\n",
      "train loss:0.0029286870790657883\n",
      "train loss:0.060737217375988174\n",
      "train loss:0.003035268452263577\n",
      "train loss:0.01267551422805071\n",
      "train loss:0.005363554919650354\n",
      "train loss:0.0039386774944712355\n",
      "train loss:0.009539035308557837\n",
      "train loss:0.02762046982847016\n",
      "train loss:0.003485252348203179\n",
      "train loss:0.022382025537381885\n",
      "train loss:0.003774569672044635\n",
      "train loss:0.0009750067540451005\n",
      "train loss:0.01136334098204455\n",
      "train loss:0.0028140071956605202\n",
      "train loss:0.0090267855499115\n",
      "train loss:0.01310291506477165\n",
      "train loss:0.006560702578082287\n",
      "train loss:0.022815584874653995\n",
      "train loss:0.0028907112297597644\n",
      "train loss:0.01844752429646669\n",
      "train loss:0.012371150178101113\n",
      "train loss:0.006179615093056617\n",
      "train loss:0.02005668691555642\n",
      "train loss:0.013556174834846\n",
      "train loss:0.03169748411222355\n",
      "train loss:0.013502649730797818\n",
      "train loss:0.003268373910476287\n",
      "train loss:0.0032546553224701543\n",
      "train loss:0.006037128065981728\n",
      "train loss:0.011489863545151389\n",
      "train loss:0.006472804706928784\n",
      "train loss:0.006769933315700092\n",
      "train loss:0.006151077742223923\n",
      "train loss:0.07912132746173467\n",
      "train loss:0.00468515700675499\n",
      "train loss:0.0034820695622902503\n",
      "train loss:0.0035040115338373936\n",
      "train loss:0.009823310555068205\n",
      "train loss:0.014515110933306652\n",
      "train loss:0.005796538221042864\n",
      "train loss:0.01879609876583157\n",
      "train loss:0.01295727552618414\n",
      "train loss:0.026520498006391457\n",
      "train loss:0.021342781349595913\n",
      "train loss:0.006995212399209211\n",
      "train loss:0.007878226258136275\n",
      "train loss:0.0029173084975069236\n",
      "train loss:0.004554703474786113\n",
      "train loss:0.005478677294854399\n",
      "train loss:0.009279206708741322\n",
      "train loss:0.0035292754404977838\n",
      "train loss:0.021132222164601352\n",
      "train loss:0.0015095549874699233\n",
      "train loss:0.00816760844743953\n",
      "train loss:0.001867633413168372\n",
      "train loss:0.03363350866632879\n",
      "train loss:0.0037511596934730823\n",
      "train loss:0.00024238715498634735\n",
      "train loss:0.004062851919341874\n",
      "train loss:0.002011884369546997\n",
      "train loss:0.007445759337917624\n",
      "train loss:0.028519633662698093\n",
      "train loss:0.08691200231135487\n",
      "train loss:0.011108841416156598\n",
      "train loss:0.008190965921783947\n",
      "train loss:0.0071978209291618\n",
      "train loss:0.0036934880778079866\n",
      "train loss:0.004280886642539009\n",
      "train loss:0.006815513406371042\n",
      "train loss:0.007858739830911449\n",
      "train loss:0.015122761318476938\n",
      "train loss:0.00855123866517269\n",
      "train loss:0.01028854040920684\n",
      "train loss:0.014953904276681395\n",
      "train loss:0.0080397954154466\n",
      "train loss:0.01433106501790462\n",
      "train loss:0.018207691462130127\n",
      "train loss:0.01614385609760353\n",
      "train loss:0.0069044878991629585\n",
      "train loss:0.004255367499253915\n",
      "train loss:0.015422066025314455\n",
      "train loss:0.035624380637458986\n",
      "train loss:0.051737849578951584\n",
      "train loss:0.00842379660146384\n",
      "train loss:0.019954013907300564\n",
      "train loss:0.012953218904254599\n",
      "train loss:0.03393496296744359\n",
      "train loss:0.009080075993204585\n",
      "train loss:0.01019038041433893\n",
      "train loss:0.024573398991440412\n",
      "train loss:0.005220676664797682\n",
      "train loss:0.004895933387344955\n",
      "train loss:0.003809571783424801\n",
      "train loss:0.04042763039143955\n",
      "train loss:0.003730938893145095\n",
      "train loss:0.0032509344602817316\n",
      "train loss:0.011044899465522319\n",
      "train loss:0.017281861416448656\n",
      "train loss:0.018657525359192562\n",
      "train loss:0.008586484944701074\n",
      "train loss:0.0018905113063763745\n",
      "train loss:0.03837668400643788\n",
      "train loss:0.006492620568483426\n",
      "train loss:0.004743089212336428\n",
      "train loss:0.16872485462401618\n",
      "train loss:0.006486383755759066\n",
      "train loss:0.004241951239360748\n",
      "train loss:0.00568005955840267\n",
      "train loss:0.016616619536092947\n",
      "train loss:0.007545521494042584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.005536488224428555\n",
      "train loss:0.004236705841423929\n",
      "train loss:0.0033240949857176725\n",
      "train loss:0.011003049958177764\n",
      "train loss:0.0048671214809586395\n",
      "train loss:0.00843636372422082\n",
      "train loss:0.03263604067487822\n",
      "train loss:0.02466126205867568\n",
      "train loss:0.008065043194564234\n",
      "train loss:0.004233074381483187\n",
      "train loss:0.0004345437187667981\n",
      "train loss:0.011081891406964415\n",
      "train loss:0.006246051625500416\n",
      "train loss:0.016416663707527188\n",
      "train loss:0.007159630487138842\n",
      "train loss:0.0069976777608199555\n",
      "train loss:0.012171465072053432\n",
      "train loss:0.011806926565917506\n",
      "train loss:0.007199710823281971\n",
      "train loss:0.010278546278285068\n",
      "train loss:0.02164931895128816\n",
      "train loss:0.017370261973863897\n",
      "train loss:0.0040826518210168436\n",
      "train loss:0.005076449673595794\n",
      "train loss:0.017157406246816328\n",
      "=== epoch:8, train acc:0.989, test acc:0.989 ===\n",
      "train loss:0.005002766711329137\n",
      "train loss:0.0028005809385233003\n",
      "train loss:0.012111621826383196\n",
      "train loss:0.010249541757800134\n",
      "train loss:0.018176053140997562\n",
      "train loss:0.001621902840403739\n",
      "train loss:0.006893857856080635\n",
      "train loss:0.0029166032907135537\n",
      "train loss:0.012208046219577311\n",
      "train loss:0.003413415411963169\n",
      "train loss:0.0047969122670166306\n",
      "train loss:0.00044453525366718136\n",
      "train loss:0.02939135918172543\n",
      "train loss:0.0029407729968116084\n",
      "train loss:0.0034470696802536803\n",
      "train loss:0.01158277145419265\n",
      "train loss:0.0027302926496042845\n",
      "train loss:0.004502949997887243\n",
      "train loss:0.018533670164336748\n",
      "train loss:0.02027465868153496\n",
      "train loss:0.004539604909943027\n",
      "train loss:0.01011967236184529\n",
      "train loss:0.018334539949553315\n",
      "train loss:0.013832431076547138\n",
      "train loss:0.06830281937113837\n",
      "train loss:0.018606819339871097\n",
      "train loss:0.009797184842007783\n",
      "train loss:0.009358058409563356\n",
      "train loss:0.01484964455194179\n",
      "train loss:0.026148714935053816\n",
      "train loss:0.01212850168178668\n",
      "train loss:0.003695281949578067\n",
      "train loss:0.01642699917164118\n",
      "train loss:0.018521542254136915\n",
      "train loss:0.0036062590169057863\n",
      "train loss:0.011938801095141996\n",
      "train loss:0.003941770783837809\n",
      "train loss:0.0032644118966181305\n",
      "train loss:0.04473716088385857\n",
      "train loss:0.03209371656675858\n",
      "train loss:0.0079910216296612\n",
      "train loss:0.009231178232600674\n",
      "train loss:0.08444013342742387\n",
      "train loss:0.003731386013794634\n",
      "train loss:0.02432356608718261\n",
      "train loss:0.032868600006395715\n",
      "train loss:0.003951103273825254\n",
      "train loss:0.006218478485744243\n",
      "train loss:0.006789158658798651\n",
      "train loss:0.004019625390016047\n",
      "train loss:0.005711346347997255\n",
      "train loss:0.0094285911402432\n",
      "train loss:0.00410683708095472\n",
      "train loss:0.016404021996395273\n",
      "train loss:0.005468603669517712\n",
      "train loss:0.001461237218165206\n",
      "train loss:0.014664985697819617\n",
      "train loss:0.021648193977461067\n",
      "train loss:0.007295773218548343\n",
      "train loss:0.011578249478583378\n",
      "train loss:0.022355833669906792\n",
      "train loss:0.005047515629987647\n",
      "train loss:0.005618668109822671\n",
      "train loss:0.031275922209093046\n",
      "train loss:0.0012969946254069097\n",
      "train loss:0.025233250193651652\n",
      "train loss:0.003023502463134132\n",
      "train loss:0.009194082329278035\n",
      "train loss:0.014050336611948362\n",
      "train loss:0.010474204728963881\n",
      "train loss:0.00776077559652093\n",
      "train loss:0.011865882020744465\n",
      "train loss:0.014047170158425507\n",
      "train loss:0.008803006530381486\n",
      "train loss:0.010998001616083428\n",
      "train loss:0.008302802477264044\n",
      "train loss:0.021614474083352788\n",
      "train loss:0.02079365560568645\n",
      "train loss:0.000787419283726367\n",
      "train loss:0.0034235762485942288\n",
      "train loss:0.020936909930481046\n",
      "train loss:0.0012561179995329236\n",
      "train loss:0.00607358443427514\n",
      "train loss:0.0044961430241748776\n",
      "train loss:0.0033212689539246863\n",
      "train loss:0.031035892218826983\n",
      "train loss:0.005876172764290585\n",
      "train loss:0.004104541954868308\n",
      "train loss:0.012092423935233056\n",
      "train loss:0.038572133872519204\n",
      "train loss:0.0008512587517019965\n",
      "train loss:0.004749324954608228\n",
      "train loss:0.007215279478837693\n",
      "train loss:0.016771923370895135\n",
      "train loss:0.021618984773090356\n",
      "train loss:0.0034260896094092286\n",
      "train loss:0.0006928926157758424\n",
      "train loss:0.0013026299939927182\n",
      "train loss:0.013709325498764118\n",
      "train loss:0.02894760558891272\n",
      "train loss:0.004080536921942424\n",
      "train loss:0.01010152778716724\n",
      "train loss:0.0019783725277626248\n",
      "train loss:0.011060457112815135\n",
      "train loss:0.0025722446991510413\n",
      "train loss:0.0024434234496239844\n",
      "train loss:0.012550358673604656\n",
      "train loss:0.007004333779955755\n",
      "train loss:0.0029330595649903228\n",
      "train loss:0.012073195976386113\n",
      "train loss:0.01248841663695552\n",
      "train loss:0.006258827275029667\n",
      "train loss:0.004445365985730586\n",
      "train loss:0.0051534341495913984\n",
      "train loss:0.003060962895620741\n",
      "train loss:0.09808902724524238\n",
      "train loss:0.002073357663201445\n",
      "train loss:0.03913592892437717\n",
      "train loss:0.007196210401662758\n",
      "train loss:0.011922361930546625\n",
      "train loss:0.011458209315145785\n",
      "train loss:0.003026949858576988\n",
      "train loss:0.014347181987995472\n",
      "train loss:0.0022719851233503484\n",
      "train loss:0.025608851359020832\n",
      "train loss:0.014867239914202744\n",
      "train loss:0.003489664155704143\n",
      "train loss:0.0025827858076382256\n",
      "train loss:0.0014028382663799665\n",
      "train loss:0.0067986640018203506\n",
      "train loss:0.009001857245889994\n",
      "train loss:0.001609680478602967\n",
      "train loss:0.005895064684188715\n",
      "train loss:0.009250168816999799\n",
      "train loss:0.00333033868320122\n",
      "train loss:0.004875180549641331\n",
      "train loss:0.004367948186079215\n",
      "train loss:0.007671224853541991\n",
      "train loss:0.002463763051823587\n",
      "train loss:0.009955768787652874\n",
      "train loss:0.03072426645410453\n",
      "train loss:0.005647919598986793\n",
      "train loss:0.03068229516614177\n",
      "train loss:0.010615275530543629\n",
      "train loss:0.04066510377516422\n",
      "train loss:0.05021250676477689\n",
      "train loss:0.009485481984272827\n",
      "train loss:0.006338193388682454\n",
      "train loss:0.08151705467483718\n",
      "train loss:0.005466959741045892\n",
      "train loss:0.006326832690050156\n",
      "train loss:0.0018590482390302226\n",
      "train loss:0.009163880067604954\n",
      "train loss:0.024837697966536395\n",
      "train loss:0.007813706935679078\n",
      "train loss:0.003923534688788423\n",
      "train loss:0.0014616661063856374\n",
      "train loss:0.002314240191151171\n",
      "train loss:0.000548429951902374\n",
      "train loss:0.0070177943038821685\n",
      "train loss:0.02700356982538954\n",
      "train loss:0.012094843782566849\n",
      "train loss:0.016939854907424556\n",
      "train loss:0.022936073937891675\n",
      "train loss:0.01640373361084109\n",
      "train loss:0.0643076686235773\n",
      "train loss:0.00270627484720398\n",
      "train loss:0.018422011271252436\n",
      "train loss:0.0011676932069421833\n",
      "train loss:0.060789200589399774\n",
      "train loss:0.018722675074538862\n",
      "train loss:0.006711301881840156\n",
      "train loss:0.00346862911550924\n",
      "train loss:0.02497365863557273\n",
      "train loss:0.009786916012741544\n",
      "train loss:0.0054945754237233435\n",
      "train loss:0.04545396811032171\n",
      "train loss:0.007912312143263617\n",
      "train loss:0.006791926871675306\n",
      "train loss:0.009173911137643116\n",
      "train loss:0.008423263299983951\n",
      "train loss:0.017621271655886298\n",
      "train loss:0.003931804874854583\n",
      "train loss:0.013748110933416964\n",
      "train loss:0.002257195669122475\n",
      "train loss:0.011661300619951577\n",
      "train loss:0.0025349954535245456\n",
      "train loss:0.0014740494334721957\n",
      "train loss:0.005149888707246337\n",
      "train loss:0.013536826481209336\n",
      "train loss:0.012694465746154562\n",
      "train loss:0.00327590875685128\n",
      "train loss:0.003494213302962939\n",
      "train loss:0.0020556721854184303\n",
      "train loss:0.022213993797359655\n",
      "train loss:0.0044467148858307855\n",
      "train loss:0.0037359515382279908\n",
      "train loss:0.003796330256147277\n",
      "train loss:0.009548796926022377\n",
      "train loss:0.01718932762961922\n",
      "train loss:0.0016500513481576945\n",
      "train loss:0.005593404403890262\n",
      "train loss:0.018745676144573075\n",
      "train loss:0.004070324388894624\n",
      "train loss:0.006538990084166589\n",
      "train loss:0.0031786171527170438\n",
      "train loss:0.013848301670015224\n",
      "train loss:0.007497857411303408\n",
      "train loss:0.04743600585536337\n",
      "train loss:0.004447920956354196\n",
      "train loss:0.017806612949074905\n",
      "train loss:0.0044995663812901834\n",
      "train loss:0.01882414617171521\n",
      "train loss:0.006000907624193974\n",
      "train loss:0.007332286541928952\n",
      "train loss:0.0045951183829546025\n",
      "train loss:0.00069023885605898\n",
      "train loss:0.006968668783926386\n",
      "train loss:0.005821809007617819\n",
      "train loss:0.014344569020481012\n",
      "train loss:0.034462895297175014\n",
      "train loss:0.008975898096212308\n",
      "train loss:0.012683336336689437\n",
      "train loss:0.029552923096764758\n",
      "train loss:0.01126876342369406\n",
      "train loss:0.004971559714297774\n",
      "train loss:0.0006840816414921136\n",
      "train loss:0.005708086709178467\n",
      "train loss:0.005083743664479323\n",
      "train loss:0.008552245086416254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.008648116734934382\n",
      "train loss:0.041817942243889704\n",
      "train loss:0.007327255686899538\n",
      "train loss:0.009409112575737111\n",
      "train loss:0.010893901864657218\n",
      "train loss:0.0014763627414729407\n",
      "train loss:0.004661799017922906\n",
      "train loss:0.0033640602244700618\n",
      "train loss:0.002253779915056629\n",
      "train loss:0.004604569607080794\n",
      "train loss:0.07657248053263965\n",
      "train loss:0.002938715194089832\n",
      "train loss:0.008116236991274844\n",
      "train loss:0.0034529068508016465\n",
      "train loss:0.007800307422530311\n",
      "train loss:0.007819294427123303\n",
      "train loss:0.005828627179841683\n",
      "train loss:0.016039590300631644\n",
      "train loss:0.0125322552373684\n",
      "train loss:0.02650292145242537\n",
      "train loss:0.008052719883118425\n",
      "train loss:0.0051866643385107755\n",
      "train loss:0.014675384320688182\n",
      "train loss:0.003404073875583532\n",
      "train loss:0.002892374580885428\n",
      "train loss:0.0074455993560614804\n",
      "train loss:0.003964351840870021\n",
      "train loss:0.002590917629785106\n",
      "train loss:0.0011103644517130953\n",
      "train loss:0.003772978902890778\n",
      "train loss:0.008022690642989464\n",
      "train loss:0.015994876871446823\n",
      "train loss:0.0014036801321625366\n",
      "train loss:0.00202604792601779\n",
      "train loss:0.006926494904525144\n",
      "train loss:0.03692892578795408\n",
      "train loss:0.009434654222248885\n",
      "train loss:0.0078071167066178036\n",
      "train loss:0.0031423292472721382\n",
      "train loss:0.004639211889989225\n",
      "train loss:0.0021720733657690687\n",
      "train loss:0.008705316656191158\n",
      "train loss:0.012837909981222242\n",
      "train loss:0.012419911132057976\n",
      "train loss:0.001312507504887203\n",
      "train loss:0.008499715687181782\n",
      "train loss:0.0012138638576100072\n",
      "train loss:0.001158524180891843\n",
      "train loss:0.002645970165067722\n",
      "train loss:0.008468602076414455\n",
      "train loss:0.005058642482550721\n",
      "train loss:0.0022386382191132152\n",
      "train loss:0.004439130004003502\n",
      "train loss:0.049861764822734765\n",
      "train loss:0.006804550444869857\n",
      "train loss:0.0064747012292591275\n",
      "train loss:0.0011916301998458583\n",
      "train loss:0.0010628860945408674\n",
      "train loss:0.0010857571348008087\n",
      "train loss:0.0015176666519452586\n",
      "train loss:0.022497436661205693\n",
      "train loss:0.0010881360825775377\n",
      "train loss:0.013257602982316237\n",
      "train loss:0.048826422876728864\n",
      "train loss:0.025595344155486085\n",
      "train loss:0.010568323037958295\n",
      "train loss:0.017518459417128023\n",
      "train loss:0.0036339483517199\n",
      "train loss:0.014313710513633598\n",
      "train loss:0.003590255532297215\n",
      "train loss:0.005645064666224244\n",
      "train loss:0.003906445360028058\n",
      "train loss:0.0046159138263131404\n",
      "train loss:0.011833496571387624\n",
      "train loss:0.012547636142009102\n",
      "train loss:0.0038998702956144988\n",
      "train loss:0.004057202874156791\n",
      "train loss:0.0037218767589051465\n",
      "train loss:0.0012513001504724148\n",
      "train loss:0.01144332381890544\n",
      "train loss:0.0027878864392329224\n",
      "train loss:0.013652080046994641\n",
      "train loss:0.009653824799802577\n",
      "train loss:0.0018730447193877715\n",
      "train loss:0.0026200330635073265\n",
      "train loss:0.002218885749793186\n",
      "train loss:0.009974258324299197\n",
      "train loss:0.006712322185199649\n",
      "train loss:0.0018512048279775875\n",
      "train loss:0.001784781604896619\n",
      "train loss:0.007962301788309973\n",
      "train loss:0.0017872661641525484\n",
      "train loss:0.0020609548626235683\n",
      "train loss:0.004735689547534541\n",
      "train loss:0.027691016225434774\n",
      "train loss:0.013226117636512767\n",
      "train loss:0.008412045028120797\n",
      "train loss:0.0063161850325150004\n",
      "train loss:0.017051961128207397\n",
      "train loss:0.014393085511519117\n",
      "train loss:0.0116156387148428\n",
      "train loss:0.0029793928465790993\n",
      "train loss:0.040487829388431734\n",
      "train loss:0.0011899868885121073\n",
      "train loss:0.0058185803348724165\n",
      "train loss:0.004284082849964963\n",
      "train loss:0.01296026335589224\n",
      "train loss:0.0010094587461544934\n",
      "train loss:0.004729788316497193\n",
      "train loss:0.012527701632858424\n",
      "train loss:0.015468980456991008\n",
      "train loss:0.013369895341386924\n",
      "train loss:0.011885302841022056\n",
      "train loss:0.003611013993189774\n",
      "train loss:0.0013153707351788657\n",
      "train loss:0.01459819443764881\n",
      "train loss:0.0034682505143462878\n",
      "train loss:0.002819503732723603\n",
      "train loss:0.15199026254359468\n",
      "train loss:0.0363180375982162\n",
      "train loss:0.0040771976388406135\n",
      "train loss:0.011173215601166096\n",
      "train loss:0.011579079411948096\n",
      "train loss:0.003953169122341016\n",
      "train loss:0.028642584808730477\n",
      "train loss:0.002437776866589086\n",
      "train loss:0.010491437958860712\n",
      "train loss:0.0040989116497814225\n",
      "train loss:0.013510531011500009\n",
      "train loss:0.005180824521181127\n",
      "train loss:0.0024204912711028224\n",
      "train loss:0.004143580736321683\n",
      "train loss:0.004833355361253492\n",
      "train loss:0.00484915205550946\n",
      "train loss:0.002490976755713995\n",
      "train loss:0.0032606749072024415\n",
      "train loss:0.03203062750238415\n",
      "train loss:0.004605093185011792\n",
      "train loss:0.001201062325644882\n",
      "train loss:0.0032773413036024683\n",
      "train loss:0.0012195170200757588\n",
      "train loss:0.01652033765541534\n",
      "train loss:0.006481638002533624\n",
      "train loss:0.012367163357518654\n",
      "train loss:0.0038317568081634367\n",
      "train loss:0.006510941667928257\n",
      "train loss:0.05549452240187953\n",
      "train loss:0.0024114863154333552\n",
      "train loss:0.034554132671915344\n",
      "train loss:0.004784648144366147\n",
      "train loss:0.005245058081941557\n",
      "train loss:0.010950955402488615\n",
      "train loss:0.011400046348726106\n",
      "train loss:0.0012663073803197509\n",
      "train loss:0.007834522270844234\n",
      "train loss:0.02556675246299166\n",
      "train loss:0.003802652273776886\n",
      "train loss:0.024714202610577423\n",
      "train loss:0.03159868261969143\n",
      "train loss:0.0024557833377721796\n",
      "train loss:0.007881152049118672\n",
      "train loss:0.004510183650602868\n",
      "train loss:0.004436948317340543\n",
      "train loss:0.016215884813411702\n",
      "train loss:0.009037683135102304\n",
      "train loss:0.004883817597695067\n",
      "train loss:0.0005499377821263151\n",
      "train loss:0.004583229890934752\n",
      "train loss:0.014757707538039485\n",
      "train loss:0.006712990720701821\n",
      "train loss:0.004100892108257474\n",
      "train loss:0.0018504399027920852\n",
      "train loss:0.004154234402279304\n",
      "train loss:0.003203377243098991\n",
      "train loss:0.004134804358848622\n",
      "train loss:0.0013155403556393355\n",
      "train loss:0.0041873012257385486\n",
      "train loss:0.00415149646988036\n",
      "train loss:0.039560710934475246\n",
      "train loss:0.0013732123749025788\n",
      "train loss:0.007168359030222083\n",
      "train loss:0.00579774977266346\n",
      "train loss:0.003980156393278181\n",
      "train loss:0.004857293741256641\n",
      "train loss:0.007895916091359027\n",
      "train loss:0.004647818367513808\n",
      "train loss:0.0036165007116198498\n",
      "train loss:0.01156153126343301\n",
      "train loss:0.003845876464359836\n",
      "train loss:0.004167361507598711\n",
      "train loss:0.01705819535978059\n",
      "train loss:0.0037265283935887066\n",
      "train loss:0.0062657042722390624\n",
      "train loss:0.0013587951811490858\n",
      "train loss:0.0018795905636684088\n",
      "train loss:0.07439768951583915\n",
      "train loss:0.006502056526867211\n",
      "train loss:0.0021492347134556273\n",
      "train loss:0.023427024969196148\n",
      "train loss:0.023022243392325514\n",
      "train loss:0.004540303573757308\n",
      "train loss:0.000767240689905089\n",
      "train loss:0.03529610626625618\n",
      "train loss:0.03122556282675285\n",
      "train loss:0.0030193901267439875\n",
      "train loss:0.00767793641659657\n",
      "train loss:0.004854345915519923\n",
      "train loss:0.003993709554921334\n",
      "train loss:0.007971683737183106\n",
      "train loss:0.001751960610994864\n",
      "train loss:0.01807552552394495\n",
      "train loss:0.008689418096489513\n",
      "train loss:0.020573360264327368\n",
      "train loss:0.0026405808991026634\n",
      "train loss:0.010895740400587429\n",
      "train loss:0.0026001198612902255\n",
      "train loss:0.007489559556356465\n",
      "train loss:0.005138720913097912\n",
      "train loss:0.000839621213190688\n",
      "train loss:0.002181585782122361\n",
      "train loss:0.007868119968736534\n",
      "train loss:0.015500256698673666\n",
      "train loss:0.00513654562922031\n",
      "train loss:0.02238163574276668\n",
      "train loss:0.02171660014504202\n",
      "train loss:0.002731189184605431\n",
      "train loss:0.0041230709425989585\n",
      "train loss:0.05192989742241633\n",
      "train loss:0.009144608231150202\n",
      "train loss:0.00973022753211482\n",
      "train loss:0.01155016165495514\n",
      "train loss:0.032064088079638765\n",
      "train loss:0.012934197631155575\n",
      "train loss:0.0036013444426633147\n",
      "train loss:0.00949324949226122\n",
      "train loss:0.01820046290761743\n",
      "train loss:0.0049920795400145955\n",
      "train loss:0.005292442817250375\n",
      "train loss:0.012305347136737768\n",
      "train loss:0.04672529646479694\n",
      "train loss:0.001872487547677801\n",
      "train loss:0.018026522626091453\n",
      "train loss:0.006638129567152131\n",
      "train loss:0.06554470500838683\n",
      "train loss:0.0009234949982670162\n",
      "train loss:0.004202341322636957\n",
      "train loss:0.04887234313417218\n",
      "train loss:0.005167265627835764\n",
      "train loss:0.015098974801868366\n",
      "train loss:0.0217110990059061\n",
      "train loss:0.012800801726781856\n",
      "train loss:0.00814656659393136\n",
      "train loss:0.0060812972911631095\n",
      "train loss:0.011768966985540452\n",
      "train loss:0.0025332422665349007\n",
      "train loss:0.002269677739208091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0013854665477245653\n",
      "train loss:0.0028278356716122523\n",
      "train loss:0.011046610435426651\n",
      "train loss:0.01690295229619212\n",
      "train loss:0.00719191405672666\n",
      "train loss:0.005470984476558335\n",
      "train loss:0.01974732220408414\n",
      "train loss:0.01597886377364187\n",
      "train loss:0.03582792884406322\n",
      "train loss:0.004466273315427016\n",
      "train loss:0.03167795163633789\n",
      "train loss:0.05253172381824278\n",
      "train loss:0.005440085404997769\n",
      "train loss:0.007870150005593247\n",
      "train loss:0.00947422478775943\n",
      "train loss:0.013288716502885543\n",
      "train loss:0.015281118401784128\n",
      "train loss:0.005931092471959002\n",
      "train loss:0.021169119470053527\n",
      "train loss:0.0034759580767601377\n",
      "train loss:0.006992676728258129\n",
      "train loss:0.002458137587892766\n",
      "train loss:0.003492660833631947\n",
      "train loss:0.0024558201148841695\n",
      "train loss:0.001689051254350918\n",
      "train loss:0.03713239900260278\n",
      "train loss:0.0007465116508078011\n",
      "train loss:0.011008394072644288\n",
      "train loss:0.0031396616329752033\n",
      "train loss:0.08978833666507366\n",
      "train loss:0.021909380874308014\n",
      "train loss:0.02208625855585291\n",
      "train loss:0.007005893406049724\n",
      "train loss:0.002212392226022738\n",
      "train loss:0.0025800612421725292\n",
      "train loss:0.006815218954839547\n",
      "train loss:0.017358440374530236\n",
      "train loss:0.010376247051926335\n",
      "train loss:0.009671293233990607\n",
      "train loss:0.03588844912661499\n",
      "train loss:0.01770440350226218\n",
      "train loss:0.015052427613572434\n",
      "train loss:0.0011149697184273423\n",
      "train loss:0.0027366368691407474\n",
      "train loss:0.005338707404271902\n",
      "train loss:0.030866012879288716\n",
      "train loss:0.01957166416937446\n",
      "train loss:0.003331342762824006\n",
      "train loss:0.005155849338989546\n",
      "train loss:0.009406760877660493\n",
      "train loss:0.012139438101175086\n",
      "train loss:0.004906964726002101\n",
      "train loss:0.007855426707096857\n",
      "train loss:0.01764685943477788\n",
      "train loss:0.009313544535805702\n",
      "train loss:0.008728995068105753\n",
      "train loss:0.006925465862352035\n",
      "train loss:0.009637126769739652\n",
      "train loss:0.006243186701468465\n",
      "train loss:0.0025355357819687873\n",
      "train loss:0.006982514057009527\n",
      "train loss:0.003950281254939306\n",
      "train loss:0.02077935370769828\n",
      "train loss:0.020022228018683575\n",
      "train loss:0.00255759094648772\n",
      "train loss:0.0030534881319626435\n",
      "train loss:0.02153690507188831\n",
      "train loss:0.008836569624620877\n",
      "train loss:0.000812312939935345\n",
      "train loss:0.006542514818799753\n",
      "train loss:0.006536561168176369\n",
      "train loss:0.007467928203445312\n",
      "train loss:0.016261142423651443\n",
      "train loss:0.0026595207062351587\n",
      "train loss:0.027845036306183752\n",
      "train loss:0.0024635091769644544\n",
      "train loss:0.0015674690972080957\n",
      "train loss:0.05768887369991352\n",
      "train loss:0.0012543622265633898\n",
      "train loss:0.013960964442231723\n",
      "train loss:0.014209434567635374\n",
      "train loss:0.010644208848921456\n",
      "train loss:0.007512921800073159\n",
      "train loss:0.0021314870283276506\n",
      "train loss:0.004802980257370348\n",
      "train loss:0.004200046730634363\n",
      "train loss:0.007467667615908546\n",
      "train loss:0.021472902581210977\n",
      "train loss:0.0062957894258419\n",
      "train loss:0.0017695931086262392\n",
      "train loss:0.013964959076670747\n",
      "train loss:0.0014840011232834327\n",
      "train loss:0.005010251676205296\n",
      "train loss:0.0045255339377886\n",
      "train loss:0.011272004415955349\n",
      "train loss:0.030800034472648802\n",
      "train loss:0.007494427421561395\n",
      "train loss:0.004588425716509655\n",
      "train loss:0.0012707608950479879\n",
      "train loss:0.0034381614392876535\n",
      "train loss:0.008845348859461368\n",
      "train loss:0.009597712357297006\n",
      "train loss:0.04267520554807213\n",
      "train loss:0.005473899836303682\n",
      "train loss:0.0021654577568269223\n",
      "train loss:0.0034975372917515246\n",
      "train loss:0.02735054725169255\n",
      "train loss:0.0012000863631238521\n",
      "train loss:0.0011512462209962424\n",
      "train loss:0.0015323794200135538\n",
      "train loss:0.00197442672874113\n",
      "train loss:0.031605593336402\n",
      "train loss:0.004844843179462483\n",
      "train loss:0.001414396469296696\n",
      "=== epoch:9, train acc:0.995, test acc:0.987 ===\n",
      "train loss:0.0017295397107973578\n",
      "train loss:0.005358439458146468\n",
      "train loss:0.011524762596023372\n",
      "train loss:0.0021700562221765975\n",
      "train loss:0.015999219762112382\n",
      "train loss:0.004950881727047415\n",
      "train loss:0.015428857355486927\n",
      "train loss:0.003601095697237412\n",
      "train loss:0.006480159977587474\n",
      "train loss:0.0331142569343143\n",
      "train loss:0.00417815138862836\n",
      "train loss:0.0023241192322530826\n",
      "train loss:0.016514051149241343\n",
      "train loss:0.0019738438292644317\n",
      "train loss:0.072303364055112\n",
      "train loss:0.009315957640469764\n",
      "train loss:0.009184730199632287\n",
      "train loss:0.005727936505044729\n",
      "train loss:0.008850915505193634\n",
      "train loss:0.0025151640546395545\n",
      "train loss:0.0044953136776746715\n",
      "train loss:0.10178957294409391\n",
      "train loss:0.0035591194777491665\n",
      "train loss:0.04296210507176079\n",
      "train loss:0.000651963216230309\n",
      "train loss:0.004614102312044221\n",
      "train loss:0.01076435399573235\n",
      "train loss:0.009948444469240121\n",
      "train loss:0.0026253801216170915\n",
      "train loss:0.0018681671349769747\n",
      "train loss:0.010931629628722253\n",
      "train loss:0.022202724205791995\n",
      "train loss:0.00951545668260241\n",
      "train loss:0.004174357964794773\n",
      "train loss:0.005256750491482105\n",
      "train loss:0.011086488826741786\n",
      "train loss:0.002877130657571574\n",
      "train loss:0.004619021319762089\n",
      "train loss:0.012507671339072289\n",
      "train loss:0.006404322509166291\n",
      "train loss:0.024931991041671285\n",
      "train loss:0.00386779228490248\n",
      "train loss:0.013115956436240946\n",
      "train loss:0.003299984601651269\n",
      "train loss:0.005357341616572571\n",
      "train loss:0.0044589587819598465\n",
      "train loss:0.003575436137242128\n",
      "train loss:0.02743564333668025\n",
      "train loss:0.0040455790053514065\n",
      "train loss:0.007040799045730255\n",
      "train loss:0.00608497498160223\n",
      "train loss:0.005746729208711379\n",
      "train loss:0.002938859691003853\n",
      "train loss:0.0065740456928068325\n",
      "train loss:0.0033182838125618767\n",
      "train loss:0.004740602504588861\n",
      "train loss:0.0037356925139689036\n",
      "train loss:0.006963982317481544\n",
      "train loss:0.008861001940926821\n",
      "train loss:0.0012720891173076568\n",
      "train loss:0.002684674631759773\n",
      "train loss:0.0022143080755359264\n",
      "train loss:0.005264921081699935\n",
      "train loss:0.015231249413774408\n",
      "train loss:0.004995381881874095\n",
      "train loss:0.008785280385747933\n",
      "train loss:0.015206324122998618\n",
      "train loss:0.003276099677094427\n",
      "train loss:0.005819022835202096\n",
      "train loss:0.01534131146163091\n",
      "train loss:0.01055142408653463\n",
      "train loss:0.009287101538962039\n",
      "train loss:0.005954877287410298\n",
      "train loss:0.0030863711818608264\n",
      "train loss:0.005343964039343607\n",
      "train loss:0.012801808974994382\n",
      "train loss:0.0041736715633837575\n",
      "train loss:0.017908477870511336\n",
      "train loss:0.007164517210584944\n",
      "train loss:0.028268912347678095\n",
      "train loss:0.0013925654066968465\n",
      "train loss:0.03278956594875649\n",
      "train loss:0.030090694881753147\n",
      "train loss:0.004386541405740223\n",
      "train loss:0.006864175413171299\n",
      "train loss:0.0044549993905602945\n",
      "train loss:0.0179683728291518\n",
      "train loss:0.004344369466553663\n",
      "train loss:0.003235681279909718\n",
      "train loss:0.006133114051917906\n",
      "train loss:0.006347137587419319\n",
      "train loss:0.021562989998066787\n",
      "train loss:0.003340624272547289\n",
      "train loss:0.0027716665586159507\n",
      "train loss:0.03322200486854501\n",
      "train loss:0.005470612882418196\n",
      "train loss:0.003371149912360132\n",
      "train loss:0.008161416644792205\n",
      "train loss:0.0021533988408077047\n",
      "train loss:0.005343582920815898\n",
      "train loss:0.0012724215963580393\n",
      "train loss:0.002929782102652315\n",
      "train loss:0.013877396425035382\n",
      "train loss:0.005713515047031912\n",
      "train loss:0.005037642418828297\n",
      "train loss:0.005297412273033206\n",
      "train loss:0.006343487051809872\n",
      "train loss:0.0017366003164282615\n",
      "train loss:0.004644131591992015\n",
      "train loss:0.025817843470143466\n",
      "train loss:0.0026192069234102777\n",
      "train loss:0.009275697053452351\n",
      "train loss:0.002127284902996854\n",
      "train loss:0.002617638156440263\n",
      "train loss:0.0016096156239212202\n",
      "train loss:0.009014914822605368\n",
      "train loss:0.0033811266406688937\n",
      "train loss:0.0012703237735169203\n",
      "train loss:0.003570557117859372\n",
      "train loss:0.0048121384533158\n",
      "train loss:0.011910132392799842\n",
      "train loss:0.005767860804629169\n",
      "train loss:0.005150826784014058\n",
      "train loss:0.021128776157417473\n",
      "train loss:0.005301166260909647\n",
      "train loss:0.0042181972639003555\n",
      "train loss:0.008210058179027003\n",
      "train loss:0.0042005374808867756\n",
      "train loss:0.0033555322757010194\n",
      "train loss:0.007269486950380282\n",
      "train loss:0.023890680435426477\n",
      "train loss:0.0019069652941141534\n",
      "train loss:0.03793556430374635\n",
      "train loss:0.0007336609591511694\n",
      "train loss:0.034619060065454024\n",
      "train loss:0.006855349126280901\n",
      "train loss:0.020950334581111778\n",
      "train loss:0.00773361787669196\n",
      "train loss:0.0035946598840046785\n",
      "train loss:0.010704235363896667\n",
      "train loss:0.02816645467919326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.007511805622288585\n",
      "train loss:0.009478239417183404\n",
      "train loss:0.011458617136441257\n",
      "train loss:0.002001606729132521\n",
      "train loss:0.0010930507582300358\n",
      "train loss:0.043034282136128234\n",
      "train loss:0.007115268792042137\n",
      "train loss:0.00901021978743446\n",
      "train loss:0.006158229669769544\n",
      "train loss:0.0068033254503389\n",
      "train loss:0.01838841107926766\n",
      "train loss:0.0058403727893225985\n",
      "train loss:0.017901037984208598\n",
      "train loss:0.019939378953910215\n",
      "train loss:0.0053830514544558825\n",
      "train loss:0.010915357482845863\n",
      "train loss:0.00361304272112474\n",
      "train loss:0.005114056505878895\n",
      "train loss:0.010133244140621613\n",
      "train loss:0.006943407662953525\n",
      "train loss:0.011197893847142322\n",
      "train loss:0.09931079046364989\n",
      "train loss:0.02313229742471024\n",
      "train loss:0.005951854208088381\n",
      "train loss:0.010751481998874584\n",
      "train loss:0.009163927232658494\n",
      "train loss:0.005338838379907156\n",
      "train loss:0.03075182214033304\n",
      "train loss:0.012524972244931992\n",
      "train loss:0.010322836597304009\n",
      "train loss:0.006310846766897746\n",
      "train loss:0.010413707885236066\n",
      "train loss:0.0010187534155068102\n",
      "train loss:0.003975642928909235\n",
      "train loss:0.010168051126868803\n",
      "train loss:0.03273414889628635\n",
      "train loss:0.00433994856717298\n",
      "train loss:0.026968231651377336\n",
      "train loss:0.00735843999687846\n",
      "train loss:0.001024671732843701\n",
      "train loss:0.0019052884231050848\n",
      "train loss:0.007455289320512509\n",
      "train loss:0.004130584002655276\n",
      "train loss:0.0016360207929795973\n",
      "train loss:0.011134975811936594\n",
      "train loss:0.003175677979867249\n",
      "train loss:0.008072977701354685\n",
      "train loss:0.019575968007564816\n",
      "train loss:0.02870406817494876\n",
      "train loss:0.001806342422880493\n",
      "train loss:0.0069210016527627575\n",
      "train loss:0.016252148496714535\n",
      "train loss:0.008291072981971922\n",
      "train loss:0.007228766793910069\n",
      "train loss:0.0013269718049688927\n",
      "train loss:0.0016571572867841425\n",
      "train loss:0.008819134633504134\n",
      "train loss:0.01878774052550334\n",
      "train loss:0.012119280676040045\n",
      "train loss:0.022612236879650457\n",
      "train loss:0.02815695269965761\n",
      "train loss:0.012681459264282354\n",
      "train loss:0.008887734426553495\n",
      "train loss:0.00946547322086269\n",
      "train loss:0.0040798363567751\n",
      "train loss:0.016024488232880153\n",
      "train loss:0.0029712658632185984\n",
      "train loss:0.001514946674191791\n",
      "train loss:0.018626159842370694\n",
      "train loss:0.016642243498613464\n",
      "train loss:0.020705731600520312\n",
      "train loss:0.0032590141095783266\n",
      "train loss:0.004878499246870994\n",
      "train loss:0.0037249902232721764\n",
      "train loss:0.0020700041181967656\n",
      "train loss:0.004540277271616861\n",
      "train loss:0.000472638301215154\n",
      "train loss:0.04026728643843508\n",
      "train loss:0.010464455677200928\n",
      "train loss:0.04778150562257359\n",
      "train loss:0.007393306354991098\n",
      "train loss:0.025264727723642348\n",
      "train loss:0.002582114498833838\n",
      "train loss:0.0054613591035908935\n",
      "train loss:0.008854566734704895\n",
      "train loss:0.026833663045230747\n",
      "train loss:0.003461344247961539\n",
      "train loss:0.009661108803413908\n",
      "train loss:0.009983999673145094\n",
      "train loss:0.0066564070198052725\n",
      "train loss:0.031098892154528122\n",
      "train loss:0.003066312465234972\n",
      "train loss:0.013043966567462826\n",
      "train loss:0.0037786670730954293\n",
      "train loss:0.018258773653502664\n",
      "train loss:0.00613063554766659\n",
      "train loss:0.016241033288046793\n",
      "train loss:0.0024292433610619123\n",
      "train loss:0.0017016494950763223\n",
      "train loss:0.03689294497045163\n",
      "train loss:0.0026423987835077155\n",
      "train loss:0.005964398705006044\n",
      "train loss:0.006526146041596476\n",
      "train loss:0.02009161064585956\n",
      "train loss:0.009075049371311664\n",
      "train loss:0.01480777048811094\n",
      "train loss:0.019073227111346597\n",
      "train loss:0.029161149302249924\n",
      "train loss:0.018063978487260924\n",
      "train loss:0.009114292251260725\n",
      "train loss:0.003364522698998649\n",
      "train loss:0.005603863916330681\n",
      "train loss:0.001285865268438122\n",
      "train loss:0.002180125775826619\n",
      "train loss:0.0012233035508944687\n",
      "train loss:0.0035371758848214987\n",
      "train loss:0.07845178294336771\n",
      "train loss:0.01334891569821358\n",
      "train loss:0.003972079141748086\n",
      "train loss:0.006620415976925201\n",
      "train loss:0.03144280711670481\n",
      "train loss:0.025108554845566174\n",
      "train loss:0.002737981035024649\n",
      "train loss:0.011645495890140118\n",
      "train loss:0.0024416548985011356\n",
      "train loss:0.009984528561490012\n",
      "train loss:0.006031474093097666\n",
      "train loss:0.013161365351535836\n",
      "train loss:0.0036797408973195424\n",
      "train loss:0.010820764566943496\n",
      "train loss:0.003145159767294082\n",
      "train loss:0.004334353105881175\n",
      "train loss:0.06992094070900037\n",
      "train loss:0.01448339345269781\n",
      "train loss:0.016365293124169025\n",
      "train loss:0.006477415260092644\n",
      "train loss:0.01728430840394014\n",
      "train loss:0.034816444508380014\n",
      "train loss:0.008715199722751688\n",
      "train loss:0.022444071504533366\n",
      "train loss:0.004978080069628582\n",
      "train loss:0.0046911002427007485\n",
      "train loss:0.021520790855124056\n",
      "train loss:0.008065940189580007\n",
      "train loss:0.0027221632489972873\n",
      "train loss:0.012146774097007823\n",
      "train loss:0.00414851433251541\n",
      "train loss:0.011653753044648451\n",
      "train loss:0.004164915828850696\n",
      "train loss:0.002408696748004824\n",
      "train loss:0.02123331008502537\n",
      "train loss:0.013420695383407804\n",
      "train loss:0.005408137767364171\n",
      "train loss:0.013908747322349885\n",
      "train loss:0.04313897012500769\n",
      "train loss:0.001792482114915704\n",
      "train loss:0.00983484326401309\n",
      "train loss:0.0016946900535479068\n",
      "train loss:0.004624770288798592\n",
      "train loss:0.00440411086143419\n",
      "train loss:0.012404370517660253\n",
      "train loss:0.006731389096422367\n",
      "train loss:0.002307559907641146\n",
      "train loss:0.01279935211753908\n",
      "train loss:0.010119866417767721\n",
      "train loss:0.010598740925307437\n",
      "train loss:0.008236037286763226\n",
      "train loss:0.010092177547740909\n",
      "train loss:0.0037089937208512848\n",
      "train loss:0.010317280378490102\n",
      "train loss:0.0013801163674935129\n",
      "train loss:0.004313931505499918\n",
      "train loss:0.004803743097397588\n",
      "train loss:0.0012856534468646719\n",
      "train loss:0.0020095973446274014\n",
      "train loss:0.002049160929342948\n",
      "train loss:0.002846853770108095\n",
      "train loss:0.032150701884751595\n",
      "train loss:0.006109541853277758\n",
      "train loss:0.007216012859958454\n",
      "train loss:0.002089250233572267\n",
      "train loss:0.014446313843681828\n",
      "train loss:0.01048418501528001\n",
      "train loss:0.00632459605138771\n",
      "train loss:0.0052743192887151945\n",
      "train loss:0.003967319207009782\n",
      "train loss:0.010012897572442017\n",
      "train loss:0.002016843962583816\n",
      "train loss:0.018200296933929997\n",
      "train loss:0.008597556300865497\n",
      "train loss:0.0018013585538951442\n",
      "train loss:0.004722714250136087\n",
      "train loss:0.003223872964603489\n",
      "train loss:0.003902396270087223\n",
      "train loss:0.005603650246576625\n",
      "train loss:0.005288860189103366\n",
      "train loss:0.004897047285408849\n",
      "train loss:0.009908548002559091\n",
      "train loss:0.00967837889201005\n",
      "train loss:0.0055147547361076785\n",
      "train loss:0.00501621897156008\n",
      "train loss:0.005917946483244828\n",
      "train loss:0.007200404540093398\n",
      "train loss:0.0024078285880454685\n",
      "train loss:0.003087021044030556\n",
      "train loss:0.001823803125814758\n",
      "train loss:0.00411875126259305\n",
      "train loss:0.00856321171952107\n",
      "train loss:0.011488728399306439\n",
      "train loss:0.007342120728406969\n",
      "train loss:0.001640440973581616\n",
      "train loss:0.0035905565684489268\n",
      "train loss:0.0013743271101599377\n",
      "train loss:0.005661134987603804\n",
      "train loss:0.02585865239808722\n",
      "train loss:0.0055112855959306315\n",
      "train loss:0.013058011277685655\n",
      "train loss:0.008876821076848854\n",
      "train loss:0.047884234712321415\n",
      "train loss:0.0013397185543469342\n",
      "train loss:0.006681560939368575\n",
      "train loss:0.005916800718155393\n",
      "train loss:0.003929506699995485\n",
      "train loss:0.01944665451368346\n",
      "train loss:0.05841834466078952\n",
      "train loss:0.012232469136826369\n",
      "train loss:0.002386154533050687\n",
      "train loss:0.03557217172345294\n",
      "train loss:0.004445315466312865\n",
      "train loss:0.014416379438222614\n",
      "train loss:0.002927197385705098\n",
      "train loss:0.0023636191722559443\n",
      "train loss:0.003252306389641476\n",
      "train loss:0.00571309648634257\n",
      "train loss:0.006803662235738459\n",
      "train loss:0.009200790365314238\n",
      "train loss:0.015190255200980201\n",
      "train loss:0.0013585689247588514\n",
      "train loss:0.0008922945714260555\n",
      "train loss:0.06547646275572473\n",
      "train loss:0.00869797961653626\n",
      "train loss:0.00810004421152777\n",
      "train loss:0.006834966691406667\n",
      "train loss:0.00421866717642217\n",
      "train loss:0.016940029285012554\n",
      "train loss:0.015522285047107398\n",
      "train loss:0.001863225594092339\n",
      "train loss:0.03307378150465903\n",
      "train loss:0.0026786646874574997\n",
      "train loss:0.004558034278083242\n",
      "train loss:0.018700709815078688\n",
      "train loss:0.007808558831550549\n",
      "train loss:0.00513422661499734\n",
      "train loss:0.0038499717550746645\n",
      "train loss:0.005058120240440211\n",
      "train loss:0.021301509915143953\n",
      "train loss:0.01371236203030178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.010323197154369352\n",
      "train loss:0.006896735882033206\n",
      "train loss:0.004156698531140432\n",
      "train loss:0.004877366544137167\n",
      "train loss:0.010006164919605771\n",
      "train loss:0.0013555776983703016\n",
      "train loss:0.001822837123515019\n",
      "train loss:0.008507318279739943\n",
      "train loss:0.011320804796719906\n",
      "train loss:0.005211204739445672\n",
      "train loss:0.008972761812189945\n",
      "train loss:0.0022116784938152915\n",
      "train loss:0.0058134533932354335\n",
      "train loss:0.02669786038865612\n",
      "train loss:0.020042307308965786\n",
      "train loss:0.0016478547580238197\n",
      "train loss:0.07865242652993405\n",
      "train loss:0.0013144425390700654\n",
      "train loss:0.008891380544071075\n",
      "train loss:0.0032985007688535817\n",
      "train loss:0.0014884028962688517\n",
      "train loss:0.010137154698921536\n",
      "train loss:0.021509975713568896\n",
      "train loss:0.003561504139692182\n",
      "train loss:0.0033431978547624835\n",
      "train loss:0.01277946308496408\n",
      "train loss:0.002289953890139464\n",
      "train loss:0.005437513371082963\n",
      "train loss:0.0027025387456435256\n",
      "train loss:0.006914591565987487\n",
      "train loss:0.010242886675304468\n",
      "train loss:0.010022313813380267\n",
      "train loss:0.0223615453829719\n",
      "train loss:0.004267144173524282\n",
      "train loss:0.011097474117882191\n",
      "train loss:0.010414583143237647\n",
      "train loss:0.01249441216063621\n",
      "train loss:0.003324303963418019\n",
      "train loss:0.005056008023184194\n",
      "train loss:0.008844398315277616\n",
      "train loss:0.006096858235471225\n",
      "train loss:0.008424291894859371\n",
      "train loss:0.024619386405189417\n",
      "train loss:0.0005590100182778071\n",
      "train loss:0.009575977740185626\n",
      "train loss:0.022096246738573706\n",
      "train loss:0.005937863986062361\n",
      "train loss:0.027385821629969893\n",
      "train loss:0.008443906036690006\n",
      "train loss:0.0027832566276225156\n",
      "train loss:0.003856644056874471\n",
      "train loss:0.005591906486358413\n",
      "train loss:0.0015397741569163567\n",
      "train loss:0.005928419190257007\n",
      "train loss:0.016123609312496866\n",
      "train loss:0.003772612792796763\n",
      "train loss:0.009733542504642813\n",
      "train loss:0.0018631595442059\n",
      "train loss:0.006173213500780416\n",
      "train loss:0.005038704478730001\n",
      "train loss:0.003253360784989876\n",
      "train loss:0.025612411679230916\n",
      "train loss:0.004249169732118263\n",
      "train loss:0.009300511375714714\n",
      "train loss:0.0013389125275982624\n",
      "train loss:0.011245165650685259\n",
      "train loss:0.006899382587881851\n",
      "train loss:0.000734818094419564\n",
      "train loss:0.0023513068621954687\n",
      "train loss:0.005032625062073625\n",
      "train loss:0.0009375216532054461\n",
      "train loss:0.005589079767813754\n",
      "train loss:0.016033106759613187\n",
      "train loss:0.0017763417344470003\n",
      "train loss:0.002671189576778413\n",
      "train loss:0.12381410115801708\n",
      "train loss:0.0036179689831264726\n",
      "train loss:0.0009474805508686766\n",
      "train loss:0.006941224616319086\n",
      "train loss:0.0015825260959366366\n",
      "train loss:0.008653688418956524\n",
      "train loss:0.0021805114978408063\n",
      "train loss:0.027457856637976702\n",
      "train loss:0.033907498242893803\n",
      "train loss:0.009099109870726188\n",
      "train loss:0.0019165406346521316\n",
      "train loss:0.0013172677662785781\n",
      "train loss:0.008581201732995977\n",
      "train loss:0.04805106450603334\n",
      "train loss:0.023460061936550036\n",
      "train loss:0.0026377328759868814\n",
      "train loss:0.0021523027976555567\n",
      "train loss:0.014756261786438013\n",
      "train loss:0.009350345604683005\n",
      "train loss:0.0013349056808162807\n",
      "train loss:0.0019677524721313728\n",
      "train loss:0.0031759781207525515\n",
      "train loss:0.0032874362356537018\n",
      "train loss:0.005923931525979325\n",
      "train loss:0.019602590918072232\n",
      "train loss:0.0010718946254263363\n",
      "train loss:0.0069372195611276145\n",
      "train loss:0.003558980790789287\n",
      "train loss:0.002542552054264864\n",
      "train loss:0.0022863387302437506\n",
      "train loss:0.009684517334806292\n",
      "train loss:0.015931885466644015\n",
      "train loss:0.0013719199584170088\n",
      "train loss:0.0010589352097524819\n",
      "train loss:0.00470105329937378\n",
      "train loss:0.004934110092875935\n",
      "train loss:0.004128193140363338\n",
      "train loss:0.0014573547303968063\n",
      "train loss:0.008313948125575413\n",
      "train loss:0.0016805250217981427\n",
      "train loss:0.006162831984483406\n",
      "train loss:0.0009878206674260868\n",
      "train loss:0.006186685787358684\n",
      "train loss:0.03784921148237053\n",
      "train loss:0.010656348004144823\n",
      "train loss:0.0037003652790357643\n",
      "train loss:0.0014737780822447484\n",
      "train loss:0.02237063339740033\n",
      "train loss:0.017385118302194687\n",
      "train loss:0.007315887156740008\n",
      "train loss:0.0019094684361523392\n",
      "train loss:0.013615483908655803\n",
      "train loss:0.001130035524124063\n",
      "train loss:0.006114562661625521\n",
      "train loss:0.001958854932891896\n",
      "train loss:0.010145561123925761\n",
      "train loss:0.004088634260675701\n",
      "train loss:0.009805375709479024\n",
      "train loss:0.0025606453033091186\n",
      "train loss:0.005247473591697115\n",
      "train loss:0.0063947202045147545\n",
      "train loss:0.007562817125996086\n",
      "train loss:0.031749744749217636\n",
      "train loss:0.008022976322640341\n",
      "train loss:0.003123378514115454\n",
      "train loss:0.010366172409686012\n",
      "train loss:0.0014323210386120206\n",
      "train loss:0.003866147472192492\n",
      "train loss:0.008405803619042947\n",
      "train loss:0.011210255016498335\n",
      "train loss:0.05040949481539456\n",
      "train loss:0.018134555573036254\n",
      "train loss:0.002478939810022077\n",
      "train loss:0.009309025749790397\n",
      "train loss:0.005482679786580747\n",
      "train loss:0.00361739300087686\n",
      "train loss:0.007068337471065743\n",
      "train loss:0.0021804839764352504\n",
      "train loss:0.006740570312097985\n",
      "train loss:0.02483517563606457\n",
      "train loss:0.001966481134261613\n",
      "train loss:0.02068015618218105\n",
      "train loss:0.011906413362088203\n",
      "train loss:0.017177587417719013\n",
      "train loss:0.03583864874535802\n",
      "train loss:0.003097697122406906\n",
      "train loss:0.031396831646284255\n",
      "train loss:0.025451672446467944\n",
      "train loss:0.0026483787268278634\n",
      "train loss:0.001796684822536936\n",
      "train loss:0.009207421361606296\n",
      "train loss:0.012410408036215617\n",
      "train loss:0.0010937653462456912\n",
      "train loss:0.004361918848334376\n",
      "train loss:0.001837782410980932\n",
      "train loss:0.013960264468513981\n",
      "train loss:0.002823943884936203\n",
      "train loss:0.019309801390889576\n",
      "train loss:0.003497456116922071\n",
      "train loss:0.007574775613464441\n",
      "train loss:0.031020161526605198\n",
      "train loss:0.006630470480244027\n",
      "train loss:0.0034033008348550147\n",
      "train loss:0.0020786926397158064\n",
      "train loss:0.010868032068245093\n",
      "train loss:0.005879157123669213\n",
      "train loss:0.01901300042546184\n",
      "train loss:0.006552238686120597\n",
      "train loss:0.011315832214510275\n",
      "train loss:0.013742174281208535\n",
      "train loss:0.005756320886896653\n",
      "train loss:0.014906384391894062\n",
      "train loss:0.008524025576497172\n",
      "train loss:0.03108346052873788\n",
      "train loss:0.006414579043528332\n",
      "train loss:0.008676760154517868\n",
      "train loss:0.0027746771720780715\n",
      "train loss:0.005651666494266294\n",
      "train loss:0.0018568976426294806\n",
      "train loss:0.014943657204011099\n",
      "train loss:0.022565818551850733\n",
      "train loss:0.006923468814284873\n",
      "train loss:0.006535795033883784\n",
      "train loss:0.009004084847722894\n",
      "train loss:0.0013526922698275231\n",
      "train loss:0.023808575713608168\n",
      "train loss:0.001020191831533233\n",
      "=== epoch:10, train acc:0.991, test acc:0.986 ===\n",
      "train loss:0.0033308563458453256\n",
      "train loss:0.0030755517112368426\n",
      "train loss:0.0065952165904085225\n",
      "train loss:0.01731385390170767\n",
      "train loss:0.0008677440870512576\n",
      "train loss:0.010459300292576546\n",
      "train loss:0.0021292920804718268\n",
      "train loss:0.002673556666699247\n",
      "train loss:0.021400741999838865\n",
      "train loss:0.012575762841769741\n",
      "train loss:0.00496259267578728\n",
      "train loss:0.002407048333119724\n",
      "train loss:0.037479788651516695\n",
      "train loss:0.0024816364760309167\n",
      "train loss:0.00486946222138501\n",
      "train loss:0.005808719154209975\n",
      "train loss:0.01219902777206491\n",
      "train loss:0.010733896750482752\n",
      "train loss:0.0023445024672386814\n",
      "train loss:0.0005263495617179107\n",
      "train loss:0.0030145296157659527\n",
      "train loss:0.013099447833015997\n",
      "train loss:0.020122010159723914\n",
      "train loss:0.02570426568649753\n",
      "train loss:0.010745634861210383\n",
      "train loss:0.00604876740771357\n",
      "train loss:0.005088981212492768\n",
      "train loss:0.03522054575112506\n",
      "train loss:0.001177973284243958\n",
      "train loss:0.006850326725980491\n",
      "train loss:0.0008043366697907856\n",
      "train loss:0.004395772998952903\n",
      "train loss:0.003995773222896752\n",
      "train loss:0.007316927684346953\n",
      "train loss:0.003240999274876318\n",
      "train loss:0.008765024301518792\n",
      "train loss:0.010661066721899284\n",
      "train loss:0.00965573538300222\n",
      "train loss:0.005515283234272952\n",
      "train loss:0.004484302991759135\n",
      "train loss:0.0031525593529004923\n",
      "train loss:0.009711375919224005\n",
      "train loss:0.002612871135685906\n",
      "train loss:0.004147991527522177\n",
      "train loss:0.002165141228081178\n",
      "train loss:0.010418683936131322\n",
      "train loss:0.0017340836943028181\n",
      "train loss:0.019998742852961774\n",
      "train loss:0.006150486908148223\n",
      "train loss:0.03410243552816928\n",
      "train loss:0.0031503086255345192\n",
      "train loss:0.0007185965946832281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.007848025903905277\n",
      "train loss:0.009191052801018586\n",
      "train loss:0.02259701850170936\n",
      "train loss:0.008000846721870519\n",
      "train loss:0.005891269135187564\n",
      "train loss:0.05355221858450378\n",
      "train loss:0.005603312470062927\n",
      "train loss:0.007347588286977984\n",
      "train loss:0.027847769157967425\n",
      "train loss:0.003711102899783844\n",
      "train loss:0.00798713241171559\n",
      "train loss:0.00895787082180237\n",
      "train loss:0.004449104854068586\n",
      "train loss:0.02197310553892728\n",
      "train loss:0.01657942926836731\n",
      "train loss:0.054395539733592874\n",
      "train loss:0.004975848086959239\n",
      "train loss:0.003358301130742233\n",
      "train loss:0.03482053337213699\n",
      "train loss:0.0031596570080537163\n",
      "train loss:0.0028971462444237466\n",
      "train loss:0.01094068552934155\n",
      "train loss:0.0020062719739470437\n",
      "train loss:0.006274753367017046\n",
      "train loss:0.000979161539953217\n",
      "train loss:0.0055354701826546\n",
      "train loss:0.007602527336669796\n",
      "train loss:0.014555728262734236\n",
      "train loss:0.0024242693032096273\n",
      "train loss:0.0007537516214269345\n",
      "train loss:0.005798778061839277\n",
      "train loss:0.004894934763582478\n",
      "train loss:0.0143738739724166\n",
      "train loss:0.006898783621510327\n",
      "train loss:0.012194760854560996\n",
      "train loss:0.004933228171600256\n",
      "train loss:0.004427891302582141\n",
      "train loss:0.01322821815015046\n",
      "train loss:0.0008485589545869557\n",
      "train loss:0.0013547018045160844\n",
      "train loss:0.0058103682491097595\n",
      "train loss:0.012922303055854423\n",
      "train loss:0.00309881914394485\n",
      "train loss:0.0014375835782152713\n",
      "train loss:0.02164762718797358\n",
      "train loss:0.0098807581704609\n",
      "train loss:0.00596895671974021\n",
      "train loss:0.001615007334579039\n",
      "train loss:0.004653613121148355\n",
      "train loss:0.0074754695217479124\n",
      "train loss:0.005069359807555288\n",
      "train loss:0.009747158406376357\n",
      "train loss:0.022760944775574127\n",
      "train loss:0.0013749259846388745\n",
      "train loss:0.0014564607359589892\n",
      "train loss:0.0029940262206982963\n",
      "train loss:0.006200880193874376\n",
      "train loss:0.015785748986520277\n",
      "train loss:0.010509688299926294\n",
      "train loss:0.007531889282175082\n",
      "train loss:0.010822359143671485\n",
      "train loss:0.014470407648883198\n",
      "train loss:0.0033349476214949323\n",
      "train loss:0.038731558413368485\n",
      "train loss:0.003221264091525179\n",
      "train loss:0.019686547684505215\n",
      "train loss:0.011065641540415803\n",
      "train loss:0.005160095817103416\n",
      "train loss:0.0019199961046081257\n",
      "train loss:0.007349502547036434\n",
      "train loss:0.006935928783453343\n",
      "train loss:0.01944010390122897\n",
      "train loss:0.006456456377844458\n",
      "train loss:0.004747137189349974\n",
      "train loss:0.033990054665130234\n",
      "train loss:0.0016199235651821243\n",
      "train loss:0.0030742553925370312\n",
      "train loss:0.0036032879763058805\n",
      "train loss:0.016051495084114055\n",
      "train loss:0.004643854150430457\n",
      "train loss:0.006446413835276348\n",
      "train loss:0.010286533078800014\n",
      "train loss:0.0009585997243138769\n",
      "train loss:0.010219636917748487\n",
      "train loss:0.008359579742719097\n",
      "train loss:0.0119858924315722\n",
      "train loss:0.002052742575398877\n",
      "train loss:0.0048369914877859094\n",
      "train loss:0.011770255605694453\n",
      "train loss:0.003153355024223077\n",
      "train loss:0.007036300094609868\n",
      "train loss:0.0009243918406505357\n",
      "train loss:0.0028934679495819043\n",
      "train loss:0.004428963384500437\n",
      "train loss:0.005948015121848565\n",
      "train loss:0.0007289860927304167\n",
      "train loss:0.016777300732609378\n",
      "train loss:0.003870505252031185\n",
      "train loss:0.001496467473651962\n",
      "train loss:0.0028688383247496133\n",
      "train loss:0.0028647322298946598\n",
      "train loss:0.0005428537705242536\n",
      "train loss:0.003467617552123086\n",
      "train loss:0.007526900448179112\n",
      "train loss:0.01818320871514654\n",
      "train loss:0.005850311606465954\n",
      "train loss:0.0033494098788437138\n",
      "train loss:0.0011274720258828287\n",
      "train loss:0.0050929903949997165\n",
      "train loss:0.007842286233437202\n",
      "train loss:0.009550816397316307\n",
      "train loss:0.01039137087505087\n",
      "train loss:0.029847507157458875\n",
      "train loss:0.005449987584589806\n",
      "train loss:0.0164458127642257\n",
      "train loss:0.001202152147661526\n",
      "train loss:0.004761675320701804\n",
      "train loss:0.0026836473626888945\n",
      "train loss:0.003442652354387542\n",
      "train loss:0.021502477272931655\n",
      "train loss:0.006472785342358168\n",
      "train loss:0.0017803799303181623\n",
      "train loss:0.006874436150218425\n",
      "train loss:0.0005403615319389612\n",
      "train loss:0.007109878290599172\n",
      "train loss:0.009011984743832717\n",
      "train loss:0.00111278002909413\n",
      "train loss:0.02293876174909677\n",
      "train loss:0.0032167555049637544\n",
      "train loss:0.017620816341901217\n",
      "train loss:0.005351250439570342\n",
      "train loss:0.027737091655693095\n",
      "train loss:0.0006074337243698168\n",
      "train loss:0.0009285387459142011\n",
      "train loss:0.00899510134204471\n",
      "train loss:0.0070336712105935895\n",
      "train loss:0.0011277651943861244\n",
      "train loss:0.002171340589407978\n",
      "train loss:0.001073380848268517\n",
      "train loss:0.002614311646404394\n",
      "train loss:0.01810589920178487\n",
      "train loss:0.006534553256278759\n",
      "train loss:0.0007094240953393424\n",
      "train loss:0.009616200893661856\n",
      "train loss:0.004122507616582051\n",
      "train loss:0.13429518735331228\n",
      "train loss:0.006400279691013433\n",
      "train loss:0.003938084338907476\n",
      "train loss:0.0004979205249343109\n",
      "train loss:0.0004083238908144245\n",
      "train loss:0.028557984656988254\n",
      "train loss:0.00801064652328814\n",
      "train loss:0.026852588180992235\n",
      "train loss:0.004441568612747091\n",
      "train loss:0.0061264603737223745\n",
      "train loss:0.00223869556997672\n",
      "train loss:0.003952666358611417\n",
      "train loss:0.013389264593402428\n",
      "train loss:0.0018461992656678167\n",
      "train loss:0.00340663629090455\n",
      "train loss:0.01877712127453372\n",
      "train loss:0.003473337080089726\n",
      "train loss:0.01171686544453774\n",
      "train loss:0.0022427013606244233\n",
      "train loss:0.00955390289139984\n",
      "train loss:0.006343758508485417\n",
      "train loss:0.015107852724732876\n",
      "train loss:0.0020596806214809894\n",
      "train loss:0.00020877874251295226\n",
      "train loss:0.002461632283857483\n",
      "train loss:0.0016173351346569986\n",
      "train loss:0.0049214178422056585\n",
      "train loss:0.0017339027481837717\n",
      "train loss:0.008281005562702844\n",
      "train loss:0.00929966032539715\n",
      "train loss:0.0042666257201941634\n",
      "train loss:0.01147499979401211\n",
      "train loss:0.008740266755680702\n",
      "train loss:0.003406379365913089\n",
      "train loss:0.001531745912296183\n",
      "train loss:0.04231135976896152\n",
      "train loss:0.0008730489327638114\n",
      "train loss:0.01367055468476317\n",
      "train loss:0.004351319255576809\n",
      "train loss:0.0302249583252649\n",
      "train loss:0.046709210816743896\n",
      "train loss:0.020834576471051736\n",
      "train loss:0.0040846982032612346\n",
      "train loss:0.006396655868091485\n",
      "train loss:0.028738712293916606\n",
      "train loss:0.006102916992317995\n",
      "train loss:0.006342172266186524\n",
      "train loss:0.0051918647219078495\n",
      "train loss:0.0005882824829263218\n",
      "train loss:0.0037358341041785086\n",
      "train loss:0.004933089641521385\n",
      "train loss:0.002905548112626697\n",
      "train loss:0.005046931917687229\n",
      "train loss:0.010107556020268294\n",
      "train loss:0.0024266709391563015\n",
      "train loss:0.020251156547558154\n",
      "train loss:0.010894282053245684\n",
      "train loss:0.0027042324172310405\n",
      "train loss:0.018144882648352664\n",
      "train loss:0.0015689614213399287\n",
      "train loss:0.0046499721582038125\n",
      "train loss:0.005095417420091536\n",
      "train loss:0.00052037416357807\n",
      "train loss:0.009381507169898624\n",
      "train loss:0.022809507725542265\n",
      "train loss:0.008446731919213878\n",
      "train loss:0.009499584863476341\n",
      "train loss:0.010165084390144106\n",
      "train loss:0.027481700047840462\n",
      "train loss:0.0065502766846997065\n",
      "train loss:0.0013418359229685622\n",
      "train loss:0.007031270791079629\n",
      "train loss:0.00732389038095386\n",
      "train loss:0.004491655104742629\n",
      "train loss:0.0013382750318280201\n",
      "train loss:0.02882020350379427\n",
      "train loss:0.0033500627107838966\n",
      "train loss:0.012636773258059848\n",
      "train loss:0.0008746206220573205\n",
      "train loss:0.02132738461726301\n",
      "train loss:0.011839812072676693\n",
      "train loss:0.0036212910231566454\n",
      "train loss:0.002054967629633643\n",
      "train loss:0.0030711051892892316\n",
      "train loss:0.006225181067311296\n",
      "train loss:0.04544559647287953\n",
      "train loss:0.01249765662605508\n",
      "train loss:0.02649607368651206\n",
      "train loss:0.0009962483401313304\n",
      "train loss:0.00548938982306423\n",
      "train loss:0.00040436307367408276\n",
      "train loss:0.01194151099194776\n",
      "train loss:0.0351920017205575\n",
      "train loss:0.004813723607021427\n",
      "train loss:0.012750076409033579\n",
      "train loss:0.0037939140811989423\n",
      "train loss:0.004782865572624302\n",
      "train loss:0.002656373467315914\n",
      "train loss:0.009387379547317443\n",
      "train loss:0.018223356629652857\n",
      "train loss:0.0052267361878868355\n",
      "train loss:0.01970990862800575\n",
      "train loss:0.0018976583944253687\n",
      "train loss:0.0033922726497212425\n",
      "train loss:0.00340553988964966\n",
      "train loss:0.004288169104311381\n",
      "train loss:0.001108689303408802\n",
      "train loss:0.0004063281970826715\n",
      "train loss:0.0016472369750771237\n",
      "train loss:0.006394244472800961\n",
      "train loss:0.004337139901099846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.015335131885291831\n",
      "train loss:0.016189111891340122\n",
      "train loss:0.005198367401077267\n",
      "train loss:0.007740220080215703\n",
      "train loss:0.0035240454753874754\n",
      "train loss:0.008437188193854982\n",
      "train loss:0.0045385170019648395\n",
      "train loss:0.00782729637716128\n",
      "train loss:0.00044184356738760996\n",
      "train loss:0.0007173817223817647\n",
      "train loss:0.001954161250535848\n",
      "train loss:0.005301892547931637\n",
      "train loss:0.009997832256038612\n",
      "train loss:0.0063454770353048185\n",
      "train loss:0.018062400000651752\n",
      "train loss:0.00450444532654795\n",
      "train loss:0.004668733550796834\n",
      "train loss:0.002130912466808115\n",
      "train loss:0.0009595512010277914\n",
      "train loss:0.002374049992638237\n",
      "train loss:0.004561410674404202\n",
      "train loss:0.003342287092077534\n",
      "train loss:0.0064112976817791625\n",
      "train loss:0.0010993435216251459\n",
      "train loss:0.008242918167744416\n",
      "train loss:0.0024331611711549466\n",
      "train loss:0.0034187877688683726\n",
      "train loss:0.009938991415575343\n",
      "train loss:0.004278426845982025\n",
      "train loss:0.0031705952357231133\n",
      "train loss:0.002056470726944032\n",
      "train loss:0.0008725370318238358\n",
      "train loss:0.003634278816345683\n",
      "train loss:0.003163511444628753\n",
      "train loss:0.005330563354501987\n",
      "train loss:0.0021365252391828972\n",
      "train loss:0.006447109786383789\n",
      "train loss:0.0011688811759735468\n",
      "train loss:0.012047365738345637\n",
      "train loss:0.0029672342772676863\n",
      "train loss:0.0010179931965700146\n",
      "train loss:0.0020273512132108324\n",
      "train loss:0.0052489841772931515\n",
      "train loss:0.00874084779251828\n",
      "train loss:0.011751145878133355\n",
      "train loss:0.006864682084637368\n",
      "train loss:0.0004735498763810257\n",
      "train loss:0.008461598031436151\n",
      "train loss:0.010553523089435296\n",
      "train loss:0.0019250802105085783\n",
      "train loss:0.0024310350912645786\n",
      "train loss:0.00473005382897484\n",
      "train loss:0.0016032317325066798\n",
      "train loss:0.004085321444028117\n",
      "train loss:0.003924299797098127\n",
      "train loss:0.006819045591191831\n",
      "train loss:0.027997984614667303\n",
      "train loss:0.00559731891111545\n",
      "train loss:0.010327559906793094\n",
      "train loss:0.04773917846760836\n",
      "train loss:0.0087467968430425\n",
      "train loss:0.004714718988720677\n",
      "train loss:0.005420416317758472\n",
      "train loss:0.01681942288900939\n",
      "train loss:0.01687806678618744\n",
      "train loss:0.005860758129920017\n",
      "train loss:0.0014711634582802865\n",
      "train loss:0.008406178718793388\n",
      "train loss:0.03072232431561588\n",
      "train loss:0.0012863235096191507\n",
      "train loss:0.01555079947064333\n",
      "train loss:0.004743663123514124\n",
      "train loss:0.004091115223867794\n",
      "train loss:0.010528419958802824\n",
      "train loss:0.006161733161297098\n",
      "train loss:0.007095482320171111\n",
      "train loss:0.00045128784984901633\n",
      "train loss:0.004278245770888148\n",
      "train loss:0.007866585304900649\n",
      "train loss:0.0013907484480200575\n",
      "train loss:0.0018173880292262816\n",
      "train loss:0.008849932920847075\n",
      "train loss:0.006888416732066102\n",
      "train loss:0.028036463470683243\n",
      "train loss:0.00847770065238923\n",
      "train loss:0.008785313395991642\n",
      "train loss:0.00856896941389954\n",
      "train loss:0.01764796196716194\n",
      "train loss:0.0005183277618356702\n",
      "train loss:0.0029159720403386185\n",
      "train loss:0.0012955750963828266\n",
      "train loss:0.00535986625931271\n",
      "train loss:0.0019454473063959996\n",
      "train loss:0.0060166525688985575\n",
      "train loss:0.011990363710316499\n",
      "train loss:0.014779316664322478\n",
      "train loss:0.09558825573812975\n",
      "train loss:0.004137699545967596\n",
      "train loss:0.0021305145631903962\n",
      "train loss:0.006914970385009072\n",
      "train loss:0.002440348820329506\n",
      "train loss:0.005367112716989816\n",
      "train loss:0.03618017057611387\n",
      "train loss:0.004383111583803664\n",
      "train loss:0.019464321058261732\n",
      "train loss:0.010092149804169923\n",
      "train loss:0.003903376398982306\n",
      "train loss:0.002625300251507033\n",
      "train loss:0.006018714326078055\n",
      "train loss:0.0025185166509056295\n",
      "train loss:0.004029393700066375\n",
      "train loss:0.004160735722313466\n",
      "train loss:0.0027094776188054375\n",
      "train loss:0.006083012384335464\n",
      "train loss:0.00656727764002226\n",
      "train loss:0.005504329630096056\n",
      "train loss:0.0026880085891924483\n",
      "train loss:0.0012467717344291542\n",
      "train loss:0.006421353502205383\n",
      "train loss:0.0015605177446609878\n",
      "train loss:0.007517859399631969\n",
      "train loss:0.0010345768841727022\n",
      "train loss:0.03786304276582451\n",
      "train loss:0.0006669826913498746\n",
      "train loss:0.012668513084895396\n",
      "train loss:0.0016289527192496923\n",
      "train loss:0.00499334656203739\n",
      "train loss:0.010837693095029419\n",
      "train loss:0.00029105057990511395\n",
      "train loss:0.0166190499048368\n",
      "train loss:0.0042115617570239435\n",
      "train loss:0.0025574714166501887\n",
      "train loss:0.008757179298390911\n",
      "train loss:0.009970870033744033\n",
      "train loss:0.0009255608137405763\n",
      "train loss:0.002798328679664328\n",
      "train loss:0.0040832281605733736\n",
      "train loss:0.006417209323201357\n",
      "train loss:0.0041956159746095\n",
      "train loss:0.007018493453455249\n",
      "train loss:0.013787634921008313\n",
      "train loss:0.006324349896672644\n",
      "train loss:0.007231291314755722\n",
      "train loss:0.031198431829978238\n",
      "train loss:0.0009035360301279032\n",
      "train loss:0.004683219634343184\n",
      "train loss:0.00926460999211664\n",
      "train loss:0.0024961152310007963\n",
      "train loss:0.0027244233793583287\n",
      "train loss:0.001824948855624995\n",
      "train loss:0.0009214882012675137\n",
      "train loss:0.01670053360240838\n",
      "train loss:0.014066485663036326\n",
      "train loss:0.011239820202863977\n",
      "train loss:0.005371282951005117\n",
      "train loss:0.010365165567543013\n",
      "train loss:0.05411445362386143\n",
      "train loss:0.006216865281515544\n",
      "train loss:0.0027476655108376147\n",
      "train loss:0.004271755139582879\n",
      "train loss:0.0012813827817067204\n",
      "train loss:0.0021034578149124942\n",
      "train loss:0.0021727770816504315\n",
      "train loss:0.0016807541159552719\n",
      "train loss:0.016180020383564583\n",
      "train loss:0.0027429506481049127\n",
      "train loss:0.01229314103128622\n",
      "train loss:0.011758210456572462\n",
      "train loss:0.007194371529579607\n",
      "train loss:0.0028069685292517084\n",
      "train loss:0.008748382061580658\n",
      "train loss:0.008441024952389166\n",
      "train loss:0.002774480514127637\n",
      "train loss:0.001114115807868437\n",
      "train loss:0.01483150916290789\n",
      "train loss:0.002986331936850486\n",
      "train loss:0.0016874419652994689\n",
      "train loss:0.004044295727521807\n",
      "train loss:0.0029912094546696534\n",
      "train loss:0.011261050914405477\n",
      "train loss:0.0014985282902897348\n",
      "train loss:0.008482276462863963\n",
      "train loss:0.003387257917466411\n",
      "train loss:0.009945877350572225\n",
      "train loss:0.005581069227307686\n",
      "train loss:0.003844905082294013\n",
      "train loss:0.00534022361854748\n",
      "train loss:0.0033683907169333813\n",
      "train loss:0.008910577902202876\n",
      "train loss:0.0011278400519284454\n",
      "train loss:0.0055422831095450755\n",
      "train loss:0.0029348007729896332\n",
      "train loss:0.0022865690810998022\n",
      "train loss:0.00323494235905458\n",
      "train loss:0.0013228215094918808\n",
      "train loss:0.0017714226545809527\n",
      "train loss:0.005348756544662989\n",
      "train loss:0.0006108242074927293\n",
      "train loss:0.00626259522367389\n",
      "train loss:0.0036010722978992867\n",
      "train loss:0.0036604387949636863\n",
      "train loss:0.002284146355307382\n",
      "train loss:0.004987219357540782\n",
      "train loss:0.01945991165959581\n",
      "train loss:0.00689012218830713\n",
      "train loss:0.013184012785787515\n",
      "train loss:0.009733888968178287\n",
      "train loss:0.005597461342326027\n",
      "train loss:0.0012872513597017088\n",
      "train loss:0.006833527160055367\n",
      "train loss:0.004752547042812602\n",
      "train loss:0.003194829557675127\n",
      "train loss:0.005948226614594923\n",
      "train loss:0.002664167255452965\n",
      "train loss:0.0064796156567383115\n",
      "train loss:0.001416211113337111\n",
      "train loss:0.008492346989119137\n",
      "train loss:0.006376391422810662\n",
      "train loss:0.008494136048087884\n",
      "train loss:0.013649094546064632\n",
      "train loss:0.004554550391896898\n",
      "train loss:0.002746154324363223\n",
      "train loss:0.0007193004403593834\n",
      "train loss:0.003178990837276756\n",
      "train loss:0.004476219722151686\n",
      "train loss:0.002304684981080095\n",
      "train loss:0.0010253346849963191\n",
      "train loss:0.003393630317753782\n",
      "train loss:0.004558336175641165\n",
      "train loss:0.0021228789676696965\n",
      "train loss:0.010201279287381088\n",
      "train loss:0.0010512461751167091\n",
      "train loss:0.001323628726851059\n",
      "train loss:0.007880535325133243\n",
      "train loss:0.001138663691276804\n",
      "train loss:0.0010372155094463744\n",
      "train loss:0.004249705423090332\n",
      "train loss:0.0026645628873063006\n",
      "train loss:0.003496838357101293\n",
      "train loss:0.015892476763990682\n",
      "train loss:0.01134230237227998\n",
      "train loss:0.0031109430955759427\n",
      "train loss:0.0021769635726993663\n",
      "train loss:0.010306238213728905\n",
      "train loss:0.0007751432616113366\n",
      "train loss:0.0050934526990290725\n",
      "train loss:0.0011025913199741797\n",
      "train loss:0.007038605776817707\n",
      "train loss:0.00935486645244428\n",
      "train loss:0.0025167535592654756\n",
      "train loss:0.001208082389036343\n",
      "train loss:0.002766919475405683\n",
      "train loss:0.040276413670652274\n",
      "train loss:0.00033071850528882584\n",
      "train loss:0.011960344131860328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0021465130734263154\n",
      "train loss:0.0003009227728040129\n",
      "train loss:0.003357850651266758\n",
      "train loss:0.0100653826029579\n",
      "train loss:0.0012628131944566515\n",
      "train loss:0.004521032268936951\n",
      "train loss:0.02548151353894005\n",
      "train loss:0.004968141290081181\n",
      "train loss:0.0009596912510215891\n",
      "train loss:0.005711507776782283\n",
      "train loss:0.0019902340975319088\n",
      "train loss:0.004073628094338125\n",
      "train loss:0.006425187305668592\n",
      "train loss:0.012786601965235664\n",
      "train loss:0.0018001179052548073\n",
      "train loss:0.0058227262682122175\n",
      "train loss:0.0030062926340032907\n",
      "train loss:0.03903691376453007\n",
      "train loss:0.03946108118071583\n",
      "train loss:0.02900922744039716\n",
      "train loss:0.007271011121444372\n",
      "train loss:0.014413869893107086\n",
      "train loss:0.0045187478388361265\n",
      "train loss:0.0015675212995301608\n",
      "train loss:0.0088029320923789\n",
      "train loss:0.0007537437670479788\n",
      "train loss:0.003353091243702557\n",
      "train loss:0.025960550025273418\n",
      "train loss:0.0014932149462286656\n",
      "train loss:0.005632611925545262\n",
      "train loss:0.005178778553642829\n",
      "train loss:0.007233843114584329\n",
      "train loss:0.0016376988125324492\n",
      "train loss:0.03707185811368574\n",
      "train loss:0.01031941103732128\n",
      "train loss:0.010188945635652228\n",
      "train loss:0.01622997688189591\n",
      "=== epoch:11, train acc:0.997, test acc:0.987 ===\n",
      "train loss:0.0019339635355098456\n",
      "train loss:0.0779752547751861\n",
      "train loss:0.001451631359944803\n",
      "train loss:0.0037289137722208\n",
      "train loss:0.016207313366851515\n",
      "train loss:0.0035491325041083054\n",
      "train loss:0.008382279624508887\n",
      "train loss:0.003935600111357173\n",
      "train loss:0.009523643287512044\n",
      "train loss:0.034913827726892825\n",
      "train loss:0.0035192172711717372\n",
      "train loss:0.005230400547065983\n",
      "train loss:0.0035692962747227238\n",
      "train loss:0.0007053302614579308\n",
      "train loss:0.0025509145739444922\n",
      "train loss:0.011604237070290459\n",
      "train loss:0.0017616282447528871\n",
      "train loss:0.007658546914357283\n",
      "train loss:0.0065239949057186875\n",
      "train loss:0.002742075661021143\n",
      "train loss:0.00938042532087476\n",
      "train loss:0.011535047948211141\n",
      "train loss:0.0014633931060946891\n",
      "train loss:0.016907123776474364\n",
      "train loss:0.002248803112463673\n",
      "train loss:0.0012072442966795155\n",
      "train loss:0.006327379152215754\n",
      "train loss:0.004477861556099529\n",
      "train loss:0.0014470304148627771\n",
      "train loss:0.0007282584667145617\n",
      "train loss:0.003556366353399499\n",
      "train loss:0.0015182832600090282\n",
      "train loss:0.002353444558549291\n",
      "train loss:0.003920476021933069\n",
      "train loss:0.00048688287313007763\n",
      "train loss:0.0030898774018661658\n",
      "train loss:0.001373461423563997\n",
      "train loss:0.0017671289424469507\n",
      "train loss:0.02252280710862071\n",
      "train loss:0.0008643889782627754\n",
      "train loss:0.0008740438015911693\n",
      "train loss:0.0012578658522718238\n",
      "train loss:0.0017073428684906316\n",
      "train loss:0.0008499626282137012\n",
      "train loss:0.008453316089923444\n",
      "train loss:0.006436027446696939\n",
      "train loss:0.00046295129880507863\n",
      "train loss:0.008807058578690125\n",
      "train loss:0.0004909798501589866\n",
      "train loss:0.012365105675300601\n",
      "train loss:0.0037946299593298568\n",
      "train loss:0.001675152059236157\n",
      "train loss:0.004905575887807284\n",
      "train loss:0.0013321218638209847\n",
      "train loss:0.002650187065484007\n",
      "train loss:0.03731577679138302\n",
      "train loss:0.0017413870811713646\n",
      "train loss:0.004636904043364077\n",
      "train loss:0.006658568863733383\n",
      "train loss:0.002002919157279881\n",
      "train loss:0.0008988175337889527\n",
      "train loss:0.002717254589407093\n",
      "train loss:0.007982637802793251\n",
      "train loss:0.0059722995031276415\n",
      "train loss:0.0016272260310578222\n",
      "train loss:0.004480641309500856\n",
      "train loss:0.0011756768871557773\n",
      "train loss:0.0017090130613223442\n",
      "train loss:0.003456154718706476\n",
      "train loss:0.001805104861511207\n",
      "train loss:0.002234569411241988\n",
      "train loss:0.006476616209124461\n",
      "train loss:0.0009710252759280911\n",
      "train loss:0.0021504853303092267\n",
      "train loss:0.023161996281338908\n",
      "train loss:0.002315578550547086\n",
      "train loss:0.005212017985300426\n",
      "train loss:0.00205262419519686\n",
      "train loss:0.003179952463843394\n",
      "train loss:0.0028989514932413235\n",
      "train loss:0.0013376936923306722\n",
      "train loss:0.003809420364056348\n",
      "train loss:0.003218422236237207\n",
      "train loss:0.0022470903859657704\n",
      "train loss:0.005778072196630512\n",
      "train loss:0.0017131886088483568\n",
      "train loss:0.002522348936597736\n",
      "train loss:0.0002234842913585117\n",
      "train loss:0.0007655169462164423\n",
      "train loss:0.0025219137929976916\n",
      "train loss:0.0004721380728032423\n",
      "train loss:0.004292158309185325\n",
      "train loss:0.03560919821588421\n",
      "train loss:0.0023420669188121733\n",
      "train loss:0.00404001578310716\n",
      "train loss:0.004165975938437525\n",
      "train loss:0.0013535913172946761\n",
      "train loss:0.003681940178500189\n",
      "train loss:0.004717594779355534\n",
      "train loss:0.00884644724177991\n",
      "train loss:0.0022463017021612896\n",
      "train loss:0.0037776312731078216\n",
      "train loss:0.016086271135991398\n",
      "train loss:0.014490384791867941\n",
      "train loss:0.0006254618002417688\n",
      "train loss:0.005090560498895129\n",
      "train loss:0.0003290574597385175\n",
      "train loss:0.0016050124801323881\n",
      "train loss:0.006043910315907453\n",
      "train loss:0.0009677374605271007\n",
      "train loss:0.002760559433342749\n",
      "train loss:0.005914195740006304\n",
      "train loss:0.005766088596315476\n",
      "train loss:0.0035409723461991296\n",
      "train loss:0.0013861013915574263\n",
      "train loss:0.009056239362935066\n",
      "train loss:0.00042492908106003715\n",
      "train loss:0.011986253252491735\n",
      "train loss:0.0010742999311820834\n",
      "train loss:0.006147979426987204\n",
      "train loss:0.0005334203001253673\n",
      "train loss:0.0008086957713641256\n",
      "train loss:0.003633556122855153\n",
      "train loss:0.00505553283002066\n",
      "train loss:0.0027820040862099583\n",
      "train loss:0.0031063001854994892\n",
      "train loss:0.0031049327126371185\n",
      "train loss:0.001967832807396302\n",
      "train loss:0.002005389765105669\n",
      "train loss:0.0027043469814413312\n",
      "train loss:0.007266782501430853\n",
      "train loss:0.0010850716214008734\n",
      "train loss:0.007623292371455312\n",
      "train loss:0.0026624398042573235\n",
      "train loss:0.004753118525385381\n",
      "train loss:0.001765763915825687\n",
      "train loss:0.0011307766210016524\n",
      "train loss:0.015621362430262485\n",
      "train loss:0.06022696820608853\n",
      "train loss:0.009750204879374662\n",
      "train loss:0.0038964015851657356\n",
      "train loss:0.001886183758976225\n",
      "train loss:0.00046471000821817995\n",
      "train loss:0.003614374656637209\n",
      "train loss:0.003686981872395253\n",
      "train loss:0.013592821357921236\n",
      "train loss:0.014357060533704271\n",
      "train loss:0.0014673633971297607\n",
      "train loss:0.0034848236514706727\n",
      "train loss:0.007346084525811317\n",
      "train loss:0.001608924236474321\n",
      "train loss:0.0016487607198571613\n",
      "train loss:0.0012922496409563586\n",
      "train loss:0.008809658754537797\n",
      "train loss:0.003622914251578372\n",
      "train loss:0.008872283865109387\n",
      "train loss:0.002189364404975916\n",
      "train loss:0.0016778640127262346\n",
      "train loss:0.000494064646641228\n",
      "train loss:0.048540748805013356\n",
      "train loss:0.0008331171465252693\n",
      "train loss:0.000573026315055186\n",
      "train loss:0.0009842596861611443\n",
      "train loss:0.005380446751634285\n",
      "train loss:0.0019340494271737937\n",
      "train loss:0.0015683801210154005\n",
      "train loss:0.0027484131550005435\n",
      "train loss:0.001095198620818022\n",
      "train loss:0.002802182684547568\n",
      "train loss:0.004630126290521391\n",
      "train loss:0.0025659771425418972\n",
      "train loss:0.007789496676185147\n",
      "train loss:0.03994545324832564\n",
      "train loss:0.006408586927515061\n",
      "train loss:0.003239227304508896\n",
      "train loss:0.006301860134371521\n",
      "train loss:0.01091561209441583\n",
      "train loss:0.007231865780501644\n",
      "train loss:0.009614914686841903\n",
      "train loss:0.0006218228823117623\n",
      "train loss:0.004450531720710044\n",
      "train loss:0.002351503419676309\n",
      "train loss:0.02648319774469427\n",
      "train loss:0.03943720535507976\n",
      "train loss:0.01839562860009348\n",
      "train loss:0.017881986507457356\n",
      "train loss:0.003459071073183662\n",
      "train loss:0.0014272456815177061\n",
      "train loss:0.0016532160301796878\n",
      "train loss:0.0057103921015171965\n",
      "train loss:0.010359397560650314\n",
      "train loss:0.0009118571377176365\n",
      "train loss:0.0032922945626958906\n",
      "train loss:0.0019223204254639422\n",
      "train loss:0.005979339923390535\n",
      "train loss:0.003595599271297132\n",
      "train loss:0.03222801670820064\n",
      "train loss:0.0016074517375088792\n",
      "train loss:0.007523934147841343\n",
      "train loss:0.001036983454975041\n",
      "train loss:0.005163349032690706\n",
      "train loss:0.009432534388838905\n",
      "train loss:0.0008609687572590022\n",
      "train loss:0.004024924333857506\n",
      "train loss:0.020556234572661262\n",
      "train loss:0.002930116333988343\n",
      "train loss:0.005488265796177894\n",
      "train loss:0.006759115452050737\n",
      "train loss:0.0015877111030748359\n",
      "train loss:0.0025047654023292606\n",
      "train loss:0.012701953468328137\n",
      "train loss:0.0029373834724124455\n",
      "train loss:0.01874414915769006\n",
      "train loss:0.0048903103002582516\n",
      "train loss:0.00016400334139590498\n",
      "train loss:0.008158995699590364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.008881977259387141\n",
      "train loss:0.0011641031088843704\n",
      "train loss:0.0014779089133794597\n",
      "train loss:0.00471653265205865\n",
      "train loss:0.0014466879654973105\n",
      "train loss:0.0011248407791050784\n",
      "train loss:0.021073420998734726\n",
      "train loss:0.0006072288552092981\n",
      "train loss:0.006807273668753435\n",
      "train loss:0.003116045900423716\n",
      "train loss:0.0031202831001778016\n",
      "train loss:0.0016831065153478384\n",
      "train loss:0.005322318641119778\n",
      "train loss:0.01195857878119068\n",
      "train loss:0.001862584299515884\n",
      "train loss:0.004126141884493454\n",
      "train loss:0.00063250559120142\n",
      "train loss:0.002607550084307163\n",
      "train loss:0.000980805128519944\n",
      "train loss:0.013027730533600863\n",
      "train loss:0.0007550912467425583\n",
      "train loss:0.000703481329074576\n",
      "train loss:0.026206808147378045\n",
      "train loss:0.010022961812579221\n",
      "train loss:0.0030849430517209345\n",
      "train loss:0.0041828922183017436\n",
      "train loss:0.002478140804061561\n",
      "train loss:0.0015417599540255068\n",
      "train loss:0.003993989446758321\n",
      "train loss:0.003678100879264956\n",
      "train loss:0.000867568280919771\n",
      "train loss:0.015893237641959268\n",
      "train loss:0.005143343056982603\n",
      "train loss:0.0002574064648093726\n",
      "train loss:0.008564804940856773\n",
      "train loss:0.004515602150329767\n",
      "train loss:0.0017277007782053669\n",
      "train loss:0.005736360311540919\n",
      "train loss:0.000986042316292276\n",
      "train loss:0.0017354911816294604\n",
      "train loss:0.002980190202528121\n",
      "train loss:0.001271533589312827\n",
      "train loss:0.010727416169597073\n",
      "train loss:0.0004724179313524432\n",
      "train loss:0.0009265666662567271\n",
      "train loss:0.00669591291814356\n",
      "train loss:0.0016385269885468062\n",
      "train loss:0.006380713572210699\n",
      "train loss:0.006123583619099459\n",
      "train loss:0.0011166367988165423\n",
      "train loss:0.003188624217601249\n",
      "train loss:0.0014108714180558828\n",
      "train loss:0.0007505634347084776\n",
      "train loss:0.016233028445739442\n",
      "train loss:0.000996839984733805\n",
      "train loss:0.007161008761320351\n",
      "train loss:0.0024623337806388155\n",
      "train loss:0.006120901683563419\n",
      "train loss:0.0424436052457677\n",
      "train loss:0.0448131955410636\n",
      "train loss:0.0013205670318935413\n",
      "train loss:0.002198061590520575\n",
      "train loss:0.0003937688752296933\n",
      "train loss:0.00023406455938981157\n",
      "train loss:0.0008618684206175482\n",
      "train loss:0.008171488697754638\n",
      "train loss:0.002499654566254916\n",
      "train loss:0.004273880512403096\n",
      "train loss:0.0019157641594035356\n",
      "train loss:0.001873985986637579\n",
      "train loss:0.0008435651970248805\n",
      "train loss:0.001817713187547734\n",
      "train loss:0.0015807231896182855\n",
      "train loss:0.005670855844520903\n",
      "train loss:0.00590066401158394\n",
      "train loss:0.031422894952759385\n",
      "train loss:0.013176763044000825\n",
      "train loss:0.0008355192699209172\n",
      "train loss:0.009456930547071002\n",
      "train loss:0.023364067603744793\n",
      "train loss:0.0043560937486733535\n",
      "train loss:0.004357130309398636\n",
      "train loss:0.0024639105394649364\n",
      "train loss:0.013664026386338258\n",
      "train loss:0.0009075259789615232\n",
      "train loss:0.0021984592709466786\n",
      "train loss:0.06964870573871432\n",
      "train loss:0.003129502248457516\n",
      "train loss:0.003425325045158442\n",
      "train loss:0.009012478256358883\n",
      "train loss:0.0004479553307119976\n",
      "train loss:0.01398232038458521\n",
      "train loss:0.0009912201206698126\n",
      "train loss:0.008964567839098096\n",
      "train loss:0.028094358081729665\n",
      "train loss:0.0034258093981326715\n",
      "train loss:0.0010375609572193998\n",
      "train loss:0.000957316358934791\n",
      "train loss:0.0035318615621471126\n",
      "train loss:0.010910615731459157\n",
      "train loss:0.0004207561768722392\n",
      "train loss:0.0006315037486116464\n",
      "train loss:0.0021825370355605007\n",
      "train loss:0.0006973556503000258\n",
      "train loss:0.001457207566375593\n",
      "train loss:0.0029158196044758774\n",
      "train loss:0.0008246036303383943\n",
      "train loss:0.008654517997718275\n",
      "train loss:0.0015477604924348598\n",
      "train loss:0.005276417396434287\n",
      "train loss:0.01081004190456954\n",
      "train loss:0.013491988768053676\n",
      "train loss:0.0006242821163015492\n",
      "train loss:0.004108046500378524\n",
      "train loss:0.016330520616881904\n",
      "train loss:0.0010094119007845789\n",
      "train loss:0.0033156122176193565\n",
      "train loss:0.010522681316039789\n",
      "train loss:0.0018052116010387228\n",
      "train loss:0.0010670015583889212\n",
      "train loss:0.0016765216891203466\n",
      "train loss:0.008881380898807877\n",
      "train loss:0.0024093023169386905\n",
      "train loss:0.0019979866576781374\n",
      "train loss:0.0060693119791548145\n",
      "train loss:0.0018645621745008451\n",
      "train loss:0.0113568846710632\n",
      "train loss:0.005458928095572334\n",
      "train loss:0.0023164956100950834\n",
      "train loss:0.00890389332906057\n",
      "train loss:0.00594908932940802\n",
      "train loss:0.0015272828518603026\n",
      "train loss:0.0012345194905976852\n",
      "train loss:0.0034362969696826256\n",
      "train loss:0.001828835611400198\n",
      "train loss:0.001014334907408436\n",
      "train loss:0.011311482279377647\n",
      "train loss:0.0026854358063565383\n",
      "train loss:0.0013551839252811768\n",
      "train loss:0.0019547403504909635\n",
      "train loss:0.003820764231124326\n",
      "train loss:0.00492353896581254\n",
      "train loss:0.02229123261169528\n",
      "train loss:0.000916486584047091\n",
      "train loss:0.0011568930686842406\n",
      "train loss:0.002081485110306459\n",
      "train loss:0.00020224176437072828\n",
      "train loss:0.001086500003534303\n",
      "train loss:0.0033227749275222197\n",
      "train loss:0.0007982126636810224\n",
      "train loss:0.012735735416785812\n",
      "train loss:0.0009600114547623794\n",
      "train loss:0.0029255217087856985\n",
      "train loss:0.003158144986623495\n",
      "train loss:0.0005417594303851102\n",
      "train loss:0.006539621908907211\n",
      "train loss:0.0029956998076570494\n",
      "train loss:0.001762100457906459\n",
      "train loss:0.0009878971927576876\n",
      "train loss:0.030856943117255772\n",
      "train loss:0.0020420351106618224\n",
      "train loss:0.015485483060818334\n",
      "train loss:0.004229847349753979\n",
      "train loss:0.024002533694675147\n",
      "train loss:0.0006389938114856901\n",
      "train loss:0.0028704846669167353\n",
      "train loss:0.006364573088477824\n",
      "train loss:0.0009230466634885768\n",
      "train loss:0.0018319795870524402\n",
      "train loss:0.0028772349056757985\n",
      "train loss:0.00171699522225492\n",
      "train loss:0.00400120465126461\n",
      "train loss:0.009043415589915775\n",
      "train loss:0.009041202957680256\n",
      "train loss:0.0004166096397282322\n",
      "train loss:0.0072680517314976335\n",
      "train loss:0.0007256666641078797\n",
      "train loss:0.00423678967618177\n",
      "train loss:0.002183625728053031\n",
      "train loss:0.0011066195163359988\n",
      "train loss:0.000903735430284026\n",
      "train loss:0.0022968739457420897\n",
      "train loss:0.008094533883174153\n",
      "train loss:0.003007064158217405\n",
      "train loss:0.006547946780509898\n",
      "train loss:0.005757834713709961\n",
      "train loss:0.011316485020982616\n",
      "train loss:0.007223446491006078\n",
      "train loss:0.005820531937543972\n",
      "train loss:0.0018155410290353017\n",
      "train loss:0.003962458723636059\n",
      "train loss:0.006212952250107004\n",
      "train loss:0.004607078478327044\n",
      "train loss:0.003310891952520575\n",
      "train loss:0.0006950713405801963\n",
      "train loss:0.0025992453215059417\n",
      "train loss:0.005121986828417684\n",
      "train loss:0.0022811485652349654\n",
      "train loss:0.025912754640324612\n",
      "train loss:0.04037072170567276\n",
      "train loss:0.008928489985504268\n",
      "train loss:0.006594803686170052\n",
      "train loss:0.0028021420024329645\n",
      "train loss:0.00040718054712522955\n",
      "train loss:0.0008285023184176258\n",
      "train loss:0.0016168147085817576\n",
      "train loss:0.002266851760925928\n",
      "train loss:0.0031498541684766147\n",
      "train loss:0.00046144121609560917\n",
      "train loss:0.0025493519273617903\n",
      "train loss:0.002394228021329425\n",
      "train loss:0.00046557813168950904\n",
      "train loss:0.004147920175926026\n",
      "train loss:0.006126858539104737\n",
      "train loss:0.005484330718741402\n",
      "train loss:0.008730863645704957\n",
      "train loss:0.0036201862700033305\n",
      "train loss:0.004766496051715925\n",
      "train loss:0.0017487258283302822\n",
      "train loss:0.008582100134501164\n",
      "train loss:0.0034788802910610704\n",
      "train loss:0.004320185678829855\n",
      "train loss:0.0018190176335732972\n",
      "train loss:0.004134414329029241\n",
      "train loss:0.0013711232828782732\n",
      "train loss:0.005555915916873725\n",
      "train loss:0.002132071717043553\n",
      "train loss:0.001975876060492495\n",
      "train loss:0.0008829551808962346\n",
      "train loss:0.004549944302365395\n",
      "train loss:0.0025966149392629406\n",
      "train loss:0.0023693313758836234\n",
      "train loss:0.0037533608731943357\n",
      "train loss:0.0031955146482146347\n",
      "train loss:0.005164717866953257\n",
      "train loss:0.003659955193971443\n",
      "train loss:0.0064084628546373715\n",
      "train loss:0.0006764827794768531\n",
      "train loss:0.0017935522452373113\n",
      "train loss:0.0023519769522098986\n",
      "train loss:0.010783397958524262\n",
      "train loss:0.004080300754025336\n",
      "train loss:0.0018802509462910364\n",
      "train loss:0.0004091184529721105\n",
      "train loss:0.0008578011288592628\n",
      "train loss:0.0007328289934555396\n",
      "train loss:0.0004818979006057173\n",
      "train loss:0.0043386230305432665\n",
      "train loss:0.01663580329492736\n",
      "train loss:0.00035144393264854704\n",
      "train loss:0.012663342335451229\n",
      "train loss:0.0009557487336230173\n",
      "train loss:0.001097863583818128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.004447076536893202\n",
      "train loss:0.006120539815899936\n",
      "train loss:0.01474108613637235\n",
      "train loss:0.00238938141702812\n",
      "train loss:0.006605884825525029\n",
      "train loss:0.0070492467484277385\n",
      "train loss:0.0014680631863908521\n",
      "train loss:0.00027438596793599143\n",
      "train loss:0.004395426228505874\n",
      "train loss:0.0029821796986918255\n",
      "train loss:0.011717884628121766\n",
      "train loss:0.0067629130944975415\n",
      "train loss:0.004652067997083315\n",
      "train loss:0.010988167938653662\n",
      "train loss:0.0026305598588506245\n",
      "train loss:0.004790086015723992\n",
      "train loss:0.002450359263130539\n",
      "train loss:0.016532750360072245\n",
      "train loss:0.004101125604544465\n",
      "train loss:0.00016415402880296388\n",
      "train loss:0.007703212155011504\n",
      "train loss:0.023042544956810667\n",
      "train loss:0.011595285723621819\n",
      "train loss:0.004582266102048293\n",
      "train loss:0.009487127240419524\n",
      "train loss:0.001639146078077839\n",
      "train loss:0.0027684207893109757\n",
      "train loss:0.006363957691922503\n",
      "train loss:0.0013208959150419711\n",
      "train loss:0.03626990135171853\n",
      "train loss:0.003972670295158033\n",
      "train loss:0.012002290505838027\n",
      "train loss:0.005934029008250118\n",
      "train loss:0.0072820344353501255\n",
      "train loss:0.001442139699102601\n",
      "train loss:0.008236859136016897\n",
      "train loss:0.006127714726958111\n",
      "train loss:0.00016434599936529084\n",
      "train loss:0.00433471644491875\n",
      "train loss:0.008187571547957535\n",
      "train loss:0.0016991020477087131\n",
      "train loss:0.0036972873851801925\n",
      "train loss:0.020782304838500097\n",
      "train loss:0.0010028828277785522\n",
      "train loss:0.0034764975020366955\n",
      "train loss:0.0047611593108243784\n",
      "train loss:0.008497701054574244\n",
      "train loss:0.007099060274682875\n",
      "train loss:0.0019755635414153397\n",
      "train loss:0.0006028200647405172\n",
      "train loss:0.011242103300817792\n",
      "train loss:0.0009304551635564423\n",
      "train loss:0.013999503768792353\n",
      "train loss:0.01195930885590328\n",
      "train loss:0.005051348745322867\n",
      "train loss:0.010401598159603112\n",
      "train loss:0.001434465576691632\n",
      "train loss:0.014511540047650455\n",
      "train loss:0.002391763449204269\n",
      "train loss:0.003957000109030525\n",
      "train loss:0.004086932669007275\n",
      "train loss:0.004061732582083549\n",
      "train loss:0.004632670427790735\n",
      "train loss:0.00754301106539781\n",
      "train loss:0.0009911480830049398\n",
      "train loss:0.0016442346430895177\n",
      "train loss:0.002140288119329278\n",
      "train loss:0.00494739646893194\n",
      "train loss:0.0038191607015596275\n",
      "train loss:0.002819750109744908\n",
      "train loss:0.0016811511987264412\n",
      "train loss:0.013670532621198151\n",
      "train loss:0.0009754323877819616\n",
      "train loss:0.009262009574134563\n",
      "train loss:0.004180542518810419\n",
      "train loss:0.007370694928391985\n",
      "train loss:0.00048723752935427115\n",
      "train loss:0.000890360366218455\n",
      "train loss:0.002214023189816089\n",
      "train loss:0.0020663672115052607\n",
      "train loss:0.0027166868107682774\n",
      "train loss:0.00030360355316864934\n",
      "train loss:0.006995298873361766\n",
      "train loss:0.0010024492351116574\n",
      "train loss:0.0011829294720773274\n",
      "train loss:0.0024635229343964882\n",
      "train loss:0.00018841460442767466\n",
      "train loss:0.0014258542212516403\n",
      "train loss:0.006133393231578577\n",
      "train loss:0.008897491356380962\n",
      "train loss:0.0023257187391327165\n",
      "train loss:0.00133021057770388\n",
      "train loss:0.013377494870934863\n",
      "train loss:0.0022241442092161058\n",
      "train loss:0.0022438127639495963\n",
      "train loss:0.005458906420407649\n",
      "train loss:0.031456263805855735\n",
      "train loss:0.0006809666773708456\n",
      "train loss:0.000414479528129276\n",
      "train loss:0.000669571834510418\n",
      "train loss:0.014991947154750902\n",
      "train loss:0.002460681093656155\n",
      "train loss:0.007230885035132703\n",
      "train loss:0.0028705526299015955\n",
      "train loss:0.0015944041283652516\n",
      "train loss:0.009801945613071282\n",
      "train loss:0.0008042916462749617\n",
      "train loss:0.0027814174625343567\n",
      "train loss:0.0006267025166988833\n",
      "train loss:0.003527520909447709\n",
      "train loss:0.012100528966359688\n",
      "train loss:0.0005069534514783278\n",
      "train loss:0.005246337416943241\n",
      "train loss:0.004410317308122423\n",
      "train loss:0.001143821600682559\n",
      "train loss:0.011987932769937266\n",
      "train loss:0.0009718958985494425\n",
      "train loss:0.005138542130914926\n",
      "train loss:0.00048116959331520945\n",
      "train loss:0.002223762235600415\n",
      "train loss:0.0007408113924301349\n",
      "train loss:0.004820722011582299\n",
      "train loss:0.004629848223057962\n",
      "train loss:0.0014719743878759237\n",
      "train loss:0.001912783607577696\n",
      "train loss:0.001320541477584518\n",
      "train loss:0.0008257738628337476\n",
      "train loss:0.009324881213475623\n",
      "train loss:0.0010982246764606716\n",
      "train loss:0.01084762261482013\n",
      "train loss:0.004139708815899223\n",
      "=== epoch:12, train acc:0.995, test acc:0.982 ===\n",
      "train loss:0.0008261291097826157\n",
      "train loss:0.0026117536844435353\n",
      "train loss:0.0049913626846861915\n",
      "train loss:0.0014061040760900698\n",
      "train loss:0.005446940731277777\n",
      "train loss:0.0021425654252937155\n",
      "train loss:0.0011426822525153037\n",
      "train loss:0.00205951081761746\n",
      "train loss:0.003435348478542802\n",
      "train loss:0.0008425495753512082\n",
      "train loss:0.0002532101695517978\n",
      "train loss:0.0005520579577617507\n",
      "train loss:0.0031486471343438183\n",
      "train loss:0.0036173237619909894\n",
      "train loss:0.008496458622410078\n",
      "train loss:0.008612355823549828\n",
      "train loss:0.005507007290720007\n",
      "train loss:0.0002879324190066824\n",
      "train loss:0.0007265048555756389\n",
      "train loss:0.0024861100576843297\n",
      "train loss:0.008792742946315973\n",
      "train loss:0.037950959823377615\n",
      "train loss:0.0013376281535261686\n",
      "train loss:0.005312158866821034\n",
      "train loss:0.0028470682101262405\n",
      "train loss:0.0014838596157662493\n",
      "train loss:0.004290752637516203\n",
      "train loss:0.0021225656857582686\n",
      "train loss:0.004979630696744201\n",
      "train loss:0.002047780120077809\n",
      "train loss:0.009870688832045808\n",
      "train loss:0.0019084095976378594\n",
      "train loss:0.04076147645681891\n",
      "train loss:0.026996362394056138\n",
      "train loss:0.010045471759480961\n",
      "train loss:0.0017701704034467785\n",
      "train loss:0.003365835562788637\n",
      "train loss:0.003473749598538949\n",
      "train loss:0.01751437590040882\n",
      "train loss:0.0003264954202767455\n",
      "train loss:0.00760551553578726\n",
      "train loss:0.02670304030884431\n",
      "train loss:0.02771697925900256\n",
      "train loss:0.011798452438873166\n",
      "train loss:0.0010046132058046382\n",
      "train loss:0.000635152044978324\n",
      "train loss:0.03067526339135704\n",
      "train loss:0.004911685234327995\n",
      "train loss:0.014805769473728032\n",
      "train loss:0.005747757369629923\n",
      "train loss:0.0030544550142821234\n",
      "train loss:0.0007788700971078445\n",
      "train loss:0.0013525498870439886\n",
      "train loss:0.005001867686334558\n",
      "train loss:0.010349982826997308\n",
      "train loss:0.007660442775353203\n",
      "train loss:0.0013023560010799761\n",
      "train loss:0.00029326735915532543\n",
      "train loss:0.0011018768352230503\n",
      "train loss:0.0014879422075811338\n",
      "train loss:0.001293511326581484\n",
      "train loss:0.0015754275596630307\n",
      "train loss:0.0010121355473787872\n",
      "train loss:0.004270275993405059\n",
      "train loss:0.001805462851485239\n",
      "train loss:0.003954709506607746\n",
      "train loss:0.028877532410101298\n",
      "train loss:0.005183741848733881\n",
      "train loss:0.001672730224985598\n",
      "train loss:0.004229841598272462\n",
      "train loss:0.0004082090002088769\n",
      "train loss:0.001441794910714844\n",
      "train loss:0.005779066958996805\n",
      "train loss:0.0010411389101183913\n",
      "train loss:0.0007613830823002423\n",
      "train loss:0.00582260653241087\n",
      "train loss:0.0025827093111659345\n",
      "train loss:0.05845288240118811\n",
      "train loss:0.0035881212317066934\n",
      "train loss:0.0025306337048683807\n",
      "train loss:0.009101507274356834\n",
      "train loss:0.002686045917607657\n",
      "train loss:0.0046406535809451555\n",
      "train loss:0.006885634039914521\n",
      "train loss:0.0024854081236799393\n",
      "train loss:0.0018982471250029356\n",
      "train loss:0.0026472419022168492\n",
      "train loss:0.004568721788383803\n",
      "train loss:0.0036518915239590155\n",
      "train loss:0.004549007543219506\n",
      "train loss:0.008801519034117354\n",
      "train loss:0.0034140900936901163\n",
      "train loss:0.004314703854914623\n",
      "train loss:0.00550666514382775\n",
      "train loss:0.01771873270407053\n",
      "train loss:0.0060623060264382075\n",
      "train loss:0.0063901809486622075\n",
      "train loss:0.0022314235364544826\n",
      "train loss:0.01407327029184713\n",
      "train loss:0.00025170003568427085\n",
      "train loss:0.0034594080593342152\n",
      "train loss:0.00047820177705796147\n",
      "train loss:0.00022368906682945606\n",
      "train loss:0.002168261201535014\n",
      "train loss:0.009914553720692014\n",
      "train loss:0.0009863923178226014\n",
      "train loss:0.015379427034619218\n",
      "train loss:0.007352615231783776\n",
      "train loss:0.001098317651453084\n",
      "train loss:0.0012131934806851275\n",
      "train loss:0.002666410820136209\n",
      "train loss:0.003149282867542827\n",
      "train loss:0.0011259337069855838\n",
      "train loss:0.002562377488177323\n",
      "train loss:0.022901036410421467\n",
      "train loss:0.0017097344824447377\n",
      "train loss:0.004549907056212433\n",
      "train loss:0.0007197754569841142\n",
      "train loss:0.0012599253415351546\n",
      "train loss:0.004260226358730995\n",
      "train loss:0.013261759652776895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.004917466587883255\n",
      "train loss:0.00035924308964185804\n",
      "train loss:0.0026339132887032855\n",
      "train loss:0.0025658408326778206\n",
      "train loss:0.0009236649492217261\n",
      "train loss:0.0014566552303204611\n",
      "train loss:0.002037107750079802\n",
      "train loss:0.003602428545293324\n",
      "train loss:0.002128253862765694\n",
      "train loss:0.002382402061900695\n",
      "train loss:0.00390721467116901\n",
      "train loss:0.001458340651534962\n",
      "train loss:0.007049116084300591\n",
      "train loss:0.0050030924250679355\n",
      "train loss:0.0049785411917252324\n",
      "train loss:0.0022863202800863154\n",
      "train loss:0.0018685147659904572\n",
      "train loss:0.002763421615418501\n",
      "train loss:0.0029615415687681184\n",
      "train loss:0.02298629246659324\n",
      "train loss:0.0038199307394237753\n",
      "train loss:0.00662693262737981\n",
      "train loss:0.003741711573559028\n",
      "train loss:0.03271007955448926\n",
      "train loss:0.015479307427387602\n",
      "train loss:0.0015277055112217072\n",
      "train loss:0.036434709697745274\n",
      "train loss:0.0039789552487539\n",
      "train loss:0.0016171460488559992\n",
      "train loss:0.006324984927565962\n",
      "train loss:0.0039911345543955255\n",
      "train loss:0.0013206583842716743\n",
      "train loss:0.0086269543883326\n",
      "train loss:0.021367811403225887\n",
      "train loss:0.002592635341426105\n",
      "train loss:0.00042514201132980633\n",
      "train loss:0.0028454971210257985\n",
      "train loss:0.0178423335460099\n",
      "train loss:0.0033253293638036974\n",
      "train loss:0.01264018726889623\n",
      "train loss:0.002378818978174872\n",
      "train loss:0.003041963107937526\n",
      "train loss:0.0016214394852175087\n",
      "train loss:0.0030687433807182083\n",
      "train loss:0.005567468520239693\n",
      "train loss:0.002619639496700926\n",
      "train loss:0.001330163860165557\n",
      "train loss:0.002355440360310135\n",
      "train loss:0.013839057401475341\n",
      "train loss:0.0012129056643614467\n",
      "train loss:0.004990436219261839\n",
      "train loss:0.025742831468203824\n",
      "train loss:0.0033354924240406357\n",
      "train loss:0.012170550060055463\n",
      "train loss:0.00921511253660973\n",
      "train loss:0.002062062236244509\n",
      "train loss:0.003535716768135205\n",
      "train loss:0.000585290546458015\n",
      "train loss:0.041540390436852065\n",
      "train loss:0.005871303224115173\n",
      "train loss:0.014222171660085684\n",
      "train loss:0.001130783230892328\n",
      "train loss:0.0037774662397168004\n",
      "train loss:0.000373201256845402\n",
      "train loss:0.0007532282876154818\n",
      "train loss:0.0028998063430155565\n",
      "train loss:0.009022304755069118\n",
      "train loss:0.003739647348059834\n",
      "train loss:0.006370540846409911\n",
      "train loss:0.0522633918794009\n",
      "train loss:0.00047483361241411586\n",
      "train loss:0.010803124198366073\n",
      "train loss:0.0010977048730535326\n",
      "train loss:0.004577971970489289\n",
      "train loss:0.003908011263342592\n",
      "train loss:0.04536079504358959\n",
      "train loss:0.0004058322876815299\n",
      "train loss:0.00022041946820189435\n",
      "train loss:0.006543508175755084\n",
      "train loss:0.01091528265555263\n",
      "train loss:0.000770890869521728\n",
      "train loss:0.00015334950300922108\n",
      "train loss:0.021677094736947403\n",
      "train loss:0.003809037391589345\n",
      "train loss:0.004070905352627588\n",
      "train loss:0.0015737204804034378\n",
      "train loss:0.002799373326963604\n",
      "train loss:0.0029833854968653786\n",
      "train loss:0.008906040791259177\n",
      "train loss:0.0018100950040133346\n",
      "train loss:0.007806585574290774\n",
      "train loss:0.006277094811863844\n",
      "train loss:0.0019465682989949237\n",
      "train loss:0.007268058131805157\n",
      "train loss:0.0016466376854219124\n",
      "train loss:0.002143406292005852\n",
      "train loss:0.001437420638851428\n",
      "train loss:0.007894842798749491\n",
      "train loss:0.00596933652370233\n",
      "train loss:0.0065683762984151215\n",
      "train loss:0.0025823518697855154\n",
      "train loss:0.0058110658182383\n",
      "train loss:0.0021616411578950358\n",
      "train loss:0.019565437650035565\n",
      "train loss:0.0012545410371203245\n",
      "train loss:0.004502250090977845\n",
      "train loss:0.0009067319433602941\n",
      "train loss:0.008113385600074591\n",
      "train loss:0.0011242746195082734\n",
      "train loss:0.0028001851944639035\n",
      "train loss:0.005656940931412766\n",
      "train loss:0.010055562998004754\n",
      "train loss:0.009813164041446406\n",
      "train loss:0.01096221938518786\n",
      "train loss:0.007990901854256653\n",
      "train loss:0.01760125016395911\n",
      "train loss:0.001726003399974266\n",
      "train loss:0.0025228545473385843\n",
      "train loss:0.004732781500302657\n",
      "train loss:0.0002808025797782661\n",
      "train loss:0.0019026137165912538\n",
      "train loss:0.0013815543491608995\n",
      "train loss:8.015865117572981e-05\n",
      "train loss:0.002792910731974511\n",
      "train loss:0.0035032886829661387\n",
      "train loss:0.004246958817360622\n",
      "train loss:0.0008362909929563297\n",
      "train loss:0.004002132230019397\n",
      "train loss:0.0005268581302901293\n",
      "train loss:0.020623812775466863\n",
      "train loss:0.0017298971702438088\n",
      "train loss:0.0010344835055288598\n",
      "train loss:0.0008783423027708112\n",
      "train loss:0.021910452173837087\n",
      "train loss:0.00255504558002493\n",
      "train loss:0.008048259917673753\n",
      "train loss:0.0007254584473636383\n",
      "train loss:0.0009449704676919059\n",
      "train loss:0.00723863253147607\n",
      "train loss:0.0005818978862896576\n",
      "train loss:0.002636926444695606\n",
      "train loss:0.0063323964070286275\n",
      "train loss:0.0016919288357877436\n",
      "train loss:0.00508827018686822\n",
      "train loss:0.00222274555708501\n",
      "train loss:0.002242156637847047\n",
      "train loss:0.000353576680024871\n",
      "train loss:0.00010318886499408186\n",
      "train loss:0.0021215501373660246\n",
      "train loss:0.0008142656469683127\n",
      "train loss:0.0005875409251084304\n",
      "train loss:0.0005116012565805357\n",
      "train loss:0.0022442292274079227\n",
      "train loss:0.0015267033579467598\n",
      "train loss:0.001044252685749642\n",
      "train loss:0.0007964346394746603\n",
      "train loss:0.00554509246784633\n",
      "train loss:0.0005278013847799217\n",
      "train loss:0.0011376443421838036\n",
      "train loss:0.01863676839311619\n",
      "train loss:0.0038984931661875167\n",
      "train loss:0.0392976688284915\n",
      "train loss:0.004020956061880303\n",
      "train loss:0.003294317025241959\n",
      "train loss:0.0030356548151929757\n",
      "train loss:0.0008701945888020231\n",
      "train loss:0.004731276252573924\n",
      "train loss:0.0026932562532344007\n",
      "train loss:0.0010240213092169975\n",
      "train loss:0.00019926982732066024\n",
      "train loss:0.013151439495772813\n",
      "train loss:0.003998201719794341\n",
      "train loss:0.0019012555515618298\n",
      "train loss:0.0025118689363679736\n",
      "train loss:0.0021210577978363503\n",
      "train loss:0.004039772183474856\n",
      "train loss:0.023458235333448797\n",
      "train loss:0.005614781818975154\n",
      "train loss:0.000534089573365531\n",
      "train loss:0.000788944492962221\n",
      "train loss:0.010314393630483304\n",
      "train loss:0.006469127233875542\n",
      "train loss:0.0064041109936567335\n",
      "train loss:0.0015766449399055758\n",
      "train loss:0.008953965055627499\n",
      "train loss:0.00430280690573187\n",
      "train loss:0.009825595385036306\n",
      "train loss:0.014192181649279226\n",
      "train loss:0.000380220722893026\n",
      "train loss:0.00094931275431148\n",
      "train loss:0.011810389619836098\n",
      "train loss:0.0025082795530409745\n",
      "train loss:0.00783025199546579\n",
      "train loss:0.0008563706717459219\n",
      "train loss:0.009844020705078983\n",
      "train loss:0.00024010503257653192\n",
      "train loss:0.002650261567362018\n",
      "train loss:0.0023489990525472414\n",
      "train loss:0.003100853298088384\n",
      "train loss:0.0026740583251482243\n",
      "train loss:0.003038387754145158\n",
      "train loss:0.0119435295528656\n",
      "train loss:0.00028042388171467184\n",
      "train loss:0.0016243445111454515\n",
      "train loss:0.00481670984141404\n",
      "train loss:0.00804600191973432\n",
      "train loss:0.007463210981205296\n",
      "train loss:0.05763084146153074\n",
      "train loss:0.00019450378766484267\n",
      "train loss:0.026901331896886517\n",
      "train loss:0.005214955486721185\n",
      "train loss:0.0013388231251282203\n",
      "train loss:0.007266058213694262\n",
      "train loss:0.01679290157853255\n",
      "train loss:0.0011552745565480069\n",
      "train loss:0.0008360739577945573\n",
      "train loss:0.0013735402043152823\n",
      "train loss:0.024601908995840326\n",
      "train loss:0.002672516781269118\n",
      "train loss:0.0022182174281333124\n",
      "train loss:0.0032690424680108386\n",
      "train loss:0.0005105738815074468\n",
      "train loss:0.002435477032766922\n",
      "train loss:0.0005892585679143059\n",
      "train loss:0.005270505706704183\n",
      "train loss:0.0005253682026923473\n",
      "train loss:0.007867900395711109\n",
      "train loss:0.00040592060094566946\n",
      "train loss:0.00718426466316161\n",
      "train loss:0.011882714408935931\n",
      "train loss:0.0028320429672069897\n",
      "train loss:0.017668557794808915\n",
      "train loss:0.006919253512991724\n",
      "train loss:0.001820501838796995\n",
      "train loss:0.007212043859598819\n",
      "train loss:0.002719569331630335\n",
      "train loss:0.00306441419036035\n",
      "train loss:0.003015480636536541\n",
      "train loss:0.0019295458185539305\n",
      "train loss:0.0007971574197173976\n",
      "train loss:0.0027802293516536692\n",
      "train loss:0.01010330247440501\n",
      "train loss:0.0028432329519116656\n",
      "train loss:0.005479932198332439\n",
      "train loss:0.00016843270501373014\n",
      "train loss:0.010710814541987275\n",
      "train loss:0.0057540641226858065\n",
      "train loss:0.0016089333559670723\n",
      "train loss:0.0008020448021469874\n",
      "train loss:0.008042338718181104\n",
      "train loss:0.024399510042637046\n",
      "train loss:0.004062784487989867\n",
      "train loss:0.005283802604465233\n",
      "train loss:0.0032829813882405525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.001134614728028968\n",
      "train loss:0.0017718405227314727\n",
      "train loss:0.002366421938940624\n",
      "train loss:0.002405876294941183\n",
      "train loss:0.010524033938184496\n",
      "train loss:0.002858734438498402\n",
      "train loss:0.009535796951851553\n",
      "train loss:0.0026104478317725984\n",
      "train loss:0.005198733432353391\n",
      "train loss:0.0059818063702243365\n",
      "train loss:0.003128286770344873\n",
      "train loss:0.002331394261098742\n",
      "train loss:0.006013697844475877\n",
      "train loss:0.007451466008813032\n",
      "train loss:0.002274333318425256\n",
      "train loss:0.0024160756319532377\n",
      "train loss:0.004653448995178211\n",
      "train loss:0.0016044927110771404\n",
      "train loss:0.012315840759230976\n",
      "train loss:0.0011056067534981804\n",
      "train loss:0.004282881717900116\n",
      "train loss:0.0432521908423133\n",
      "train loss:0.0008657055671238791\n",
      "train loss:0.000932730628566921\n",
      "train loss:0.0003623236650293361\n",
      "train loss:0.0003857130289771429\n",
      "train loss:0.0008728999519669919\n",
      "train loss:0.00023238530318725082\n",
      "train loss:0.005265145312607353\n",
      "train loss:0.001311361772667204\n",
      "train loss:0.0011742028577365734\n",
      "train loss:0.002503920294597756\n",
      "train loss:0.0014006106625062966\n",
      "train loss:0.0008983024117573124\n",
      "train loss:0.0050081372699136975\n",
      "train loss:0.013096203186338994\n",
      "train loss:0.0029557701712802664\n",
      "train loss:0.0036990217489981958\n",
      "train loss:0.00134336707078899\n",
      "train loss:0.027961056983614157\n",
      "train loss:0.002350647420929556\n",
      "train loss:0.007987261959460545\n",
      "train loss:0.0017010521556576493\n",
      "train loss:0.013803908569349804\n",
      "train loss:0.0009581434000077861\n",
      "train loss:0.0013868365641226071\n",
      "train loss:0.0018836074145274278\n",
      "train loss:0.0005020124212506877\n",
      "train loss:0.016839651542415172\n",
      "train loss:0.0029578822749109263\n",
      "train loss:0.0013118135802778269\n",
      "train loss:0.0017931799358383421\n",
      "train loss:0.0005018288900928419\n",
      "train loss:0.010366609343478429\n",
      "train loss:0.0033959172003093707\n",
      "train loss:0.00041439137717883136\n",
      "train loss:0.0070520057402314726\n",
      "train loss:0.0035155828312763994\n",
      "train loss:0.00178445694207997\n",
      "train loss:0.0005136849032522917\n",
      "train loss:0.0022060222772046145\n",
      "train loss:0.004973694034384377\n",
      "train loss:0.0012221431298157007\n",
      "train loss:0.0030502940040188346\n",
      "train loss:0.001303726225335114\n",
      "train loss:0.00909142579121731\n",
      "train loss:0.015318706930327004\n",
      "train loss:0.004166600595473827\n",
      "train loss:0.0026545973436722546\n",
      "train loss:0.000842243787668078\n",
      "train loss:0.004113099923680409\n",
      "train loss:0.001028518418399967\n",
      "train loss:0.002531748375196613\n",
      "train loss:0.004228124686618459\n",
      "train loss:0.0030907389615477936\n",
      "train loss:0.0036234076236235707\n",
      "train loss:0.000159941515215624\n",
      "train loss:0.0008571534731972739\n",
      "train loss:0.0016343638992116969\n",
      "train loss:0.005781564785505101\n",
      "train loss:0.0048621932855154\n",
      "train loss:0.03410399643434308\n",
      "train loss:0.0018236286796219417\n",
      "train loss:0.0009277357473583499\n",
      "train loss:0.00643094427948744\n",
      "train loss:0.0015519885958004936\n",
      "train loss:0.0026299260917694404\n",
      "train loss:0.006332894524431698\n",
      "train loss:0.00623198177946919\n",
      "train loss:0.004711967264405419\n",
      "train loss:0.0011018521559044948\n",
      "train loss:0.008227724365588218\n",
      "train loss:0.0019963503693590677\n",
      "train loss:0.0055010020434387704\n",
      "train loss:0.0008989525048480866\n",
      "train loss:0.061898616829675464\n",
      "train loss:0.0046857052705462565\n",
      "train loss:0.003668246180158549\n",
      "train loss:0.0007224935455029781\n",
      "train loss:0.001811643842214778\n",
      "train loss:0.0057116280695380574\n",
      "train loss:0.0074040000572941555\n",
      "train loss:0.004205877590899456\n",
      "train loss:0.013492166438547054\n",
      "train loss:0.004010275053024061\n",
      "train loss:0.0016612253253369088\n",
      "train loss:0.0018547519748703845\n",
      "train loss:0.02313883224877414\n",
      "train loss:0.0016563767123103004\n",
      "train loss:0.03555410591060437\n",
      "train loss:0.0027349084097536163\n",
      "train loss:0.000497734698435734\n",
      "train loss:0.008991940560618547\n",
      "train loss:0.0006056883888472149\n",
      "train loss:0.000621887449536831\n",
      "train loss:0.003216085457398948\n",
      "train loss:0.0010217552882790448\n",
      "train loss:0.0007080740667769667\n",
      "train loss:0.0009363037723409412\n",
      "train loss:0.0016795834309509526\n",
      "train loss:0.0063826315743337\n",
      "train loss:0.0031822295492761853\n",
      "train loss:0.004453637492823562\n",
      "train loss:0.008650564173094793\n",
      "train loss:0.02396626023058076\n",
      "train loss:0.01218155650613417\n",
      "train loss:0.009944572272729088\n",
      "train loss:0.012538872259137676\n",
      "train loss:0.003556111961542325\n",
      "train loss:0.0013862098435889973\n",
      "train loss:0.00010262368580119345\n",
      "train loss:0.0011181035167373286\n",
      "train loss:0.005841039144412765\n",
      "train loss:0.009190861534680898\n",
      "train loss:0.0007316396454842292\n",
      "train loss:0.007413509815808413\n",
      "train loss:0.005756902736302643\n",
      "train loss:0.008633482729495915\n",
      "train loss:0.0011323018318561667\n",
      "train loss:0.005267857925255339\n",
      "train loss:0.0033849396410328136\n",
      "train loss:0.002609831668467911\n",
      "train loss:0.0024779476945894544\n",
      "train loss:0.004478702711391579\n",
      "train loss:0.007037190571922216\n",
      "train loss:0.0013058058647630374\n",
      "train loss:0.007743236101942418\n",
      "train loss:0.0009949786211644223\n",
      "train loss:0.0009016550848911269\n",
      "train loss:0.0007560957950331409\n",
      "train loss:0.000507911024036437\n",
      "train loss:0.0014868237704343387\n",
      "train loss:0.002733273343203242\n",
      "train loss:0.0007002708659037032\n",
      "train loss:0.00020446924841569552\n",
      "train loss:0.0030729292059920033\n",
      "train loss:0.03703759520457279\n",
      "train loss:0.004376319135770211\n",
      "train loss:0.00019490901067152562\n",
      "train loss:0.0007454864711113344\n",
      "train loss:0.001415118779961784\n",
      "train loss:0.00457370742993677\n",
      "train loss:0.0035085658246198975\n",
      "train loss:0.016716730805706653\n",
      "train loss:0.0023008347298137987\n",
      "train loss:0.02150947189235481\n",
      "train loss:0.0009914080931298288\n",
      "train loss:0.028625208410032736\n",
      "train loss:0.0003643315404241707\n",
      "train loss:0.019266799179846465\n",
      "train loss:0.0224785883485218\n",
      "train loss:0.0022168763713865127\n",
      "train loss:0.017990278451018672\n",
      "train loss:0.028545000028028435\n",
      "train loss:0.0031979870918839555\n",
      "train loss:0.0003259432978735086\n",
      "train loss:0.0012170031622271312\n",
      "train loss:0.004308056657724278\n",
      "train loss:0.0029536726355173073\n",
      "train loss:0.025417477066183736\n",
      "train loss:0.0009867825354356455\n",
      "train loss:0.005903752751922849\n",
      "train loss:0.00016653326145288307\n",
      "train loss:0.00530471947748269\n",
      "train loss:0.008802861359993346\n",
      "train loss:0.008253622688208246\n",
      "train loss:0.020022050370567753\n",
      "train loss:0.004427964367418847\n",
      "train loss:0.004824152704664708\n",
      "train loss:0.0027379434377641392\n",
      "train loss:0.006401358226042101\n",
      "train loss:0.0007683378812869175\n",
      "train loss:0.0012698850743958615\n",
      "train loss:0.006031101358061683\n",
      "train loss:0.01549776314373529\n",
      "train loss:0.003468304459325894\n",
      "train loss:0.003696423575617386\n",
      "train loss:0.0023350853167080927\n",
      "train loss:0.005620351287832413\n",
      "train loss:0.006124056477435754\n",
      "train loss:0.004503822949307874\n",
      "train loss:0.0008030237534903485\n",
      "train loss:0.007506563486161513\n",
      "train loss:0.003875901081417193\n",
      "train loss:0.0009607867818157556\n",
      "train loss:0.0019354334986582133\n",
      "train loss:0.0017282105302571151\n",
      "train loss:0.010337172586368168\n",
      "train loss:0.000631204748334432\n",
      "train loss:0.005870205737171341\n",
      "train loss:0.005541583386218382\n",
      "train loss:0.0004031803621159086\n",
      "train loss:0.0007841397261500045\n",
      "train loss:0.00044531326851921687\n",
      "train loss:0.0031415928501971157\n",
      "train loss:0.010631905677934851\n",
      "train loss:0.0011447869166477415\n",
      "train loss:0.0009480342173399594\n",
      "train loss:0.01002645501463067\n",
      "train loss:0.0050231898293201785\n",
      "train loss:0.0012122509210321809\n",
      "train loss:0.00032563626094513195\n",
      "train loss:0.012411760300938974\n",
      "train loss:0.0017305023191985474\n",
      "train loss:0.005347057785089564\n",
      "=== epoch:13, train acc:0.997, test acc:0.99 ===\n",
      "train loss:0.002790054811901631\n",
      "train loss:0.002136644629157905\n",
      "train loss:0.008527072699564466\n",
      "train loss:0.0016470904877914588\n",
      "train loss:0.002948625493581957\n",
      "train loss:0.10763884505844194\n",
      "train loss:0.0028096445084524525\n",
      "train loss:0.0017276230579519158\n",
      "train loss:0.002893663723591078\n",
      "train loss:0.00035281969317074073\n",
      "train loss:0.002176884798382086\n",
      "train loss:0.0037579452597093876\n",
      "train loss:0.00114983025189226\n",
      "train loss:0.0052629824598221485\n",
      "train loss:0.0008104799643591956\n",
      "train loss:0.0009506907610472269\n",
      "train loss:0.00428413398133042\n",
      "train loss:0.0020342944566880063\n",
      "train loss:0.0012922764736872038\n",
      "train loss:0.0023537198537327817\n",
      "train loss:0.0077128129784955314\n",
      "train loss:0.003934742806534444\n",
      "train loss:0.0032539012376247263\n",
      "train loss:0.009446253517713093\n",
      "train loss:0.001317762347554555\n",
      "train loss:0.014407165381384061\n",
      "train loss:0.002954618093643449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0026930201234421167\n",
      "train loss:0.0009362781297175494\n",
      "train loss:0.01136793113051318\n",
      "train loss:0.0001877689076791585\n",
      "train loss:0.0019778689809640333\n",
      "train loss:0.001868759718336359\n",
      "train loss:0.004951476489283011\n",
      "train loss:0.002113203319889667\n",
      "train loss:0.0005520659643866179\n",
      "train loss:0.0031222223929528847\n",
      "train loss:0.021349831980660854\n",
      "train loss:0.010308461110024963\n",
      "train loss:0.008698440838632951\n",
      "train loss:0.013709446354276098\n",
      "train loss:0.0056057937506810195\n",
      "train loss:0.025728691551133397\n",
      "train loss:0.01599015524803971\n",
      "train loss:0.0010304488226612158\n",
      "train loss:0.011469957684458233\n",
      "train loss:0.003120681886319832\n",
      "train loss:0.0019462265328680556\n",
      "train loss:0.006450938897406932\n",
      "train loss:0.0022669626824918273\n",
      "train loss:0.0038491520452972267\n",
      "train loss:0.0019004248376228363\n",
      "train loss:0.00613821242800713\n",
      "train loss:0.016605197237315114\n",
      "train loss:0.002937512175168272\n",
      "train loss:0.003365507639254677\n",
      "train loss:0.031123707600816727\n",
      "train loss:0.05483004937534511\n",
      "train loss:0.0019487770843179483\n",
      "train loss:0.002274742843943329\n",
      "train loss:0.001969361707302847\n",
      "train loss:0.0019223429666980923\n",
      "train loss:0.0025504245253898227\n",
      "train loss:0.008294906425785597\n",
      "train loss:0.008016425246874575\n",
      "train loss:0.004060208909390877\n",
      "train loss:0.006567977306750272\n",
      "train loss:0.0027285163135073957\n",
      "train loss:0.007947038364217306\n",
      "train loss:0.018212850884488055\n",
      "train loss:0.008406009556561367\n",
      "train loss:0.002190788682420115\n",
      "train loss:0.0036860052876644196\n",
      "train loss:0.0025358960532263046\n",
      "train loss:0.006770512981436671\n",
      "train loss:0.0009436943934686474\n",
      "train loss:0.006274588908801586\n",
      "train loss:0.024016646970563032\n",
      "train loss:0.0003011561333834625\n",
      "train loss:0.009669650615029543\n",
      "train loss:0.0033778543730060145\n",
      "train loss:0.019185316196685148\n",
      "train loss:0.004190047187994645\n",
      "train loss:0.09932132900244187\n",
      "train loss:0.003039906433026901\n",
      "train loss:0.0015537607275540879\n",
      "train loss:0.001841860176977738\n",
      "train loss:0.005194136242700147\n",
      "train loss:0.01875658585689777\n",
      "train loss:0.004192858239082619\n",
      "train loss:0.008214521579237594\n",
      "train loss:0.0011487844795771565\n",
      "train loss:0.001186647350577402\n",
      "train loss:0.004555551337298891\n",
      "train loss:0.0032671069182146186\n",
      "train loss:0.0024046445365173215\n",
      "train loss:0.004458407674481143\n",
      "train loss:0.0005352144911794001\n",
      "train loss:0.001216987237019467\n",
      "train loss:0.0005786080760376548\n",
      "train loss:0.00048279508062137264\n",
      "train loss:0.0016091856439087388\n",
      "train loss:0.002462692640687048\n",
      "train loss:0.000497975614418302\n",
      "train loss:0.007973490213629015\n",
      "train loss:0.00249363137298272\n",
      "train loss:0.008516389028933697\n",
      "train loss:0.0003016208370706665\n",
      "train loss:0.0015132511789625056\n",
      "train loss:0.001753099608919888\n",
      "train loss:0.0007951378392570891\n",
      "train loss:0.004036706268514903\n",
      "train loss:0.005811825420605271\n",
      "train loss:0.04388488284787437\n",
      "train loss:0.0013985411470178355\n",
      "train loss:0.0056848011617845265\n",
      "train loss:0.0010351733734834743\n",
      "train loss:0.0008799430003895562\n",
      "train loss:0.0053360104627122075\n",
      "train loss:0.0030986642224321904\n",
      "train loss:0.004581399350596416\n",
      "train loss:0.010023733688525804\n",
      "train loss:0.0013838767590222162\n",
      "train loss:0.0035960254140934046\n",
      "train loss:0.0007747791961698158\n",
      "train loss:0.040947125745269576\n",
      "train loss:0.06560037828919389\n",
      "train loss:0.003098179894083612\n",
      "train loss:0.0021164721100324487\n",
      "train loss:0.013163089177664022\n",
      "train loss:0.00038118917603862897\n",
      "train loss:0.000949277770307801\n",
      "train loss:0.0016683532113657207\n",
      "train loss:0.004456434845389957\n",
      "train loss:0.0014060802417395551\n",
      "train loss:0.0007499065587319682\n",
      "train loss:0.003900468158281573\n",
      "train loss:0.0008759675674650816\n",
      "train loss:0.008648862411938048\n",
      "train loss:0.0025944886854031603\n",
      "train loss:0.0037356096700757384\n",
      "train loss:0.004488335626899436\n",
      "train loss:0.003968471013073902\n",
      "train loss:0.0018404568908837\n",
      "train loss:0.002133272636155057\n",
      "train loss:0.0024421439117257283\n",
      "train loss:0.0015185546647709697\n",
      "train loss:0.0038484010317763706\n",
      "train loss:0.001294342741278067\n",
      "train loss:0.0011115182989712374\n",
      "train loss:0.004830921007377199\n",
      "train loss:0.0050649785918087465\n",
      "train loss:0.017179364838470386\n",
      "train loss:0.0011597828800964704\n",
      "train loss:0.0010616338006651162\n",
      "train loss:0.00039143536363181567\n",
      "train loss:0.0016188095065649982\n",
      "train loss:0.00174952499201334\n",
      "train loss:0.001531727537888489\n",
      "train loss:0.0004320934140443969\n",
      "train loss:0.0039602193366964685\n",
      "train loss:0.0040441736857159925\n",
      "train loss:0.0008274970293811177\n",
      "train loss:0.0017843920139938001\n",
      "train loss:0.0006627338744705196\n",
      "train loss:0.01186414890906629\n",
      "train loss:0.0011398538840057379\n",
      "train loss:0.0003843901213579637\n",
      "train loss:0.00518437396235931\n",
      "train loss:0.06488027361050183\n",
      "train loss:0.05255672117183069\n",
      "train loss:0.005656040358175557\n",
      "train loss:0.0009820658063557331\n",
      "train loss:0.0005088106910886285\n",
      "train loss:0.0005655067903642423\n",
      "train loss:0.00022300711202347063\n",
      "train loss:0.0017499629594710906\n",
      "train loss:0.0010662430067339523\n",
      "train loss:0.0018181795854235944\n",
      "train loss:0.0004498367480112167\n",
      "train loss:0.006799301993735327\n",
      "train loss:0.0070532068443705095\n",
      "train loss:0.007387983852115064\n",
      "train loss:0.0005513421057991678\n",
      "train loss:0.06227425618409616\n",
      "train loss:0.026990540857411937\n",
      "train loss:0.00270748805990085\n",
      "train loss:0.006800347848038546\n",
      "train loss:0.0017941710988052329\n",
      "train loss:0.001193641368856363\n",
      "train loss:0.0060911805493940145\n",
      "train loss:0.004023977681045097\n",
      "train loss:0.002128292518044576\n",
      "train loss:0.0001095480592018467\n",
      "train loss:0.00572900355572608\n",
      "train loss:0.007968711040121187\n",
      "train loss:0.005415910730201181\n",
      "train loss:0.0008623341411727902\n",
      "train loss:0.001517148019504847\n",
      "train loss:0.0024956168547406467\n",
      "train loss:0.0009404161763677502\n",
      "train loss:0.005017701602818518\n",
      "train loss:0.0006607433204395294\n",
      "train loss:0.0025752450640690737\n",
      "train loss:0.0001597198873748473\n",
      "train loss:0.007884508724015797\n",
      "train loss:0.008415920714629807\n",
      "train loss:0.002559860734138916\n",
      "train loss:0.005440780651165906\n",
      "train loss:0.005077339836691552\n",
      "train loss:0.005938948091572528\n",
      "train loss:0.002393794964375087\n",
      "train loss:0.0009119820289512518\n",
      "train loss:0.0006251915704510634\n",
      "train loss:0.00397335043007414\n",
      "train loss:0.0009725130799764229\n",
      "train loss:0.0034883318359416947\n",
      "train loss:0.0014485558954840964\n",
      "train loss:0.0035139933691581875\n",
      "train loss:0.00914582494962149\n",
      "train loss:0.01609516806463501\n",
      "train loss:0.003943406828403249\n",
      "train loss:0.005311676216656799\n",
      "train loss:0.00810884922331477\n",
      "train loss:0.0011028453149636564\n",
      "train loss:0.0026282633805283185\n",
      "train loss:0.0008803973702436217\n",
      "train loss:0.0009498474397905056\n",
      "train loss:0.0018402074601378126\n",
      "train loss:0.0009026395829851207\n",
      "train loss:0.0013053005786863787\n",
      "train loss:4.935843222580157e-05\n",
      "train loss:0.0008981906410479372\n",
      "train loss:0.0066028091600980245\n",
      "train loss:0.000998131356581656\n",
      "train loss:0.004448545511485029\n",
      "train loss:0.006267690914211504\n",
      "train loss:0.0002079128060668906\n",
      "train loss:0.0009560850629094487\n",
      "train loss:0.013960068505263707\n",
      "train loss:0.004659792368943659\n",
      "train loss:0.001861526407670268\n",
      "train loss:0.006963295518236453\n",
      "train loss:0.003543522567941432\n",
      "train loss:0.0014678819045101958\n",
      "train loss:0.010563640982004845\n",
      "train loss:0.0007985284700435982\n",
      "train loss:0.00218228642815451\n",
      "train loss:0.0033829045014549673\n",
      "train loss:0.002330059954411595\n",
      "train loss:0.0008611366836446248\n",
      "train loss:0.0021824632515874787\n",
      "train loss:0.001472765509521534\n",
      "train loss:0.002638975198263726\n",
      "train loss:0.006632406009641201\n",
      "train loss:0.0002238535993655811\n",
      "train loss:0.0033388190167497446\n",
      "train loss:0.0005482416903078131\n",
      "train loss:0.0014800169259084586\n",
      "train loss:0.0009490037550439979\n",
      "train loss:0.0011556311871636297\n",
      "train loss:0.014725640366726142\n",
      "train loss:0.0015910601318810066\n",
      "train loss:0.008565402750518224\n",
      "train loss:0.00017144440117036478\n",
      "train loss:0.007422368918024749\n",
      "train loss:0.006768144844861034\n",
      "train loss:0.006881280736271429\n",
      "train loss:0.004611814002092438\n",
      "train loss:0.000662270572192276\n",
      "train loss:0.007674602153617343\n",
      "train loss:0.011978332784731736\n",
      "train loss:0.004214482515027293\n",
      "train loss:0.012179644508058812\n",
      "train loss:0.0029302952908646473\n",
      "train loss:0.00032817350799378806\n",
      "train loss:0.015052938079017171\n",
      "train loss:0.0006242231824458614\n",
      "train loss:0.004040200938269792\n",
      "train loss:0.01124309160769147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0017556977670287633\n",
      "train loss:0.0014783651098573566\n",
      "train loss:0.0013405650688660554\n",
      "train loss:0.02023749238062927\n",
      "train loss:0.006037729049396329\n",
      "train loss:0.005329418605438773\n",
      "train loss:0.004182749277626382\n",
      "train loss:0.009466380953125426\n",
      "train loss:0.003480446195745736\n",
      "train loss:0.006049072064438999\n",
      "train loss:0.0016274071855143823\n",
      "train loss:0.0030727979932655743\n",
      "train loss:0.0035879680844769853\n",
      "train loss:0.00020287678570211082\n",
      "train loss:0.002792365622898109\n",
      "train loss:0.0034674728281305156\n",
      "train loss:0.010850457624277802\n",
      "train loss:0.0010234523692483409\n",
      "train loss:0.0019966025090381594\n",
      "train loss:0.005202265698035427\n",
      "train loss:0.0006862490960966523\n",
      "train loss:0.0006736369036297645\n",
      "train loss:0.006104600640063307\n",
      "train loss:0.028646151124862632\n",
      "train loss:0.0018554410871626614\n",
      "train loss:0.0010865837127924565\n",
      "train loss:0.005967333766484625\n",
      "train loss:0.004769381888392325\n",
      "train loss:0.015709158680087786\n",
      "train loss:0.0003647104047208808\n",
      "train loss:0.0011873312885160021\n",
      "train loss:0.00524562466055618\n",
      "train loss:0.000990592531166927\n",
      "train loss:0.00416156195262397\n",
      "train loss:0.004670210462700355\n",
      "train loss:0.003411098467615563\n",
      "train loss:0.0009115758508560104\n",
      "train loss:0.0205982026827799\n",
      "train loss:0.0035234323280753433\n",
      "train loss:0.0010780948403147739\n",
      "train loss:0.0040540586283947765\n",
      "train loss:0.010546764125906917\n",
      "train loss:0.0008647886107529984\n",
      "train loss:0.0014260716616298077\n",
      "train loss:0.001877032034143398\n",
      "train loss:0.004028025075824432\n",
      "train loss:0.0005106365412847612\n",
      "train loss:0.0037552340449609027\n",
      "train loss:0.0003014988652599452\n",
      "train loss:0.0013174600905627614\n",
      "train loss:0.004121269659714429\n",
      "train loss:0.001115628514625575\n",
      "train loss:0.0008212208510689696\n",
      "train loss:0.0005722051757589266\n",
      "train loss:0.01081534490785563\n",
      "train loss:0.004836955493947557\n",
      "train loss:0.007068613959216255\n",
      "train loss:0.004322742165646308\n",
      "train loss:0.008072080201926474\n",
      "train loss:0.003149810187305367\n",
      "train loss:0.0022064373269252923\n",
      "train loss:0.0008792561565258681\n",
      "train loss:0.0006432474474905924\n",
      "train loss:0.005374583580659451\n",
      "train loss:0.034373670096949596\n",
      "train loss:0.0034092291167944684\n",
      "train loss:0.0013059574916305038\n",
      "train loss:0.003489028853089212\n",
      "train loss:0.0011289476959630155\n",
      "train loss:0.0036172510992389132\n",
      "train loss:0.0030594234855487153\n",
      "train loss:0.0035570326771851126\n",
      "train loss:0.0012784799100749441\n",
      "train loss:0.017638641491856788\n",
      "train loss:0.005784725324742128\n",
      "train loss:0.0018647365037594722\n",
      "train loss:0.007401501156304273\n",
      "train loss:0.0020792910921479785\n",
      "train loss:0.0027437194891225818\n",
      "train loss:0.009656015951614472\n",
      "train loss:0.0014409107531732704\n",
      "train loss:0.0007099669463439308\n",
      "train loss:0.0028876272509398503\n",
      "train loss:0.01801732184063359\n",
      "train loss:0.0015420945880561172\n",
      "train loss:0.008515533015639115\n",
      "train loss:0.0013671487043202652\n",
      "train loss:0.007003315036408089\n",
      "train loss:0.0013857206612705344\n",
      "train loss:0.0022802847016378646\n",
      "train loss:0.00412298956680262\n",
      "train loss:0.0016003196841282929\n",
      "train loss:0.000550346540307014\n",
      "train loss:0.001144797769101093\n",
      "train loss:0.0042048660510874926\n",
      "train loss:0.006610058843235927\n",
      "train loss:0.0031272129485126958\n",
      "train loss:0.0014726669385154007\n",
      "train loss:0.00015155046328655728\n",
      "train loss:0.020239545034653143\n",
      "train loss:0.004745156640966003\n",
      "train loss:0.0019921177403635837\n",
      "train loss:0.001418226721315726\n",
      "train loss:0.000518346371041088\n",
      "train loss:0.001194868290349686\n",
      "train loss:0.00853064743896645\n",
      "train loss:0.0009250404680375463\n",
      "train loss:0.0029838821820929416\n",
      "train loss:0.006980347034227118\n",
      "train loss:0.0003401569606960356\n",
      "train loss:0.006195894041791777\n",
      "train loss:0.007289124212391298\n",
      "train loss:0.014704780838168431\n",
      "train loss:0.0016156766579239032\n",
      "train loss:0.0024859005538498636\n",
      "train loss:0.003473194587720861\n",
      "train loss:0.0017045541601473277\n",
      "train loss:0.010720869201905701\n",
      "train loss:0.0013218660853469726\n",
      "train loss:0.0028289334346145987\n",
      "train loss:0.00041549779716946637\n",
      "train loss:0.01806610061908604\n",
      "train loss:0.003371348680563992\n",
      "train loss:0.0019807324004655373\n",
      "train loss:0.0014441390752717401\n",
      "train loss:0.008329807360919799\n",
      "train loss:0.002677107571296817\n",
      "train loss:0.0002367960205742229\n",
      "train loss:0.009911779306374107\n",
      "train loss:0.0016063949894103773\n",
      "train loss:0.0013546924035971188\n",
      "train loss:0.002667986639830835\n",
      "train loss:0.0008115037940036146\n",
      "train loss:0.00014546031888007453\n",
      "train loss:0.0027656137685236697\n",
      "train loss:0.0009316693241833097\n",
      "train loss:0.0006302119287639994\n",
      "train loss:0.013447762725308636\n",
      "train loss:0.001034979600444889\n",
      "train loss:0.003784073481265216\n",
      "train loss:0.0002267207581605435\n",
      "train loss:0.002752030319823271\n",
      "train loss:0.0022537289723171838\n",
      "train loss:0.0007485762662141255\n",
      "train loss:0.0017730255207076097\n",
      "train loss:0.0018037150426764266\n",
      "train loss:0.0025012899661654067\n",
      "train loss:0.0019797090597776083\n",
      "train loss:0.0009996737641233616\n",
      "train loss:0.005377315382659221\n",
      "train loss:0.0019687002019015713\n",
      "train loss:0.0007332357567756599\n",
      "train loss:0.0008781998313460885\n",
      "train loss:0.005545350257374194\n",
      "train loss:0.0013911683472331805\n",
      "train loss:0.0003418030064000772\n",
      "train loss:0.0023276963795917445\n",
      "train loss:0.004094495154024612\n",
      "train loss:0.0006633633876763853\n",
      "train loss:0.003988993460052411\n",
      "train loss:0.000997265924632986\n",
      "train loss:0.0025696151907576388\n",
      "train loss:0.00026922016797649494\n",
      "train loss:0.004638417623935789\n",
      "train loss:0.004378409995557483\n",
      "train loss:0.0005352538667632383\n",
      "train loss:0.001287299208297118\n",
      "train loss:0.0007838503654985743\n",
      "train loss:0.0010533259361522767\n",
      "train loss:0.0026708310309093543\n",
      "train loss:0.0043365594214229254\n",
      "train loss:0.03831046815685295\n",
      "train loss:0.00026719376700886304\n",
      "train loss:0.00843223233653341\n",
      "train loss:0.012010075068417949\n",
      "train loss:0.004420037477263739\n",
      "train loss:0.004736664588274858\n",
      "train loss:0.002360588607689713\n",
      "train loss:0.005009507643163939\n",
      "train loss:0.0015780012974582866\n",
      "train loss:0.002496138139812151\n",
      "train loss:0.0009321409744935816\n",
      "train loss:0.0013597749771991452\n",
      "train loss:0.0018380944226117132\n",
      "train loss:0.006199904544232502\n",
      "train loss:0.0003368912019694145\n",
      "train loss:0.018321365659092207\n",
      "train loss:0.0030003786500101296\n",
      "train loss:0.0009864339908714685\n",
      "train loss:0.00016220672194960288\n",
      "train loss:0.00503531158803308\n",
      "train loss:0.006677486748999818\n",
      "train loss:0.000364191579292048\n",
      "train loss:0.0004727028403814772\n",
      "train loss:0.0047642649489329425\n",
      "train loss:0.0012926698690373163\n",
      "train loss:0.004313813072503841\n",
      "train loss:0.0005218948631310337\n",
      "train loss:0.0004302201989400717\n",
      "train loss:0.03257394264763089\n",
      "train loss:0.0004509490971066656\n",
      "train loss:0.0017760761949093666\n",
      "train loss:0.0008190665494496833\n",
      "train loss:0.01865293002545974\n",
      "train loss:0.0007141680245745827\n",
      "train loss:0.002428571226647362\n",
      "train loss:0.03268587129658947\n",
      "train loss:0.005755041474673626\n",
      "train loss:0.026242773737298573\n",
      "train loss:0.0015058689828374168\n",
      "train loss:0.02989579541280663\n",
      "train loss:0.00112227881290879\n",
      "train loss:0.002306043846834994\n",
      "train loss:0.001454715499279232\n",
      "train loss:0.03314224930484833\n",
      "train loss:0.0025156857333518707\n",
      "train loss:0.00026607326428060367\n",
      "train loss:0.0016362161782630669\n",
      "train loss:0.0029895526309480663\n",
      "train loss:0.0042731620596391205\n",
      "train loss:0.0018257494003951246\n",
      "train loss:0.0028507101407613824\n",
      "train loss:0.00027584696000605756\n",
      "train loss:0.00024119249220240662\n",
      "train loss:0.0017120815765935945\n",
      "train loss:0.0024068212895029598\n",
      "train loss:0.004149962739214264\n",
      "train loss:0.0010732147066613857\n",
      "train loss:0.006398116918517152\n",
      "train loss:0.0062590771483618975\n",
      "train loss:0.0013750450871075827\n",
      "train loss:0.002665102343327244\n",
      "train loss:0.0012368804380788736\n",
      "train loss:0.0009422577354138562\n",
      "train loss:0.00457438674799315\n",
      "train loss:0.000516047118697105\n",
      "train loss:0.007539043106801138\n",
      "train loss:0.007750426432589972\n",
      "train loss:0.003044796023183485\n",
      "train loss:0.0039530296833252525\n",
      "train loss:0.004903134642727134\n",
      "train loss:0.0005602984485744045\n",
      "train loss:0.0066870157139324584\n",
      "train loss:0.0006488859803291272\n",
      "train loss:0.0021130673823161307\n",
      "train loss:0.000574305326309143\n",
      "train loss:0.00018576061904019124\n",
      "train loss:0.002108571726851482\n",
      "train loss:0.0013302106424896612\n",
      "train loss:0.003399363182313899\n",
      "train loss:0.008858495330874561\n",
      "train loss:0.0032817182734349993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002489962002050833\n",
      "train loss:0.010355915101239167\n",
      "train loss:0.00029950953831196526\n",
      "train loss:0.007645016871537517\n",
      "train loss:0.00047932934558816287\n",
      "train loss:0.0006012453091307873\n",
      "train loss:0.0029655633676289998\n",
      "train loss:0.006465534949113796\n",
      "train loss:0.004806448185783542\n",
      "train loss:0.0028054102788044764\n",
      "train loss:0.0009769757941207003\n",
      "train loss:0.0035370685540573664\n",
      "train loss:0.018169059331967153\n",
      "train loss:0.000878304756040876\n",
      "train loss:0.029227208896904666\n",
      "train loss:0.001231519138563934\n",
      "train loss:0.004737857644879136\n",
      "train loss:0.002485035773478786\n",
      "train loss:0.0013043808878387376\n",
      "train loss:0.0020460207692026195\n",
      "train loss:0.002077166378150645\n",
      "train loss:0.0009185678381205283\n",
      "train loss:0.0008715496011677682\n",
      "train loss:0.00012724794900465246\n",
      "train loss:0.002829606866306114\n",
      "train loss:0.007881282739270093\n",
      "train loss:0.0002818859240357897\n",
      "train loss:0.005303690670197009\n",
      "train loss:0.0036555404018041855\n",
      "train loss:0.01174430346318053\n",
      "train loss:0.010598577214716833\n",
      "train loss:0.02920515721859669\n",
      "train loss:0.003701301087615603\n",
      "train loss:0.003678893189933641\n",
      "train loss:0.08982003292708321\n",
      "train loss:0.04271490394860645\n",
      "train loss:0.0017272684912809499\n",
      "train loss:0.0030816481134180117\n",
      "train loss:0.006514287656565361\n",
      "train loss:0.00018973738197356125\n",
      "train loss:0.0005903957641187545\n",
      "train loss:0.004446594520490574\n",
      "train loss:0.008762574072452308\n",
      "train loss:0.02467833849556185\n",
      "train loss:0.011379760963312996\n",
      "train loss:0.01849247282855342\n",
      "train loss:0.008023972629698142\n",
      "train loss:0.00044910238296527857\n",
      "train loss:0.002762495190171759\n",
      "train loss:0.010719155085819778\n",
      "train loss:0.05442254995153356\n",
      "train loss:0.004185443970679895\n",
      "train loss:0.0012051666436550706\n",
      "train loss:0.0018249779607403124\n",
      "train loss:0.010290918303899327\n",
      "train loss:0.0030607240430506255\n",
      "train loss:0.004201785151125107\n",
      "train loss:0.005326035002494887\n",
      "train loss:0.003489505484990345\n",
      "train loss:0.0010941469104444092\n",
      "train loss:0.0069916745892501485\n",
      "train loss:0.0009591727557662431\n",
      "train loss:0.002014254388224532\n",
      "train loss:0.004897355616866987\n",
      "train loss:0.011589296780503227\n",
      "train loss:0.00023639953481044513\n",
      "train loss:0.015833919665355623\n",
      "train loss:0.0005843079593592102\n",
      "=== epoch:14, train acc:0.998, test acc:0.988 ===\n",
      "train loss:0.0042507741367679005\n",
      "train loss:0.0002859981094205218\n",
      "train loss:0.002014613933069786\n",
      "train loss:0.0024241297673484093\n",
      "train loss:0.0010248930287411822\n",
      "train loss:0.0004935101706663252\n",
      "train loss:0.006095243956038669\n",
      "train loss:0.0004808693461738433\n",
      "train loss:0.02792108994140044\n",
      "train loss:0.010371443093547105\n",
      "train loss:0.0005396579719072009\n",
      "train loss:0.023731925455418842\n",
      "train loss:0.0005793734008221212\n",
      "train loss:0.0005135103682803181\n",
      "train loss:0.0012948359742144299\n",
      "train loss:0.002261571573729581\n",
      "train loss:0.00028867218413975994\n",
      "train loss:0.0007121683974158092\n",
      "train loss:0.0018872899637515633\n",
      "train loss:0.0024254459744218844\n",
      "train loss:0.0024027841609813045\n",
      "train loss:0.005871744644437245\n",
      "train loss:0.0017787089892676244\n",
      "train loss:0.0003296528175294039\n",
      "train loss:0.023154566030794344\n",
      "train loss:0.0021640145678026783\n",
      "train loss:0.0035645480327114974\n",
      "train loss:0.0010688812765258541\n",
      "train loss:0.003925036798158127\n",
      "train loss:0.0053868134129298065\n",
      "train loss:0.0030407686228013926\n",
      "train loss:0.0008608435445736884\n",
      "train loss:0.0027019577592625552\n",
      "train loss:0.002050689720784646\n",
      "train loss:0.002596994457433412\n",
      "train loss:0.006556289196359486\n",
      "train loss:0.002052095245149481\n",
      "train loss:0.000630651421964276\n",
      "train loss:0.003399761993705821\n",
      "train loss:0.0003729478213710467\n",
      "train loss:0.0014179120585783745\n",
      "train loss:0.0027430000640177583\n",
      "train loss:0.0018573394327571068\n",
      "train loss:0.001524289293234763\n",
      "train loss:0.009159776546103138\n",
      "train loss:0.004623665941250427\n",
      "train loss:0.002487588233689138\n",
      "train loss:0.00757677193316148\n",
      "train loss:0.0007540013093398524\n",
      "train loss:0.0006853508604311376\n",
      "train loss:0.0035438929119014366\n",
      "train loss:0.0007065384710123417\n",
      "train loss:0.004165396378341569\n",
      "train loss:0.027284217152545604\n",
      "train loss:0.0033025594279237976\n",
      "train loss:0.004816200894040556\n",
      "train loss:0.00048542777190970654\n",
      "train loss:0.002633750669161004\n",
      "train loss:0.0013562516577931125\n",
      "train loss:0.02572429043408347\n",
      "train loss:0.0015755875511401826\n",
      "train loss:0.0008757391335032247\n",
      "train loss:0.03197691165157063\n",
      "train loss:0.0015257521516327335\n",
      "train loss:0.0008732688050252219\n",
      "train loss:0.01108736505167058\n",
      "train loss:0.008563961008141732\n",
      "train loss:0.0011775390678189388\n",
      "train loss:0.007699929621337024\n",
      "train loss:0.0051913239363477436\n",
      "train loss:0.0024395362307766434\n",
      "train loss:0.0009643068200848642\n",
      "train loss:0.0006318964767811844\n",
      "train loss:0.007509628901626791\n",
      "train loss:0.0026800670428580907\n",
      "train loss:0.0012985463240945928\n",
      "train loss:0.00013190857453209591\n",
      "train loss:0.0009981210241641959\n",
      "train loss:0.003972437080459518\n",
      "train loss:0.0032750685782529936\n",
      "train loss:0.0017401933027400814\n",
      "train loss:0.0011371304255309654\n",
      "train loss:0.0005245598441889327\n",
      "train loss:0.010194567510699746\n",
      "train loss:0.00014985626491398191\n",
      "train loss:0.0004962980455929742\n",
      "train loss:0.0010692410552423837\n",
      "train loss:0.0006893115390588267\n",
      "train loss:0.002002270913077276\n",
      "train loss:0.010918168526412196\n",
      "train loss:0.00348431742787573\n",
      "train loss:0.008380075358920845\n",
      "train loss:0.003593093024115003\n",
      "train loss:0.002503276269318098\n",
      "train loss:0.004370859647549983\n",
      "train loss:0.0045706432067278355\n",
      "train loss:0.008557778020183036\n",
      "train loss:0.00034280249673907486\n",
      "train loss:0.0014218450113439155\n",
      "train loss:0.002763311864875127\n",
      "train loss:0.017989626311036015\n",
      "train loss:0.0008011355048096515\n",
      "train loss:0.0013434895529254886\n",
      "train loss:0.006310908673503349\n",
      "train loss:0.00020560492242196454\n",
      "train loss:0.03298798727002142\n",
      "train loss:0.0014756006899733847\n",
      "train loss:0.013303397928606416\n",
      "train loss:0.0002231085201488888\n",
      "train loss:0.005747024284071183\n",
      "train loss:0.005577152168796434\n",
      "train loss:0.0005204887044338618\n",
      "train loss:0.0028647105428395024\n",
      "train loss:0.0014566429037943674\n",
      "train loss:0.00398993421739917\n",
      "train loss:0.0006273094109781482\n",
      "train loss:0.0024687013666763627\n",
      "train loss:0.005772507591742985\n",
      "train loss:0.058686311904020946\n",
      "train loss:0.0027637461679992908\n",
      "train loss:0.0007209174783158244\n",
      "train loss:0.0009329641385331328\n",
      "train loss:0.0010968366696943066\n",
      "train loss:0.002193464762877819\n",
      "train loss:0.00230569631076824\n",
      "train loss:0.0010294759772104742\n",
      "train loss:0.00566218999614697\n",
      "train loss:0.003183711945979681\n",
      "train loss:0.00028965256598863774\n",
      "train loss:0.00523318191083699\n",
      "train loss:0.0027190913408708683\n",
      "train loss:0.012244587210814522\n",
      "train loss:0.0008107532528337631\n",
      "train loss:0.0004521095748084924\n",
      "train loss:0.0011487431979547288\n",
      "train loss:0.0019462946206099132\n",
      "train loss:0.0004141091855516307\n",
      "train loss:0.0022991321267983008\n",
      "train loss:0.001506186041624665\n",
      "train loss:0.00490235928281629\n",
      "train loss:0.0073842407403543146\n",
      "train loss:0.009296599603273382\n",
      "train loss:0.0017996802607955983\n",
      "train loss:0.0034416918230343\n",
      "train loss:0.00012731537731126334\n",
      "train loss:0.00018163258353630647\n",
      "train loss:0.0002040255370038569\n",
      "train loss:0.006164461089474755\n",
      "train loss:0.007430425872233321\n",
      "train loss:0.0014838124607911224\n",
      "train loss:0.0029882854819778424\n",
      "train loss:0.0052795032556998125\n",
      "train loss:0.003380244719975614\n",
      "train loss:0.0025410989838049484\n",
      "train loss:0.014181093681248945\n",
      "train loss:0.002369841808671892\n",
      "train loss:0.003151176124581148\n",
      "train loss:0.0035577788097632713\n",
      "train loss:0.0002871386002111355\n",
      "train loss:0.025823873787341186\n",
      "train loss:0.00047045770745886094\n",
      "train loss:0.0022199607156222403\n",
      "train loss:0.00027886267670348275\n",
      "train loss:0.003002321830748169\n",
      "train loss:0.0007234189606018994\n",
      "train loss:0.0012363196808118102\n",
      "train loss:0.000698795346186795\n",
      "train loss:0.0007263979442222016\n",
      "train loss:0.002670965288571586\n",
      "train loss:0.010236684995063472\n",
      "train loss:0.0003878391386550916\n",
      "train loss:0.003773676113698549\n",
      "train loss:0.0009612298849628883\n",
      "train loss:0.002600869572410191\n",
      "train loss:0.004706959676163435\n",
      "train loss:0.0005009984257710982\n",
      "train loss:0.005854184384714946\n",
      "train loss:0.0028312580042898334\n",
      "train loss:0.0027442593365913826\n",
      "train loss:0.0008587213766588838\n",
      "train loss:0.0004898868560179527\n",
      "train loss:0.01173315354193412\n",
      "train loss:0.0009514944250569819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0004772749327968423\n",
      "train loss:0.00205439456961596\n",
      "train loss:0.006161471237338114\n",
      "train loss:0.027565046679998248\n",
      "train loss:0.03628048003301896\n",
      "train loss:0.00043863489376945843\n",
      "train loss:0.002648747583699895\n",
      "train loss:0.0005040971033039249\n",
      "train loss:0.0019349147612659175\n",
      "train loss:0.026891595137333454\n",
      "train loss:0.0005953701555951942\n",
      "train loss:0.0001953128039812021\n",
      "train loss:0.0014415134101600812\n",
      "train loss:0.00046910665143721353\n",
      "train loss:0.0018516948015636124\n",
      "train loss:0.00018042174790434257\n",
      "train loss:0.0009428516250558175\n",
      "train loss:0.0011088097470494615\n",
      "train loss:0.006605197649859163\n",
      "train loss:0.0018259475314398638\n",
      "train loss:0.0005079116480445546\n",
      "train loss:0.0015997188248537942\n",
      "train loss:0.0015864373204764845\n",
      "train loss:0.0037855147317920014\n",
      "train loss:0.01318359206650368\n",
      "train loss:0.00016060639305456878\n",
      "train loss:0.0009201328836305182\n",
      "train loss:0.0030902449535688908\n",
      "train loss:0.0005839980301896126\n",
      "train loss:0.013206585255669857\n",
      "train loss:0.0045159847174435\n",
      "train loss:0.0027404064254353566\n",
      "train loss:0.0011806089186508408\n",
      "train loss:0.0017082644109310777\n",
      "train loss:0.0011790489814851811\n",
      "train loss:0.002445747423832422\n",
      "train loss:0.017053174642311146\n",
      "train loss:0.008535339350714564\n",
      "train loss:0.027867387645513175\n",
      "train loss:0.0006716949679984159\n",
      "train loss:0.00407889607474381\n",
      "train loss:0.01671607437048783\n",
      "train loss:0.0008224783421372027\n",
      "train loss:0.002167430967914637\n",
      "train loss:0.00041835580621937785\n",
      "train loss:0.0018892148635184902\n",
      "train loss:0.011220036880978636\n",
      "train loss:0.0029174405634636046\n",
      "train loss:0.0064569314101454115\n",
      "train loss:0.0022778263751153053\n",
      "train loss:0.0010677762471237389\n",
      "train loss:0.002976573088672203\n",
      "train loss:0.0019117109232419042\n",
      "train loss:0.0024608697592312877\n",
      "train loss:0.0008944133246110942\n",
      "train loss:0.001508069871279924\n",
      "train loss:0.0002058940010901243\n",
      "train loss:0.0007949198015852138\n",
      "train loss:0.0003216322716106489\n",
      "train loss:0.01057270687776051\n",
      "train loss:0.001252533803425007\n",
      "train loss:0.0070020797343462995\n",
      "train loss:0.0011698178961344894\n",
      "train loss:0.0007837475621065645\n",
      "train loss:0.0015842305571424284\n",
      "train loss:0.0026938337519527454\n",
      "train loss:0.010591543223813525\n",
      "train loss:0.0027029193957409116\n",
      "train loss:0.0021184692795873524\n",
      "train loss:0.0021844310946341748\n",
      "train loss:0.007648787850287611\n",
      "train loss:0.0029363648426350875\n",
      "train loss:0.010329631901517214\n",
      "train loss:0.020120790136329853\n",
      "train loss:0.0005102743613494802\n",
      "train loss:0.02759756011598594\n",
      "train loss:0.008904369752270961\n",
      "train loss:0.0019585150526001543\n",
      "train loss:0.0006339037531602135\n",
      "train loss:0.003913225011853686\n",
      "train loss:0.004237700967838524\n",
      "train loss:0.003964247526354235\n",
      "train loss:0.003149208073367156\n",
      "train loss:0.0015268184374945728\n",
      "train loss:0.0001791965958475376\n",
      "train loss:0.0008583206056988889\n",
      "train loss:0.007766708880705344\n",
      "train loss:0.000647722132929331\n",
      "train loss:0.005365503264484494\n",
      "train loss:0.0012603252875675649\n",
      "train loss:0.0007495570309728103\n",
      "train loss:0.0024028311869624137\n",
      "train loss:0.0014911861433375207\n",
      "train loss:0.002495247348950411\n",
      "train loss:0.0034700986378380454\n",
      "train loss:0.0006854726217687212\n",
      "train loss:0.005229091558353308\n",
      "train loss:0.00042047293571430353\n",
      "train loss:0.0031210624797974786\n",
      "train loss:0.002148688499925361\n",
      "train loss:0.0011129418397635865\n",
      "train loss:0.0008858932522752791\n",
      "train loss:0.004987443997021797\n",
      "train loss:0.004844156490908817\n",
      "train loss:0.0008559680972119271\n",
      "train loss:0.0019027166957679383\n",
      "train loss:0.0009405662870872243\n",
      "train loss:0.0019261020685400797\n",
      "train loss:0.004594642567951679\n",
      "train loss:0.00458030726264655\n",
      "train loss:0.0004418386936982652\n",
      "train loss:0.0013847950761698416\n",
      "train loss:0.0037762530601737065\n",
      "train loss:0.002806376495244053\n",
      "train loss:0.009507104496563477\n",
      "train loss:0.00031915417217413144\n",
      "train loss:0.00415572373159448\n",
      "train loss:0.013992331127074507\n",
      "train loss:0.0006279023572988269\n",
      "train loss:0.007636436207535364\n",
      "train loss:0.002456433348031936\n",
      "train loss:0.007996895740528078\n",
      "train loss:0.011407191922276919\n",
      "train loss:0.0002947555815606584\n",
      "train loss:0.002204792206473644\n",
      "train loss:0.002936086205794119\n",
      "train loss:0.00015316673277487446\n",
      "train loss:0.00731298248705408\n",
      "train loss:0.00850620867507556\n",
      "train loss:0.00011778045459713847\n",
      "train loss:0.0003084822217124287\n",
      "train loss:0.002245813538342669\n",
      "train loss:0.0005851442093385405\n",
      "train loss:0.00024175856922501124\n",
      "train loss:0.0024874509636365195\n",
      "train loss:0.003351369731883033\n",
      "train loss:0.000507129787249324\n",
      "train loss:0.00103401354099428\n",
      "train loss:0.003101332289226988\n",
      "train loss:0.007443098149348702\n",
      "train loss:0.00367510445685208\n",
      "train loss:0.0003845407501240328\n",
      "train loss:0.0015101994522956875\n",
      "train loss:0.003448915588709066\n",
      "train loss:0.014700845238218473\n",
      "train loss:0.0010619249718903908\n",
      "train loss:0.001170527627684156\n",
      "train loss:0.0014870877102983473\n",
      "train loss:0.0029410804613090157\n",
      "train loss:0.0005545722206173615\n",
      "train loss:0.03633380623095804\n",
      "train loss:0.00023371023278609822\n",
      "train loss:0.001514936653665206\n",
      "train loss:0.002902274445961721\n",
      "train loss:0.0038090800200105196\n",
      "train loss:0.0037766292678603026\n",
      "train loss:0.0011979094532389338\n",
      "train loss:0.00456700657945306\n",
      "train loss:0.0006766229828595599\n",
      "train loss:0.002073217800633329\n",
      "train loss:0.0005905890732551132\n",
      "train loss:0.0032205894319663037\n",
      "train loss:0.003744007833259013\n",
      "train loss:0.004360506455773965\n",
      "train loss:0.0027287173421289166\n",
      "train loss:0.0015812148896415684\n",
      "train loss:0.0020702156862446707\n",
      "train loss:0.007233749725291283\n",
      "train loss:0.0009200310335615888\n",
      "train loss:0.005979433073044052\n",
      "train loss:0.0003723843517676947\n",
      "train loss:0.00275088001601839\n",
      "train loss:0.00802823239233962\n",
      "train loss:0.0005080044579426883\n",
      "train loss:0.002984319091200038\n",
      "train loss:0.0025158474750360915\n",
      "train loss:0.0024974264486821865\n",
      "train loss:0.003284907618243333\n",
      "train loss:0.00010090888994560101\n",
      "train loss:0.0005825458003381381\n",
      "train loss:0.003680086426471395\n",
      "train loss:0.00047016606658264613\n",
      "train loss:0.0008664996615441758\n",
      "train loss:0.0001728330687900364\n",
      "train loss:0.006876114268677114\n",
      "train loss:0.0008799728867707128\n",
      "train loss:0.0007188981719349619\n",
      "train loss:0.00085267268673119\n",
      "train loss:0.00027931279638609627\n",
      "train loss:0.00032799616410714996\n",
      "train loss:0.002119540902941042\n",
      "train loss:0.0024900409222617928\n",
      "train loss:0.002709320873115861\n",
      "train loss:0.002838348766724099\n",
      "train loss:0.000310230980595859\n",
      "train loss:0.0014736096194447375\n",
      "train loss:0.0005509011320016765\n",
      "train loss:0.0007977702144775694\n",
      "train loss:0.00034248106955044364\n",
      "train loss:0.0032286645917350663\n",
      "train loss:0.001117440704601741\n",
      "train loss:0.003958889078625694\n",
      "train loss:0.004006704078947518\n",
      "train loss:0.01947318203544883\n",
      "train loss:0.006838416647105352\n",
      "train loss:0.003686327943616641\n",
      "train loss:0.0009408931958705015\n",
      "train loss:0.004389393408069348\n",
      "train loss:0.0028280020828353796\n",
      "train loss:0.0029478084608778716\n",
      "train loss:0.009730737137094\n",
      "train loss:0.00437331124581696\n",
      "train loss:0.006745947940851204\n",
      "train loss:0.002168432620723027\n",
      "train loss:0.004717029352760891\n",
      "train loss:0.0030325431769057036\n",
      "train loss:0.02732586240433115\n",
      "train loss:0.0008151283742028189\n",
      "train loss:0.0014154841067794228\n",
      "train loss:0.0029554737163383802\n",
      "train loss:0.0010017188201743095\n",
      "train loss:0.0020236259527860864\n",
      "train loss:0.0011153989019483531\n",
      "train loss:0.0009009837379929851\n",
      "train loss:0.004377221833410017\n",
      "train loss:0.00026442990774672317\n",
      "train loss:0.0014209853531521556\n",
      "train loss:0.002259027207357468\n",
      "train loss:0.0004451028609061324\n",
      "train loss:0.0009554159828018108\n",
      "train loss:0.03074081460120427\n",
      "train loss:0.004288818612800052\n",
      "train loss:0.001238097233188668\n",
      "train loss:0.0026405077724641775\n",
      "train loss:0.007190865509854618\n",
      "train loss:0.0011727344267955253\n",
      "train loss:0.0008469958011286041\n",
      "train loss:0.0038291795512186057\n",
      "train loss:0.0004925519257764213\n",
      "train loss:0.005348109397752515\n",
      "train loss:0.00042735443041237996\n",
      "train loss:0.0029279715221518674\n",
      "train loss:0.00557012855254304\n",
      "train loss:0.002607124343542577\n",
      "train loss:0.0014339925401546988\n",
      "train loss:0.001799019853456297\n",
      "train loss:0.0026275386932333895\n",
      "train loss:0.002452971605350256\n",
      "train loss:0.00016285832997284938\n",
      "train loss:0.0008204134230055831\n",
      "train loss:0.004073002761856554\n",
      "train loss:0.0011439022943990152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0007644877280773823\n",
      "train loss:0.0004565786983324495\n",
      "train loss:0.003525889187194764\n",
      "train loss:0.0036241841776736695\n",
      "train loss:0.002258489302654143\n",
      "train loss:0.002296024062263906\n",
      "train loss:0.005465795213941393\n",
      "train loss:0.0002432623572452668\n",
      "train loss:0.000470792524368372\n",
      "train loss:0.004591459411526779\n",
      "train loss:0.001465483005467316\n",
      "train loss:0.0015269643253809184\n",
      "train loss:0.00047812290716753845\n",
      "train loss:0.0008049393524792927\n",
      "train loss:0.0009814478742575011\n",
      "train loss:0.013290444352885948\n",
      "train loss:0.001881439841142106\n",
      "train loss:0.002213514189663922\n",
      "train loss:0.012715295651090157\n",
      "train loss:0.0039948197432197515\n",
      "train loss:0.0015577979553254065\n",
      "train loss:0.00036077460731442587\n",
      "train loss:0.0010584473605093705\n",
      "train loss:0.0010462249847962906\n",
      "train loss:0.0005770487093092758\n",
      "train loss:0.003113076302217282\n",
      "train loss:0.0003508447018780438\n",
      "train loss:0.0014667980395844339\n",
      "train loss:0.0012305835044959866\n",
      "train loss:0.00016313637241165794\n",
      "train loss:0.0012598255358277075\n",
      "train loss:0.009360201509469708\n",
      "train loss:0.0012447864751635338\n",
      "train loss:0.0044175655025876885\n",
      "train loss:0.0027729355745902905\n",
      "train loss:0.004021679955729148\n",
      "train loss:0.00579233498986723\n",
      "train loss:0.0064604548493493695\n",
      "train loss:0.0007246025049863601\n",
      "train loss:0.003402843522801604\n",
      "train loss:0.004006816716633636\n",
      "train loss:0.00014603961805048467\n",
      "train loss:0.0005615133187993412\n",
      "train loss:0.0010110047081169375\n",
      "train loss:0.005201105723762875\n",
      "train loss:0.0004573168801158909\n",
      "train loss:0.001970760433576895\n",
      "train loss:0.0011399381815269394\n",
      "train loss:0.0038653905476629478\n",
      "train loss:0.0014120392526330828\n",
      "train loss:0.023560443945815347\n",
      "train loss:0.002382567047903593\n",
      "train loss:0.0010356983740508387\n",
      "train loss:8.952053137157227e-05\n",
      "train loss:0.001187650556456084\n",
      "train loss:0.0005512883253755706\n",
      "train loss:0.004062909246853256\n",
      "train loss:0.001646840306039096\n",
      "train loss:0.00046508562623010446\n",
      "train loss:0.00043882439922515113\n",
      "train loss:0.0013267988276911143\n",
      "train loss:0.002646848368602053\n",
      "train loss:0.0032454182960146238\n",
      "train loss:0.004670310634098123\n",
      "train loss:0.0019424791506595209\n",
      "train loss:0.0005096377798111853\n",
      "train loss:0.0005434909083350891\n",
      "train loss:0.0011964548222914227\n",
      "train loss:0.0006176235167118916\n",
      "train loss:0.0020965358169509883\n",
      "train loss:2.0335522677754567e-05\n",
      "train loss:0.0015774747889071728\n",
      "train loss:0.00045003908594605025\n",
      "train loss:0.000982499273661632\n",
      "train loss:0.0005839784891349309\n",
      "train loss:0.0007180610823828884\n",
      "train loss:0.002088238807759431\n",
      "train loss:0.000814985334094249\n",
      "train loss:0.0004820338208691401\n",
      "train loss:0.00019300355717587534\n",
      "train loss:0.0005853889544840786\n",
      "train loss:0.0004114810928306879\n",
      "train loss:0.0007225740572434532\n",
      "train loss:0.00037263507636457597\n",
      "train loss:0.0013038314775532288\n",
      "train loss:0.0006802973268734959\n",
      "train loss:0.0004489092871123871\n",
      "train loss:0.0007821562549922011\n",
      "train loss:0.0002361768055766489\n",
      "train loss:0.007722691650743971\n",
      "train loss:0.0013024552404815432\n",
      "train loss:0.0028961833311417994\n",
      "train loss:0.0009510415543644297\n",
      "train loss:0.00015713567645613224\n",
      "train loss:0.0003213882139547987\n",
      "train loss:0.0006892568936248882\n",
      "train loss:0.003775384524604477\n",
      "train loss:0.0015381132060177751\n",
      "train loss:0.0018646653470742833\n",
      "train loss:0.004618888150777726\n",
      "train loss:0.001829569642776273\n",
      "train loss:0.021913507658452437\n",
      "train loss:0.003986030855739318\n",
      "train loss:0.0004020105643349314\n",
      "train loss:0.0009167342434076372\n",
      "train loss:0.00025702169096427464\n",
      "train loss:0.0035976769531850155\n",
      "train loss:5.054020782188402e-05\n",
      "train loss:0.003910787129048677\n",
      "train loss:0.00044782649928026835\n",
      "train loss:0.001522024613491339\n",
      "train loss:0.001018546502328116\n",
      "train loss:0.0006609641855405684\n",
      "train loss:0.007620914222926328\n",
      "train loss:0.0037250198847728886\n",
      "train loss:0.001734809266900714\n",
      "train loss:0.044072010711420785\n",
      "train loss:0.007506038167221004\n",
      "train loss:0.003551571678538879\n",
      "train loss:0.011148646839295142\n",
      "train loss:0.00040624439812981844\n",
      "train loss:0.0001200877242883097\n",
      "train loss:0.0019937055143528933\n",
      "train loss:0.003670688347381316\n",
      "train loss:0.005692563930998442\n",
      "train loss:0.007211356282096714\n",
      "train loss:0.0010283566952090082\n",
      "train loss:0.005311658901775712\n",
      "train loss:0.0024703199887810097\n",
      "train loss:0.00280956186767683\n",
      "train loss:0.029107665724411924\n",
      "train loss:0.0010923137970490961\n",
      "train loss:0.0023479266521525878\n",
      "train loss:0.0005329164310680032\n",
      "train loss:0.0016520580668700424\n",
      "train loss:0.0038386567115206533\n",
      "train loss:0.0009006070393517774\n",
      "train loss:0.001950399625426895\n",
      "train loss:0.020367856892207183\n",
      "train loss:0.0011664626003794706\n",
      "train loss:0.0037929010136883833\n",
      "train loss:0.00028242891700102106\n",
      "train loss:0.0021204931543073267\n",
      "train loss:0.0021937001813454367\n",
      "train loss:0.0019786082285972477\n",
      "train loss:0.0003794722197345014\n",
      "train loss:0.0006375780185745249\n",
      "train loss:0.001792414878877683\n",
      "train loss:0.0005147590130705988\n",
      "train loss:0.00904563069118232\n",
      "train loss:0.00041442952921074647\n",
      "train loss:0.0010944342134520388\n",
      "train loss:0.004863124667532332\n",
      "train loss:4.276700514291246e-05\n",
      "train loss:0.003354257885231598\n",
      "train loss:0.009450316516031152\n",
      "train loss:0.00016496583572338952\n",
      "train loss:0.001964331750721926\n",
      "train loss:0.0018326466070068442\n",
      "train loss:0.0038092868030260734\n",
      "train loss:0.002610455409144064\n",
      "train loss:0.0012497447854891272\n",
      "train loss:0.0005706575002425931\n",
      "train loss:0.0039878717933335426\n",
      "train loss:0.001954735265423587\n",
      "=== epoch:15, train acc:0.995, test acc:0.984 ===\n",
      "train loss:0.0036986382415794385\n",
      "train loss:0.0031097750869765873\n",
      "train loss:0.0007978476341172012\n",
      "train loss:0.0007680675118332896\n",
      "train loss:0.007615251088710654\n",
      "train loss:0.0027784454490528965\n",
      "train loss:0.003870034386259008\n",
      "train loss:0.0014407679066246498\n",
      "train loss:0.00040288349360402163\n",
      "train loss:0.0012493101236314029\n",
      "train loss:0.0012105953251958436\n",
      "train loss:0.000608394478009763\n",
      "train loss:0.003421093023130553\n",
      "train loss:0.003202291580456867\n",
      "train loss:0.008584494699057038\n",
      "train loss:0.001003480110210553\n",
      "train loss:0.0029325465200978184\n",
      "train loss:0.001213873654691954\n",
      "train loss:0.004704902445655271\n",
      "train loss:0.0017843487145175348\n",
      "train loss:0.0031966847730362335\n",
      "train loss:0.0005347417358972301\n",
      "train loss:0.0014755444664140218\n",
      "train loss:0.0002646115306712794\n",
      "train loss:0.003432673718636664\n",
      "train loss:0.00027337523717537793\n",
      "train loss:0.0005179074845428583\n",
      "train loss:0.0008821408953759082\n",
      "train loss:0.000842221824448062\n",
      "train loss:0.002703460307383873\n",
      "train loss:0.002041430811217228\n",
      "train loss:0.003888508475872661\n",
      "train loss:0.0016576164132859478\n",
      "train loss:0.00421436359411132\n",
      "train loss:0.0021884876406651314\n",
      "train loss:0.0041384463857152606\n",
      "train loss:0.0013821992496551604\n",
      "train loss:0.0004345596388223207\n",
      "train loss:0.007189294014883537\n",
      "train loss:0.0004696399795143465\n",
      "train loss:0.000920317464727883\n",
      "train loss:0.00015482442676048166\n",
      "train loss:0.0002795609102351811\n",
      "train loss:0.012768205530717834\n",
      "train loss:0.0024052566914829075\n",
      "train loss:0.0008288318711546224\n",
      "train loss:0.0008525429470823861\n",
      "train loss:0.0023318713522292914\n",
      "train loss:0.004749115383635919\n",
      "train loss:0.009656723685260871\n",
      "train loss:0.002531212664448665\n",
      "train loss:0.0006791052687568707\n",
      "train loss:0.0029068676743065815\n",
      "train loss:8.341339774399245e-05\n",
      "train loss:0.000413608165609607\n",
      "train loss:0.00019075910603599518\n",
      "train loss:0.0018696552808181624\n",
      "train loss:0.0030747003030654795\n",
      "train loss:0.003040836378556532\n",
      "train loss:0.008216698091773243\n",
      "train loss:0.0015209492860013105\n",
      "train loss:0.0005756900656335986\n",
      "train loss:0.0014164088558888171\n",
      "train loss:0.0008173857331882541\n",
      "train loss:0.0014236797302353665\n",
      "train loss:0.0009310318257842543\n",
      "train loss:0.001689665609596959\n",
      "train loss:2.3055734129451967e-05\n",
      "train loss:0.002989089573706469\n",
      "train loss:0.0027972666897500375\n",
      "train loss:0.0003284994278426276\n",
      "train loss:0.0022928761282456456\n",
      "train loss:0.0005139514377630435\n",
      "train loss:0.0026740375467004924\n",
      "train loss:0.01422194570067091\n",
      "train loss:0.003228180265598273\n",
      "train loss:0.0012723575918165341\n",
      "train loss:0.002117723463269779\n",
      "train loss:0.0014796497834924827\n",
      "train loss:0.0024468134915667026\n",
      "train loss:0.0017672579206444818\n",
      "train loss:0.006765689928198363\n",
      "train loss:0.0014265559948649956\n",
      "train loss:0.002906124742497142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00017868396414303137\n",
      "train loss:0.00016471997568331696\n",
      "train loss:0.001456573713570482\n",
      "train loss:0.0003985344523202339\n",
      "train loss:0.00011745133173719935\n",
      "train loss:0.0016428616509096142\n",
      "train loss:0.00017963516775648604\n",
      "train loss:0.0019338001271447893\n",
      "train loss:0.004422990392679098\n",
      "train loss:0.000742546938144965\n",
      "train loss:0.0018601437264067174\n",
      "train loss:0.001620824320433598\n",
      "train loss:0.004910051023262504\n",
      "train loss:0.002161961050131355\n",
      "train loss:0.00023297528019419238\n",
      "train loss:0.0011279133206007251\n",
      "train loss:0.00014534753097438446\n",
      "train loss:6.13001986454927e-05\n",
      "train loss:0.002286850812243841\n",
      "train loss:0.0024862974324681027\n",
      "train loss:0.001384788928800836\n",
      "train loss:0.004331095769204185\n",
      "train loss:0.0001491177289347576\n",
      "train loss:0.0018660742314773283\n",
      "train loss:0.0013645793126173366\n",
      "train loss:0.0007162019813580203\n",
      "train loss:0.00028351692088242125\n",
      "train loss:0.0014571621501799333\n",
      "train loss:0.0005334298630401057\n",
      "train loss:0.0026659432837575197\n",
      "train loss:0.0010826301921969526\n",
      "train loss:0.0007855772010121098\n",
      "train loss:8.508626910528774e-05\n",
      "train loss:0.00040148400399559847\n",
      "train loss:0.0031064199972302394\n",
      "train loss:0.0004952361432421132\n",
      "train loss:0.0023715676522807604\n",
      "train loss:4.162156713825795e-05\n",
      "train loss:0.001102238605301511\n",
      "train loss:0.00043040279252262443\n",
      "train loss:0.004308585654634823\n",
      "train loss:0.002549213033550121\n",
      "train loss:0.0005996671181586857\n",
      "train loss:0.00021285534841421544\n",
      "train loss:0.0007920180838304927\n",
      "train loss:0.0005290569468719546\n",
      "train loss:0.0005618897673568778\n",
      "train loss:0.0012215231867845698\n",
      "train loss:0.0018770022481018325\n",
      "train loss:0.00021024014106674083\n",
      "train loss:0.00267675600319123\n",
      "train loss:0.0009161634293364949\n",
      "train loss:0.0019887278726014646\n",
      "train loss:0.003206591013218152\n",
      "train loss:0.0006708879256047269\n",
      "train loss:0.0021990492447368885\n",
      "train loss:0.0014440521571324808\n",
      "train loss:0.00017848146861156004\n",
      "train loss:0.0003569713385450452\n",
      "train loss:0.0007551182121367406\n",
      "train loss:0.0018187311286015206\n",
      "train loss:0.0017726652299138224\n",
      "train loss:0.00010572672439099127\n",
      "train loss:0.001094709150895945\n",
      "train loss:0.001762986776279967\n",
      "train loss:0.0002746757876257429\n",
      "train loss:0.0020830946685287247\n",
      "train loss:0.0002637934628424529\n",
      "train loss:0.0022978148897054938\n",
      "train loss:0.004697327074734418\n",
      "train loss:0.003850299330453073\n",
      "train loss:0.0011242596137079849\n",
      "train loss:0.0033021195069443204\n",
      "train loss:0.005366377215108222\n",
      "train loss:0.004082629546343368\n",
      "train loss:0.0018759592456686195\n",
      "train loss:0.000961191273464446\n",
      "train loss:0.002639576045081917\n",
      "train loss:0.004640116286737828\n",
      "train loss:0.0044837622621383315\n",
      "train loss:0.0005843054055233273\n",
      "train loss:0.007428194688288636\n",
      "train loss:0.004664386302105544\n",
      "train loss:0.0009500545201344242\n",
      "train loss:0.00679943139764096\n",
      "train loss:0.01020857014999851\n",
      "train loss:0.0031014603641732036\n",
      "train loss:0.0004096187291220019\n",
      "train loss:0.002287926300323783\n",
      "train loss:0.0021327016682705507\n",
      "train loss:0.0007479492446071675\n",
      "train loss:0.0010396320209237382\n",
      "train loss:0.003249406051416308\n",
      "train loss:0.016933728033624296\n",
      "train loss:0.0009916693673075296\n",
      "train loss:0.0027823769854865505\n",
      "train loss:0.0027376408784293136\n",
      "train loss:0.00019586208425995068\n",
      "train loss:0.0012036823086794108\n",
      "train loss:0.021382660599732806\n",
      "train loss:6.568914656535661e-05\n",
      "train loss:0.0024231841739456466\n",
      "train loss:3.7154184811527996e-05\n",
      "train loss:0.008996231639015678\n",
      "train loss:0.0012115432725564252\n",
      "train loss:0.000145362956759288\n",
      "train loss:0.0014016199221503329\n",
      "train loss:0.0008334294696739683\n",
      "train loss:0.006269662261696237\n",
      "train loss:0.0014989842634669558\n",
      "train loss:0.00012574665815117737\n",
      "train loss:0.00200689726929247\n",
      "train loss:0.0014073015572599967\n",
      "train loss:0.005775531583814826\n",
      "train loss:0.0009053711567637881\n",
      "train loss:0.00099305209483259\n",
      "train loss:0.0030534673851929624\n",
      "train loss:0.0015951293895078466\n",
      "train loss:0.002710952350335315\n",
      "train loss:0.0014162355137307251\n",
      "train loss:0.002903964168626324\n",
      "train loss:0.022228645187190074\n",
      "train loss:0.0021295489561198454\n",
      "train loss:0.0007301559439255375\n",
      "train loss:0.020563992726516666\n",
      "train loss:0.0017839545613622671\n",
      "train loss:0.0016844542588003062\n",
      "train loss:0.002652668990213018\n",
      "train loss:0.0012493546690701\n",
      "train loss:0.001121945793318174\n",
      "train loss:0.0025827684461760363\n",
      "train loss:0.004345710943829057\n",
      "train loss:0.0002870760430256069\n",
      "train loss:0.012696503948441584\n",
      "train loss:0.004015296685358607\n",
      "train loss:0.05090160974009814\n",
      "train loss:0.0006097451463074248\n",
      "train loss:0.0006546473832633534\n",
      "train loss:0.0006987173495298863\n",
      "train loss:0.007103424036628135\n",
      "train loss:0.00027732170661808736\n",
      "train loss:0.0002833338335617482\n",
      "train loss:0.001540255035261685\n",
      "train loss:0.000924444525893501\n",
      "train loss:0.014551866776416383\n",
      "train loss:0.0005581077525453021\n",
      "train loss:0.002205498174080803\n",
      "train loss:0.009586972811697896\n",
      "train loss:0.011949186492927012\n",
      "train loss:0.009768740090574391\n",
      "train loss:0.0007048301884902405\n",
      "train loss:0.0006419746656472121\n",
      "train loss:0.0007691333941400337\n",
      "train loss:0.00240706217213798\n",
      "train loss:0.0003381199808244584\n",
      "train loss:0.003104856151792607\n",
      "train loss:0.002090645779867424\n",
      "train loss:0.0006812579090629818\n",
      "train loss:0.0020692214032903304\n",
      "train loss:5.7803147429774825e-05\n",
      "train loss:0.011268935072749375\n",
      "train loss:0.001529365727446608\n",
      "train loss:0.002904616765984866\n",
      "train loss:0.001225026949421789\n",
      "train loss:0.003399166572581777\n",
      "train loss:0.0006741301977888198\n",
      "train loss:0.004373490488935535\n",
      "train loss:0.0013040517286307673\n",
      "train loss:0.008561770823995741\n",
      "train loss:0.00027787209817657426\n",
      "train loss:0.00017096504188598017\n",
      "train loss:0.043874554042521316\n",
      "train loss:0.007457175956597067\n",
      "train loss:0.002780828885599549\n",
      "train loss:0.010257051170680735\n",
      "train loss:0.0029755178959538116\n",
      "train loss:0.0029493904315245323\n",
      "train loss:0.003032180582537387\n",
      "train loss:0.00015384277459270983\n",
      "train loss:0.031303405790539626\n",
      "train loss:0.004741642330397586\n",
      "train loss:0.00025403333315278625\n",
      "train loss:0.002193808756292395\n",
      "train loss:0.0019036788473939309\n",
      "train loss:0.020201517294965186\n",
      "train loss:0.013261857387820222\n",
      "train loss:0.0025413472243559576\n",
      "train loss:0.0021461310199463106\n",
      "train loss:0.0019994086317448316\n",
      "train loss:0.0026981443382417185\n",
      "train loss:0.0005830330357100398\n",
      "train loss:0.0006057306651617257\n",
      "train loss:0.0008772909720457625\n",
      "train loss:0.0006369460361445271\n",
      "train loss:0.001789778480528725\n",
      "train loss:0.007824587629095808\n",
      "train loss:0.003805035792416418\n",
      "train loss:0.004335768997296989\n",
      "train loss:0.0029660386007472977\n",
      "train loss:0.002067234926587302\n",
      "train loss:0.0069205135342951685\n",
      "train loss:0.0008612798805383782\n",
      "train loss:0.00213508423924506\n",
      "train loss:0.026894585549118707\n",
      "train loss:0.0017071263616651427\n",
      "train loss:0.0031862703118225376\n",
      "train loss:0.00437110053184272\n",
      "train loss:0.00044090843573024805\n",
      "train loss:0.006896089909020501\n",
      "train loss:0.0011441719978104803\n",
      "train loss:0.0007254215967581959\n",
      "train loss:0.00239610213018395\n",
      "train loss:0.0023097955359726906\n",
      "train loss:0.0007999315097751534\n",
      "train loss:0.006828945541815844\n",
      "train loss:0.0017078259801748613\n",
      "train loss:0.004833649035078776\n",
      "train loss:0.005530451569469216\n",
      "train loss:0.0007524517945475618\n",
      "train loss:0.0020762682692634406\n",
      "train loss:0.0013775558295744956\n",
      "train loss:0.005241874931369792\n",
      "train loss:0.0028375272066668723\n",
      "train loss:0.018902755537803753\n",
      "train loss:0.0024060794340708684\n",
      "train loss:0.00023504136270267488\n",
      "train loss:0.005462593508954653\n",
      "train loss:0.0013319314485723426\n",
      "train loss:0.004421872127530715\n",
      "train loss:0.021217475098067835\n",
      "train loss:0.0011086714664413492\n",
      "train loss:0.01736001198460998\n",
      "train loss:0.0008196476770233914\n",
      "train loss:0.002956822313876482\n",
      "train loss:0.0011562418374281868\n",
      "train loss:0.0004412291808608861\n",
      "train loss:0.0002330786338375997\n",
      "train loss:0.012792617809733337\n",
      "train loss:0.0027998425132567785\n",
      "train loss:0.013888890935348753\n",
      "train loss:9.18415371010532e-05\n",
      "train loss:0.001570072985196123\n",
      "train loss:0.000790860497791705\n",
      "train loss:0.0018067704800824068\n",
      "train loss:0.0009460991114956175\n",
      "train loss:0.00010713873302861649\n",
      "train loss:0.00044653935002203786\n",
      "train loss:0.0009414889323119123\n",
      "train loss:1.3580106222056613e-05\n",
      "train loss:0.002059414283713402\n",
      "train loss:0.01608368933685509\n",
      "train loss:0.0055006976044021895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002877411340061565\n",
      "train loss:0.0003832799056679464\n",
      "train loss:0.014085786406772143\n",
      "train loss:0.0012234837768131015\n",
      "train loss:0.002107957882558434\n",
      "train loss:0.0003051030420267024\n",
      "train loss:0.0021575469840110677\n",
      "train loss:0.0036633551933123103\n",
      "train loss:0.005837250726356601\n",
      "train loss:0.00016621139968195578\n",
      "train loss:0.0013185639818959088\n",
      "train loss:0.0001651124878236496\n",
      "train loss:0.001649670376932275\n",
      "train loss:0.0020021903975743645\n",
      "train loss:0.0034445273571234412\n",
      "train loss:0.00535437642574238\n",
      "train loss:0.014947213704335171\n",
      "train loss:0.00023837781841382224\n",
      "train loss:0.0005575146687005993\n",
      "train loss:0.0004950612991975359\n",
      "train loss:0.010072596938560312\n",
      "train loss:0.0006489989128791069\n",
      "train loss:0.004688343445857158\n",
      "train loss:0.01041674650001457\n",
      "train loss:0.000939724955293031\n",
      "train loss:0.005995067524767243\n",
      "train loss:0.00134428588590736\n",
      "train loss:0.0022009148314497784\n",
      "train loss:0.00040412301274134205\n",
      "train loss:0.006174746161076756\n",
      "train loss:0.0030192308472413516\n",
      "train loss:0.001058463264949375\n",
      "train loss:0.000827269680367551\n",
      "train loss:0.002365836460428303\n",
      "train loss:0.00015244916980776787\n",
      "train loss:0.0008651051342452443\n",
      "train loss:0.0011601658076644378\n",
      "train loss:0.0074596245141350034\n",
      "train loss:0.004161601772377517\n",
      "train loss:0.0020337897185685734\n",
      "train loss:0.00563296702859106\n",
      "train loss:0.0029515607990993693\n",
      "train loss:0.002298518867062511\n",
      "train loss:0.0007374073406394336\n",
      "train loss:0.0017304603434048198\n",
      "train loss:0.0012139218664219326\n",
      "train loss:0.005289306703399508\n",
      "train loss:0.005263950115481737\n",
      "train loss:0.00020906592932326093\n",
      "train loss:0.0041375718025847275\n",
      "train loss:0.0008508398520832569\n",
      "train loss:0.00042871630292754757\n",
      "train loss:0.0024555529504981565\n",
      "train loss:0.0025206597825343335\n",
      "train loss:0.0012019693301380204\n",
      "train loss:0.0008234180065529163\n",
      "train loss:0.0012201245658163492\n",
      "train loss:0.0003202376323003718\n",
      "train loss:0.0032887923501457145\n",
      "train loss:0.001149820382463945\n",
      "train loss:0.018932431631360724\n",
      "train loss:0.0001231857723859547\n",
      "train loss:0.0008015808396886998\n",
      "train loss:0.00041052581714624316\n",
      "train loss:0.0018141256724829092\n",
      "train loss:0.007616963210855489\n",
      "train loss:0.0014453661594300393\n",
      "train loss:0.0016011141077912816\n",
      "train loss:0.0004039226375784921\n",
      "train loss:0.001485638462022615\n",
      "train loss:9.852298940560202e-05\n",
      "train loss:0.0010407715660694249\n",
      "train loss:6.600315038076686e-05\n",
      "train loss:0.010197469320808585\n",
      "train loss:0.00263429066626023\n",
      "train loss:0.002716843432073152\n",
      "train loss:0.0031461253698332027\n",
      "train loss:0.01632498100241074\n",
      "train loss:0.0015186535056922396\n",
      "train loss:0.0011960368494941327\n",
      "train loss:0.007865620905353891\n",
      "train loss:0.0011600572624611636\n",
      "train loss:0.001106695086487525\n",
      "train loss:0.0012443127942163685\n",
      "train loss:0.0010024227256450113\n",
      "train loss:0.007664063111052653\n",
      "train loss:0.0008791507118426838\n",
      "train loss:0.01963997710580422\n",
      "train loss:0.0026939932636615366\n",
      "train loss:0.003566532707712919\n",
      "train loss:0.0015679098745236474\n",
      "train loss:0.0012303264779083766\n",
      "train loss:0.0030764968491558235\n",
      "train loss:0.007790351248644328\n",
      "train loss:0.0015750557806035333\n",
      "train loss:0.0014548971361385472\n",
      "train loss:0.0005816911671642935\n",
      "train loss:0.0011062506469366835\n",
      "train loss:0.0012072230742642181\n",
      "train loss:0.004784552786917809\n",
      "train loss:0.006503775307191095\n",
      "train loss:0.001030048909042403\n",
      "train loss:0.002446996065148155\n",
      "train loss:0.05362428319887729\n",
      "train loss:0.0015378465025007687\n",
      "train loss:0.004314776640766953\n",
      "train loss:0.002250592973858106\n",
      "train loss:0.0027676463733421653\n",
      "train loss:0.008950959329318999\n",
      "train loss:0.0012696429540445333\n",
      "train loss:0.0021239281190815855\n",
      "train loss:0.0007855429963749345\n",
      "train loss:0.0009202341034132268\n",
      "train loss:0.0017636205110272698\n",
      "train loss:0.0007448828386977623\n",
      "train loss:0.006500315101926053\n",
      "train loss:0.008275502742427932\n",
      "train loss:0.0030769959300479283\n",
      "train loss:0.0034703222920928513\n",
      "train loss:0.001568640400484682\n",
      "train loss:0.001933351754139935\n",
      "train loss:0.0001141121345574778\n",
      "train loss:0.003422764976392006\n",
      "train loss:0.0041132959737368805\n",
      "train loss:0.0010425079162762483\n",
      "train loss:0.00025939787575256397\n",
      "train loss:0.0012824645244533417\n",
      "train loss:0.007369999674077858\n",
      "train loss:0.0017393560388735089\n",
      "train loss:0.0025122291047985274\n",
      "train loss:0.011066591986827978\n",
      "train loss:0.0030694422558137963\n",
      "train loss:0.0008673415174625661\n",
      "train loss:0.0018375749773116784\n",
      "train loss:0.0002324760740761956\n",
      "train loss:0.0018409521026250366\n",
      "train loss:0.0007248740293977075\n",
      "train loss:0.004279143427668206\n",
      "train loss:0.003911292028699744\n",
      "train loss:0.0007508379812928353\n",
      "train loss:0.04518884036051871\n",
      "train loss:0.022049362965763996\n",
      "train loss:0.004836223423096885\n",
      "train loss:0.004015375297077914\n",
      "train loss:0.0015689603219070846\n",
      "train loss:0.0004368655046478525\n",
      "train loss:0.004920192201942414\n",
      "train loss:0.001422470751365708\n",
      "train loss:0.00014634422921710002\n",
      "train loss:0.001581727619378406\n",
      "train loss:0.0026222515290584007\n",
      "train loss:0.000679436177010119\n",
      "train loss:0.004231243789860456\n",
      "train loss:0.0009268965526933456\n",
      "train loss:0.0015522792742259184\n",
      "train loss:0.004088825821298627\n",
      "train loss:0.00015924776591386857\n",
      "train loss:0.001725489401378755\n",
      "train loss:0.00031919430630465267\n",
      "train loss:0.0013292845152806712\n",
      "train loss:0.0008933055285260125\n",
      "train loss:0.0007015258016451167\n",
      "train loss:0.0008895318196256263\n",
      "train loss:0.001016135768904194\n",
      "train loss:0.0005223684245523054\n",
      "train loss:0.002156518386234771\n",
      "train loss:0.0006966242345876473\n",
      "train loss:0.006025199245705481\n",
      "train loss:0.00015084433426456798\n",
      "train loss:0.0005606655985539668\n",
      "train loss:0.0011276355654265824\n",
      "train loss:0.0008142702402959561\n",
      "train loss:0.0007494947820241313\n",
      "train loss:0.00153934934399266\n",
      "train loss:0.0013607640271020504\n",
      "train loss:0.0010694813304654605\n",
      "train loss:0.0010378011426346865\n",
      "train loss:0.006161786941634971\n",
      "train loss:0.0008991587358617401\n",
      "train loss:0.0030099726776279855\n",
      "train loss:0.0009686753118319062\n",
      "train loss:0.009680564784803843\n",
      "train loss:0.003573869428318616\n",
      "train loss:0.00017644535589977326\n",
      "train loss:0.004465635063336051\n",
      "train loss:0.0011600430110743037\n",
      "train loss:0.0023402760178972055\n",
      "train loss:0.0003426347908001428\n",
      "train loss:0.001048124725904974\n",
      "train loss:0.0076138997466929596\n",
      "train loss:0.0029181487132434363\n",
      "train loss:0.0013645396968208275\n",
      "train loss:0.0026660907733648733\n",
      "train loss:0.000997383353656759\n",
      "train loss:3.3734863233497934e-05\n",
      "train loss:0.0018533465108341906\n",
      "train loss:0.0008769370793755639\n",
      "train loss:0.00175918498598382\n",
      "train loss:0.008843014787770841\n",
      "train loss:0.00040080912949046774\n",
      "train loss:0.0009805782602272887\n",
      "train loss:0.00296714556306451\n",
      "train loss:0.003937319589501854\n",
      "train loss:0.0004908817061865581\n",
      "train loss:0.001230309239253623\n",
      "train loss:0.001192908921687615\n",
      "train loss:0.0024490349973685086\n",
      "train loss:0.0024226044850933844\n",
      "train loss:0.03197211288213046\n",
      "train loss:0.0002764365105066464\n",
      "train loss:0.0013205035733034707\n",
      "train loss:0.0010361092634086954\n",
      "train loss:0.002291195998024237\n",
      "train loss:0.003933105708246957\n",
      "train loss:0.003274698759349492\n",
      "train loss:0.00026550131777307474\n",
      "train loss:0.004609259814608172\n",
      "train loss:0.002767808169444178\n",
      "train loss:0.002646537140473713\n",
      "train loss:0.0005852508237289246\n",
      "train loss:0.0031106684525645427\n",
      "train loss:0.0005990325925190606\n",
      "train loss:0.006910054249783521\n",
      "train loss:0.0008167046246784566\n",
      "train loss:0.00020676679467911816\n",
      "train loss:0.039368093185628825\n",
      "train loss:0.00036723086891247097\n",
      "train loss:0.003137207048238042\n",
      "train loss:0.0035897804153115277\n",
      "train loss:0.0028134422946224486\n",
      "train loss:0.002192573918189442\n",
      "train loss:0.0016329609383227853\n",
      "train loss:0.0008469952767921384\n",
      "train loss:0.004495857585152748\n",
      "train loss:0.01115824790032327\n",
      "train loss:0.0009688961457219522\n",
      "train loss:0.000691868881641814\n",
      "train loss:0.0018247146568596846\n",
      "train loss:0.0030141705608996844\n",
      "train loss:0.010017965696711355\n",
      "train loss:0.0012522365824857483\n",
      "train loss:0.0034906464212437526\n",
      "train loss:0.004922735705882122\n",
      "train loss:0.0026466586791277402\n",
      "train loss:0.001391150115326741\n",
      "train loss:0.003389620776133132\n",
      "train loss:0.00011035657945528085\n",
      "train loss:0.00208090605752796\n",
      "train loss:0.009272261968263201\n",
      "train loss:0.0036661929414130243\n",
      "train loss:0.0038051905395811297\n",
      "train loss:0.000935978831101284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0010226110293346654\n",
      "train loss:0.0020818668476475293\n",
      "train loss:0.0010120238890969607\n",
      "train loss:0.0023181030883301828\n",
      "train loss:0.0008314049356636505\n",
      "train loss:0.0007004573122634293\n",
      "train loss:0.0004875813689169393\n",
      "train loss:0.0006372858575419382\n",
      "train loss:0.0011103551199693725\n",
      "train loss:0.0004580644898803178\n",
      "train loss:0.0010176618222794962\n",
      "train loss:0.0014548344394852278\n",
      "=== epoch:16, train acc:0.996, test acc:0.988 ===\n",
      "train loss:0.00387265227915378\n",
      "train loss:0.005676795122397819\n",
      "train loss:0.002864843193825372\n",
      "train loss:0.0022585519013966133\n",
      "train loss:0.0007396573018439231\n",
      "train loss:0.0006837682966328169\n",
      "train loss:0.0003489434282757526\n",
      "train loss:0.0014844889018849048\n",
      "train loss:0.0017092306712426658\n",
      "train loss:0.001798763426386209\n",
      "train loss:0.0056928140938731905\n",
      "train loss:0.0013426719094820413\n",
      "train loss:0.00018899220163310696\n",
      "train loss:0.0015138664496471158\n",
      "train loss:0.0002712748459814204\n",
      "train loss:0.0012670701328265474\n",
      "train loss:0.0004740696754017466\n",
      "train loss:0.0049244640383988925\n",
      "train loss:0.003497265180466433\n",
      "train loss:0.00034216386295967674\n",
      "train loss:0.006027600975755092\n",
      "train loss:0.0007989317380974426\n",
      "train loss:0.002751514046022617\n",
      "train loss:0.00044100754401417837\n",
      "train loss:0.0060052437266488205\n",
      "train loss:0.009472280992261373\n",
      "train loss:0.0010303645944220537\n",
      "train loss:0.00026910381725136356\n",
      "train loss:0.0012061468871752128\n",
      "train loss:0.003080656245518961\n",
      "train loss:0.0008986572324212029\n",
      "train loss:0.002608391153893406\n",
      "train loss:0.00785097150249619\n",
      "train loss:0.00018704231314276465\n",
      "train loss:0.015143010719838321\n",
      "train loss:0.004336228582015009\n",
      "train loss:0.0013290913313607205\n",
      "train loss:0.008898479375980813\n",
      "train loss:0.00046294837604708407\n",
      "train loss:0.0008243285746017876\n",
      "train loss:0.005750099664770347\n",
      "train loss:0.001400138516079465\n",
      "train loss:0.003000822701731267\n",
      "train loss:0.003999062975516565\n",
      "train loss:0.001025653215598591\n",
      "train loss:0.0035242140069264133\n",
      "train loss:0.002531897369795562\n",
      "train loss:0.0010970368246111064\n",
      "train loss:0.005998206275681246\n",
      "train loss:7.846752266863693e-05\n",
      "train loss:0.000846453693036498\n",
      "train loss:6.824312971828558e-05\n",
      "train loss:0.000989824580034845\n",
      "train loss:0.0008749660442615016\n",
      "train loss:0.003633175657653606\n",
      "train loss:0.0003880889478257766\n",
      "train loss:0.004226629265759018\n",
      "train loss:0.0027555896805281878\n",
      "train loss:0.00038554653333619537\n",
      "train loss:0.00321126545339969\n",
      "train loss:0.0012914182986702427\n",
      "train loss:0.0014817904466377868\n",
      "train loss:0.003183017501758114\n",
      "train loss:0.003154298980322989\n",
      "train loss:0.0010704479808498054\n",
      "train loss:0.0002802079439988651\n",
      "train loss:0.004863936684693596\n",
      "train loss:7.450735347737622e-05\n",
      "train loss:0.004095148650638262\n",
      "train loss:0.0002701827851443118\n",
      "train loss:0.0011439275446704451\n",
      "train loss:0.002545608655972408\n",
      "train loss:0.002775556396198983\n",
      "train loss:0.002345732529891962\n",
      "train loss:0.007563322666793513\n",
      "train loss:0.0003080324675723636\n",
      "train loss:0.0004907540131240989\n",
      "train loss:0.0012756256152473661\n",
      "train loss:0.002287956568758949\n",
      "train loss:0.0007145731718771222\n",
      "train loss:0.0006163707850547425\n",
      "train loss:0.009931425379041566\n",
      "train loss:0.004732050164619226\n",
      "train loss:0.0010565492145073636\n",
      "train loss:0.0002482958629033163\n",
      "train loss:0.0025202136313504297\n",
      "train loss:0.003424813062593808\n",
      "train loss:0.0001276048915254793\n",
      "train loss:7.17500614569732e-05\n",
      "train loss:0.0011481605791150906\n",
      "train loss:0.0022499766807128484\n",
      "train loss:0.0008906842811391054\n",
      "train loss:0.000705176557289098\n",
      "train loss:0.003375096235907623\n",
      "train loss:0.0035710354230549567\n",
      "train loss:0.0035426030582064185\n",
      "train loss:0.0005167969300297527\n",
      "train loss:0.0010487691457757974\n",
      "train loss:0.0018792609130016673\n",
      "train loss:0.0033241402356707305\n",
      "train loss:0.0005347450999188555\n",
      "train loss:0.0003258865619080952\n",
      "train loss:0.0011734180132291342\n",
      "train loss:0.0008103318262427276\n",
      "train loss:0.0031627767211676572\n",
      "train loss:0.0002722487793579538\n",
      "train loss:0.003551774426622113\n",
      "train loss:0.003338090413982711\n",
      "train loss:0.028785503223553995\n",
      "train loss:0.002965868953512188\n",
      "train loss:0.004574414917351819\n",
      "train loss:0.00013113238996271149\n",
      "train loss:0.003314240198047493\n",
      "train loss:0.0001441813969561947\n",
      "train loss:0.00020778732307030528\n",
      "train loss:0.0025771391670334765\n",
      "train loss:0.0011409822714336904\n",
      "train loss:0.0005925131773708393\n",
      "train loss:0.0013477369817251382\n",
      "train loss:0.0007315820096489012\n",
      "train loss:0.003153106711450983\n",
      "train loss:0.002391315997903913\n",
      "train loss:0.0004820783193481466\n",
      "train loss:0.005011413624546599\n",
      "train loss:0.0013004240031367009\n",
      "train loss:0.0003667053583457077\n",
      "train loss:0.00044301945148932055\n",
      "train loss:0.0004077052447615073\n",
      "train loss:0.001351444073559086\n",
      "train loss:0.0007804870049404006\n",
      "train loss:0.00027300167811241814\n",
      "train loss:0.0001759138390849941\n",
      "train loss:0.0002094123625450186\n",
      "train loss:8.833957565072974e-05\n",
      "train loss:0.0011761402016616167\n",
      "train loss:0.0016004253174730094\n",
      "train loss:0.0007316778850446136\n",
      "train loss:0.00018072015200414155\n",
      "train loss:0.005079933367687555\n",
      "train loss:0.0009040433949867096\n",
      "train loss:0.0018652502856444978\n",
      "train loss:0.0035945560893826606\n",
      "train loss:0.0003114373657054526\n",
      "train loss:4.725524924473335e-05\n",
      "train loss:0.000260302103876106\n",
      "train loss:0.001267925995964203\n",
      "train loss:0.0013088658711230847\n",
      "train loss:0.004868525555536085\n",
      "train loss:0.0006009727976337867\n",
      "train loss:0.0021487758543777976\n",
      "train loss:8.716775679824667e-05\n",
      "train loss:0.00012801814103102413\n",
      "train loss:0.0034992716762272257\n",
      "train loss:0.0002972177837900216\n",
      "train loss:0.003553623746843859\n",
      "train loss:0.0022307817323710412\n",
      "train loss:0.0017720000147226382\n",
      "train loss:0.003560248646828771\n",
      "train loss:0.0014488073141341081\n",
      "train loss:0.0026208482881854016\n",
      "train loss:0.0012858212481573266\n",
      "train loss:0.0018898376112338028\n",
      "train loss:0.0006959610856088627\n",
      "train loss:0.0019169245467813912\n",
      "train loss:0.0003054060795957415\n",
      "train loss:0.00016160257138115013\n",
      "train loss:0.0002123128157327836\n",
      "train loss:0.0011678431392629165\n",
      "train loss:0.0011132520671485074\n",
      "train loss:0.00031946760424060534\n",
      "train loss:0.0033619636196805854\n",
      "train loss:0.0004063379879851574\n",
      "train loss:0.0014443993776254807\n",
      "train loss:0.0009824678783681689\n",
      "train loss:0.0050321091086309765\n",
      "train loss:0.0041331291173894525\n",
      "train loss:0.023290269513421197\n",
      "train loss:0.0016649798327145284\n",
      "train loss:0.0035823610795668766\n",
      "train loss:0.0010775286764092352\n",
      "train loss:0.0017036508302802008\n",
      "train loss:0.0014035342531246394\n",
      "train loss:0.0005205355209438839\n",
      "train loss:0.0010234430248208767\n",
      "train loss:0.0012334240544820555\n",
      "train loss:0.014999454133472033\n",
      "train loss:0.0001551428613056946\n",
      "train loss:0.00037885714258800544\n",
      "train loss:0.0007386645295344181\n",
      "train loss:0.003299060700608457\n",
      "train loss:0.008502800698872241\n",
      "train loss:0.001305775165815104\n",
      "train loss:0.0004144564807990551\n",
      "train loss:0.0036869005223794694\n",
      "train loss:0.0015919808869350757\n",
      "train loss:0.002193752215385783\n",
      "train loss:0.0009162815724861385\n",
      "train loss:0.0013404841411409011\n",
      "train loss:0.005561779475986064\n",
      "train loss:0.0017310596257606003\n",
      "train loss:0.00019124958580011328\n",
      "train loss:0.0003391065929547269\n",
      "train loss:0.0009552599778135337\n",
      "train loss:0.0018395530185048197\n",
      "train loss:0.0008140769950183145\n",
      "train loss:0.0019324810776442849\n",
      "train loss:0.0012347697350299357\n",
      "train loss:0.0025271756921592028\n",
      "train loss:0.0005687001044203686\n",
      "train loss:0.0004125468744714796\n",
      "train loss:0.0010773488664788024\n",
      "train loss:0.0022975776264494404\n",
      "train loss:0.016688103216850384\n",
      "train loss:0.001752343577725894\n",
      "train loss:0.0019460836408051044\n",
      "train loss:0.0035198761814135525\n",
      "train loss:0.004651320448152211\n",
      "train loss:8.254258340536679e-05\n",
      "train loss:0.00018979416810963726\n",
      "train loss:0.003378202094312505\n",
      "train loss:0.0018257231352195832\n",
      "train loss:0.002713806501935982\n",
      "train loss:0.00023049827532176017\n",
      "train loss:0.00035674046871913835\n",
      "train loss:0.0009459985952283324\n",
      "train loss:0.0027280515623305385\n",
      "train loss:0.004004598573464886\n",
      "train loss:0.0010929387772048852\n",
      "train loss:0.00012670434704464833\n",
      "train loss:0.0019201308870719128\n",
      "train loss:0.0006525105533132694\n",
      "train loss:0.0031436962258837627\n",
      "train loss:0.00048803439980247843\n",
      "train loss:0.0016647294557109928\n",
      "train loss:0.001024296305492221\n",
      "train loss:0.0006430644221043404\n",
      "train loss:0.0033682057570464706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.001060974739661704\n",
      "train loss:0.00010919321395855715\n",
      "train loss:0.0009040047342670275\n",
      "train loss:0.00024690665391681867\n",
      "train loss:0.0003485474518674897\n",
      "train loss:0.0008103601580115028\n",
      "train loss:0.0005939258165497313\n",
      "train loss:0.0016604867845356605\n",
      "train loss:0.010863285276891605\n",
      "train loss:0.001849921330896051\n",
      "train loss:0.004074666109554887\n",
      "train loss:0.004588408297240556\n",
      "train loss:0.00214396235646775\n",
      "train loss:0.001461943984535444\n",
      "train loss:0.0005525767276018755\n",
      "train loss:0.004205525831686938\n",
      "train loss:0.012014602849926139\n",
      "train loss:9.26500379906621e-05\n",
      "train loss:0.006314469121419821\n",
      "train loss:0.0037470436615171725\n",
      "train loss:0.0007873052203099074\n",
      "train loss:0.0004580162624833254\n",
      "train loss:0.0003614195207380202\n",
      "train loss:0.005485516019020086\n",
      "train loss:0.0005698847940742766\n",
      "train loss:0.0025973885587397484\n",
      "train loss:0.0018010180629774112\n",
      "train loss:0.0033106861043142345\n",
      "train loss:0.00516978821532224\n",
      "train loss:0.0002949631939782146\n",
      "train loss:0.003465069634183588\n",
      "train loss:0.0008925423628830611\n",
      "train loss:0.0026061912921479143\n",
      "train loss:0.001190556072434868\n",
      "train loss:0.005082482194443603\n",
      "train loss:0.0017157619188077921\n",
      "train loss:0.001215372345744734\n",
      "train loss:0.0024035821289808738\n",
      "train loss:0.0018154727354844555\n",
      "train loss:0.00038879876365866797\n",
      "train loss:0.0004443881895019005\n",
      "train loss:0.00036931302618137035\n",
      "train loss:0.0032812089742996413\n",
      "train loss:0.0032880625780433107\n",
      "train loss:0.0011141591879918614\n",
      "train loss:0.004703319999301847\n",
      "train loss:0.00020905686070554877\n",
      "train loss:0.0006115505240247143\n",
      "train loss:0.002142323285419816\n",
      "train loss:0.0006832128096158932\n",
      "train loss:0.0016016854345893463\n",
      "train loss:0.0004106817899964552\n",
      "train loss:0.000469944616980963\n",
      "train loss:0.001049991212789772\n",
      "train loss:0.00014543607038689586\n",
      "train loss:0.004154036053515457\n",
      "train loss:0.0010607156568208417\n",
      "train loss:0.0039589527671076066\n",
      "train loss:0.0015838758889253186\n",
      "train loss:0.004115945239592756\n",
      "train loss:0.004131191237416585\n",
      "train loss:0.00010810045086012218\n",
      "train loss:0.003225866257550011\n",
      "train loss:5.7983399715593886e-05\n",
      "train loss:0.00011009884875828\n",
      "train loss:0.001979867766302095\n",
      "train loss:0.012069727677803494\n",
      "train loss:0.0005798198369709837\n",
      "train loss:0.0021890632123436186\n",
      "train loss:0.004014703364879689\n",
      "train loss:0.0030002353293495055\n",
      "train loss:0.0011069876493309443\n",
      "train loss:0.0037302259318903563\n",
      "train loss:0.0003310138496027442\n",
      "train loss:0.0007585383102323306\n",
      "train loss:0.005294067549437204\n",
      "train loss:0.0010513921938889673\n",
      "train loss:0.013684725548391428\n",
      "train loss:0.002787870039952128\n",
      "train loss:0.0021157226556700786\n",
      "train loss:0.005287318549817858\n",
      "train loss:0.00021975274939842697\n",
      "train loss:0.0034027025731895554\n",
      "train loss:0.008012154566546463\n",
      "train loss:0.00043681868145555627\n",
      "train loss:0.0009733938179646038\n",
      "train loss:0.0009275707785500945\n",
      "train loss:0.0012680421238236287\n",
      "train loss:0.0005145867099222956\n",
      "train loss:0.0007177024650817905\n",
      "train loss:0.001013110753251115\n",
      "train loss:0.0007430991458821\n",
      "train loss:0.0008368165745486404\n",
      "train loss:0.012813320801341937\n",
      "train loss:0.00527870563825042\n",
      "train loss:0.002131546206078488\n",
      "train loss:0.0023373057818911313\n",
      "train loss:0.00037407013091661517\n",
      "train loss:0.00020326334885790217\n",
      "train loss:0.0004745337968195508\n",
      "train loss:0.0006828881563081791\n",
      "train loss:0.0010996606289319438\n",
      "train loss:0.002746780044427719\n",
      "train loss:0.0026722612708141975\n",
      "train loss:0.003387396361430558\n",
      "train loss:0.0037464445477048327\n",
      "train loss:0.008543945696403337\n",
      "train loss:0.001446914086090885\n",
      "train loss:0.03680350955272139\n",
      "train loss:0.0006730012246711707\n",
      "train loss:0.027744007723152456\n",
      "train loss:0.0019662418812788044\n",
      "train loss:0.0020744775016258575\n",
      "train loss:9.677651751239472e-05\n",
      "train loss:0.001001181670063928\n",
      "train loss:0.0011515509207143057\n",
      "train loss:0.006155579519372083\n",
      "train loss:0.0035836084016007664\n",
      "train loss:0.006138323222963907\n",
      "train loss:0.0024237364899313153\n",
      "train loss:0.0002106321207962594\n",
      "train loss:0.0036635866324768607\n",
      "train loss:0.00558230464414334\n",
      "train loss:0.007037826701074631\n",
      "train loss:0.00014457196925465792\n",
      "train loss:0.003398732595350846\n",
      "train loss:0.008773241960221102\n",
      "train loss:0.00120658285819866\n",
      "train loss:0.003164726524056331\n",
      "train loss:0.0007755228810267944\n",
      "train loss:0.0002580486187883524\n",
      "train loss:0.005972614823981569\n",
      "train loss:0.00039255933184124123\n",
      "train loss:0.0014023959179465637\n",
      "train loss:0.0017984236128168495\n",
      "train loss:0.0026229964775083712\n",
      "train loss:0.0009063585827527796\n",
      "train loss:0.00038386609035964415\n",
      "train loss:0.001154996836284157\n",
      "train loss:0.0008867925910655834\n",
      "train loss:0.0002616865053310653\n",
      "train loss:0.01153918062609665\n",
      "train loss:0.0002977890170769717\n",
      "train loss:0.006512178378767419\n",
      "train loss:0.002461456673183938\n",
      "train loss:0.0011678242925678244\n",
      "train loss:0.0038577890421459472\n",
      "train loss:0.003726503543574015\n",
      "train loss:0.002448245356080536\n",
      "train loss:0.0014912961439304958\n",
      "train loss:0.0024513576741477835\n",
      "train loss:0.016693579905214515\n",
      "train loss:0.0009951593270502886\n",
      "train loss:0.005363953304816384\n",
      "train loss:0.00369868735982192\n",
      "train loss:0.00017593731750794626\n",
      "train loss:6.038731093057429e-05\n",
      "train loss:0.001529438360908211\n",
      "train loss:0.0033504105453861653\n",
      "train loss:0.0020819956180731865\n",
      "train loss:0.0002685304079872298\n",
      "train loss:0.004073459563583476\n",
      "train loss:0.0011823113965001924\n",
      "train loss:0.003685589834211933\n",
      "train loss:0.0005369037288646696\n",
      "train loss:0.0005476426696052157\n",
      "train loss:0.006614879620130393\n",
      "train loss:0.00044739236584049035\n",
      "train loss:0.0011586189037881777\n",
      "train loss:0.0024076714264906858\n",
      "train loss:0.002456575779304236\n",
      "train loss:0.00012854328062025805\n",
      "train loss:0.00040196360574332114\n",
      "train loss:0.0008185052625866123\n",
      "train loss:0.002457036708177848\n",
      "train loss:0.0022724668672281837\n",
      "train loss:0.00027686139241928196\n",
      "train loss:0.001472687535848016\n",
      "train loss:0.00047822803576222627\n",
      "train loss:0.0006841967504369805\n",
      "train loss:0.003634442496399239\n",
      "train loss:0.0005310941539449133\n",
      "train loss:0.0003015678424805067\n",
      "train loss:0.00025442445638083596\n",
      "train loss:0.0002807553218899741\n",
      "train loss:0.0001251185243411302\n",
      "train loss:0.00021516189011397063\n",
      "train loss:0.001925582821115252\n",
      "train loss:0.00027873263597278855\n",
      "train loss:0.031475864582117326\n",
      "train loss:0.0013581063066721983\n",
      "train loss:0.004032803380534015\n",
      "train loss:0.005982754303891565\n",
      "train loss:0.010426536212770897\n",
      "train loss:0.0013320905786847195\n",
      "train loss:0.0005282716531668613\n",
      "train loss:0.0019367882214676969\n",
      "train loss:0.0008497864795537867\n",
      "train loss:0.011494965255632211\n",
      "train loss:0.0011863707117569361\n",
      "train loss:0.008274607972545634\n",
      "train loss:0.0010017726533251032\n",
      "train loss:0.012430008227595197\n",
      "train loss:0.002435722390851854\n",
      "train loss:0.002942456576907766\n",
      "train loss:0.00011741928652104838\n",
      "train loss:0.0003970042544080114\n",
      "train loss:0.002169120846248528\n",
      "train loss:0.009440465491397645\n",
      "train loss:0.005686203917731022\n",
      "train loss:0.0012729807674683549\n",
      "train loss:0.004144349295282039\n",
      "train loss:0.006360376535961856\n",
      "train loss:0.0017372391062480356\n",
      "train loss:0.010877303048197687\n",
      "train loss:0.004253541011728853\n",
      "train loss:0.002644882373114331\n",
      "train loss:0.01532079292030556\n",
      "train loss:0.001086164918307812\n",
      "train loss:3.149097044879262e-05\n",
      "train loss:0.003954209605466368\n",
      "train loss:0.004712479834929995\n",
      "train loss:0.003936713083280711\n",
      "train loss:0.001249171389368516\n",
      "train loss:0.004002362275312476\n",
      "train loss:0.005434949967989975\n",
      "train loss:0.0012649636095984724\n",
      "train loss:0.0012314264882705324\n",
      "train loss:0.03236903530988826\n",
      "train loss:0.005640575383573456\n",
      "train loss:0.0042589071047644846\n",
      "train loss:0.0029020225181298296\n",
      "train loss:0.0006888132391807938\n",
      "train loss:0.0008831091073961962\n",
      "train loss:0.007395358057270195\n",
      "train loss:0.0004997009904531993\n",
      "train loss:0.0003218817281911243\n",
      "train loss:0.0004914033867831161\n",
      "train loss:0.00047935729373410206\n",
      "train loss:0.0011002829266257344\n",
      "train loss:0.00017978147082891072\n",
      "train loss:0.003739462955690631\n",
      "train loss:0.00011579666839721427\n",
      "train loss:0.0011286433616219376\n",
      "train loss:0.00016544844056643178\n",
      "train loss:0.0002720390249155357\n",
      "train loss:0.0007525700348530783\n",
      "train loss:0.0004002877289483766\n",
      "train loss:0.000758494386308402\n",
      "train loss:0.0005009246028725294\n",
      "train loss:0.0026638903729997872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002220513658712487\n",
      "train loss:0.0017815192714512316\n",
      "train loss:0.0025087206921952905\n",
      "train loss:0.0013889904667463704\n",
      "train loss:0.001117163462835306\n",
      "train loss:0.0038940646943185398\n",
      "train loss:0.0023240218548011256\n",
      "train loss:0.0018647093584350364\n",
      "train loss:0.0001702055293678397\n",
      "train loss:0.00014367527194889654\n",
      "train loss:0.012641671969440025\n",
      "train loss:0.0026019453251639835\n",
      "train loss:0.0023801345394404904\n",
      "train loss:0.0005275330807941888\n",
      "train loss:0.0001148536256301261\n",
      "train loss:0.004006440415771868\n",
      "train loss:0.00020439569916134035\n",
      "train loss:0.002355458796061784\n",
      "train loss:0.0007582400701175182\n",
      "train loss:0.00411957948703555\n",
      "train loss:0.005618244065298586\n",
      "train loss:0.0002185530463888333\n",
      "train loss:0.00283260322139239\n",
      "train loss:0.00103314060034375\n",
      "train loss:0.0010234712903528854\n",
      "train loss:0.0016190168230466161\n",
      "train loss:0.0009474248239742488\n",
      "train loss:0.0010097913579502583\n",
      "train loss:0.002486409889485053\n",
      "train loss:0.0009275229823196132\n",
      "train loss:0.0009252318141030927\n",
      "train loss:0.0006509726678348915\n",
      "train loss:0.0046111945238433115\n",
      "train loss:0.0009682817544217497\n",
      "train loss:0.002440860736457322\n",
      "train loss:8.390877266108955e-05\n",
      "train loss:0.002715450399813004\n",
      "train loss:0.0016169792825943003\n",
      "train loss:0.0006522188535403784\n",
      "train loss:0.008595356059107294\n",
      "train loss:0.002349552073869745\n",
      "train loss:0.0004187606281420185\n",
      "train loss:0.0023894858137663783\n",
      "train loss:0.004363007048504894\n",
      "train loss:0.0021534580656156614\n",
      "train loss:0.0007946418582610145\n",
      "train loss:0.0009291656851820776\n",
      "train loss:0.0037418436283729517\n",
      "train loss:0.0013279553813516263\n",
      "train loss:0.006272242501634312\n",
      "train loss:0.00016882119761667418\n",
      "train loss:0.0002682644052287891\n",
      "train loss:0.0010852159274386448\n",
      "train loss:0.00010837491937639125\n",
      "train loss:0.0025787576190469848\n",
      "train loss:0.0008511726598872124\n",
      "train loss:0.0016564416048308515\n",
      "train loss:0.0032712704200291583\n",
      "train loss:0.001734453952780493\n",
      "train loss:0.0013759684459500976\n",
      "train loss:0.00044653999662427044\n",
      "train loss:0.0024564418425781277\n",
      "train loss:0.0011032517316096797\n",
      "train loss:0.0015625244717351737\n",
      "train loss:0.0031318610710949833\n",
      "train loss:0.00041979318044602613\n",
      "train loss:0.0029559931489652087\n",
      "train loss:0.0011224426568820515\n",
      "train loss:0.0020354569148126715\n",
      "train loss:0.0018033201483099127\n",
      "train loss:0.001482142489325633\n",
      "train loss:0.0005461861062890194\n",
      "train loss:0.00024910587334283805\n",
      "train loss:0.001269086428481228\n",
      "train loss:0.000928759325199263\n",
      "train loss:0.0004300622032662805\n",
      "train loss:0.0008780805422571762\n",
      "train loss:0.00024317908771920793\n",
      "train loss:8.504118426925312e-05\n",
      "train loss:0.002152339374842154\n",
      "train loss:0.0017050035581682383\n",
      "train loss:0.001026456175655741\n",
      "train loss:0.00035860069663812174\n",
      "train loss:6.073170497293241e-05\n",
      "train loss:0.002110110182975663\n",
      "train loss:0.0013746834552283583\n",
      "train loss:0.00014550164766336774\n",
      "train loss:0.0002177505175575065\n",
      "train loss:0.0038932839571493905\n",
      "train loss:0.0013908448243492696\n",
      "train loss:0.00453825329483411\n",
      "train loss:0.00029910776250965465\n",
      "train loss:0.001957159381650128\n",
      "train loss:0.0002850297964343678\n",
      "train loss:0.0007076764821738365\n",
      "train loss:0.0019446728723854173\n",
      "train loss:0.0014041359161871237\n",
      "train loss:0.0001874064175296216\n",
      "train loss:0.0025316739376574932\n",
      "train loss:0.0028263044286429124\n",
      "train loss:0.0005313306026352347\n",
      "train loss:0.0036093251142241905\n",
      "train loss:0.0006873036489428639\n",
      "train loss:0.005209665945485864\n",
      "train loss:0.0025011077400928943\n",
      "train loss:7.59423916039371e-05\n",
      "train loss:0.0009247866090578944\n",
      "train loss:0.0010627071973681047\n",
      "train loss:0.0038565075248518997\n",
      "train loss:0.0005847800278705992\n",
      "train loss:0.00030950181131963897\n",
      "train loss:0.00022271022137323237\n",
      "=== epoch:17, train acc:0.997, test acc:0.987 ===\n",
      "train loss:0.00013707047727594887\n",
      "train loss:0.0005846606560762045\n",
      "train loss:0.0005753010437641051\n",
      "train loss:0.0011415112456414447\n",
      "train loss:0.0012150815212610122\n",
      "train loss:0.0015613835258227308\n",
      "train loss:0.0011991375524301835\n",
      "train loss:0.0006116224336824385\n",
      "train loss:0.0045244208491137475\n",
      "train loss:0.00019014023046797998\n",
      "train loss:0.007772115972041711\n",
      "train loss:0.000398888831752765\n",
      "train loss:0.0009962250933545683\n",
      "train loss:0.0005385195823593087\n",
      "train loss:0.00018412396891715022\n",
      "train loss:0.0008795668813231726\n",
      "train loss:0.0019352542656810615\n",
      "train loss:0.0004633435569982891\n",
      "train loss:0.0007452455412160765\n",
      "train loss:0.0012501781332667447\n",
      "train loss:0.0025652298910385164\n",
      "train loss:0.00034026744882995064\n",
      "train loss:5.670074675117298e-05\n",
      "train loss:0.00011538799232133828\n",
      "train loss:0.00026518086088719373\n",
      "train loss:0.002166998852027736\n",
      "train loss:0.00012041984581466816\n",
      "train loss:0.009171610491549935\n",
      "train loss:0.004371333948547594\n",
      "train loss:0.000721093880376813\n",
      "train loss:0.00021231368218688632\n",
      "train loss:0.004066612582573279\n",
      "train loss:0.0030129034668515005\n",
      "train loss:0.002574412748250549\n",
      "train loss:0.003313103896061122\n",
      "train loss:0.007484056278935718\n",
      "train loss:0.003058036360409976\n",
      "train loss:0.0074873196794381655\n",
      "train loss:0.0015505259370326185\n",
      "train loss:0.0009824813064929368\n",
      "train loss:0.0016117937821213512\n",
      "train loss:0.0006380985043124031\n",
      "train loss:0.0005273629332012295\n",
      "train loss:0.0006833246604044681\n",
      "train loss:0.00022815904817398858\n",
      "train loss:0.0005165988239778583\n",
      "train loss:0.00761075954884692\n",
      "train loss:0.004201107613437302\n",
      "train loss:0.0028413807246953143\n",
      "train loss:0.0016629365474497499\n",
      "train loss:0.0005864094050811438\n",
      "train loss:0.000626035331331502\n",
      "train loss:0.002220870416790752\n",
      "train loss:0.0025354032893679162\n",
      "train loss:0.001988563132476957\n",
      "train loss:0.00034006638134561056\n",
      "train loss:0.0026858419347588975\n",
      "train loss:0.0013332979178604205\n",
      "train loss:0.0010836590532826355\n",
      "train loss:0.0014315490032946662\n",
      "train loss:0.0017045485296812025\n",
      "train loss:0.0014336734617413594\n",
      "train loss:0.001702036075068262\n",
      "train loss:0.0005359618097659179\n",
      "train loss:0.0010577982983512478\n",
      "train loss:0.016315878020322274\n",
      "train loss:0.0030339443473475784\n",
      "train loss:0.0011536561389370867\n",
      "train loss:0.0027417880449918776\n",
      "train loss:0.007513478185856471\n",
      "train loss:0.00037685210677816807\n",
      "train loss:0.0009121417733629879\n",
      "train loss:0.0014122405371361174\n",
      "train loss:0.0011027701906319172\n",
      "train loss:0.0005769428109025692\n",
      "train loss:0.004481240261103102\n",
      "train loss:0.0005691097978128168\n",
      "train loss:0.00025849854010844675\n",
      "train loss:0.000477937659222577\n",
      "train loss:0.0004511782559461086\n",
      "train loss:0.00010406391019903467\n",
      "train loss:0.0001509786007636687\n",
      "train loss:0.0013770048790850073\n",
      "train loss:0.0019206608797145883\n",
      "train loss:0.0040858222062237414\n",
      "train loss:7.953927400038586e-05\n",
      "train loss:0.0005330451359763358\n",
      "train loss:0.00021577517508397447\n",
      "train loss:0.0051443383005887015\n",
      "train loss:0.0026802015166470794\n",
      "train loss:0.0002915829137875834\n",
      "train loss:0.00019653712000767325\n",
      "train loss:0.0060181289455429445\n",
      "train loss:0.0011339424148793795\n",
      "train loss:0.0010320695584543332\n",
      "train loss:0.0005079993919142484\n",
      "train loss:0.00010925397185947067\n",
      "train loss:0.0003940914742619121\n",
      "train loss:0.00024162076513095014\n",
      "train loss:0.0022742662568813613\n",
      "train loss:0.001691042214844874\n",
      "train loss:0.0019225638359032227\n",
      "train loss:0.0020701854042417768\n",
      "train loss:0.00012071692296963642\n",
      "train loss:0.0002760310233061377\n",
      "train loss:0.00017372987269095516\n",
      "train loss:0.002103732525593707\n",
      "train loss:0.0012381636751006716\n",
      "train loss:0.003102842028290571\n",
      "train loss:0.0017665159783757814\n",
      "train loss:0.005812252124448376\n",
      "train loss:0.017030717577368258\n",
      "train loss:0.0030822182123648413\n",
      "train loss:0.0034155929787378792\n",
      "train loss:0.0022002692933149447\n",
      "train loss:9.655811584710855e-05\n",
      "train loss:0.0007179931126277293\n",
      "train loss:0.0012314728897193901\n",
      "train loss:0.0008114823293997955\n",
      "train loss:0.0032688639158621065\n",
      "train loss:0.006630942399459018\n",
      "train loss:0.0008292625153605927\n",
      "train loss:0.00011455207419906601\n",
      "train loss:0.007672162828845551\n",
      "train loss:0.0007849441174247522\n",
      "train loss:0.00058958832513539\n",
      "train loss:0.00010716376740262127\n",
      "train loss:0.0005384919026191544\n",
      "train loss:0.00030242296889019366\n",
      "train loss:0.0029489521963646332\n",
      "train loss:4.1283198377150215e-05\n",
      "train loss:0.0008775065652570823\n",
      "train loss:0.0011178268825618265\n",
      "train loss:0.002272605029140962\n",
      "train loss:0.0001101370893469746\n",
      "train loss:0.00043982005082704895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002650569089904445\n",
      "train loss:0.000536553775748524\n",
      "train loss:0.0003624924767292797\n",
      "train loss:0.0011932683512172419\n",
      "train loss:0.008026943636600548\n",
      "train loss:0.0021540840404068104\n",
      "train loss:7.275936704131364e-05\n",
      "train loss:0.011338746062933612\n",
      "train loss:0.00041878392530475284\n",
      "train loss:0.0004058071016522869\n",
      "train loss:0.002454868177075767\n",
      "train loss:0.0011158536441625213\n",
      "train loss:0.0003685829344683762\n",
      "train loss:0.001724914342139343\n",
      "train loss:0.0006417749287656828\n",
      "train loss:0.0007228182633399096\n",
      "train loss:0.012684970682737828\n",
      "train loss:0.018898998119952763\n",
      "train loss:0.0031696808292399083\n",
      "train loss:0.0013331497414713596\n",
      "train loss:0.0006757548790234913\n",
      "train loss:0.0026648776883290365\n",
      "train loss:0.0004088451121350732\n",
      "train loss:2.890923666429814e-05\n",
      "train loss:0.00013058970925307749\n",
      "train loss:0.0013740897840528049\n",
      "train loss:0.0005670354626327933\n",
      "train loss:0.0031302437410742744\n",
      "train loss:0.0020116348580199402\n",
      "train loss:0.0016534047567911957\n",
      "train loss:5.142176778611819e-05\n",
      "train loss:0.0014468995553476006\n",
      "train loss:0.00018423066510552623\n",
      "train loss:0.0005434958873717284\n",
      "train loss:0.0008526629343803842\n",
      "train loss:0.0005340665855840964\n",
      "train loss:0.005602649261631046\n",
      "train loss:0.005046140476663322\n",
      "train loss:0.0010266729640496313\n",
      "train loss:0.00047212971217572996\n",
      "train loss:0.0008819188323303951\n",
      "train loss:0.00613030065044601\n",
      "train loss:0.0017140364961280572\n",
      "train loss:0.007666808367151421\n",
      "train loss:0.0010967934172696591\n",
      "train loss:7.659764238628915e-05\n",
      "train loss:0.0005308192252923361\n",
      "train loss:0.00020276092189410683\n",
      "train loss:0.0018947161395334844\n",
      "train loss:0.0009300755445890845\n",
      "train loss:6.273966664599149e-05\n",
      "train loss:0.00027828811510836887\n",
      "train loss:0.0009536748431272324\n",
      "train loss:0.0007994789456153056\n",
      "train loss:0.0005977746575637603\n",
      "train loss:0.00039456222177229795\n",
      "train loss:0.0021487795030469626\n",
      "train loss:0.0020728177044292253\n",
      "train loss:0.0027034416953420587\n",
      "train loss:0.00040792633653353343\n",
      "train loss:0.0006450856515198382\n",
      "train loss:0.0005405231072397233\n",
      "train loss:0.000444840191256458\n",
      "train loss:0.0002329579764454532\n",
      "train loss:0.0004009351874277952\n",
      "train loss:0.0009730933364057784\n",
      "train loss:0.0005110768800272475\n",
      "train loss:6.512101928962823e-05\n",
      "train loss:0.002764605336214575\n",
      "train loss:6.936071910253257e-05\n",
      "train loss:8.876650704117063e-05\n",
      "train loss:0.0022138187230954422\n",
      "train loss:0.0002645616398250157\n",
      "train loss:0.0030274045462060023\n",
      "train loss:0.005677463820011925\n",
      "train loss:0.0012575293412476287\n",
      "train loss:0.002490823616139184\n",
      "train loss:0.0005438268772797396\n",
      "train loss:0.0017707887432956773\n",
      "train loss:0.000754313951376479\n",
      "train loss:0.002011574602422817\n",
      "train loss:0.0016935976186469549\n",
      "train loss:0.0006181567657306294\n",
      "train loss:0.002530224656574412\n",
      "train loss:0.05546005605832852\n",
      "train loss:0.0016678855568508125\n",
      "train loss:0.0003074636394761535\n",
      "train loss:0.0004847576309973287\n",
      "train loss:0.003921034346462902\n",
      "train loss:0.0009839666043834551\n",
      "train loss:0.00012727112415986415\n",
      "train loss:0.0003509456090086302\n",
      "train loss:0.00028545388858836225\n",
      "train loss:0.0005454550787841693\n",
      "train loss:0.002842247274038877\n",
      "train loss:0.0021251056696288155\n",
      "train loss:0.0013512154362498217\n",
      "train loss:0.001635247657970973\n",
      "train loss:0.00045916649690714526\n",
      "train loss:0.005058945553693996\n",
      "train loss:0.01821097870111467\n",
      "train loss:0.0018238293220496906\n",
      "train loss:0.0025589758652769233\n",
      "train loss:0.00024773155960343776\n",
      "train loss:0.0009134122276034845\n",
      "train loss:0.00012365200665051936\n",
      "train loss:0.0007847262890162895\n",
      "train loss:0.003985425146051829\n",
      "train loss:0.00038603535667814515\n",
      "train loss:0.0027491026140054626\n",
      "train loss:0.00211890835409374\n",
      "train loss:0.0011074739410780745\n",
      "train loss:0.0011173934808979878\n",
      "train loss:0.0019920742303008083\n",
      "train loss:0.0006618702628982793\n",
      "train loss:0.0018080441608001698\n",
      "train loss:0.0019680953512347245\n",
      "train loss:0.0006939277612172776\n",
      "train loss:2.9937764038139256e-05\n",
      "train loss:0.00024376709845359137\n",
      "train loss:4.784602227484229e-05\n",
      "train loss:0.0013919815852149863\n",
      "train loss:0.002067698327770177\n",
      "train loss:0.004880753295717416\n",
      "train loss:0.0009307117837719871\n",
      "train loss:0.0010383527766466187\n",
      "train loss:0.00016134831755646196\n",
      "train loss:0.005741411527665995\n",
      "train loss:0.0006603374525529686\n",
      "train loss:0.0021093548605060127\n",
      "train loss:0.00035346714000584345\n",
      "train loss:0.002500822200682541\n",
      "train loss:0.0018276428170920591\n",
      "train loss:0.004293510165188769\n",
      "train loss:0.0019275361208674804\n",
      "train loss:0.0007271534188385577\n",
      "train loss:0.0025675679917582014\n",
      "train loss:0.0013114624033587175\n",
      "train loss:0.002686348878742079\n",
      "train loss:0.00045777210988538265\n",
      "train loss:0.0003454464786369757\n",
      "train loss:0.0038187751483053224\n",
      "train loss:0.0008770011453065891\n",
      "train loss:3.6056568108135345e-05\n",
      "train loss:0.001663156700444621\n",
      "train loss:0.00017789309845973235\n",
      "train loss:0.0007053362048941554\n",
      "train loss:0.0006212375578168896\n",
      "train loss:0.00023367124202002692\n",
      "train loss:0.0008436549616373305\n",
      "train loss:7.72251711163051e-05\n",
      "train loss:0.00034421434069847894\n",
      "train loss:0.0011983866907367107\n",
      "train loss:0.002664272359221578\n",
      "train loss:0.0018135993419515141\n",
      "train loss:0.0020565444773514145\n",
      "train loss:0.0011082951702092623\n",
      "train loss:8.721033138396171e-05\n",
      "train loss:7.725578874998047e-05\n",
      "train loss:0.0004945402162263691\n",
      "train loss:0.0013615533557254688\n",
      "train loss:0.0024582756185569216\n",
      "train loss:0.002152636857977541\n",
      "train loss:0.0011079030033760684\n",
      "train loss:0.0009174894097570344\n",
      "train loss:0.00015416191321695392\n",
      "train loss:0.002260693372296638\n",
      "train loss:0.0017390022152892967\n",
      "train loss:0.0031509858953102953\n",
      "train loss:0.0030113176949271483\n",
      "train loss:0.006893556748131271\n",
      "train loss:0.0008549058375338178\n",
      "train loss:0.0010396306682866135\n",
      "train loss:0.0007700524415812707\n",
      "train loss:0.00013225329706110625\n",
      "train loss:0.00022727237320850112\n",
      "train loss:0.0008484955342743252\n",
      "train loss:0.0018224969473720446\n",
      "train loss:0.0004210905177062961\n",
      "train loss:0.0008083962795493676\n",
      "train loss:0.0021098660744675963\n",
      "train loss:0.0005314885470243145\n",
      "train loss:0.0014208341196715094\n",
      "train loss:0.0007595358682639442\n",
      "train loss:0.0035783045987158447\n",
      "train loss:0.000489203327093302\n",
      "train loss:0.0005209203063928172\n",
      "train loss:0.006887326356293236\n",
      "train loss:0.0015980432801028926\n",
      "train loss:0.00235805001676201\n",
      "train loss:0.0012492767539091518\n",
      "train loss:0.0013344870696159826\n",
      "train loss:0.0002222872212929193\n",
      "train loss:0.0006195580128551511\n",
      "train loss:0.00014505559425952294\n",
      "train loss:0.0008988896466811787\n",
      "train loss:5.131244833703607e-05\n",
      "train loss:0.005936699183794175\n",
      "train loss:0.0019832878249792215\n",
      "train loss:0.0021231346475188264\n",
      "train loss:0.0005272471155539769\n",
      "train loss:0.0016237058784053205\n",
      "train loss:0.005443604407144135\n",
      "train loss:0.0033774200563484015\n",
      "train loss:0.002823636049773724\n",
      "train loss:0.00015006378163350185\n",
      "train loss:0.0013509918304822999\n",
      "train loss:0.0005352365872353194\n",
      "train loss:0.0006779749917935369\n",
      "train loss:0.004412552429326744\n",
      "train loss:0.00019830283398733045\n",
      "train loss:0.0005118286300024133\n",
      "train loss:0.002094231488377374\n",
      "train loss:0.0006931848910660205\n",
      "train loss:0.0006228999495218587\n",
      "train loss:0.005181947884937769\n",
      "train loss:0.00011128967085628095\n",
      "train loss:0.0011557648242921132\n",
      "train loss:0.0005669480174574806\n",
      "train loss:1.8750945189502914e-05\n",
      "train loss:0.00018306739452283446\n",
      "train loss:0.0029777656929243735\n",
      "train loss:0.0005567592554540622\n",
      "train loss:0.0007779678200893408\n",
      "train loss:0.0015713589283283826\n",
      "train loss:0.011384717186735121\n",
      "train loss:0.00046504153839991636\n",
      "train loss:0.0023337844603541213\n",
      "train loss:0.0007082503729634852\n",
      "train loss:0.000245396565826775\n",
      "train loss:0.004238990816243752\n",
      "train loss:0.0019295834184610027\n",
      "train loss:0.0030728804583312953\n",
      "train loss:0.001370207237174091\n",
      "train loss:0.0022714717426567687\n",
      "train loss:0.00039141098933606296\n",
      "train loss:0.002495510591950249\n",
      "train loss:0.011889490271613085\n",
      "train loss:0.00016947350345573872\n",
      "train loss:0.008482738686720441\n",
      "train loss:0.00031847656440946366\n",
      "train loss:0.002396559787024423\n",
      "train loss:0.0006085463334375885\n",
      "train loss:0.0007063225337530568\n",
      "train loss:0.0037245737610023606\n",
      "train loss:8.873111206853589e-05\n",
      "train loss:1.8553766264257155e-05\n",
      "train loss:0.0002560548226399198\n",
      "train loss:0.00028016479753381206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0006383976658643812\n",
      "train loss:0.0007424657723160594\n",
      "train loss:0.0060597378019575385\n",
      "train loss:0.002641424424166644\n",
      "train loss:0.00037960039530668963\n",
      "train loss:0.004791141347294837\n",
      "train loss:0.001761755762809377\n",
      "train loss:0.001109079474096821\n",
      "train loss:0.002075985947841458\n",
      "train loss:0.001028993535299816\n",
      "train loss:0.00011445963628404502\n",
      "train loss:0.000778923425786934\n",
      "train loss:0.0018018818618215867\n",
      "train loss:0.001248123223800842\n",
      "train loss:0.0001908126827479935\n",
      "train loss:0.006614003412452393\n",
      "train loss:0.00025774939248239174\n",
      "train loss:0.0007958956822049775\n",
      "train loss:0.0013086355047069234\n",
      "train loss:0.0012123633517200209\n",
      "train loss:0.001135511962064122\n",
      "train loss:0.0011645240195326818\n",
      "train loss:0.0013693857825937572\n",
      "train loss:0.0007403770356014384\n",
      "train loss:0.0012528633056389793\n",
      "train loss:0.00047436385131112706\n",
      "train loss:0.0003319837222097964\n",
      "train loss:0.00026680382219333563\n",
      "train loss:0.0011748826010294774\n",
      "train loss:0.00010200903864131076\n",
      "train loss:0.0023150022557622708\n",
      "train loss:0.00575776969984498\n",
      "train loss:0.0005728547154417367\n",
      "train loss:0.0018332127378910634\n",
      "train loss:0.0001992572167258584\n",
      "train loss:0.0030240538647333826\n",
      "train loss:0.0006284939958145585\n",
      "train loss:0.0004825586443999745\n",
      "train loss:0.003301706627327357\n",
      "train loss:0.0010280661424651044\n",
      "train loss:0.023470108362412746\n",
      "train loss:0.0024168085608832044\n",
      "train loss:0.0007219027173243611\n",
      "train loss:5.5334785396720645e-06\n",
      "train loss:0.0003237896009272644\n",
      "train loss:0.0016025768594057205\n",
      "train loss:0.00028336842101137224\n",
      "train loss:0.001389298618979257\n",
      "train loss:0.00012237568492619752\n",
      "train loss:0.005601786266281082\n",
      "train loss:0.0010119532257307229\n",
      "train loss:0.005601438674908981\n",
      "train loss:2.2041807861939194e-05\n",
      "train loss:0.0030363194716853015\n",
      "train loss:5.6305877951170264e-05\n",
      "train loss:0.0046421162235420295\n",
      "train loss:0.0017368663561086154\n",
      "train loss:0.0005811152043811194\n",
      "train loss:0.00024747078014513514\n",
      "train loss:0.000434754771436041\n",
      "train loss:0.0016689321849416836\n",
      "train loss:0.0012310133580313595\n",
      "train loss:0.0004972963720300506\n",
      "train loss:0.019863781412216095\n",
      "train loss:0.024621100614297925\n",
      "train loss:0.002887114682949899\n",
      "train loss:0.00036872676626038825\n",
      "train loss:0.01634649554498001\n",
      "train loss:0.0022599507966192256\n",
      "train loss:0.0015535512021114678\n",
      "train loss:0.00016806792209638605\n",
      "train loss:0.0009879130657442607\n",
      "train loss:0.007126510322163628\n",
      "train loss:0.0012674807782304795\n",
      "train loss:0.0006331210868745556\n",
      "train loss:0.00276527017690879\n",
      "train loss:0.0009069061023413784\n",
      "train loss:0.004277231236323782\n",
      "train loss:0.007939145780515402\n",
      "train loss:0.0008616461330341325\n",
      "train loss:0.0019303001310217397\n",
      "train loss:0.00048695265360621686\n",
      "train loss:0.0008010982816247758\n",
      "train loss:8.206114334088075e-05\n",
      "train loss:0.00048712897342503456\n",
      "train loss:0.00011980850392144522\n",
      "train loss:0.0032820476657218884\n",
      "train loss:0.000542556582453087\n",
      "train loss:0.003611366139863945\n",
      "train loss:0.003221764613279742\n",
      "train loss:0.00029069242140617433\n",
      "train loss:0.0045122984124457656\n",
      "train loss:0.0008338748355284269\n",
      "train loss:0.0008904760413247906\n",
      "train loss:0.0007391240659347573\n",
      "train loss:0.009429218393287375\n",
      "train loss:0.0037456420673288387\n",
      "train loss:0.00014497615276347592\n",
      "train loss:0.0025909846485330816\n",
      "train loss:0.0021632866504668787\n",
      "train loss:0.0024126060801198394\n",
      "train loss:0.0022973116652237934\n",
      "train loss:0.00015195742121739257\n",
      "train loss:0.000935395733230858\n",
      "train loss:0.0017777633944942159\n",
      "train loss:0.0022215128942757183\n",
      "train loss:0.0036561885424607143\n",
      "train loss:0.0013615907153194684\n",
      "train loss:0.0012721156460121289\n",
      "train loss:0.00010632770290027626\n",
      "train loss:0.0004720605997450392\n",
      "train loss:0.00029374942623194616\n",
      "train loss:0.0007754381450518136\n",
      "train loss:0.0012708001937490004\n",
      "train loss:0.0016575861715761074\n",
      "train loss:0.004084770680127043\n",
      "train loss:0.002573598691292595\n",
      "train loss:0.0012690171385222925\n",
      "train loss:0.0006504356573508685\n",
      "train loss:0.0018135070505828908\n",
      "train loss:0.0006014799305637058\n",
      "train loss:0.0031424943066321533\n",
      "train loss:0.003422402062201206\n",
      "train loss:0.0024810256266760895\n",
      "train loss:0.018091480489647236\n",
      "train loss:0.002451504092443568\n",
      "train loss:0.001971543077888641\n",
      "train loss:0.012562674574231398\n",
      "train loss:0.0007472243193855525\n",
      "train loss:0.0028638227655164135\n",
      "train loss:0.0006841872535099235\n",
      "train loss:0.0003929526278331691\n",
      "train loss:0.0036003917081739224\n",
      "train loss:0.0012318109062273432\n",
      "train loss:0.0007597421653062714\n",
      "train loss:0.006859467680060143\n",
      "train loss:0.013112964161648942\n",
      "train loss:0.004709929005145006\n",
      "train loss:0.025412425629320095\n",
      "train loss:0.005760853220327579\n",
      "train loss:0.0022440186246894\n",
      "train loss:5.1298825157517404e-05\n",
      "train loss:0.0005605400885353818\n",
      "train loss:0.0007237797473045409\n",
      "train loss:0.003949204368434923\n",
      "train loss:0.002415720200385763\n",
      "train loss:0.011457231525487839\n",
      "train loss:0.0027514128871445926\n",
      "train loss:0.016776839491181736\n",
      "train loss:0.0022253589557097208\n",
      "train loss:0.008166157707378179\n",
      "train loss:0.0008287270786504311\n",
      "train loss:0.0014631246359537561\n",
      "train loss:0.004604644012587324\n",
      "train loss:0.0004935288517771708\n",
      "train loss:0.001234632022852029\n",
      "train loss:7.299017716826133e-05\n",
      "train loss:0.000814340120730251\n",
      "train loss:0.018096093452516775\n",
      "train loss:0.0010279021043355402\n",
      "train loss:0.0005052821560938763\n",
      "train loss:0.002705380491838137\n",
      "train loss:0.0015469231521806088\n",
      "train loss:0.003971909338119606\n",
      "train loss:0.009599631510559285\n",
      "train loss:0.0051803012507804095\n",
      "train loss:0.0004862815627598891\n",
      "train loss:0.003924323648153258\n",
      "train loss:0.0005191769211187134\n",
      "train loss:0.0035374723727791203\n",
      "train loss:0.001514879163684186\n",
      "train loss:0.0014137802823752832\n",
      "train loss:0.0006924184598212023\n",
      "train loss:0.007108745600946186\n",
      "train loss:0.0013629947090266032\n",
      "train loss:0.005488285038295062\n",
      "train loss:0.004705883077797655\n",
      "train loss:0.0020705574841113693\n",
      "train loss:0.0007758472781422173\n",
      "train loss:0.0015338980063169902\n",
      "train loss:0.0011273914264833874\n",
      "train loss:0.0032840748368293603\n",
      "train loss:0.0008286678976306437\n",
      "train loss:0.002394253458282215\n",
      "train loss:0.003663144235602878\n",
      "train loss:0.0020527103454225136\n",
      "train loss:0.00868507920827185\n",
      "train loss:0.00012431692945038208\n",
      "train loss:0.0009567397003553635\n",
      "train loss:0.02086020649828536\n",
      "train loss:0.00019751713537378632\n",
      "train loss:0.024459460732572456\n",
      "train loss:0.0064443595651317775\n",
      "train loss:0.0005645053523778197\n",
      "train loss:0.0009036024977461063\n",
      "train loss:0.006418114531476065\n",
      "train loss:0.00035956138237258785\n",
      "train loss:8.404976474798722e-05\n",
      "train loss:9.40295748541392e-05\n",
      "train loss:0.0031305374363930377\n",
      "train loss:0.0025298904359665\n",
      "train loss:0.001410213619059237\n",
      "train loss:0.0012872104788020239\n",
      "train loss:0.0003043019070098215\n",
      "train loss:0.0037799286542602086\n",
      "train loss:0.0008479452801607543\n",
      "train loss:0.000718361888472282\n",
      "train loss:0.00530607393365206\n",
      "train loss:0.00040599328927680894\n",
      "train loss:0.0008519565107829417\n",
      "train loss:0.0008711048745415037\n",
      "train loss:0.0009593372746156372\n",
      "train loss:0.004856696743172871\n",
      "train loss:5.394176099098521e-05\n",
      "train loss:0.0026747987389038543\n",
      "=== epoch:18, train acc:0.996, test acc:0.987 ===\n",
      "train loss:0.0011311050892017574\n",
      "train loss:0.0006666082342798879\n",
      "train loss:0.000995125199436248\n",
      "train loss:0.002149976003073133\n",
      "train loss:0.0018269815493949682\n",
      "train loss:0.0006369743628206577\n",
      "train loss:0.000587427005004116\n",
      "train loss:0.0020539255818526163\n",
      "train loss:0.0032449134252279777\n",
      "train loss:0.008797601624123338\n",
      "train loss:0.0024227708926401765\n",
      "train loss:0.0013694254844273729\n",
      "train loss:0.0021770932616031542\n",
      "train loss:0.0006509283545574709\n",
      "train loss:0.0018750924531259034\n",
      "train loss:0.00794292282980779\n",
      "train loss:0.008373048510262701\n",
      "train loss:0.0006669608559285826\n",
      "train loss:0.003929744910766583\n",
      "train loss:7.629001827551712e-05\n",
      "train loss:0.0008705836168175019\n",
      "train loss:0.0005983747339134972\n",
      "train loss:0.01343845735275659\n",
      "train loss:0.004104313546446669\n",
      "train loss:0.002237538466044135\n",
      "train loss:0.0004394012948069484\n",
      "train loss:0.0012350978745093828\n",
      "train loss:0.0028187715711382216\n",
      "train loss:0.0009247336801184809\n",
      "train loss:0.0019895147618408356\n",
      "train loss:0.0014268144253725534\n",
      "train loss:0.00038502501569351836\n",
      "train loss:0.00018983352928399265\n",
      "train loss:0.0006154992496160186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.003529130856861642\n",
      "train loss:0.006236865447897071\n",
      "train loss:0.0039057205319222342\n",
      "train loss:0.0037781899063483435\n",
      "train loss:0.003020353438291411\n",
      "train loss:0.032968183882343766\n",
      "train loss:0.003963199547768828\n",
      "train loss:0.0023659702255328778\n",
      "train loss:0.0005178045496844331\n",
      "train loss:0.0031079926170107562\n",
      "train loss:0.003129372605152189\n",
      "train loss:0.0026377437028709894\n",
      "train loss:0.005703591059495255\n",
      "train loss:2.4997289995464614e-05\n",
      "train loss:0.0020286818313788326\n",
      "train loss:0.0015314585753805456\n",
      "train loss:0.0005741348888446464\n",
      "train loss:0.00019361138933552525\n",
      "train loss:0.0026523938489496747\n",
      "train loss:0.0008723261879914838\n",
      "train loss:0.0007457255682423961\n",
      "train loss:0.0004109719292510779\n",
      "train loss:0.00022970286537212523\n",
      "train loss:0.003399730372503866\n",
      "train loss:0.0033288658844846954\n",
      "train loss:0.017627571130531264\n",
      "train loss:0.0008322300601868093\n",
      "train loss:0.0015015299033864467\n",
      "train loss:0.0016776551834299016\n",
      "train loss:0.000772436614381263\n",
      "train loss:0.0006755283199136405\n",
      "train loss:0.0008163782013678414\n",
      "train loss:0.0034038194588770377\n",
      "train loss:0.00023636877272651142\n",
      "train loss:0.004345410133141355\n",
      "train loss:0.002822469591604308\n",
      "train loss:0.0008036493322249441\n",
      "train loss:0.0006924062692733961\n",
      "train loss:0.003116641593067757\n",
      "train loss:0.012976967148855054\n",
      "train loss:0.004800067665620361\n",
      "train loss:0.011581358075022894\n",
      "train loss:0.0012265501752841738\n",
      "train loss:0.0007573006516610114\n",
      "train loss:0.004497616621197101\n",
      "train loss:0.0016609299990142986\n",
      "train loss:0.00038808703251188236\n",
      "train loss:0.012875568161407124\n",
      "train loss:0.0009643993282326713\n",
      "train loss:0.004083965893276789\n",
      "train loss:0.00800399846400289\n",
      "train loss:0.003280256315501881\n",
      "train loss:5.8410575128355454e-05\n",
      "train loss:0.0013490395569527424\n",
      "train loss:3.8612193600696674e-05\n",
      "train loss:0.0012821452847147981\n",
      "train loss:0.009684490621498012\n",
      "train loss:0.0002764742006129928\n",
      "train loss:4.3896452448145316e-05\n",
      "train loss:0.001123458310477432\n",
      "train loss:0.003390864850998125\n",
      "train loss:0.01149259075682842\n",
      "train loss:0.003433430634957268\n",
      "train loss:0.0027095814934844044\n",
      "train loss:0.0019048923390930128\n",
      "train loss:0.0016294217742171308\n",
      "train loss:0.00011955602989869068\n",
      "train loss:0.0033723031346811877\n",
      "train loss:0.003419528148577842\n",
      "train loss:0.003222617128322921\n",
      "train loss:0.0012450057606093743\n",
      "train loss:0.0021851344475391056\n",
      "train loss:0.0003691894049826275\n",
      "train loss:0.014196537870025689\n",
      "train loss:0.0010791743362122668\n",
      "train loss:0.005568848622796374\n",
      "train loss:0.004023965593140324\n",
      "train loss:0.0012352441826866572\n",
      "train loss:0.0011937490791783512\n",
      "train loss:0.00047862252066953196\n",
      "train loss:0.004413363943330654\n",
      "train loss:0.0010327347354997314\n",
      "train loss:0.0003354573429215146\n",
      "train loss:0.000774504321475644\n",
      "train loss:0.0008023822778109849\n",
      "train loss:0.0009729277477165126\n",
      "train loss:5.9664421912879806e-05\n",
      "train loss:0.005447228978018075\n",
      "train loss:0.0005707351686437368\n",
      "train loss:0.004016802315058714\n",
      "train loss:0.0148275651997278\n",
      "train loss:0.002524500626112564\n",
      "train loss:4.072552953334925e-05\n",
      "train loss:0.0025280604273402395\n",
      "train loss:0.0012732490000966418\n",
      "train loss:0.0002800244768253212\n",
      "train loss:0.002827438376297633\n",
      "train loss:0.0024410581253205446\n",
      "train loss:0.00207288524625124\n",
      "train loss:0.0010369975302661997\n",
      "train loss:0.0006413665324485962\n",
      "train loss:0.0018073618003233178\n",
      "train loss:0.000856452785035562\n",
      "train loss:0.0001229876218328921\n",
      "train loss:0.0003541644929644028\n",
      "train loss:0.0004507979271273879\n",
      "train loss:0.0023225288918165784\n",
      "train loss:0.0007491666957192258\n",
      "train loss:0.0005258363100512741\n",
      "train loss:0.00044252528944328974\n",
      "train loss:0.0002937710906144687\n",
      "train loss:0.0001821398395209908\n",
      "train loss:0.0007879699061580271\n",
      "train loss:0.0006877959997860296\n",
      "train loss:0.0030655315830555967\n",
      "train loss:0.007969098615454646\n",
      "train loss:0.0006561890489641368\n",
      "train loss:0.0019120217840005798\n",
      "train loss:0.0010945642716794367\n",
      "train loss:0.002692658536053972\n",
      "train loss:0.0011806330942036984\n",
      "train loss:0.0009584500275647729\n",
      "train loss:0.0016675492144090187\n",
      "train loss:0.00047901161202853115\n",
      "train loss:0.0009219092278207482\n",
      "train loss:0.0004360696438984947\n",
      "train loss:0.00021866521694254191\n",
      "train loss:0.0008181645784506913\n",
      "train loss:0.001926542146786951\n",
      "train loss:0.0008731135876853406\n",
      "train loss:0.0030485590802129484\n",
      "train loss:0.0008707881453243665\n",
      "train loss:0.0010134041351583245\n",
      "train loss:0.004509891571879312\n",
      "train loss:0.0002800283891915896\n",
      "train loss:0.0006905538579709066\n",
      "train loss:0.0012984475905286298\n",
      "train loss:0.0021756171284849886\n",
      "train loss:0.007274205125198638\n",
      "train loss:0.00043266507537780224\n",
      "train loss:0.003796841780479446\n",
      "train loss:0.00023697362361016258\n",
      "train loss:0.002212983603511213\n",
      "train loss:0.00128070032548432\n",
      "train loss:0.0002755666857932056\n",
      "train loss:0.005872888042166605\n",
      "train loss:0.0010494700416935159\n",
      "train loss:0.0008667169647686775\n",
      "train loss:0.00358431192913103\n",
      "train loss:0.0008209564465349783\n",
      "train loss:0.00022255493983074214\n",
      "train loss:0.0002631702777070663\n",
      "train loss:0.0030792705771795882\n",
      "train loss:0.00682127627357739\n",
      "train loss:0.003456563627459572\n",
      "train loss:0.0037259012750242935\n",
      "train loss:0.0011852300533940578\n",
      "train loss:0.0110883355064895\n",
      "train loss:7.79773712591343e-05\n",
      "train loss:0.0007370576416426018\n",
      "train loss:0.0003849097655142353\n",
      "train loss:0.0012985023606714035\n",
      "train loss:0.005383013532158173\n",
      "train loss:0.0016318127141001831\n",
      "train loss:0.0024998009847614967\n",
      "train loss:0.0010162483415474758\n",
      "train loss:0.0037561429343906778\n",
      "train loss:0.0032297964448522298\n",
      "train loss:0.002395534588591132\n",
      "train loss:0.012558849838675\n",
      "train loss:0.0003836681074068421\n",
      "train loss:0.00013630323911244168\n",
      "train loss:0.008324606898343731\n",
      "train loss:0.004482166011200918\n",
      "train loss:0.002520681663543646\n",
      "train loss:0.0011418006508837244\n",
      "train loss:0.001997493534626732\n",
      "train loss:0.00024949638572643407\n",
      "train loss:0.0005738650868205787\n",
      "train loss:0.0031082422233952457\n",
      "train loss:0.014769093979204496\n",
      "train loss:0.0015531838207433917\n",
      "train loss:0.0011846051315210627\n",
      "train loss:0.00020393246048497934\n",
      "train loss:0.0007446110369060548\n",
      "train loss:0.0009859174031885774\n",
      "train loss:0.014284250031924444\n",
      "train loss:0.0005595491552897353\n",
      "train loss:0.0002804349807947125\n",
      "train loss:0.006505718331640087\n",
      "train loss:0.0005515870971458889\n",
      "train loss:0.0021220674692998044\n",
      "train loss:0.00014799130743590222\n",
      "train loss:0.0022295609034235194\n",
      "train loss:0.004034296338639528\n",
      "train loss:0.00011133192087325879\n",
      "train loss:0.0015837475651376185\n",
      "train loss:0.0035097221906067854\n",
      "train loss:0.006252492964457774\n",
      "train loss:0.0006510125363394325\n",
      "train loss:0.0038862336957440945\n",
      "train loss:0.0009848312350398828\n",
      "train loss:0.0036414195843437556\n",
      "train loss:0.01933608476184346\n",
      "train loss:0.00042651489633417075\n",
      "train loss:0.0014022156415975612\n",
      "train loss:0.0013192630700482242\n",
      "train loss:0.00116337789270294\n",
      "train loss:0.0006528664446408275\n",
      "train loss:0.001303993878909089\n",
      "train loss:0.0010084957138701018\n",
      "train loss:0.0017502748151398964\n",
      "train loss:0.006121540419007325\n",
      "train loss:0.0029759814639180727\n",
      "train loss:0.00038144611556875066\n",
      "train loss:0.0004948894990425503\n",
      "train loss:0.0007939005482176083\n",
      "train loss:0.0018255742375303003\n",
      "train loss:0.0005993908117431375\n",
      "train loss:0.0017853261912966786\n",
      "train loss:0.006167713730381009\n",
      "train loss:0.001795287804788887\n",
      "train loss:0.0004507677452067576\n",
      "train loss:0.00032212862225110966\n",
      "train loss:0.03048159253174522\n",
      "train loss:0.0015769937687509896\n",
      "train loss:0.0015835066087294216\n",
      "train loss:0.0029340583266487226\n",
      "train loss:2.9822814004297737e-05\n",
      "train loss:0.0008366182398042472\n",
      "train loss:0.0022332522687198843\n",
      "train loss:0.0008431350012435276\n",
      "train loss:0.0021086978711760216\n",
      "train loss:0.0012039254720409619\n",
      "train loss:0.0006247722887890849\n",
      "train loss:0.0006581670822634458\n",
      "train loss:9.668498451449232e-05\n",
      "train loss:0.0003856455480158795\n",
      "train loss:0.004735969805262702\n",
      "train loss:0.0009034475545171783\n",
      "train loss:0.003962266124924934\n",
      "train loss:0.0012795498283078356\n",
      "train loss:0.0014737834971629731\n",
      "train loss:0.025543162306363137\n",
      "train loss:0.001601659668883236\n",
      "train loss:0.002672740163183129\n",
      "train loss:0.0006554230044059144\n",
      "train loss:0.0012368339493176949\n",
      "train loss:0.00019188930653022505\n",
      "train loss:0.0014782812268750562\n",
      "train loss:0.01776744147631206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.003102741769186766\n",
      "train loss:0.0022453843633377774\n",
      "train loss:8.971894135906149e-05\n",
      "train loss:0.0016801907310548176\n",
      "train loss:0.000802902022712588\n",
      "train loss:0.0023844641270954585\n",
      "train loss:0.01205465105678438\n",
      "train loss:0.00031536196594720894\n",
      "train loss:0.0007832387379809141\n",
      "train loss:0.0004402859077511177\n",
      "train loss:0.00012283436025839305\n",
      "train loss:0.002396046808743071\n",
      "train loss:0.0023944589368477967\n",
      "train loss:0.0018950847300061927\n",
      "train loss:0.0003995366273659269\n",
      "train loss:0.001277878794205104\n",
      "train loss:0.0001308282935390463\n",
      "train loss:0.0012407166490160438\n",
      "train loss:0.0010996776186002512\n",
      "train loss:0.0010739268840471862\n",
      "train loss:0.001588254327211974\n",
      "train loss:0.00010426535084620596\n",
      "train loss:0.006212435851020263\n",
      "train loss:6.192388827071418e-05\n",
      "train loss:5.325885158870943e-05\n",
      "train loss:0.007809596977820018\n",
      "train loss:0.0001833547550315899\n",
      "train loss:6.049525522473201e-05\n",
      "train loss:0.00023626590142248206\n",
      "train loss:0.0009262316942214241\n",
      "train loss:0.0071253798455019265\n",
      "train loss:0.0006881422419725261\n",
      "train loss:0.0002291197863569517\n",
      "train loss:0.0008454473393626479\n",
      "train loss:0.011380435767738693\n",
      "train loss:0.0010210303694176198\n",
      "train loss:0.0001763472372634807\n",
      "train loss:0.00014848255833302184\n",
      "train loss:0.00339411070566433\n",
      "train loss:0.004135266547240865\n",
      "train loss:0.0012117968023349606\n",
      "train loss:0.0024366977839608934\n",
      "train loss:0.0005131769001824771\n",
      "train loss:0.0023617874879646645\n",
      "train loss:0.0029405308853978594\n",
      "train loss:0.0002842371982569769\n",
      "train loss:0.0008307639594272517\n",
      "train loss:0.00018950204863035308\n",
      "train loss:0.00021092908217968667\n",
      "train loss:0.0003339393090191164\n",
      "train loss:0.0010360472610700896\n",
      "train loss:0.01976473194241701\n",
      "train loss:0.0022801348564897217\n",
      "train loss:0.0020206368772508077\n",
      "train loss:0.0017958087064815545\n",
      "train loss:0.0013687507891646195\n",
      "train loss:0.00114152643694999\n",
      "train loss:0.0028970237635761926\n",
      "train loss:0.0028784871275603376\n",
      "train loss:0.000702845667920336\n",
      "train loss:0.0003084787293618996\n",
      "train loss:0.0005848729314540032\n",
      "train loss:0.002330758436580242\n",
      "train loss:0.0020170078734190033\n",
      "train loss:0.0019501557254589768\n",
      "train loss:0.0004052405534535004\n",
      "train loss:0.001008080260372109\n",
      "train loss:0.0009023256115474754\n",
      "train loss:0.030486880094102987\n",
      "train loss:0.00611674041860618\n",
      "train loss:0.0023392012405772378\n",
      "train loss:0.001490796186892856\n",
      "train loss:0.0005641221171071432\n",
      "train loss:0.0029230230355114734\n",
      "train loss:0.00022031576112899046\n",
      "train loss:0.0004248631408240118\n",
      "train loss:0.001167785945965254\n",
      "train loss:0.0021656332369140107\n",
      "train loss:0.001728498739156899\n",
      "train loss:0.002641182252832556\n",
      "train loss:0.0004059269482273272\n",
      "train loss:0.002126948222819599\n",
      "train loss:0.012890162161740415\n",
      "train loss:0.0009120218231947377\n",
      "train loss:0.019831830094680016\n",
      "train loss:0.0011207206582740192\n",
      "train loss:0.00026402914734790015\n",
      "train loss:0.00036136402194992054\n",
      "train loss:0.0015970709211192602\n",
      "train loss:0.0007066609169152817\n",
      "train loss:0.002726124247865327\n",
      "train loss:0.0015003669643687126\n",
      "train loss:0.0027308687033729944\n",
      "train loss:0.003331466238726129\n",
      "train loss:7.28791157408643e-05\n",
      "train loss:0.00014567284313243156\n",
      "train loss:0.004221001275344691\n",
      "train loss:0.000560041620934394\n",
      "train loss:0.009705496273326265\n",
      "train loss:0.0015009753018463369\n",
      "train loss:0.0005826994005895434\n",
      "train loss:0.0001749671389030957\n",
      "train loss:0.02678703777131565\n",
      "train loss:0.0014796670079482474\n",
      "train loss:0.007195679353956897\n",
      "train loss:0.0007592468671853891\n",
      "train loss:0.0009255906825819159\n",
      "train loss:5.961085439332649e-05\n",
      "train loss:0.0014124114066354962\n",
      "train loss:4.4428983042707656e-05\n",
      "train loss:0.0039532421376053326\n",
      "train loss:0.0027022692785915836\n",
      "train loss:0.0010361980070451495\n",
      "train loss:0.0007247762718410385\n",
      "train loss:0.0005551247603654626\n",
      "train loss:0.0004914448289342223\n",
      "train loss:0.00206118337516654\n",
      "train loss:0.009480027041396579\n",
      "train loss:0.0016717930994515607\n",
      "train loss:0.005784723769136646\n",
      "train loss:0.002056686795601782\n",
      "train loss:0.0014074770768610495\n",
      "train loss:0.0012963873207828336\n",
      "train loss:0.0010880975438466492\n",
      "train loss:0.003343177748222016\n",
      "train loss:0.0003646456540929101\n",
      "train loss:0.00042284971835581346\n",
      "train loss:0.0013813620489900908\n",
      "train loss:7.059692889168116e-05\n",
      "train loss:0.00019118359504990758\n",
      "train loss:9.479837168119207e-05\n",
      "train loss:8.361142991599607e-05\n",
      "train loss:0.00025103563515388693\n",
      "train loss:0.0020362320401865995\n",
      "train loss:0.00018213905798203465\n",
      "train loss:0.0007111628600532287\n",
      "train loss:0.0013637349576195315\n",
      "train loss:0.0007108484268184448\n",
      "train loss:0.0013092395678899553\n",
      "train loss:0.0008313533631300578\n",
      "train loss:0.00011278711738773426\n",
      "train loss:0.00023189328043921498\n",
      "train loss:0.001013012385903993\n",
      "train loss:0.001106407605504541\n",
      "train loss:0.0010384284444809047\n",
      "train loss:0.0005149219445464082\n",
      "train loss:0.00490325519609028\n",
      "train loss:7.90612694385665e-05\n",
      "train loss:0.0018872666471420891\n",
      "train loss:0.003038113256034359\n",
      "train loss:2.3783178197587246e-05\n",
      "train loss:0.0006692608299574608\n",
      "train loss:0.0009836644789813222\n",
      "train loss:0.0009568305624352669\n",
      "train loss:0.0005127433376234073\n",
      "train loss:0.0001762863382319904\n",
      "train loss:0.0005919793516368918\n",
      "train loss:0.0009677811176091009\n",
      "train loss:0.013250069867234251\n",
      "train loss:0.0020126279630288423\n",
      "train loss:4.7007631503321457e-05\n",
      "train loss:0.003127950164784203\n",
      "train loss:0.00048598953596687395\n",
      "train loss:0.00023866247549830073\n",
      "train loss:0.00018332977352281333\n",
      "train loss:0.0004582855450712842\n",
      "train loss:0.0016311805300017073\n",
      "train loss:0.000370843861585172\n",
      "train loss:0.0008861892199183461\n",
      "train loss:0.0007643883349682998\n",
      "train loss:0.001498673026191859\n",
      "train loss:0.004608434932572311\n",
      "train loss:0.004047386086704545\n",
      "train loss:0.00036102914033677027\n",
      "train loss:0.0003309678996351852\n",
      "train loss:0.0007564513035205055\n",
      "train loss:0.0006231060808384809\n",
      "train loss:0.0006646593450870173\n",
      "train loss:0.00025725544400625767\n",
      "train loss:0.002019135624367848\n",
      "train loss:0.000794260489145894\n",
      "train loss:0.00030435327457360793\n",
      "train loss:0.0006116979659783848\n",
      "train loss:0.00026309723258398826\n",
      "train loss:0.0075343058753565475\n",
      "train loss:0.0002739000453382511\n",
      "train loss:0.0002354933129352351\n",
      "train loss:0.0007282214979671879\n",
      "train loss:0.004053956068205126\n",
      "train loss:0.0009251159139300953\n",
      "train loss:0.0022691660193931455\n",
      "train loss:0.00017469492345214172\n",
      "train loss:0.0016969369142578418\n",
      "train loss:0.0004877155083977057\n",
      "train loss:0.0010882269883715626\n",
      "train loss:0.0005744049320511287\n",
      "train loss:0.0005481100642054804\n",
      "train loss:0.001165925771983635\n",
      "train loss:0.0024802794128989548\n",
      "train loss:0.000746883112351851\n",
      "train loss:0.0002954323476790917\n",
      "train loss:0.000566766857020993\n",
      "train loss:0.0004023573119045372\n",
      "train loss:0.0015417598844429023\n",
      "train loss:0.004612507625438884\n",
      "train loss:0.0005165739879179235\n",
      "train loss:0.00018007956614599777\n",
      "train loss:0.0011086872063324237\n",
      "train loss:0.0014239469095493334\n",
      "train loss:0.00014562111007173365\n",
      "train loss:0.0035785592318733086\n",
      "train loss:0.00018601409988600506\n",
      "train loss:0.0003384139326549413\n",
      "train loss:0.002805826124902861\n",
      "train loss:0.0013151957315345863\n",
      "train loss:0.00046178246763210745\n",
      "train loss:0.0008691767910789188\n",
      "train loss:0.0031137345038621776\n",
      "train loss:0.0008299553648774172\n",
      "train loss:0.0013855936420468663\n",
      "train loss:5.3625959351061376e-05\n",
      "train loss:0.0006777447819091252\n",
      "train loss:0.00012802778425703137\n",
      "train loss:0.0008785223108343863\n",
      "train loss:0.00014674838515065024\n",
      "train loss:0.0073062027935180554\n",
      "train loss:0.000553950267310613\n",
      "train loss:0.0012530157480926869\n",
      "train loss:0.0017073475580683785\n",
      "train loss:0.00013523153018951188\n",
      "train loss:0.004407753109893134\n",
      "train loss:0.0004957067412743334\n",
      "train loss:1.793864203586082e-05\n",
      "train loss:4.335060173821023e-05\n",
      "train loss:0.000401063926361867\n",
      "train loss:0.0021831059963648616\n",
      "train loss:0.0007666911983802351\n",
      "train loss:8.143363582688904e-05\n",
      "train loss:0.004542101059081052\n",
      "train loss:0.00020707950536829323\n",
      "train loss:0.005155112178622876\n",
      "train loss:0.002734946193660094\n",
      "train loss:0.00017266299177288668\n",
      "train loss:0.0032136100728737604\n",
      "train loss:0.0008499159524835584\n",
      "train loss:0.00022964794769933148\n",
      "train loss:0.0004997796639844654\n",
      "train loss:0.000154687410289702\n",
      "train loss:0.00010604688830385144\n",
      "train loss:3.517709919096583e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:4.964549784944766e-05\n",
      "train loss:0.0019801949788682783\n",
      "train loss:0.0003800274649767504\n",
      "train loss:0.0004872488036818092\n",
      "train loss:0.0005627600213508701\n",
      "train loss:0.0020142113766672414\n",
      "train loss:0.00041968337800877073\n",
      "train loss:0.029203786779589666\n",
      "train loss:0.0034771313388435392\n",
      "train loss:0.0003348877645335421\n",
      "train loss:0.0004298596746154255\n",
      "train loss:0.0003813883853039198\n",
      "train loss:0.0013841668484851546\n",
      "train loss:0.00014467366520892297\n",
      "train loss:0.00015132323070244646\n",
      "train loss:0.0004049018880381938\n",
      "train loss:0.000649602951877559\n",
      "train loss:0.0011726393177982895\n",
      "train loss:0.00021033201358340345\n",
      "train loss:0.0009860495530511083\n",
      "train loss:0.00016607241046748565\n",
      "train loss:0.0009136468344069949\n",
      "train loss:7.606807403813567e-05\n",
      "train loss:0.0004471527568291223\n",
      "train loss:0.0005948719151194465\n",
      "train loss:0.0028015497031957247\n",
      "train loss:0.0034538772024867792\n",
      "train loss:0.0016698355272001036\n",
      "train loss:5.837037966845892e-05\n",
      "train loss:0.0002275437046794727\n",
      "train loss:0.0009724113155999342\n",
      "train loss:0.0005054295113505091\n",
      "train loss:0.005083235774459112\n",
      "train loss:8.116163733097104e-05\n",
      "train loss:0.00022965152464925767\n",
      "train loss:0.0005734662284209976\n",
      "train loss:0.0002414122824622306\n",
      "train loss:0.0007093897842087017\n",
      "train loss:0.00041763152055061706\n",
      "train loss:0.0005006274573011257\n",
      "train loss:8.371233119628238e-05\n",
      "train loss:0.0004961091120905546\n",
      "train loss:0.001538204296075681\n",
      "train loss:0.00504116940146381\n",
      "train loss:0.001799370705569275\n",
      "train loss:6.855306226671956e-05\n",
      "train loss:6.448045332185283e-05\n",
      "train loss:0.0014747520190808213\n",
      "train loss:0.004734126369120674\n",
      "train loss:0.002167757794856006\n",
      "train loss:0.0012297497841529368\n",
      "train loss:0.0020676793107948987\n",
      "train loss:0.00037669750273162646\n",
      "train loss:0.007959745194903296\n",
      "train loss:0.002590451061354933\n",
      "train loss:0.00047140149524124914\n",
      "train loss:0.0015873361511526663\n",
      "train loss:0.0006179283165900633\n",
      "train loss:0.0018226053852519629\n",
      "train loss:0.00033385223600367677\n",
      "train loss:0.0005980686624164454\n",
      "train loss:0.0004001360337582279\n",
      "train loss:0.0005566564696226213\n",
      "train loss:7.310908123199518e-05\n",
      "train loss:0.0008108179675398134\n",
      "=== epoch:19, train acc:0.998, test acc:0.985 ===\n",
      "train loss:0.0034922700341718026\n",
      "train loss:0.000584352352151811\n",
      "train loss:5.057428095676555e-05\n",
      "train loss:9.156133914339176e-05\n",
      "train loss:0.0013216127842470516\n",
      "train loss:0.005298001746308643\n",
      "train loss:0.0009609996576098713\n",
      "train loss:7.965239502622002e-05\n",
      "train loss:0.00041561813110930053\n",
      "train loss:0.0004487394797011328\n",
      "train loss:0.005531737644626059\n",
      "train loss:0.0013371330757770685\n",
      "train loss:0.00043683084784128625\n",
      "train loss:0.0014298576974557406\n",
      "train loss:0.0012623014631586856\n",
      "train loss:0.00019495413704042754\n",
      "train loss:0.00037707014072459964\n",
      "train loss:0.0019153492643086544\n",
      "train loss:0.0005324214753125154\n",
      "train loss:2.329445466686602e-05\n",
      "train loss:0.00016696383468367036\n",
      "train loss:0.001501391621756403\n",
      "train loss:0.0008897399935337561\n",
      "train loss:0.0003854536159537589\n",
      "train loss:0.0015474631915263\n",
      "train loss:0.0010585507051128864\n",
      "train loss:7.231130699875372e-05\n",
      "train loss:0.0018410129051808699\n",
      "train loss:0.0011239871071408545\n",
      "train loss:0.0014021815087582404\n",
      "train loss:0.00025733329936947333\n",
      "train loss:0.0006021391912372407\n",
      "train loss:0.0010459155640916281\n",
      "train loss:7.272046335140302e-05\n",
      "train loss:0.0004051328658854849\n",
      "train loss:2.807183238844788e-05\n",
      "train loss:0.00021769023973422914\n",
      "train loss:0.0009365251700312813\n",
      "train loss:0.000770321744830826\n",
      "train loss:0.0013372889663010765\n",
      "train loss:0.00025349453559509214\n",
      "train loss:0.0007458750976232973\n",
      "train loss:0.0004422128679704612\n",
      "train loss:0.00011212021699246128\n",
      "train loss:0.0006272475844173573\n",
      "train loss:0.0008949976976529668\n",
      "train loss:0.0007576772860582736\n",
      "train loss:0.0002906724567187992\n",
      "train loss:0.00025468807404304154\n",
      "train loss:7.45264721202279e-05\n",
      "train loss:0.0005527180140681435\n",
      "train loss:0.0015291560625324836\n",
      "train loss:0.0002863799755789305\n",
      "train loss:0.004171191032905983\n",
      "train loss:5.476250059060203e-05\n",
      "train loss:0.0001721832339985223\n",
      "train loss:0.0004583197932799853\n",
      "train loss:9.535435341776734e-05\n",
      "train loss:0.0006651795427239871\n",
      "train loss:0.00012996931813151607\n",
      "train loss:0.0011741868334766118\n",
      "train loss:0.00029154305164147735\n",
      "train loss:0.00117208673379704\n",
      "train loss:0.00031497733851066734\n",
      "train loss:3.699767360514751e-05\n",
      "train loss:0.00303973706844359\n",
      "train loss:0.0010384622301379135\n",
      "train loss:0.00012577920253214588\n",
      "train loss:0.0003757888672152608\n",
      "train loss:0.00017617707402379053\n",
      "train loss:0.004521180552854639\n",
      "train loss:0.00047472036389244133\n",
      "train loss:0.0009996070652235108\n",
      "train loss:0.00017165958131317577\n",
      "train loss:0.00040593836665243536\n",
      "train loss:0.0029746651791691266\n",
      "train loss:0.0012573750950943185\n",
      "train loss:0.0001426726300967493\n",
      "train loss:0.0007922844811038751\n",
      "train loss:0.003067675832506003\n",
      "train loss:0.0003626852891945285\n",
      "train loss:0.0010431301293094023\n",
      "train loss:0.0007634785532288467\n",
      "train loss:0.0005843703164519714\n",
      "train loss:0.00014526057544959707\n",
      "train loss:0.000870505578956826\n",
      "train loss:0.0019055649670971964\n",
      "train loss:0.0005440927845891127\n",
      "train loss:0.003577945299627056\n",
      "train loss:0.00021459235164016755\n",
      "train loss:0.0023536804688337526\n",
      "train loss:0.00021241526660527348\n",
      "train loss:0.000308188383388557\n",
      "train loss:0.000929327026866076\n",
      "train loss:0.0003388680239883653\n",
      "train loss:0.0002024290109298903\n",
      "train loss:0.002764391187208602\n",
      "train loss:0.00018102137491860033\n",
      "train loss:0.0004811440551294804\n",
      "train loss:0.0006098208204755378\n",
      "train loss:0.001730160762883117\n",
      "train loss:0.002076934466072497\n",
      "train loss:0.000715426906678175\n",
      "train loss:0.00025505542258350515\n",
      "train loss:0.0004928577428739635\n",
      "train loss:1.7867790759119077e-05\n",
      "train loss:0.0002384348287748527\n",
      "train loss:1.9284685201568665e-05\n",
      "train loss:8.41881466289705e-05\n",
      "train loss:9.974185731032593e-05\n",
      "train loss:0.0008161386372086544\n",
      "train loss:9.468611624388474e-05\n",
      "train loss:7.900813633876749e-05\n",
      "train loss:0.00143810705057209\n",
      "train loss:0.00038454558267319016\n",
      "train loss:0.0019149806312044784\n",
      "train loss:0.00061613909103235\n",
      "train loss:7.688284229972244e-05\n",
      "train loss:0.0033601480246406527\n",
      "train loss:0.0006313269736524026\n",
      "train loss:0.0017076426173200038\n",
      "train loss:0.0007979030867945255\n",
      "train loss:0.00031438965326230014\n",
      "train loss:2.6646255356176066e-05\n",
      "train loss:0.001244772604420961\n",
      "train loss:0.0010439613646772785\n",
      "train loss:6.34421232326508e-05\n",
      "train loss:0.0005150793957776126\n",
      "train loss:0.00013193402524753933\n",
      "train loss:0.0010074962243292141\n",
      "train loss:0.00012139805142134217\n",
      "train loss:2.818494660072995e-05\n",
      "train loss:0.00012021126680921474\n",
      "train loss:6.483183408036045e-05\n",
      "train loss:0.00018504852270478974\n",
      "train loss:0.00012150534314101645\n",
      "train loss:0.00014003989035210653\n",
      "train loss:0.0003135033955962125\n",
      "train loss:0.0008814723189679587\n",
      "train loss:0.0005181193246795474\n",
      "train loss:0.0021471259804911255\n",
      "train loss:0.0007119183856698269\n",
      "train loss:0.0015920444090588124\n",
      "train loss:0.00014781160935934832\n",
      "train loss:7.9492462568727e-05\n",
      "train loss:0.0005747133780702828\n",
      "train loss:0.0018624831735341288\n",
      "train loss:0.0003574275716348843\n",
      "train loss:0.0003079541455230569\n",
      "train loss:0.00014614998789507573\n",
      "train loss:9.812048225486994e-05\n",
      "train loss:1.999397717466713e-05\n",
      "train loss:0.0012428425473214766\n",
      "train loss:0.0015933034538484039\n",
      "train loss:0.0005026158353329779\n",
      "train loss:0.00019992371636486233\n",
      "train loss:0.0007042797670444914\n",
      "train loss:0.0010991012661469728\n",
      "train loss:0.00011545256550454675\n",
      "train loss:0.0006082939827461414\n",
      "train loss:0.006981446467835939\n",
      "train loss:0.0008026394620945029\n",
      "train loss:0.0020266541619042085\n",
      "train loss:0.0005054564491633269\n",
      "train loss:5.282108978882094e-05\n",
      "train loss:3.588168173522787e-05\n",
      "train loss:0.002966839009207819\n",
      "train loss:0.00017325674858067292\n",
      "train loss:0.00024923167445371807\n",
      "train loss:0.001351284169095587\n",
      "train loss:0.00018406154162279797\n",
      "train loss:0.000690413398268989\n",
      "train loss:0.00290492680354121\n",
      "train loss:0.0004224684904201556\n",
      "train loss:9.352083378520005e-05\n",
      "train loss:0.0006369018876044208\n",
      "train loss:3.841840393219625e-05\n",
      "train loss:0.001653026625345415\n",
      "train loss:6.0379221228634295e-05\n",
      "train loss:0.0007293987649441881\n",
      "train loss:0.0013582172251046707\n",
      "train loss:0.0009323638971233638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00015553766502067403\n",
      "train loss:0.0009737518707650615\n",
      "train loss:0.0006461885454240754\n",
      "train loss:0.00048028666009306367\n",
      "train loss:0.00016758204468337714\n",
      "train loss:0.00014176078332857223\n",
      "train loss:0.00010559204749296495\n",
      "train loss:0.0005369267373079718\n",
      "train loss:0.00043283420507836726\n",
      "train loss:0.0001701347785351609\n",
      "train loss:0.002190138875985905\n",
      "train loss:0.0009412980561037808\n",
      "train loss:0.00043291183499751245\n",
      "train loss:6.100293395533412e-05\n",
      "train loss:0.0005069021744874573\n",
      "train loss:0.004028798278162063\n",
      "train loss:0.0001294406850097382\n",
      "train loss:0.00029576767911329945\n",
      "train loss:0.001011463410483804\n",
      "train loss:2.6851520917778603e-05\n",
      "train loss:0.001548251029832879\n",
      "train loss:0.0003423531545323693\n",
      "train loss:0.0005296222271622597\n",
      "train loss:0.0005254846332976832\n",
      "train loss:0.0005987935757972057\n",
      "train loss:9.666666012608352e-05\n",
      "train loss:0.0010043114399176994\n",
      "train loss:6.87538793619757e-05\n",
      "train loss:0.00045147553694632937\n",
      "train loss:0.0028656729798125754\n",
      "train loss:5.032498092709124e-05\n",
      "train loss:0.0006816822136124425\n",
      "train loss:5.642828578227476e-05\n",
      "train loss:0.00010191273920291373\n",
      "train loss:0.0002928086111425369\n",
      "train loss:0.0003727773785863156\n",
      "train loss:0.00044008850253239145\n",
      "train loss:0.0020372995139928533\n",
      "train loss:0.00015494593377280653\n",
      "train loss:0.006003188448589645\n",
      "train loss:0.004217296722880378\n",
      "train loss:0.00158599520514344\n",
      "train loss:0.002014858725487876\n",
      "train loss:0.0001358432276024339\n",
      "train loss:0.000320110445383393\n",
      "train loss:0.0001585664283454323\n",
      "train loss:0.0009535651287948828\n",
      "train loss:0.001546783669235563\n",
      "train loss:3.013210808229842e-05\n",
      "train loss:0.0032422507113754207\n",
      "train loss:0.0002534482231796758\n",
      "train loss:0.0002599944571033508\n",
      "train loss:0.006569211197200758\n",
      "train loss:0.00024792461211564957\n",
      "train loss:0.00018214541211103953\n",
      "train loss:0.0002994199206559183\n",
      "train loss:0.003075679119710049\n",
      "train loss:0.0007986020409808544\n",
      "train loss:0.0015333313037458134\n",
      "train loss:0.0021558120589810536\n",
      "train loss:0.00032884875488343963\n",
      "train loss:4.3740878521038846e-05\n",
      "train loss:0.00026070231409407293\n",
      "train loss:0.00024403476117592165\n",
      "train loss:0.0009958644471818308\n",
      "train loss:0.0013822630826097657\n",
      "train loss:0.0005637588699187379\n",
      "train loss:0.0007240576596641654\n",
      "train loss:0.00013356759883978588\n",
      "train loss:0.0009373306133561798\n",
      "train loss:0.002000559681698848\n",
      "train loss:0.0005436941112799623\n",
      "train loss:0.00020141931541898427\n",
      "train loss:0.0017038029902922821\n",
      "train loss:0.0015247621592485966\n",
      "train loss:0.0009424203306088661\n",
      "train loss:0.0010048763314336275\n",
      "train loss:0.00044049059171300567\n",
      "train loss:0.000545528946188444\n",
      "train loss:0.0016156915277007534\n",
      "train loss:0.0013652770334860605\n",
      "train loss:0.0025494283725873805\n",
      "train loss:0.00012963289350565046\n",
      "train loss:0.00294941141996678\n",
      "train loss:0.0008491203658813076\n",
      "train loss:6.827526638618012e-05\n",
      "train loss:0.0001365339450063947\n",
      "train loss:9.300890583834657e-05\n",
      "train loss:0.0027808464336045134\n",
      "train loss:0.0017555840715671317\n",
      "train loss:0.0005674036499439751\n",
      "train loss:0.0017008760195195574\n",
      "train loss:0.0006107633940538064\n",
      "train loss:0.0001276788896004138\n",
      "train loss:0.0018787617117706368\n",
      "train loss:0.0002796049434953556\n",
      "train loss:0.0014437934891614317\n",
      "train loss:0.0009064143669233574\n",
      "train loss:2.6240451101775325e-05\n",
      "train loss:0.003253647116800286\n",
      "train loss:0.0011029996385840226\n",
      "train loss:0.0002479243160665052\n",
      "train loss:0.0004801661496826828\n",
      "train loss:0.0002394156600376468\n",
      "train loss:0.0005399987791414198\n",
      "train loss:0.0018994393500544888\n",
      "train loss:0.03191656492773317\n",
      "train loss:0.0007684116856904728\n",
      "train loss:0.00034211318879203605\n",
      "train loss:0.0012816966716489354\n",
      "train loss:0.0001019078541348248\n",
      "train loss:0.0016863018194327908\n",
      "train loss:0.00011687912363180777\n",
      "train loss:0.00021416134881227695\n",
      "train loss:0.003399757467022131\n",
      "train loss:6.805727260866965e-05\n",
      "train loss:0.0010520826216108019\n",
      "train loss:0.001127396890493593\n",
      "train loss:0.0006296218575958031\n",
      "train loss:0.00030354251099773356\n",
      "train loss:8.829879899831883e-05\n",
      "train loss:5.102033954135276e-05\n",
      "train loss:0.007966109017969344\n",
      "train loss:0.00038196576399188013\n",
      "train loss:0.0009237901016383815\n",
      "train loss:0.0005384684651719056\n",
      "train loss:0.004019430199943555\n",
      "train loss:0.00025501888861509815\n",
      "train loss:0.000223827094499847\n",
      "train loss:0.002001979111937712\n",
      "train loss:0.0007613769113368994\n",
      "train loss:4.163547468035916e-05\n",
      "train loss:0.0007070578357296634\n",
      "train loss:0.002025413467679751\n",
      "train loss:0.003798792097654782\n",
      "train loss:0.002449506337935768\n",
      "train loss:0.00019649875701608483\n",
      "train loss:0.00038718387014010904\n",
      "train loss:0.0003040022345352129\n",
      "train loss:0.00011906041406045278\n",
      "train loss:0.00018198068978985494\n",
      "train loss:0.0003354976177145309\n",
      "train loss:5.2392333861785205e-05\n",
      "train loss:0.0015967863551281185\n",
      "train loss:8.505440433923026e-05\n",
      "train loss:0.001325210467439133\n",
      "train loss:0.0002742895199543745\n",
      "train loss:0.0040136774282028605\n",
      "train loss:0.0021270054254894253\n",
      "train loss:0.000229614659534418\n",
      "train loss:0.005102126680912858\n",
      "train loss:0.043091764301065455\n",
      "train loss:5.2257478279088024e-05\n",
      "train loss:7.19172774604022e-05\n",
      "train loss:5.791975423586793e-05\n",
      "train loss:0.0002821255576265694\n",
      "train loss:0.00020164766954984992\n",
      "train loss:0.0002020247712056514\n",
      "train loss:0.00016618936742257554\n",
      "train loss:0.0021591243481021084\n",
      "train loss:0.003380210616867988\n",
      "train loss:0.00017452996693364598\n",
      "train loss:0.0017236849117473405\n",
      "train loss:0.0005376814922480603\n",
      "train loss:0.0001273327043383325\n",
      "train loss:0.00021113402972394949\n",
      "train loss:0.00014318908798246867\n",
      "train loss:0.012187357298487885\n",
      "train loss:0.002029091400526276\n",
      "train loss:0.00032201314423759654\n",
      "train loss:0.00044432028942073635\n",
      "train loss:0.00010567854929960466\n",
      "train loss:0.00021633456617138827\n",
      "train loss:0.008603367675545086\n",
      "train loss:0.0018641325550065703\n",
      "train loss:0.008148223565525563\n",
      "train loss:0.0032987365399709647\n",
      "train loss:0.0005085689616173848\n",
      "train loss:0.0004185279921441594\n",
      "train loss:0.0015017139978145229\n",
      "train loss:0.0007145562984933833\n",
      "train loss:0.0018181842620059987\n",
      "train loss:0.0007846660157576617\n",
      "train loss:0.007280939691622714\n",
      "train loss:6.531315868718644e-05\n",
      "train loss:0.0006234145930235657\n",
      "train loss:9.649618275153734e-05\n",
      "train loss:0.0007685084360128755\n",
      "train loss:0.00564279332799149\n",
      "train loss:9.875571237926201e-05\n",
      "train loss:0.000492622792710539\n",
      "train loss:0.00032076207021401813\n",
      "train loss:0.0014065222345566548\n",
      "train loss:0.0004761831951931548\n",
      "train loss:0.0002781849157561251\n",
      "train loss:0.0007044268196535558\n",
      "train loss:0.0009414400606555642\n",
      "train loss:0.0018035157840444688\n",
      "train loss:0.000846860426178475\n",
      "train loss:0.00020707650428658883\n",
      "train loss:0.0005384387539050491\n",
      "train loss:0.00035226705522077746\n",
      "train loss:0.0016955049897014757\n",
      "train loss:0.0001517432579268928\n",
      "train loss:0.0001927680421649795\n",
      "train loss:6.28848997474436e-05\n",
      "train loss:0.0033485173458631034\n",
      "train loss:0.00019113088777852617\n",
      "train loss:0.0005070751527881303\n",
      "train loss:0.002480880233687651\n",
      "train loss:0.00037642330069555534\n",
      "train loss:0.00025532069218161965\n",
      "train loss:0.0005150709035251593\n",
      "train loss:0.00029790300485902315\n",
      "train loss:0.0001654192524441618\n",
      "train loss:0.0027143647195844106\n",
      "train loss:3.1015251601890506e-05\n",
      "train loss:0.0007758397063887711\n",
      "train loss:0.001406274550253886\n",
      "train loss:0.0029237093738092566\n",
      "train loss:0.0003534003494275942\n",
      "train loss:0.0004748179094072669\n",
      "train loss:0.0017981523900884124\n",
      "train loss:8.89490993109617e-05\n",
      "train loss:0.0002895246005994808\n",
      "train loss:0.0001555477422227795\n",
      "train loss:0.00046048361876417106\n",
      "train loss:0.00057886298315862\n",
      "train loss:0.0009595717439593826\n",
      "train loss:0.00014650360782514628\n",
      "train loss:0.0027754920828922053\n",
      "train loss:5.5141541296810156e-05\n",
      "train loss:0.0002094701549911725\n",
      "train loss:0.0006341999688706723\n",
      "train loss:0.0007810915599664528\n",
      "train loss:3.278455792270061e-05\n",
      "train loss:0.00017472915255070326\n",
      "train loss:0.00017607951586257522\n",
      "train loss:0.002146736418223383\n",
      "train loss:0.00017089207978140516\n",
      "train loss:3.0957398847420926e-05\n",
      "train loss:0.0012888039121470363\n",
      "train loss:0.00026474954382226136\n",
      "train loss:0.0007241728362609417\n",
      "train loss:0.0009007560795274808\n",
      "train loss:0.0006852053441588618\n",
      "train loss:0.00012175837814993512\n",
      "train loss:0.0005583774372570583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:7.800475754898019e-05\n",
      "train loss:7.749722313945092e-05\n",
      "train loss:0.008045924179549985\n",
      "train loss:2.4082621621626837e-05\n",
      "train loss:0.0004809895575483486\n",
      "train loss:0.0016318610937929403\n",
      "train loss:0.00047309510403816424\n",
      "train loss:0.0004600967562597713\n",
      "train loss:0.001242260338222924\n",
      "train loss:7.751900429394598e-05\n",
      "train loss:2.229565907442277e-05\n",
      "train loss:0.001480350904756029\n",
      "train loss:0.0005481887492150037\n",
      "train loss:0.0009923222251036698\n",
      "train loss:0.00011743134173088412\n",
      "train loss:0.0002839277262975107\n",
      "train loss:0.00015356240238776627\n",
      "train loss:0.0010225974689876054\n",
      "train loss:0.0008115712895435756\n",
      "train loss:0.0005240788454434292\n",
      "train loss:0.000328495352502876\n",
      "train loss:1.056431467658111e-05\n",
      "train loss:4.023204284974131e-05\n",
      "train loss:8.695628493757428e-05\n",
      "train loss:0.0013392530080700692\n",
      "train loss:7.139277233562495e-05\n",
      "train loss:0.00031720990871707386\n",
      "train loss:0.0003901822410776336\n",
      "train loss:0.0008910712082616957\n",
      "train loss:0.00047634223169699854\n",
      "train loss:0.0027554381191505204\n",
      "train loss:0.00024834797375317195\n",
      "train loss:5.748472408582063e-06\n",
      "train loss:2.0224062478020558e-05\n",
      "train loss:0.003607950079209314\n",
      "train loss:0.0005425885689805219\n",
      "train loss:0.00033300167853505153\n",
      "train loss:8.693632750881865e-06\n",
      "train loss:0.0015332969312828208\n",
      "train loss:0.00111830010608338\n",
      "train loss:0.0006457401985347213\n",
      "train loss:0.0001972615280600336\n",
      "train loss:0.0005930373850317766\n",
      "train loss:0.00012123249365015494\n",
      "train loss:0.0001449851441434046\n",
      "train loss:0.0003049631163137698\n",
      "train loss:0.00044034579479364515\n",
      "train loss:0.0024001709671650014\n",
      "train loss:5.447129311079433e-05\n",
      "train loss:0.0018220617301491604\n",
      "train loss:0.0035833443198601818\n",
      "train loss:0.0009877103867934195\n",
      "train loss:0.0007897488730948314\n",
      "train loss:0.0005572133829906166\n",
      "train loss:0.00015401929547489878\n",
      "train loss:0.001751587130395321\n",
      "train loss:0.000937757876200718\n",
      "train loss:0.0013811478343853441\n",
      "train loss:0.0007794262370476986\n",
      "train loss:0.0002362114764212542\n",
      "train loss:0.0011878114280015333\n",
      "train loss:0.00010387239601444911\n",
      "train loss:0.0002210015411870744\n",
      "train loss:0.0032459248273021234\n",
      "train loss:0.0021669959373678215\n",
      "train loss:0.004379604035632954\n",
      "train loss:0.0016381555358089305\n",
      "train loss:0.00020316406681164447\n",
      "train loss:0.00047777547461299083\n",
      "train loss:0.0002527867383294641\n",
      "train loss:0.0008536801741251543\n",
      "train loss:0.0009628262649977435\n",
      "train loss:0.0003109058846730742\n",
      "train loss:0.004011689470852083\n",
      "train loss:0.0014365686196648262\n",
      "train loss:0.004090325325271878\n",
      "train loss:0.00014175980244466728\n",
      "train loss:0.002247138971999362\n",
      "train loss:0.0007698091849100423\n",
      "train loss:8.205675777158706e-05\n",
      "train loss:0.003275471893334398\n",
      "train loss:6.75693546062686e-05\n",
      "train loss:0.0026803143974480775\n",
      "train loss:0.0004630815589539645\n",
      "train loss:0.00028190488080451296\n",
      "train loss:5.391086507777445e-05\n",
      "train loss:0.0007226239166366465\n",
      "train loss:0.0007250536327194272\n",
      "train loss:8.109860607760161e-05\n",
      "train loss:0.0005302819304774538\n",
      "train loss:0.000546030637823329\n",
      "train loss:0.002229739730137146\n",
      "train loss:0.0007442844678149238\n",
      "train loss:0.0021142232623981316\n",
      "train loss:0.0011396085033298635\n",
      "train loss:0.0015215624349228588\n",
      "train loss:0.000509740106991721\n",
      "train loss:4.4871017822081936e-05\n",
      "train loss:0.00017109087867220855\n",
      "train loss:0.003382436543247351\n",
      "train loss:0.0016397922990194396\n",
      "train loss:0.004807755392386642\n",
      "train loss:0.0011440527252409925\n",
      "train loss:0.001302066171872263\n",
      "train loss:0.008335201464463059\n",
      "train loss:0.0008679145401182947\n",
      "train loss:0.0027331225537511657\n",
      "train loss:0.0003125956893616851\n",
      "train loss:0.0015782218737702127\n",
      "train loss:0.0256710052812429\n",
      "train loss:0.001143217103259468\n",
      "train loss:0.00040490375534121375\n",
      "train loss:0.0015784475534332792\n",
      "train loss:0.0014090447797147363\n",
      "train loss:4.8456944465855646e-05\n",
      "train loss:0.0008633760593202911\n",
      "train loss:8.977778056904327e-05\n",
      "train loss:0.0003768202459407365\n",
      "train loss:0.0033029985202087998\n",
      "train loss:0.004941949185898354\n",
      "train loss:0.0011011808262341412\n",
      "train loss:0.0007212396063419966\n",
      "train loss:0.010758204889877318\n",
      "train loss:0.0021975196000404407\n",
      "train loss:0.0011981949153208348\n",
      "train loss:0.002735717455490914\n",
      "train loss:0.0018715482237918381\n",
      "train loss:5.678582991396822e-05\n",
      "train loss:0.0024177139767968974\n",
      "train loss:0.003836019973923615\n",
      "train loss:0.0018751204243079994\n",
      "train loss:0.006212669071403226\n",
      "train loss:0.0005307999117326107\n",
      "train loss:0.003430096379767485\n",
      "train loss:0.012464459556398622\n",
      "train loss:0.00018610860422098205\n",
      "train loss:0.00140040917357238\n",
      "train loss:0.000815105817357263\n",
      "train loss:0.0006920156835376527\n",
      "train loss:0.0004629555980643478\n",
      "train loss:0.0018060065286844866\n",
      "train loss:0.002225200496455525\n",
      "train loss:0.0009523268679984523\n",
      "train loss:0.001396202804612787\n",
      "train loss:0.00013226905912606937\n",
      "train loss:0.0012474482240635609\n",
      "train loss:0.00010124419788322242\n",
      "train loss:0.0002644538507983727\n",
      "train loss:0.0022749758558862215\n",
      "train loss:0.0008262718817215304\n",
      "train loss:0.0005824620201719482\n",
      "train loss:0.0026014802881006794\n",
      "train loss:0.003546679426040586\n",
      "train loss:0.00015286382179261753\n",
      "train loss:0.0031296920934708056\n",
      "train loss:0.0026627183267369475\n",
      "train loss:0.002365712109921174\n",
      "train loss:0.0017384049637979915\n",
      "train loss:0.00021713260888067156\n",
      "train loss:0.00033355377651606585\n",
      "train loss:0.001146535991082197\n",
      "train loss:2.0664427835207526e-05\n",
      "train loss:0.002566987404370784\n",
      "train loss:0.00129302670845226\n",
      "train loss:0.00013079653150717535\n",
      "train loss:0.00022357367221160972\n",
      "train loss:0.0043457856637929325\n",
      "train loss:0.0005784670359304031\n",
      "train loss:0.00038316624319901545\n",
      "train loss:0.00031320489826688295\n",
      "=== epoch:20, train acc:0.998, test acc:0.987 ===\n",
      "train loss:0.006187652403911575\n",
      "train loss:0.0036539569171712073\n",
      "train loss:0.00039485291408066864\n",
      "train loss:0.0008237215015586975\n",
      "train loss:0.001363948815188922\n",
      "train loss:0.0015092714209750697\n",
      "train loss:0.00012290950789824824\n",
      "train loss:0.0021147133008765904\n",
      "train loss:0.0006258825836637546\n",
      "train loss:0.002034449984677041\n",
      "train loss:0.0012432846152295928\n",
      "train loss:0.0002601739109093978\n",
      "train loss:0.0006344914563396378\n",
      "train loss:0.0008525220429066588\n",
      "train loss:0.0012453246810612078\n",
      "train loss:0.0010249906439695723\n",
      "train loss:0.0014057162282213338\n",
      "train loss:0.00018468115877601565\n",
      "train loss:0.003265568626861248\n",
      "train loss:0.0004691128304684663\n",
      "train loss:0.001510207661752878\n",
      "train loss:0.0007471031172523339\n",
      "train loss:0.0005817087540843283\n",
      "train loss:0.0003636750946859654\n",
      "train loss:0.0002722167734591993\n",
      "train loss:9.142568798596179e-05\n",
      "train loss:0.0030482847388781493\n",
      "train loss:0.0010341442914486069\n",
      "train loss:0.00012403469074309182\n",
      "train loss:0.0007889311261795253\n",
      "train loss:0.006626122706311525\n",
      "train loss:8.166555414649293e-05\n",
      "train loss:0.004120769785642824\n",
      "train loss:0.0005556881949461068\n",
      "train loss:0.0020126407348887002\n",
      "train loss:0.011010928096203966\n",
      "train loss:0.0009869285567000099\n",
      "train loss:0.004073370548736836\n",
      "train loss:0.0012207303898175458\n",
      "train loss:0.0002695253037717396\n",
      "train loss:0.00013639300690495345\n",
      "train loss:0.001028547108548391\n",
      "train loss:0.000698893457509449\n",
      "train loss:0.0004215096456434273\n",
      "train loss:0.000380762586688448\n",
      "train loss:1.1650029518856123e-05\n",
      "train loss:0.00013404830231452552\n",
      "train loss:0.002730452053225644\n",
      "train loss:0.0005517239438653101\n",
      "train loss:0.0037347509731050204\n",
      "train loss:3.165034704350073e-05\n",
      "train loss:0.0001282146100293058\n",
      "train loss:0.0005554166910821868\n",
      "train loss:0.0013527138113551673\n",
      "train loss:1.733940727528598e-05\n",
      "train loss:0.00013769424309666086\n",
      "train loss:0.0010836625117733583\n",
      "train loss:0.0004895178225139049\n",
      "train loss:0.00013708192475231007\n",
      "train loss:0.0001162317691305087\n",
      "train loss:0.00044612249074117325\n",
      "train loss:0.0011779600219317444\n",
      "train loss:0.0013652255412930708\n",
      "train loss:3.9642801567784544e-05\n",
      "train loss:0.0004848668266209888\n",
      "train loss:0.002251388172214295\n",
      "train loss:0.0003907603603478771\n",
      "train loss:0.001460967326252145\n",
      "train loss:7.681557118091039e-05\n",
      "train loss:9.037450373964655e-05\n",
      "train loss:0.0005809364019526386\n",
      "train loss:0.001109521480974831\n",
      "train loss:0.0006563923850627803\n",
      "train loss:0.002226072992549649\n",
      "train loss:6.780807981598279e-05\n",
      "train loss:0.0019303974477579509\n",
      "train loss:0.00024460460504838384\n",
      "train loss:0.0020627625435730153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0006761822467866403\n",
      "train loss:0.004448107262792721\n",
      "train loss:3.6414985748081374e-05\n",
      "train loss:3.872792434247785e-05\n",
      "train loss:0.00014192976836216114\n",
      "train loss:6.601939764935982e-05\n",
      "train loss:0.0001722235256254137\n",
      "train loss:0.0008550282183317846\n",
      "train loss:0.001951583069944379\n",
      "train loss:0.0013447194478375724\n",
      "train loss:0.0005658031659045706\n",
      "train loss:0.0011166109045918022\n",
      "train loss:0.0013521297517571234\n",
      "train loss:0.00010777480880284683\n",
      "train loss:0.007860423142216721\n",
      "train loss:0.0026185532475687316\n",
      "train loss:0.00015504617651201526\n",
      "train loss:0.0009262848910024303\n",
      "train loss:0.00030672095412548626\n",
      "train loss:0.0027809704949059277\n",
      "train loss:5.9987570030077394e-05\n",
      "train loss:0.018727288820610952\n",
      "train loss:0.004625961282838076\n",
      "train loss:0.0003457440702266106\n",
      "train loss:0.0002767396639758323\n",
      "train loss:0.0008283652900519174\n",
      "train loss:0.02103338883486374\n",
      "train loss:0.0009091117572092665\n",
      "train loss:0.0018720485706883502\n",
      "train loss:0.013227987499405215\n",
      "train loss:0.0024625847081367973\n",
      "train loss:0.0005261433290702144\n",
      "train loss:0.0015512650731889647\n",
      "train loss:0.0030009487130816547\n",
      "train loss:0.001551772772979219\n",
      "train loss:0.002610809720748239\n",
      "train loss:0.0001884831574002079\n",
      "train loss:0.003928783015638926\n",
      "train loss:0.005254539427141999\n",
      "train loss:0.0009583857760215374\n",
      "train loss:0.004834390462638869\n",
      "train loss:0.0010826474626911067\n",
      "train loss:0.0018619476685293463\n",
      "train loss:0.004868959882089791\n",
      "train loss:0.0005455881830055729\n",
      "train loss:0.0010133577627866625\n",
      "train loss:0.0016348243070020115\n",
      "train loss:7.886421277665241e-05\n",
      "train loss:2.387115099557742e-05\n",
      "train loss:0.00020117089567964916\n",
      "train loss:0.0006843582969886478\n",
      "train loss:0.0004439918145667264\n",
      "train loss:0.004386225851119447\n",
      "train loss:0.0006907295017250098\n",
      "train loss:0.0009000671358055353\n",
      "train loss:0.00170309612371633\n",
      "train loss:0.00038224243290499476\n",
      "train loss:0.00016625931980505777\n",
      "train loss:0.004512276076981407\n",
      "train loss:0.0003956437317880975\n",
      "train loss:0.013882404561853422\n",
      "train loss:0.0015223381461143331\n",
      "train loss:0.0007334991792347007\n",
      "train loss:0.0009704181983845006\n",
      "train loss:7.998510893826558e-05\n",
      "train loss:8.799041830637205e-05\n",
      "train loss:0.00026987638440147826\n",
      "train loss:0.0016690130729726167\n",
      "train loss:0.0017544819929042215\n",
      "train loss:0.0006056204583517311\n",
      "train loss:0.0002813121834295497\n",
      "train loss:0.007689524774303216\n",
      "train loss:6.046624845074321e-05\n",
      "train loss:0.0020217480108080965\n",
      "train loss:0.005991056007045728\n",
      "train loss:0.0005748417798598989\n",
      "train loss:2.787553453065595e-05\n",
      "train loss:0.0004887942747363501\n",
      "train loss:0.0027522978155520715\n",
      "train loss:0.007618796637887453\n",
      "train loss:0.0019095740314058593\n",
      "train loss:0.004728261226782438\n",
      "train loss:0.002131883330440694\n",
      "train loss:0.0006189217376260958\n",
      "train loss:0.00011860701058643544\n",
      "train loss:0.001112005785914295\n",
      "train loss:0.008492278170748211\n",
      "train loss:0.023117574725094573\n",
      "train loss:0.0009107410763569728\n",
      "train loss:0.00044893451998437165\n",
      "train loss:0.0014525509162430527\n",
      "train loss:0.00045512434934832544\n",
      "train loss:0.0009045171868110489\n",
      "train loss:8.889981248026944e-05\n",
      "train loss:0.00029837512031338266\n",
      "train loss:0.0011564615024677826\n",
      "train loss:0.002928247784565902\n",
      "train loss:0.0007572144813799493\n",
      "train loss:0.000941735582926677\n",
      "train loss:0.00533071811650607\n",
      "train loss:6.105815265417666e-05\n",
      "train loss:0.0019265265350833407\n",
      "train loss:0.0017565307098363913\n",
      "train loss:0.0023142139714155477\n",
      "train loss:0.0004633097743740458\n",
      "train loss:9.214371476198746e-05\n",
      "train loss:0.005987344550679178\n",
      "train loss:0.0006746252948661792\n",
      "train loss:0.001776606377228641\n",
      "train loss:3.216358411136502e-05\n",
      "train loss:0.0008883077835535408\n",
      "train loss:0.00035334826395080963\n",
      "train loss:0.00016166179095445342\n",
      "train loss:0.00015195347017142336\n",
      "train loss:0.0019251755157178824\n",
      "train loss:0.0013507078054371192\n",
      "train loss:7.93973932577659e-05\n",
      "train loss:0.001315177530701445\n",
      "train loss:0.0004284615378539767\n",
      "train loss:0.002088034425316504\n",
      "train loss:0.00018882773967005437\n",
      "train loss:0.0004555950693681188\n",
      "train loss:0.00480303159241822\n",
      "train loss:0.002446838109498731\n",
      "train loss:0.0014263043068224563\n",
      "train loss:0.006325083516039451\n",
      "train loss:0.00038979734098291855\n",
      "train loss:0.0017045220035739191\n",
      "train loss:0.0002303655273025014\n",
      "train loss:0.0006915548574857417\n",
      "train loss:0.0027908898018033585\n",
      "train loss:0.0005522606051059863\n",
      "train loss:1.6943500091494606e-05\n",
      "train loss:0.0002689478844641945\n",
      "train loss:0.0020926885867137302\n",
      "train loss:0.00027447463844922825\n",
      "train loss:0.00011792142477064636\n",
      "train loss:0.0023600639567915634\n",
      "train loss:0.00010466197764558406\n",
      "train loss:0.0058103541503403975\n",
      "train loss:0.003066932969223822\n",
      "train loss:0.0032715295348172036\n",
      "train loss:0.00043286952667373957\n",
      "train loss:0.008921438919985602\n",
      "train loss:0.0038107191767529133\n",
      "train loss:0.0001769325697488418\n",
      "train loss:0.0006549260422608002\n",
      "train loss:0.00040872333064344193\n",
      "train loss:0.00020542552451894837\n",
      "train loss:0.002144954359673905\n",
      "train loss:9.29903994956508e-05\n",
      "train loss:8.038380040444413e-05\n",
      "train loss:0.00033751325153711764\n",
      "train loss:0.0009564158424034\n",
      "train loss:0.00011071285716032217\n",
      "train loss:0.00011863154046206834\n",
      "train loss:0.0012744099261048267\n",
      "train loss:0.001269728406301748\n",
      "train loss:0.002066307152388057\n",
      "train loss:0.00012777897644991696\n",
      "train loss:0.0006105796698247593\n",
      "train loss:0.0027477029143199083\n",
      "train loss:0.0001308065489184302\n",
      "train loss:0.001242084592591918\n",
      "train loss:0.002137324145591953\n",
      "train loss:0.0008257599360572356\n",
      "train loss:0.006352840369589214\n",
      "train loss:4.917486542600116e-05\n",
      "train loss:0.003651225079297435\n",
      "train loss:0.00041425846339664666\n",
      "train loss:0.0013398348308658059\n",
      "train loss:0.0028480048213238864\n",
      "train loss:0.0018653233413220322\n",
      "train loss:0.0017505634474231405\n",
      "train loss:0.0026294173454708635\n",
      "train loss:0.00027953584183667077\n",
      "train loss:0.0005880656013259341\n",
      "train loss:0.0028915212711643234\n",
      "train loss:0.0013674751070520924\n",
      "train loss:0.0002579842341100634\n",
      "train loss:0.0008247510954722107\n",
      "train loss:0.001000298379142585\n",
      "train loss:0.0020318167411122576\n",
      "train loss:0.003917435091928467\n",
      "train loss:7.569013510502878e-05\n",
      "train loss:0.00040911825602281355\n",
      "train loss:0.0005155074959857878\n",
      "train loss:0.016377800692082934\n",
      "train loss:0.00044848591072077076\n",
      "train loss:0.003880888759464464\n",
      "train loss:0.0006211000500996655\n",
      "train loss:0.0001098784637649831\n",
      "train loss:0.0029676627053564788\n",
      "train loss:0.0007002883367165522\n",
      "train loss:0.00017549557353123627\n",
      "train loss:0.0001114945069357396\n",
      "train loss:0.0001694637591459765\n",
      "train loss:6.201348703201273e-05\n",
      "train loss:0.0015653259558399372\n",
      "train loss:0.000346359822601415\n",
      "train loss:0.002988360499556089\n",
      "train loss:0.0031908678088462135\n",
      "train loss:0.003109045971697109\n",
      "train loss:3.551633658195501e-05\n",
      "train loss:0.0005725943228475166\n",
      "train loss:6.898161999892073e-05\n",
      "train loss:0.0004782891309005348\n",
      "train loss:0.0003961163652348956\n",
      "train loss:0.0010406947355895934\n",
      "train loss:0.0002920846388283077\n",
      "train loss:2.9160172568723033e-05\n",
      "train loss:0.00012299581415501956\n",
      "train loss:0.00326584328560531\n",
      "train loss:6.837103613637148e-05\n",
      "train loss:0.0017487576347342542\n",
      "train loss:0.00010365830980557375\n",
      "train loss:0.0003047096443985067\n",
      "train loss:7.851165325960824e-05\n",
      "train loss:0.0013807002506541965\n",
      "train loss:0.00047429172015530817\n",
      "train loss:0.001975501550395967\n",
      "train loss:0.0037185879279134477\n",
      "train loss:0.00022080573211020576\n",
      "train loss:0.00382519064289472\n",
      "train loss:1.821265093579072e-05\n",
      "train loss:0.0001919235930367985\n",
      "train loss:0.00447627856063248\n",
      "train loss:7.387670095769782e-05\n",
      "train loss:0.0009393931975124428\n",
      "train loss:0.0016357460812431467\n",
      "train loss:0.00044031203836524246\n",
      "train loss:0.00016751604710127946\n",
      "train loss:0.001064265098528878\n",
      "train loss:0.00022155992832904612\n",
      "train loss:0.0012045540275138357\n",
      "train loss:0.0006212546637315583\n",
      "train loss:0.0010302979751411411\n",
      "train loss:0.0005607830736250321\n",
      "train loss:0.0006152984658402947\n",
      "train loss:0.0007850403894168971\n",
      "train loss:0.002495955606524272\n",
      "train loss:0.006977615650524788\n",
      "train loss:0.0011770367239310848\n",
      "train loss:0.001185728975766391\n",
      "train loss:0.0013471174227218145\n",
      "train loss:0.00034820203629368234\n",
      "train loss:0.0015490298086720594\n",
      "train loss:5.812925234752989e-05\n",
      "train loss:0.0006114573575673075\n",
      "train loss:0.001356651497529645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00018018821702175676\n",
      "train loss:0.005199891123463798\n",
      "train loss:0.002429513040914805\n",
      "train loss:0.0004164455235858762\n",
      "train loss:0.00036233840365647736\n",
      "train loss:0.0004270160589389745\n",
      "train loss:0.0026067226869112997\n",
      "train loss:0.0001427400092269864\n",
      "train loss:0.0005589050053401624\n",
      "train loss:0.0019024664524100404\n",
      "train loss:0.00041016951340726955\n",
      "train loss:0.0019399496756250549\n",
      "train loss:0.00012905464468911706\n",
      "train loss:7.134926900561124e-05\n",
      "train loss:0.0019228210451953057\n",
      "train loss:0.0006816429830347172\n",
      "train loss:0.0008598454162006809\n",
      "train loss:0.0005605098967827119\n",
      "train loss:0.000256650219868368\n",
      "train loss:0.0001932353965525057\n",
      "train loss:9.299730690752909e-05\n",
      "train loss:0.0002757923929743284\n",
      "train loss:0.013475486872409443\n",
      "train loss:3.701781238759435e-05\n",
      "train loss:0.0011359906504902185\n",
      "train loss:0.002655144688086762\n",
      "train loss:0.0009703288115350686\n",
      "train loss:0.0003551323312365457\n",
      "train loss:0.009273421426932844\n",
      "train loss:0.003557846063536924\n",
      "train loss:0.0013540155224437786\n",
      "train loss:0.0009613265749414237\n",
      "train loss:0.003777950236085184\n",
      "train loss:0.00014874172415812713\n",
      "train loss:8.502691378981917e-05\n",
      "train loss:0.0001712226844295019\n",
      "train loss:0.0021110348704239524\n",
      "train loss:0.00011154995633780525\n",
      "train loss:0.0010053909030993988\n",
      "train loss:0.001052650795519832\n",
      "train loss:7.97325369173739e-05\n",
      "train loss:0.001311465821384005\n",
      "train loss:0.00033109230087206474\n",
      "train loss:0.0006224214682331104\n",
      "train loss:0.0019895850000112895\n",
      "train loss:0.00326895252749358\n",
      "train loss:0.0014111321695501602\n",
      "train loss:0.00018322874779224066\n",
      "train loss:0.002493126352135178\n",
      "train loss:0.002065646201981223\n",
      "train loss:0.0004356947055453572\n",
      "train loss:0.0008650989407076964\n",
      "train loss:0.0035900623245304865\n",
      "train loss:0.0013836225306353277\n",
      "train loss:0.00393057659489306\n",
      "train loss:0.001741235544288354\n",
      "train loss:0.0008509726287980997\n",
      "train loss:0.0004652471259995508\n",
      "train loss:6.872979920650788e-05\n",
      "train loss:9.28550975464186e-05\n",
      "train loss:0.00017529223478352128\n",
      "train loss:0.0028244636614102574\n",
      "train loss:0.00020846563528319087\n",
      "train loss:7.541630994159772e-05\n",
      "train loss:0.0009280166148698046\n",
      "train loss:0.0017643671951086055\n",
      "train loss:4.606998738826433e-05\n",
      "train loss:0.00038547415775211537\n",
      "train loss:0.006888419228211402\n",
      "train loss:0.0015227270208994059\n",
      "train loss:0.0002584974256230831\n",
      "train loss:0.0004639023742402592\n",
      "train loss:0.00048807572837528514\n",
      "train loss:0.0006525007282168612\n",
      "train loss:0.0019516918980590902\n",
      "train loss:0.00025989386759897115\n",
      "train loss:0.0003213778748554201\n",
      "train loss:0.0003461561799490831\n",
      "train loss:9.613082452344074e-05\n",
      "train loss:0.032508457599834714\n",
      "train loss:6.822679874629113e-05\n",
      "train loss:0.0005271119355292435\n",
      "train loss:0.0016836161807181366\n",
      "train loss:0.003677985169109366\n",
      "train loss:0.00015013720206210829\n",
      "train loss:0.0006946302653026431\n",
      "train loss:0.001572372050842004\n",
      "train loss:0.004066966817253213\n",
      "train loss:0.00044928314211226095\n",
      "train loss:0.0010829301280914122\n",
      "train loss:0.0011548310587179327\n",
      "train loss:0.001045380080737861\n",
      "train loss:0.000870495747833884\n",
      "train loss:0.00019194040722500346\n",
      "train loss:0.0006020139943561737\n",
      "train loss:0.00030520930374568716\n",
      "train loss:0.0053093740634273\n",
      "train loss:0.001955276916988451\n",
      "train loss:0.0008015130232975293\n",
      "train loss:0.001575278197101092\n",
      "train loss:5.47666923186475e-05\n",
      "train loss:0.0002560887659685265\n",
      "train loss:0.0006478107755852853\n",
      "train loss:0.00019195200171028549\n",
      "train loss:0.00031689623578281574\n",
      "train loss:0.0014539795352951285\n",
      "train loss:0.005237465844455689\n",
      "train loss:0.0006181238375173992\n",
      "train loss:5.439896387147264e-05\n",
      "train loss:0.0005247653475525996\n",
      "train loss:0.0001287029627214154\n",
      "train loss:0.0014488833523885348\n",
      "train loss:0.0020178591735854987\n",
      "train loss:0.0002895445898844694\n",
      "train loss:6.632708587845116e-05\n",
      "train loss:0.0004971998759113347\n",
      "train loss:0.0014316939262405237\n",
      "train loss:0.0025462500971571217\n",
      "train loss:0.00037699644666704286\n",
      "train loss:0.00020870910012820083\n",
      "train loss:0.0003361897144325821\n",
      "train loss:8.952897738694331e-05\n",
      "train loss:0.0007926842767672785\n",
      "train loss:0.0016370792564167316\n",
      "train loss:0.0025252965964021206\n",
      "train loss:6.3247662439796085e-06\n",
      "train loss:0.002042536449087795\n",
      "train loss:0.003776711372409484\n",
      "train loss:0.0005394656154630729\n",
      "train loss:0.004362295197396715\n",
      "train loss:0.00043916707165724217\n",
      "train loss:0.0001000568611807786\n",
      "train loss:0.007528582642431867\n",
      "train loss:0.0023586968057283855\n",
      "train loss:0.0009420145683307372\n",
      "train loss:0.0005790339647704336\n",
      "train loss:0.00316302456942726\n",
      "train loss:0.0001963452637002797\n",
      "train loss:0.002508355259442975\n",
      "train loss:0.00017143174317797691\n",
      "train loss:0.006297411614781581\n",
      "train loss:0.0008947238814455204\n",
      "train loss:0.0003099840283396708\n",
      "train loss:9.374822780861832e-05\n",
      "train loss:0.00022984638196813499\n",
      "train loss:0.002600095906928333\n",
      "train loss:0.00025062584510502956\n",
      "train loss:0.00041555438316843795\n",
      "train loss:0.0003257842408265542\n",
      "train loss:0.00015505923662693344\n",
      "train loss:0.0002641717098456201\n",
      "train loss:0.0004912960880471978\n",
      "train loss:0.0038407416716790457\n",
      "train loss:0.0011756695156025427\n",
      "train loss:0.0001356901512231353\n",
      "train loss:0.0004592535615379617\n",
      "train loss:0.00014980347602441233\n",
      "train loss:0.0036562455186250342\n",
      "train loss:0.005591305311830682\n",
      "train loss:0.001009555790481107\n",
      "train loss:0.000635543351352858\n",
      "train loss:0.0010171347840357667\n",
      "train loss:0.00043238685093800587\n",
      "train loss:0.000688051926479487\n",
      "train loss:0.0002631671724662751\n",
      "train loss:0.0001002645045379231\n",
      "train loss:0.0007237354894277573\n",
      "train loss:0.0008824964299642268\n",
      "train loss:0.0010049689670139968\n",
      "train loss:0.0016881107019110647\n",
      "train loss:0.0024547649665083403\n",
      "train loss:0.00026465867365748106\n",
      "train loss:0.00012024861363234615\n",
      "train loss:0.0004041064961701129\n",
      "train loss:0.002531925494644389\n",
      "train loss:1.9749391051698778e-05\n",
      "train loss:0.0028547180141737984\n",
      "train loss:0.0001223320705637875\n",
      "train loss:0.0028274553048498368\n",
      "train loss:0.00017493858157785643\n",
      "train loss:9.128552929927579e-05\n",
      "train loss:0.0001670824939469257\n",
      "train loss:0.0014305431050382937\n",
      "train loss:0.000535599945240939\n",
      "train loss:7.335166135032879e-05\n",
      "train loss:0.0013629168233196046\n",
      "train loss:0.0005868713840878019\n",
      "train loss:0.00037883537617572447\n",
      "train loss:0.00303040641463181\n",
      "train loss:0.0006313363108827771\n",
      "train loss:0.0007500496212902573\n",
      "train loss:0.00028045049665535596\n",
      "train loss:0.0014728153751838835\n",
      "train loss:0.0014043484872448833\n",
      "train loss:9.832114434016932e-05\n",
      "train loss:0.0008249557234338186\n",
      "train loss:6.216376812692655e-05\n",
      "train loss:0.001119631331777204\n",
      "train loss:0.0022375567368491723\n",
      "train loss:0.0029907300143948903\n",
      "train loss:0.000690815003934982\n",
      "train loss:0.00012059865484105909\n",
      "train loss:0.003396246419588125\n",
      "train loss:0.00016815619469758163\n",
      "train loss:0.0004049153251560828\n",
      "train loss:0.00024248418681076348\n",
      "train loss:9.916166998531069e-05\n",
      "train loss:4.901204640660794e-05\n",
      "train loss:0.0003848636641306483\n",
      "train loss:0.0002425388360389354\n",
      "train loss:0.00048492037032482247\n",
      "train loss:0.0003136385926960101\n",
      "train loss:0.0008064205772528577\n",
      "train loss:0.00015136611648081994\n",
      "train loss:0.0019093207481834925\n",
      "train loss:0.0002549471635447737\n",
      "train loss:4.422785155119202e-05\n",
      "train loss:0.00016286555776876745\n",
      "train loss:0.0011398608234596103\n",
      "train loss:0.013714511979892208\n",
      "train loss:0.0003617464308894276\n",
      "train loss:2.111529378253056e-05\n",
      "train loss:0.0002835913549580176\n",
      "train loss:0.00014422977318269317\n",
      "train loss:0.0012538058307079393\n",
      "train loss:0.0022986157912945203\n",
      "train loss:0.001124874889605987\n",
      "train loss:0.003500084346140729\n",
      "train loss:0.0006459289333927146\n",
      "train loss:0.00037937821764001597\n",
      "train loss:0.00010946920487541064\n",
      "train loss:0.0003077343175954855\n",
      "train loss:0.008478700891080259\n",
      "train loss:0.00041520962362500004\n",
      "train loss:0.0004466674538616878\n",
      "train loss:0.0004722219328418247\n",
      "train loss:0.00020127822776470496\n",
      "train loss:0.00018326565401718918\n",
      "train loss:0.00027775956625673186\n",
      "train loss:0.0005944304958133616\n",
      "train loss:0.0016168771411707765\n",
      "train loss:0.00019434962588942332\n",
      "train loss:0.00013059038827772866\n",
      "train loss:0.0010507964591856124\n",
      "train loss:0.00033344149512818717\n",
      "train loss:0.0002762056287580008\n",
      "train loss:0.00018555535663677676\n",
      "train loss:1.4726524538149523e-05\n",
      "train loss:0.0006047750619533103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.026947845310998822\n",
      "train loss:0.0003015158535746494\n",
      "train loss:0.00019421404145461877\n",
      "train loss:8.873589469095554e-06\n",
      "train loss:2.7396201296218792e-05\n",
      "train loss:0.0002809863416270537\n",
      "train loss:0.0025135995996352217\n",
      "train loss:0.00023895324453211873\n",
      "train loss:0.004022120856316499\n",
      "train loss:0.00015324271592649468\n",
      "train loss:0.00021315857534416748\n",
      "train loss:0.0011811854810282077\n",
      "train loss:0.008947717261315933\n",
      "train loss:0.0007586556433259476\n",
      "train loss:0.0019711284271473396\n",
      "train loss:5.158364208301291e-05\n",
      "train loss:0.0003319073624990832\n",
      "train loss:0.001002842271359857\n",
      "train loss:1.1008497115842369e-05\n",
      "train loss:0.011412172487191936\n",
      "train loss:0.0005834808073173993\n",
      "train loss:0.0026532358272846513\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9893\n",
      "Saved Network Parameters!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3de5gkBXnv8e/b3dM903O/sLDsoiwEQTQKuqIGMRKjsGgEcxLjNYbErETI0TwHApwcFXN5QkI0Hk6UDXqIGu8KitFV8IL65CiBXVju4C4oMLuwO/f7TE93v+ePqtntne2e6dmdmp7t+n2ep5/urqruerump39d1VVvmbsjIiLxlah1ASIiUlsKAhGRmFMQiIjEnIJARCTmFAQiIjGnIBARibnIgsDMbjKzfWb2YIXxZmbXm9kuM7vfzF4SVS0iIlJZlGsEnwHOX2D8JuCU8LIZuCHCWkREpILIgsDdfwoMLjDJhcDnPHAn0GFma6OqR0REykvVcN7rgKdL7veGw56ZP6GZbSZYa6C5ufmlp5122ooUWC+GJ2d5dnSa2UKRhmSC49oa6cg21LqsFVFwx595kBT5Q8blSZFY++skbHnmlS86hYKTLxbJFz24X3S6xh4jRaHM/JM823QKCQMzwwyM4HbCwAiHGSTMMMABd8cdiqW33cNx4TDCYQ7HT++qOP9fpk4Ch+AR4eNh/7ADtwNztczVnLS5eoNhiURwu3S6faMzFMp0MEgmjLXtjfuf38MCDtyuXIuHN+ae1b38MHDWzTxe8fXvzvza/uVOuMznXufc28LCZY8dvHz3L/eDhjlFP1BP0WG2UDxk3nMStrQ3X09LmmPbGpf0mDnbt2/vd/djyo2rZRCUWwJl+124+43AjQAbN270bdu2RVlXXZn++5NonBk4dHimm8arn1iZIq47BSb2HTq8eQ1csbPqpykUneHJHIMTOQYmcgyF14MTB4YNTswwMJ5jKJxutuD8qvHtFZ/zxOmPkEwYLZkULZkUrY3BdUvjwfebMymy6SRj0/lgPuNz85xhaHKWockc5bq1JIAdC8z/5en/TS5fDC6FIrOFA0+y/wMRynyMHWBAkuCDNZ1MkE6Fl2SCTCrBj8YvrPjYv3jO9RQtDak0xUSaZDJJImEkzUglgw/1VML2f8Dn8kWmZgvBJRdcJmcLTOcKTM7mmcoVmZ4tMJnLUwyLfzLzZxxjI4fMu8/bednMP1d8TaXXhK8vOVdbWNNB12HNSbMD0yaM7wy+seLrP699C/likaITXBeD60IRCsUihTDMCx5cH1jGSTIlyzld7nYqQSaZ4OqH31Tx9X/q5bdVrK2cV57UzbmnrVnSY+aY2ZOVxtUyCHqBE0rurwf21KiW6CzTh+Acd2d8Js/I1CzDk7OMTs0yPDXLSHgZngyuRydzjE1N8rkyIQDQODPACz70vZJ/mATJBKQSCRJz1zZ3P/hHSyaMxoYE2XSKpoYkTekkTQ1JsukkjeH9udvZcFxTOslvlHv9ABP7uOUnd1EYH8Am+rGpfpJTg6RnBsnkhsjODpEtjNBWGKHdR2hnnFYSZGigmxQ5Gsh5cJ1PNFBMpPFkGktmsEyGRHOGZLoR9lZenl879cdMF42ZPEwVYCpvTE/D1LgxmXcm88bkrDOQhwIJkua0pRM8L2O0pI22jNHSGtxuboDmhgTNDU42ZWRTTmMK+H+V5/9f72iGpg5o7ICmTorJDLlCEAr7AyJ/4H4qefCHfYYCmek+GiaeITm+B0afgdE9MLo7uB47ZAX7IP/81O8fPCCRgmQGUul51xlIpiHTApk2aGqFjlZIt0CmNby07b/tmRZyqRamLUv7Jw79EAQ4xkb4+cXHkSqMk5ydIDU7TnJ2jERunOTsOIncGJYLr2fGIDcefNVOpCCRDC6WLHM/HDZ3e4EN1LedtnXB5XOIRDJcFgsso7nruduPVH79//O0vZDPQWEG8jNQmA1vlw7LHbi2VxP8vLq8LMqmc2Z2IvBtd39hmXFvAC4DLgBeDlzv7mct9pxH3RrBNe0LjAveIJ6fYWyon6HBfYwO7mNiZIDp0QFmxwcoTA7D9DCpmWFSs2MkijnSzIaX/IFrC64zzJK24HoxE6lOZpJZphPNTCeC66lElinL7r+etCYmyTJpWSZIU8znKc5O4/kZPHyzWiEHhaCmjOUPqe0PUj9e0iIrkGDcWhlPtjPZ0MFUQye5dBeFxg6aUkZzskBTokBTIk9jIk+aPMlibt4/Tck/0+AKrfkcwoIPpOLif4v9Uo37Q6E0IGjqCD5kJwcP/qCf6OOQFemGLLQdH17WwX1fqjy/C/7p4A+aSsswn4P8NOQmgg/kmVGYGYPpUfCF1leOQLq1JGRagtCxBBTz4MXgulgI7xfC22Xujy3w/TKzwP/nITx47vxMdK+5kmQYNq+8FM69+rCewsy2u/vGcuMiWyMwsy8BrwF6zKwX+DDQAODuW4CtBCGwC5gELo6qltWq/69PJlscJ8s0bUBbhekmLMtUso1cY0vwQZHKkkhlSDRkSDY0kko3kso0kk43kkpnsNJvLD/624rzbz7jd2meGQv+oWfGwn/uPQfuF2aqeyEJDtrtwJMZislgU0MxkQ7+uhWM/vZ1pFt7yLSvwZqPgWwPyaYO2hNJlvIvuqCFwvjDw2U+PCp90BTDjeSpQ791zv92aklIJBaf/7u+AVNDMBUE/v7bU0MwPQIjvfDsA8G43Dg0tgcf7m3Hw9oXBbdb1x4Y1nZ8ME3ptueFguCsP13aspzPPQiIg95DYwdftl5e+fG//9lD1ibIhGsaiWXal2Wh5X/1U4f3nMVC+bAs/RZfyAXDvvDfKj/PH22dtybRUH7tYom/JSxVZEHg7m9bZLwDl0Y1/5XmxSJ9e35J3867mXl6B5n+Bzlm4hcstDXv4caXUGxsx5o6STV3kWnrJtvWTWvnGjq6jqGlowdr7KA5maL5cAtbIAh448cWfmx+BmZKvv3NToabDtLz3qglq8fJhuBHRILt1sCC/4htr9q81Fe0vMwgmQoutXDyb1U/bbEQhMxqYgYNTcGlpcK7faEgeMFF0dQVtUQS0lkge2TPc+LZy1LOkarlbwRHpWLR2T04zp7H72f8yXtJ7n2AjtFHeW7ucdbYGGuAohtP2XHszJzKmkLlDdSv/suvrVzhhyMVfjNp7q51JUemeU3l32mOpvkfbgjU+vXXWtxffxUUBFXq3bOH+z53BeumHuVUnuIEywGQI0Vvw4k80fOb5Nf8OtnnnMHa572M53Z1caLZwqulK2E1/BPUuobD+FFe819Gcf/71/r1V0FBUKXd27/DG6a/zZPNL+TJNW8hs/4Mun9tI20nvJCTkgvsk1/rN0Gt/wlWSw1SO3H/+x8Fr19BUKXiWLCJp+s9N9PadVz1DzwK3gQiEm/qPlql4ng/eU/Q0lH2wDwRkaOWgqBKyal+hq0NW217bYiIHCEFQZXS0wOMJjtqXYaIyLJTEFQpOzvIZENXrcsQEVl2CoIqtRSGmUkrCESk/igIquDudBRHyDcd5QdWiYiUoSCowuTEOC02Bc3aY0hE6o+CoArD/UEr30SLgkBE6o+CoApjg0EQZNqPrXElIiLLT0FQhamhZwFo6lzCEcUiIkcJBUEVZkeCIGjpWlvjSkRElp+CoAr5sT4AOnqOr3ElIiLLT0FQBZvoZ9IzNLVUOoeYiMjRS0FQhdR0PyOJGp9XQEQkIgqCKmRmBhlTnyERqVMKgipk80NMqc+QiNQpBUEV2grD5BrVXkJE6pOCYBHFQpFOH6GQ7al1KSIikVAQLGJspJ8GK6jPkIjULQXBIob79gCQal2hk82LiKwwBcEiJvb3GVJ7CRGpTwqCRUyP7AWguUtBICL1SUGwiNmRfQC09ajPkIjUJwXBIorjYZ+hbq0RiEh9UhAswqb6GKKVVEO61qWIiERCQbCI9PQAowm1lxCR+qUgWERjbpDxlIJAROqXgmARLfkhptPqMyQi9UtBsIj24jCz6jMkInVMQbCA2dw07Uzg6jMkInVMQbCAkf7gXMXWovYSIlK/Ig0CMzvfzB4zs11mdlWZ8e1m9h9mdp+ZPWRmF0dZz1KN9AftJdJtCgIRqV+RBYGZJYFPAJuA04G3mdnp8ya7FHjY3V8MvAb4qJmtmh32J4eDIGjs0MFkIlK/olwjOAvY5e5PuHsO+DJw4bxpHGg1MwNagEEgH2FNS5IL+wy16KhiEaljUQbBOuDpkvu94bBS/wI8H9gDPAC8392L85/IzDab2TYz29bX1xdVvYfIjwbzau9Zv2LzFBFZaVEGgZUZ5vPunwfsAI4HzgD+xczaDnmQ+43uvtHdNx5zzMqdIMYn+sh5irb2zhWbp4jISosyCHqBE0ruryf45l/qYuAWD+wCfgmcFmFNS5Kc7GfI2rGEdq4SkfoV5Sfc3cApZrYh/AH4rcC35k3zFPBaADM7FjgVeCLCmpYkPTPAaFLtJUSkvqWiemJ3z5vZZcBtQBK4yd0fMrNLwvFbgL8BPmNmDxBsSrrS3fujqmmpmmaHmGzQZiERqW+RBQGAu28Fts4btqXk9h7g9VHWcCRaC0MMZzfUugwRkUhp43cl7nQUR8g3qc+QiNQ3BUEFUxOjNFkOmlduLyURkVpQEFQw3LcbgGSr2kuISH1TEFQwPhC0l8i0KwhEpL4pCCqYGg46j6rPkIjUOwVBBbmRfQC0da+tcSUiItFSEFRQGA+CoOMYBYGI1DcFQQU20c+YN5HNttS6FBGRSCkIKkhN9zOcUHsJEal/CoIKMjODjKvPkIjEgIKggub8EFPprlqXISISOQVBBW2FYXIZtZcQkfqnICjDC3nafZRCtqfWpYiIRE5BUMbYcB9Jc0x9hkQkBhQEZYz0BSdSS7WpvYSI1D8FQRkTQ0F7iUz7sTWuREQkegqCMqbDPkPNXeozJCL1T0FQxuxo2Geo5/gaVyIiEj0FQRk+vo+CGx1d2jQkIvVPQVBGYrKfIWsj3RDpKZ1FRFYFBUEZDdMDjKjPkIjEhIKgjKbcIBOpzlqXISKyIhQEZTTnh5hWnyERiQkFQRntPsJso/oMiUg8KAjmyU9P0MIUnlV7CRGJBwXBPCMDwcFkiVYFgYjEg4JgnrGBoM9QQ6uOIRCReFAQzDMZ9hlq6lQQiEg8KAjmmRkJ2ku0dK+tcSUiIitDQTBPfmwvAG3d6jMkIvGgIJhvvJ9Jz9DRriOLRSQeFATzJKf6GbJ2EgmrdSkiIitCQTBPemaQsaTWBkQkPhQE82RnB5lsUJ8hEYmPSIPAzM43s8fMbJeZXVVhmteY2Q4ze8jMfhJlPdVoLQwxk1F7CRGJj8ga7ptZEvgE8DqgF7jbzL7l7g+XTNMBfBI4392fMrPani3enY7iCIUmBYGIxEeUawRnAbvc/Ql3zwFfBi6cN83bgVvc/SkAd98XYT2Lmh4bpMEK0Kz2EiISH1EGwTrg6ZL7veGwUs8DOs3sx2a23cz+sNwTmdlmM9tmZtv6+voiKhdG+oP2EskWBYGIxEeUQVBu/0ufdz8FvBR4A3Ae8EEze94hD3K/0d03uvvGY46J7kN6fPAZABra1V5CROKjqiAws5vN7A1mtpTg6AVOKLm/HthTZprvufuEu/cDPwVevIR5LKup4aDPULbzuFqVICKy4qr9YL+BYHv+TjO71sxOq+IxdwOnmNkGM0sDbwW+NW+aW4FzzCxlZlng5cAjVda07HJhn6E29RkSkRipaq8hd/8B8AMzawfeBnzfzJ4GPgV83t1nyzwmb2aXAbcBSeAmd3/IzC4Jx29x90fM7HvA/UAR+LS7P7gsr+wwFMeCIOjoURCISHxUvfuomXUD7wTeBdwLfAF4FfBu4DXlHuPuW4Gt84ZtmXf/OuC6pRQdFZvsZ8hb6GhqrHUpIiIrpqogMLNbgNOAfwd+x92fCUd9xcy2RVXcSktO9TOSaKfT1GdIROKj2jWCf3H3H5Ub4e4bl7GemmrMDTKeVHsJEYmXan8sfn54FDAAZtZpZu+LqKaaac4PMZnuqnUZIiIrqtog+FN3H5674+5DwJ9GU1LttBWGyanPkIjETLVBkDA7sOE87COUjqak2vB8jnbGKWZ7al2KiMiKqvY3gtuAr5rZFoKjgy8BvhdZVTUwMbyXFsDUXkJEYqbaILgSeC/wZwStI24HPh1VUbUw0v8MLUCqtbYNUEVEVlq1B5QVCY4uviHacmpnYjDoftHYoT5DIhIv1R5HcArw98DpwP6jrdz9pIjqWnHTw3sBaO7UUcUiEi/V/lj8bwRrA3ngXOBzBAeX1Y38aNhnSO0lRCRmqg2CJnf/IWDu/qS7XwP8VnRlrTyf6CPnSTq7tNeQiMRLtT8WT4ctqHeGjeR2A3X1q2pisp8ha+fYhsjO3ikisipVu0bwASAL/HeCE8m8k6DZXN1omB5gJNGx+IQiInVm0a+/4cFjb3H3K4Bx4OLIq6qBptwgoyn1GRKR+Fl0jcDdC8BLS48srkfN+WGm1WdIRGKo2g3i9wK3mtnXgIm5ge5+SyRVrTR3OnyY2Ub1GRKR+Kk2CLqAAQ7eU8iBugiCwsw4jeSgWXsMiUj8VHtkcV3+LjBntH8PnUBCfYZEJIaqPbL43wjWAA7i7n+87BXVwNjAM3QCDW3H1boUEZEVV+2moW+X3G4E3gzsWf5yamNyKGgv0dipPkMiEj/Vbhq6ufS+mX0J+EEkFdXAzMizALR0HV/jSkREVl61B5TNdwrwnOUspJYKY30AtPdo05CIxE+1vxGMcfBvBM8SnKOgPkz0MepNdLa11boSEZEVV+2modaoC6ml5FQ/w9ZOW6Kuj5kTESmrqk1DZvZmM2svud9hZhdFV9bKyswMMJZUnyERiadqfyP4sLuPzN1x92Hgw9GUtPKaZoeYbFB7CRGJp2qDoNx0ddOvubUwxExGQSAi8VRtEGwzs4+Z2clmdpKZ/TOwPcrCVkyxQLuPUmhSewkRiadqg+DPgRzwFeCrwBRwaVRFraTc2ABJHLIKAhGJp2r3GpoAroq4lpoY7d9DD5Bsq6sTromIVK3avYa+b2YdJfc7zey26MpaOWODzwCQblN7CRGJp2o3DfWEewoB4O5D1Mk5i6eGgz5D2U4dVSwi8VRtEBTNbH9LCTM7kTLdSI9GuZEgCFp71GdIROKp2l1A/wr4TzP7SXj/1cDmaEpaWcXxfRTc6OyuixUcEZElq/bH4u+Z2UaCD/8dwK0Eew4d9WyynyHa6G7K1LoUEZGaqPbH4vcAPwT+R3j5d+CaKh53vpk9Zma7zKziXkdm9jIzK5jZ71VX9vJJTQ0wnOjATH2GRCSeqv2N4P3Ay4An3f1c4Eygb6EHmFkS+ASwCTgdeJuZnV5hun8AarIXUmNukPGU+gyJSHxVGwTT7j4NYGYZd38UOHWRx5wF7HL3J9w9B3wZuLDMdH8O3Azsq7KWZdU8O8SU+gyJSIxVGwS94XEE3wS+b2a3svipKtcBT5c+RzhsPzNbR3Dayy0LPZGZbTazbWa2ra9vwRWRJWsrDjOb6V7W5xQROZpU+2Pxm8Ob15jZHUA78L1FHlZuo/v8XU4/Dlzp7oWFttG7+43AjQAbN25ctt1WfXaKFiYpZBUEIhJfS+4g6u4/WXwqIFgDOKHk/noOXYvYCHw5DIEe4AIzy7v7N5da1+GYGtpLFrAW7ToqIvEVZSvpu4FTzGwDsBt4K/D20gncfcPcbTP7DPDtlQoBCPoMZYFUq4JAROIrsiBw97yZXUawN1ASuMndHzKzS8LxC/4usBLGh54FoKlDfYZEJL4iPbmMu28Fts4bVjYA3P2PoqylnOmwz1Bz19qVnrWIyKpR7V5DdSk/GgRBm/oMiUiMxToIfKKPKU/T1aEDykQkvmIdBInJfgZppzFdN6dfFhFZslgHQXpmgNGk1gZEJN5iHQRNuSEm1GdIRGIu1kHQnB9iOq2jikUk3uIbBO50+Aj5JgWBiMRbbIOgODVMA3k821PrUkREaiq2QTA2EBxVrD5DIhJ38Q2CwWcASLervYSIxFtsg2AyDIKmjuNqXImISG3FNghyo8EJ0Vq6FAQiEm+xDYJC2GeovUdBICLxFtsg8Ik+hryFrtbmWpciIlJTsQ2C1FQ/Q9ZOKhnbRSAiAsQ4CNIzg4ypz5CISHyDIDs7xFRDZ63LEBGpudgGQWthmJmM2kuIiMQzCAqztDNGoUntJUREYhkEs2N9wY1mBYGISCyDYGwgOKo42ao+QyIisQ6CjPoMiYjEMwimhoPOo9lOHVUsIhLLIJgN+wy1dq+tcSUiIrUXyyAojO0j50m6uvQbgYhILIMgMdnPIO20ZRtqXYqISM3FMghS0wMMJ9oxs1qXIiJSc7EMgsbcIONJtZcQEYGYBkHL7CDT6a5alyEisirELwjcaSsOk2tUEIiIQByDIDdBIzmKTcfUuhIRkVUhdkEwdzCZtajPkIgIxDAIRvuD9hINbWovISICMQyCiaFgjaCxQ0EgIgIRB4GZnW9mj5nZLjO7qsz4d5jZ/eHlZ2b24ijrAZgJNw01d6m9hIgIRBgEZpYEPgFsAk4H3mZmp8+b7JfAb7r7i4C/AW6Mqp45+bGgz1B7txrOiYhAtGsEZwG73P0Jd88BXwYuLJ3A3X/m7kPh3TuB9RHWE8xzvI8xb6Kroz3qWYmIHBWiDIJ1wNMl93vDYZX8CfDdciPMbLOZbTOzbX19fUdUVGKqn0HayKZTR/Q8IiL1IsogKNfIx8tOaHYuQRBcWW68u9/o7hvdfeMxxxzZ/v/p6UFGkx1H9BwiIvUkyiDoBU4oub8e2DN/IjN7EfBp4EJ3H4iwHgAaZweZSKnPkIjInCiD4G7gFDPbYGZp4K3At0onMLPnALcA73L3X0RYy34t+SFm1GdIRGS/yDaUu3vezC4DbgOSwE3u/pCZXRKO3wJ8COgGPhm2hM67+8aoaqJYpN1HyTd1RzYLEZGjTaS/mLr7VmDrvGFbSm6/B3hPlDUcNO+pQZIUKTbrzGQiInNitevM+OCztALJFjWcE4mb2dlZent7mZ6ernUpkWpsbGT9+vU0NFR/BsZYBcFY/25agYY2rRGIxE1vby+tra2ceOKJdXt2QndnYGCA3t5eNmzYUPXjYtVraGp4LwBNHTqqWCRupqen6e7urtsQADAzuru7l7zWE6sgmBkJ+gy1dKvPkEgc1XMIzDmc1xirICiM9VFwo7NbnUdFRObEKgiY6GOQVjpbmmpdiYisct+8dzdnX/sjNlz1Hc6+9kd8897dR/R8w8PDfPKTn1zy4y644AKGh4ePaN6LiVUQJKcGGLZ20qlYvWwRWaJv3rubq295gN3DUziwe3iKq2954IjCoFIQFAqFBR+3detWOjqibYsTq72GMjMDjCTVXkIk7j7yHw/x8J7RiuPvfWqYXKF40LCp2QJ/+fX7+dJdT5V9zOnHt/Hh33lBxee86qqrePzxxznjjDNoaGigpaWFtWvXsmPHDh5++GEuuuginn76aaanp3n/+9/P5s2bATjxxBPZtm0b4+PjbNq0iVe96lX87Gc/Y926ddx66600NR35Fo5YfTXOzg4x1aAgEJGFzQ+BxYZX49prr+Xkk09mx44dXHfdddx111383d/9HQ8//DAAN910E9u3b2fbtm1cf/31DAwc2npt586dXHrppTz00EN0dHRw8803H3Y9pWK1RtBWGGamRe0lROJuoW/uAGdf+yN2D08dMnxdRxNfee8rl6WGs84666B9/a+//nq+8Y1vAPD000+zc+dOursP/rzasGEDZ5xxBgAvfelL+dWvfrUstcRnjWB2mmYmKajPkIgs4orzTqWpIXnQsKaGJFecd+qyzaO5uXn/7R//+Mf84Ac/4Oc//zn33XcfZ555ZtljATKZzP7byWSSfD6/LLXU/xrBdafAxL79d1/37Kfgmk9B8xq4YmcNCxOR1eqiM4NzaF1322PsGZ7i+I4mrjjv1P3DD0draytjY2Nlx42MjNDZ2Uk2m+XRRx/lzjvvPOz5HI76D4KSEKhquIgIQRgcyQf/fN3d3Zx99tm88IUvpKmpiWOPPXA80/nnn8+WLVt40YtexKmnnsorXvGKZZtvNeo/CEREVokvfvGLZYdnMhm++92yZ+rd/ztAT08PDz744P7hl19++bLVFZ/fCEREpCwFgYhIzCkIRERiru6DYDpTfnfRSsNFROKm7n8sbrz6Cb557+5l3Q1MRKSe1H0QwPLvBiYiUk9iEQQiIksy70DU/Y7gQNTh4WG++MUv8r73vW/Jj/34xz/O5s2byWazhzXvxdT9bwQiIksWwYGoh3s+AgiCYHJy8rDnvRitEYhI/Hz3Knj2gcN77L+9ofzw434dNl1b8WGlbahf97rXsWbNGr761a8yMzPDm9/8Zj7ykY8wMTHBW97yFnp7eykUCnzwgx9k79697Nmzh3PPPZeenh7uuOOOw6t7AQoCEZEVcO211/Lggw+yY8cObr/9dr7+9a9z11134e686U1v4qc//Sl9fX0cf/zxfOc73wGCHkTt7e187GMf44477qCnpyeS2hQEIhI/C3xzB+Ca9srjLv7OEc/+9ttv5/bbb+fMM88EYHx8nJ07d3LOOedw+eWXc+WVV/LGN76Rc84554jnVQ0FgYjICnN3rr76at773vceMm779u1s3bqVq6++mte//vV86EMfirwe/VgsIjJf85qlDa9CaRvq8847j5tuuonx8XEAdu/ezb59+9izZw/ZbJZ3vvOdXH755dxzzz2HPDYKWiMQEZkvgnOVlLah3rRpE29/+9t55SuDs521tLTw+c9/nl27dnHFFVeQSCRoaGjghhtuAGDz5s1s2rSJtWvXRvJjsbn7sj9plDZu3Ojbtm2rdRkicpR55JFHeP7zn1/rMlZEuddqZtvdfWO56bVpSEQk5hQEIiIxpyAQkdg42jaFH47DeY0KAhGJhcbGRgYGBuo6DNydgYEBGhsbl/Q47TUkIrGwfv16ent76evrq3UpkWpsbGT9+vVLeoyCQERioaGhgQ0bNtS6jFUp0k1DZna+mT1mZrvM7Koy483Mrg/H329mL4myHhEROVRkQdaCtG4AAAb5SURBVGBmSeATwCbgdOBtZnb6vMk2AaeEl83ADVHVIyIi5UW5RnAWsMvdn3D3HPBl4MJ501wIfM4DdwIdZrY2wppERGSeKH8jWAc8XXK/F3h5FdOsA54pncjMNhOsMQCMm9ljh1lTD9B/mI9dCau9Plj9Naq+I6P6jsxqru+5lUZEGQRWZtj8/baqmQZ3vxG48YgLMttW6RDr1WC11werv0bVd2RU35FZ7fVVEuWmoV7ghJL764E9hzGNiIhEKMoguBs4xcw2mFkaeCvwrXnTfAv4w3DvoVcAI+7+zPwnEhGR6ES2acjd82Z2GXAbkARucveHzOyScPwWYCtwAbALmAQujqqe0BFvXorYaq8PVn+Nqu/IqL4js9rrK+uoa0MtIiLLS72GRERiTkEgIhJzdRkEq7m1hZmdYGZ3mNkjZvaQmb2/zDSvMbMRM9sRXqI/e/XB8/+VmT0QzvuQ08HVePmdWrJcdpjZqJl9YN40K778zOwmM9tnZg+WDOsys++b2c7wurPCYxd8v0ZY33Vm9mj4N/yGmXVUeOyC74cI67vGzHaX/B0vqPDYWi2/r5TU9isz21HhsZEvvyPm7nV1Ifhh+nHgJCAN3AecPm+aC4DvEhzH8Argv1awvrXAS8LbrcAvytT3GuDbNVyGvwJ6Fhhfs+VX5m/9LPDcWi8/4NXAS4AHS4b9I3BVePsq4B8qvIYF368R1vd6IBXe/ody9VXzfoiwvmuAy6t4D9Rk+c0b/1HgQ7Vafkd6qcc1glXd2sLdn3H3e8LbY8AjBEdTH01WS2uQ1wKPu/uTNZj3Qdz9p8DgvMEXAp8Nb38WuKjMQ6t5v0ZSn7vf7u758O6dBMfx1ESF5VeNmi2/OWZmwFuALy33fFdKPQZBpbYVS50mcmZ2InAm8F9lRr/SzO4zs++a2QtWtLDg6O7bzWx72N5jvlWx/AiOTan0z1fL5TfnWA+Piwmv15SZZrUsyz8mWMsrZ7H3Q5QuCzdd3VRh09pqWH7nAHvdfWeF8bVcflWpxyBYttYWUTKzFuBm4APuPjpv9D0EmzteDPwf4JsrWRtwtru/hKA77KVm9up541fD8ksDbwK+VmZ0rZffUqyGZflXQB74QoVJFns/ROUG4GTgDIL+Yx8tM03Nlx/wNhZeG6jV8qtaPQbBqm9tYWYNBCHwBXe/Zf54dx919/Hw9lagwcx6Vqo+d98TXu8DvkGw+l1qNbQG2QTc4+5754+o9fIrsXduk1l4va/MNLV+L74beCPwDg83aM9XxfshEu6+190L7l4EPlVhvrVefingd4GvVJqmVstvKeoxCFZ1a4twe+L/BR5x949VmOa4cDrM7CyCv9PACtXXbGatc7cJflB8cN5kq6E1SMVvYbVcfvN8C3h3ePvdwK1lpqnm/RoJMzsfuBJ4k7tPVpimmvdDVPWV/u705grzrdnyC/028Ki795YbWcvltyS1/rU6igvBXi2/INib4K/CYZcAl4S3jeCkOY8DDwAbV7C2VxGsut4P7AgvF8yr7zLgIYI9IO4EfmMF6zspnO99YQ2ravmF888SfLC3lwyr6fIjCKVngFmCb6l/AnQDPwR2htdd4bTHA1sXer+uUH27CLavz70Pt8yvr9L7YYXq+/fw/XU/wYf72tW0/MLhn5l735VMu+LL70gvajEhIhJz9bhpSERElkBBICIScwoCEZGYUxCIiMScgkBEJOYUBCIRC7uhfrvWdYhUoiAQEYk5BYFIyMzeaWZ3hX3j/9XMkmY2bmYfNbN7zOyHZnZMOO0ZZnZnSS//znD4r5nZD8KGd/eY2cnh07eY2dfD/v9fKDny+Vozezh8nn+q0UuXmFMQiABm9nzgDwgahJ0BFIB3AM0EPY1eAvwE+HD4kM8BV7r7iwiOfp0b/gXgEx40vPsNgqNRIegy+wHgdIKjTc82sy6C1gkvCJ/nb6N9lSLlKQhEAq8FXgrcHZ5p6rUEH9hFDjQU+zzwKjNrBzrc/Sfh8M8Crw57yqxz928AuPu0H+jhc5e793rQQG0HcCIwCkwDnzaz3wXK9vsRiZqCQCRgwGfd/Yzwcqq7X1NmuoV6spRriTxnpuR2geDMYHmCTpQ3E5y05ntLrFlkWSgIRAI/BH7PzNbA/vMNP5fgf+T3wmneDvynu48AQ2Z2Tjj8XcBPPDivRK+ZXRQ+R8bMspVmGJ6Tot2DVtkfIOi7L7LiUrUuQGQ1cPeHzex/EZxJKkHQZfJSYAJ4gZltB0YIfkeAoK30lvCD/gng4nD4u4B/NbO/Dp/j9xeYbStwq5k1EqxN/MUyvyyRqqj7qMgCzGzc3VtqXYdIlLRpSEQk5rRGICISc1ojEBGJOQWBiEjMKQhERGJOQSAiEnMKAhGRmPv/Jil4KygHj7AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from simple_convnet import SimpleConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 시간이 오래 걸릴 경우 데이터를 줄인다.\n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 매개변수 보존\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from simple_convnet import SimpleConvNet\n",
    "\n",
    "def filter_show(filters, nx=8, margin=3, scale=10):\n",
    "    \"\"\"\n",
    "    c.f. https://gist.github.com/aidiary/07d530d5e08011832b12#file-draw_weight-py\n",
    "    \"\"\"\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(FN):\n",
    "        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "network = SimpleConvNet()\n",
    "# 무작위(랜덤) 초기화 후의 가중치\n",
    "filter_show(network.params['W1'])\n",
    "\n",
    "# 학습된 가중치\n",
    "network.load_params(\"params.pkl\")\n",
    "filter_show(network.params['W1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
