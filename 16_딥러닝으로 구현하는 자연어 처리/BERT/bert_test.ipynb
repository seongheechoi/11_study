{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bert_test.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"EbD6tnUxPdce"},"source":["# 학습 전 폴더 구조\n","```bash\n","├── BERT/                     \n","    ├── bert_test.py                               - 실행파일\n","    │ \n","    ├── src/                                       - BERT 공식 코드 폴더\n","    │   ├── make_vocab/                            \n","    │   │          └── wordpiece.py                - BERT vocab 생성 코드\n","    │   │          \n","    │   ├── make_preprocessed_data/  \n","    │   │          ├── tokenization.py             - 학습데이터 전처리 코드\n","    │   │          └── create_pretraining_data.py  - 학습데이터 전처리 코드\n","    │   │          \n","    │   └── make_bert_model/                       - BERT 학습 코드\n","    │              ├── tokenization.py  \n","    │              ├── run_squad.py                - KorQuAD 학습에 필요한 파일\n","    │              ├── run_pretraining.py  \n","    │              ├── run_multi_classifier.py     - 관계 추출 실습에 필요한 파일\n","    │              ├── run_classifier.py           - 감정분류 학습에 필요한 파일  \n","    │              ├── optimization.py  \n","    │              ├── modeling.py  \n","    │              ├── extract_features.py  \n","    │              └── evaluate.py     \n","    │ \n","    └── rsc/               \n","        ├── trainig_data/                         - 학습할 데이터\n","        │     ├── wiki_20190620.txt\n","        │     └── wiki_20190620_small.txt\n","        │\n","        ├── preprocessed_training_data/           - output 폴더\n","        │     └── wiki_20190620_512_tf.record     - 테스트를 위해 미리 생성한 데이터\n","        │\n","        ├── my_pretrained_model/                  - output 폴더\n","        ├── my_conf/                              - output 폴더\n","        ├── my_preprocessed_training_data/        - output 폴더\n","        └── conf/   \n","              └── bert_config.json\n","\n","                    \n","     \n","```\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zhN7nG8S9ZVX","executionInfo":{"status":"ok","timestamp":1607072115637,"user_tz":-540,"elapsed":1488,"user":{"displayName":"김정인","photoUrl":"","userId":"08669711361714769540"}},"outputId":"74d7e6d5-c82c-4c71-9284-f09a13203417"},"source":["!pip uninstall tensorflow -y"],"execution_count":27,"outputs":[{"output_type":"stream","text":["\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QdiAHBTP6wV4","executionInfo":{"status":"ok","timestamp":1607072156346,"user_tz":-540,"elapsed":16915,"user":{"displayName":"김정인","photoUrl":"","userId":"08669711361714769540"}},"outputId":"77fe956b-70e7-4b6d-b6aa-c05fbc8acfe8"},"source":["! pip install --user --upgrade tensorflow==1.14"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==1.14\n","  Using cached https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl\n","Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.0.8)\n","Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.1)\n","Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.33.2)\n","Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.18.5)\n","Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.2)\n","Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.0)\n","Requirement already satisfied, skipping upgrade: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.14.0)\n","Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n","Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.35.1)\n","Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.10.0)\n","Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.3.3)\n","Requirement already satisfied, skipping upgrade: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.14.0)\n","Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.15.0)\n","Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n","Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.12.4)\n","Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n","Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (50.3.2)\n","Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n","Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.3.3)\n","Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (2.0.0)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.4.0)\n","Installing collected packages: tensorflow\n","\u001b[33m  WARNING: The scripts freeze_graph, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/root/.local/bin' which is not on PATH.\n","  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n","Successfully installed tensorflow-1.14.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JKkm7apGQcN7"},"source":["텐서플로우 1.14설치후 런타임을 재시작 해야함"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AWZ81efU69tA","executionInfo":{"status":"ok","timestamp":1607076984123,"user_tz":-540,"elapsed":1048,"user":{"displayName":"김정인","photoUrl":"","userId":"08669711361714769540"}},"outputId":"8799faea-f7cd-468b-b7ad-f49757e45b49"},"source":["import tensorflow as tf\n","print(tf.__version__)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["1.14.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":782},"id":"yvFoqKDN5i_b","executionInfo":{"status":"ok","timestamp":1607071474144,"user_tz":-540,"elapsed":27211,"user":{"displayName":"김정인","photoUrl":"","userId":"08669711361714769540"}},"outputId":"019ef6a9-34b7-42fb-ff8b-487f789c9e23"},"source":["!pip install tensorflow==1.14.0"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==1.14.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n","\u001b[K     |████████████████████████████████| 109.2MB 64kB/s \n","\u001b[?25hCollecting tensorboard<1.15.0,>=1.14.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 43.4MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.10.0)\n","Collecting keras-applications>=1.0.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 7.5MB/s \n","\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.12.4)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.3)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n","Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n","\u001b[K     |████████████████████████████████| 491kB 41.2MB/s \n","\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.2)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.33.2)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.35.1)\n","Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.18.5)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.15.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.3.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (50.3.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (2.0.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.4.0)\n","Installing collected packages: tensorboard, keras-applications, tensorflow-estimator, tensorflow\n","  Found existing installation: tensorboard 2.3.0\n","    Uninstalling tensorboard-2.3.0:\n","      Successfully uninstalled tensorboard-2.3.0\n","  Found existing installation: tensorflow-estimator 2.3.0\n","    Uninstalling tensorflow-estimator-2.3.0:\n","      Successfully uninstalled tensorflow-estimator-2.3.0\n","Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["tensorboard","tensorflow"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FbfuCHyt6ikh","executionInfo":{"status":"ok","timestamp":1607073684028,"user_tz":-540,"elapsed":1205,"user":{"displayName":"김정인","photoUrl":"","userId":"08669711361714769540"}},"outputId":"0f6899ff-f48c-4105-8139-38ae7d1b7a87"},"source":["import tensorflow as tf\n","print(tf.__version__)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["1.14.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Wlo-z0KvPmmw"},"source":["## 1. 구글 드라이브 저장소 설정"]},{"cell_type":"code","metadata":{"id":"LXOaCVLNiYrG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607072181828,"user_tz":-540,"elapsed":1171,"user":{"displayName":"김정인","photoUrl":"","userId":"08669711361714769540"}},"outputId":"819b81b0-9043-4a4e-f496-0ab95fb3e0bc"},"source":["# 구글드라이브의 디렉토리와 Colab 연동\n","# colab 좌측 상단 메뉴, 런타임 -> 런타임 유형 변경 -> 하드웨어 가속기 -> GPU 선택 후 저장\n","!nvidia-smi"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Fri Dec  4 08:56:21 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   73C    P8    33W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mNOlHVyui2KT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607072185910,"user_tz":-540,"elapsed":1432,"user":{"displayName":"김정인","photoUrl":"","userId":"08669711361714769540"}},"outputId":"322f55d6-35a7-4ad7-b20e-9d95304cd121"},"source":["# 내 구글 드라이브 저장소와 colab연결\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CbPmqRmfjCdY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607072188114,"user_tz":-540,"elapsed":1074,"user":{"displayName":"김정인","photoUrl":"","userId":"08669711361714769540"}},"outputId":"46791830-42da-4bce-dca1-b47231e25417"},"source":["# 연결된 내 드라이브 안에 디렉토리 확인\n","! ls "],"execution_count":7,"outputs":[{"output_type":"stream","text":["drive  sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CF0DsXOJjFmF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607072190181,"user_tz":-540,"elapsed":1036,"user":{"displayName":"김정인","photoUrl":"","userId":"08669711361714769540"}},"outputId":"11bf16b1-e0f9-4f88-8b5e-805a30a376f4"},"source":["# bert실행 파일들을 저장한 폴더 안의 디렉토리/파일 확인\n","! ls drive/MyDrive/BERT"],"execution_count":8,"outputs":[{"output_type":"stream","text":["bert_test.ipynb  rsc  src\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cChOcdWK4hN8","executionInfo":{"status":"ok","timestamp":1607072192470,"user_tz":-540,"elapsed":1031,"user":{"displayName":"김정인","photoUrl":"","userId":"08669711361714769540"}},"outputId":"c9b262c6-f531-4e52-b9ef-312c8ac14bee"},"source":["!ls drive/MyDrive/BERT/rsc/trainig_data/wiki_20190620_small.txt"],"execution_count":9,"outputs":[{"output_type":"stream","text":["drive/MyDrive/BERT/rsc/trainig_data/wiki_20190620_small.txt\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Jmbl1kcpPslT"},"source":["## 2. BERT 학습을 위한 vocab 만들기\n","- wiki_20190620_small.txt 파일을 wordpiece.py로 my_vacab.txt 생성"]},{"cell_type":"code","metadata":{"id":"7cBtc8drjrgC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607072209983,"user_tz":-540,"elapsed":15449,"user":{"displayName":"김정인","photoUrl":"","userId":"08669711361714769540"}},"outputId":"44c967a9-3c81-4858-dfab-ae6899014b7b"},"source":["# BERT학습을 위한 vocab 만들기\n","!python drive/MyDrive/BERT/src/make_vocab/wordpiece.py \\\n","--corpus=drive/MyDrive/BERT/rsc/trainig_data/wiki_20190620_small.txt \\\n","--iter=100 \\\n","--fname=drive/MyDrive/BERT/rsc/my_conf/my_vocab.txt"],"execution_count":10,"outputs":[{"output_type":"stream","text":["begin vocabulary scanning\rterminated vocabulary scanning\n","('##다', '##.')\n","('##으', '##로')\n","('##에', '##서')\n","('있', '##다.')\n","('1', '##9')\n","('##o', '##r')\n","('##l', '##a')\n","('##u', '##la')\n","('##or', '##m')\n","('##orm', '##ula')\n","('f', '##ormula')\n","('##이', '##다.')\n","('##하', '##는')\n","('##었', '##다.')\n","('##하', '##였')\n","('##하', '##여')\n","('##0', '##0')\n","('##고', '##,')\n","('##했', '##다.')\n","('대', '##한')\n","('##며', '##,')\n","('##한', '##다.')\n","('##에', '##는')\n","('##하였', '##다.')\n","('##적', '##인')\n","('##하', '##고')\n","('다', '##음')\n","('사', '##용')\n","('##라', '##고')\n","('##적', '##으로')\n","('2', '##00')\n","('##부', '##터')\n","('있', '##는')\n","('##되', '##었다.')\n","('##지', '##만')\n","('한', '##다.')\n","('##다', '##는')\n","('같', '##은')\n","('따', '##라')\n","('##0', '##년')\n","('##라', '##는')\n","('다음', '##과')\n","('##하', '##기')\n","('formula', '##1')\n","('##무', '##현')\n","('##다', '##고')\n","('##으', '##며,')\n","('또', '##한')\n","('##민', '##국')\n","('노', '##무현')\n","('##까', '##지')\n","('##에서', '##는')\n","('##들', '##이')\n","('##들', '##은')\n","('2', '##0')\n","('##면', '##서')\n","('이', '##후')\n","('대한', '##민국')\n","('##통', '##령')\n","('##정', '##식')\n","('일', '##본')\n","('##이', '##나')\n","('경', '##우')\n","('대', '##통령')\n","('운', '##동')\n","('##하', '##게')\n","('##으', '##나')\n","('대', '##해')\n","('##되', '##어')\n","('한', '##국')\n","('##수', '##의')\n","('##된', '##다.')\n","('공', '##간')\n","('나', '##타')\n","('때', '##문')\n","('그', '##러')\n","('19', '##9')\n","('##주', '##의')\n","('방', '##정식')\n","('집', '##합')\n","('다', '##른')\n","('정', '##의')\n","('시', '##작')\n","('위', '##해')\n","('##에', '##게')\n","('##너', '##지')\n","('프', '##로')\n","('20', '##1')\n","('##들', '##의')\n","('##프', '##트')\n","('##기', '##도')\n","('##하', '##지')\n","('가', '##지')\n","('여', '##러')\n","('##이', '##라고')\n","('그러', '##나')\n","('##되', '##었')\n","('미', '##국')\n","('##퓨', '##터')\n","('위', '##키')\n","training bpe 100 / 100('##년', '##에')\n","training bpe was done                                        \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vLEUkdmZQEAs"},"source":["## 3. 데이터 전처리\n","- 데이터 : wiki_20190620_small.txt, my_vocab.txt\n","- 모듈 : create_pretraining_data.py\n","- 파라미터 : do_lower_case=False, max_seq_length=512\n","- output : my_preprocessed_training_data/wiki_20190620_small_512_tf.record"]},{"cell_type":"code","metadata":{"id":"M_OkljjlQAQr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607073116655,"user_tz":-540,"elapsed":38465,"user":{"displayName":"김정인","photoUrl":"","userId":"08669711361714769540"}},"outputId":"48a01bea-7048-4f62-e013-a993c169b5e0"},"source":["!python drive/MyDrive/BERT/src/make_preprocessed_data/create_pretraining_data.py \\\n","--input_file=drive/MyDrive/BERT/rsc/trainig_data/wiki_20190620_small.txt \\\n","--vocab_file=drive/MyDrive/BERT/rsc/my_conf/my_vocab.txt \\\n","--do_lower_case=False \\\n","--max_seq_length=512 \\\n","--output_file=drive/MyDrive/BERT/rsc/my_preprocessed_training_data/wiki_20190620_small_512_tf.record"],"execution_count":20,"outputs":[{"output_type":"stream","text":["/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","WARNING:tensorflow:From drive/MyDrive/BERT/src/make_preprocessed_data/create_pretraining_data.py:469: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From drive/MyDrive/BERT/src/make_preprocessed_data/create_pretraining_data.py:437: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n","\n","W1204 09:11:20.811463 139694404269952 deprecation_wrapper.py:119] From drive/MyDrive/BERT/src/make_preprocessed_data/create_pretraining_data.py:437: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n","\n","WARNING:tensorflow:From drive/MyDrive/BERT/src/make_preprocessed_data/create_pretraining_data.py:437: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n","\n","W1204 09:11:20.811731 139694404269952 deprecation_wrapper.py:119] From drive/MyDrive/BERT/src/make_preprocessed_data/create_pretraining_data.py:437: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/BERT/src/make_preprocessed_data/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W1204 09:11:20.811960 139694404269952 deprecation_wrapper.py:119] From /content/drive/MyDrive/BERT/src/make_preprocessed_data/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","WARNING:tensorflow:From drive/MyDrive/BERT/src/make_preprocessed_data/create_pretraining_data.py:444: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n","\n","W1204 09:11:20.824039 139694404269952 deprecation_wrapper.py:119] From drive/MyDrive/BERT/src/make_preprocessed_data/create_pretraining_data.py:444: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n","\n","WARNING:tensorflow:From drive/MyDrive/BERT/src/make_preprocessed_data/create_pretraining_data.py:446: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","W1204 09:11:20.826244 139694404269952 deprecation_wrapper.py:119] From drive/MyDrive/BERT/src/make_preprocessed_data/create_pretraining_data.py:446: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","INFO:tensorflow:*** Reading from input files ***\n","I1204 09:11:20.826472 139694404269952 create_pretraining_data.py:446] *** Reading from input files ***\n","INFO:tensorflow:  drive/MyDrive/BERT/rsc/trainig_data/wiki_20190620_small.txt\n","I1204 09:11:20.826682 139694404269952 create_pretraining_data.py:448]   drive/MyDrive/BERT/rsc/trainig_data/wiki_20190620_small.txt\n","INFO:tensorflow:*** Writing to output files ***\n","I1204 09:11:45.443242 139694404269952 create_pretraining_data.py:457] *** Writing to output files ***\n","INFO:tensorflow:  drive/MyDrive/BERT/rsc/my_preprocessed_training_data/wiki_20190620_small_512_tf.record\n","I1204 09:11:45.443509 139694404269952 create_pretraining_data.py:459]   drive/MyDrive/BERT/rsc/my_preprocessed_training_data/wiki_20190620_small_512_tf.record\n","WARNING:tensorflow:From drive/MyDrive/BERT/src/make_preprocessed_data/create_pretraining_data.py:101: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","W1204 09:11:45.443747 139694404269952 deprecation_wrapper.py:119] From drive/MyDrive/BERT/src/make_preprocessed_data/create_pretraining_data.py:101: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","INFO:tensorflow:*** Example ***\n","I1204 09:11:45.453496 139694404269952 create_pretraining_data.py:149] *** Example ***\n","INFO:tensorflow:tokens: [CLS] 200 ##4 ##년 3 ##월 3 ##일 [MASK] ##앙 ##선 ##거 ##관 ##리 ##위 ##원 ##회 ##는 민 ##주 ##당 ##이 고 ##발 ##한 노무현 ##의 열 ##린 ##우 ##리 ##당 지 ##지 ##발 ##언 ##에 대해 [MASK] 대통령 ##이 선 ##거 ##중 ##립 의 ##무 위 ##반 ##이 있 ##다고 인 ##정 ##하고 선 ##거 ##중 ##립 ##의 ##무 준 ##수 ##요 ##청 ##을 했 ##다 . 민 ##주 ##당 ##은 이 조 ##치 ##를 근 ##거 ##로 노무현 ##이 선 ##거 ##법 위 ##반 ##에 대해 사 ##과 ##하지 않 ##으 ##면 탄 ##핵 ##을 발 ##의 ##하 ##겠 ##다 ##며 야 ##3 ##당 ##과 함 ##께 노무현 대통령 탄 ##핵 소 ##추 ##를 추 ##진 ##하기 시작 ##했 ##다 . 같은 달 그 ##의 형 ##인 노 ##건 ##평 ##이 대 ##우 ##건 ##설 사 ##장 남 ##상 ##국 ##으로 ##부터 청 ##탁 ##성 명 ##목 ##으로 뇌 ##물 ##을 수 ##수 ##한 사 ##실 [MASK] 언 ##론 ##에 보 ##도 ##되었 ##다 . 노무현 ##은 언 ##론 브 ##리 ##핑 ##에서 \" 대 ##우 ##건 ##설 ##의 사 ##장 ##처 ##럼 좋 ##은 학 ##교 나 [MASK] [MASK] ##고 크 [MASK] 성 ##공 ##하 ##신 분 ##들이 시 ##골 ##에 있는 별 볼 ##일 없 ##는 사 ##람 ##에게 가 ##서 머 ##리 조 ##아 ##리 ##고 돈 주 ##고 그 ##런 일 이 ##제 ##는 없 ##었 ##으 ##면 좋 ##겠 ##다 \" 면 ##서 남 ##상 ##국 ##을 질 ##타 [MASK] ##고 , 200 ##4 ##년 [MASK] [MASK] 1 [MASK] ##일 남 [MASK] ##국 ##은 한 ##강 ##에서 투 ##신 ##했 ##다 . 이 ##️ ##건 ##으로 노 ##건 ##평 ##은 유 ##죄 ##가 인 ##정 [MASK] 집 ##행 ##유 ##예 [MASK] [MASK] ##을 받 ##았 ##다 . [SEP] 토 ##론 ##의 광 [MASK] 5 ##4 . 대 ##화 ##실 5 ##5 . 동 ##호 ##인 코 ##너 5 ##6 . 컴 ##퓨터 / 통 ##신 5 ##7 . P ##C 라 ##인 번 ##호 / 명 [MASK] [ [MASK] 분 ##류 : 컴 ##퓨터 통 ##신 ] ] [SEP]\n","I1204 09:11:45.453776 139694404269952 create_pretraining_data.py:151] tokens: [CLS] 200 ##4 ##년 3 ##월 3 ##일 [MASK] ##앙 ##선 ##거 ##관 ##리 ##위 ##원 ##회 ##는 민 ##주 ##당 ##이 고 ##발 ##한 노무현 ##의 열 ##린 ##우 ##리 ##당 지 ##지 ##발 ##언 ##에 대해 [MASK] 대통령 ##이 선 ##거 ##중 ##립 의 ##무 위 ##반 ##이 있 ##다고 인 ##정 ##하고 선 ##거 ##중 ##립 ##의 ##무 준 ##수 ##요 ##청 ##을 했 ##다 . 민 ##주 ##당 ##은 이 조 ##치 ##를 근 ##거 ##로 노무현 ##이 선 ##거 ##법 위 ##반 ##에 대해 사 ##과 ##하지 않 ##으 ##면 탄 ##핵 ##을 발 ##의 ##하 ##겠 ##다 ##며 야 ##3 ##당 ##과 함 ##께 노무현 대통령 탄 ##핵 소 ##추 ##를 추 ##진 ##하기 시작 ##했 ##다 . 같은 달 그 ##의 형 ##인 노 ##건 ##평 ##이 대 ##우 ##건 ##설 사 ##장 남 ##상 ##국 ##으로 ##부터 청 ##탁 ##성 명 ##목 ##으로 뇌 ##물 ##을 수 ##수 ##한 사 ##실 [MASK] 언 ##론 ##에 보 ##도 ##되었 ##다 . 노무현 ##은 언 ##론 브 ##리 ##핑 ##에서 \" 대 ##우 ##건 ##설 ##의 사 ##장 ##처 ##럼 좋 ##은 학 ##교 나 [MASK] [MASK] ##고 크 [MASK] 성 ##공 ##하 ##신 분 ##들이 시 ##골 ##에 있는 별 볼 ##일 없 ##는 사 ##람 ##에게 가 ##서 머 ##리 조 ##아 ##리 ##고 돈 주 ##고 그 ##런 일 이 ##제 ##는 없 ##었 ##으 ##면 좋 ##겠 ##다 \" 면 ##서 남 ##상 ##국 ##을 질 ##타 [MASK] ##고 , 200 ##4 ##년 [MASK] [MASK] 1 [MASK] ##일 남 [MASK] ##국 ##은 한 ##강 ##에서 투 ##신 ##했 ##다 . 이 ##️ ##건 ##으로 노 ##건 ##평 ##은 유 ##죄 ##가 인 ##정 [MASK] 집 ##행 ##유 ##예 [MASK] [MASK] ##을 받 ##았 ##다 . [SEP] 토 ##론 ##의 광 [MASK] 5 ##4 . 대 ##화 ##실 5 ##5 . 동 ##호 ##인 코 ##너 5 ##6 . 컴 ##퓨터 / 통 ##신 5 ##7 . P ##C 라 ##인 번 ##호 / 명 [MASK] [ [MASK] 분 ##류 : 컴 ##퓨터 통 ##신 ] ] [SEP]\n","INFO:tensorflow:input_ids: 0 210 106 34 180 91 180 42 4 693 84 206 265 19 142 80 114 8 397 89 131 6 176 366 16 284 5 498 404 221 19 131 63 31 366 465 10 356 4 337 6 183 206 299 207 124 369 138 192 6 71 277 83 47 154 183 206 299 207 5 369 828 29 283 621 7 407 104 1326 397 89 131 12 14 119 82 11 523 206 15 284 6 183 206 172 138 192 10 356 43 25 444 188 319 88 688 885 7 134 5 48 949 104 190 767 95 131 25 197 514 284 337 688 885 158 765 11 326 132 269 414 222 104 1326 246 534 37 5 378 27 199 262 649 6 45 221 262 381 43 50 375 59 70 24 224 623 1169 60 389 684 24 1117 259 7 22 29 16 43 402 4 453 123 10 107 18 452 104 1326 284 12 453 123 677 19 1384 26 170 45 221 262 381 5 43 50 638 763 964 12 435 145 238 4 4 30 416 4 195 156 48 187 148 295 109 951 10 225 891 813 42 273 8 43 390 422 54 38 1045 19 119 74 19 30 1026 101 30 37 646 79 14 62 8 273 251 319 88 964 949 104 170 912 38 375 59 70 7 589 248 4 30 947 210 106 34 4 4 41 4 42 375 4 70 12 97 553 26 758 187 222 104 1326 14 2301 262 24 199 262 649 12 77 1108 13 83 47 4 516 249 200 713 4 4 7 308 296 104 1326 2 663 123 5 535 4 290 106 1326 45 56 402 290 102 1326 175 208 27 549 762 290 108 1326 445 454 1199 164 187 290 113 1326 429 413 478 27 562 208 1199 389 4 1062 4 148 349 1545 445 454 164 187 2540 2540 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","I1204 09:11:45.454128 139694404269952 create_pretraining_data.py:161] input_ids: 0 210 106 34 180 91 180 42 4 693 84 206 265 19 142 80 114 8 397 89 131 6 176 366 16 284 5 498 404 221 19 131 63 31 366 465 10 356 4 337 6 183 206 299 207 124 369 138 192 6 71 277 83 47 154 183 206 299 207 5 369 828 29 283 621 7 407 104 1326 397 89 131 12 14 119 82 11 523 206 15 284 6 183 206 172 138 192 10 356 43 25 444 188 319 88 688 885 7 134 5 48 949 104 190 767 95 131 25 197 514 284 337 688 885 158 765 11 326 132 269 414 222 104 1326 246 534 37 5 378 27 199 262 649 6 45 221 262 381 43 50 375 59 70 24 224 623 1169 60 389 684 24 1117 259 7 22 29 16 43 402 4 453 123 10 107 18 452 104 1326 284 12 453 123 677 19 1384 26 170 45 221 262 381 5 43 50 638 763 964 12 435 145 238 4 4 30 416 4 195 156 48 187 148 295 109 951 10 225 891 813 42 273 8 43 390 422 54 38 1045 19 119 74 19 30 1026 101 30 37 646 79 14 62 8 273 251 319 88 964 949 104 170 912 38 375 59 70 7 589 248 4 30 947 210 106 34 4 4 41 4 42 375 4 70 12 97 553 26 758 187 222 104 1326 14 2301 262 24 199 262 649 12 77 1108 13 83 47 4 516 249 200 713 4 4 7 308 296 104 1326 2 663 123 5 535 4 290 106 1326 45 56 402 290 102 1326 175 208 27 549 762 290 108 1326 445 454 1199 164 187 290 113 1326 429 413 478 27 562 208 1199 389 4 1062 4 148 349 1545 445 454 164 187 2540 2540 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","I1204 09:11:45.454429 139694404269952 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","I1204 09:11:45.454712 139694404269952 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:masked_lm_positions: 8 16 38 64 159 191 192 195 247 253 254 256 259 271 283 288 289 300 334 336\n","I1204 09:11:45.454974 139694404269952 create_pretraining_data.py:161] masked_lm_positions: 8 16 38 64 159 191 192 195 247 253 254 256 259 271 283 288 289 300 334 336\n","INFO:tensorflow:masked_lm_ids: 69 114 284 621 6 393 33 147 222 180 91 85 59 43 354 620 361 50 698 1062\n","I1204 09:11:45.455140 139694404269952 create_pretraining_data.py:161] masked_lm_ids: 69 114 284 621 6 393 33 147 222 180 91 85 59 43 354 620 361 50 698 1062\n","INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","I1204 09:11:45.455302 139694404269952 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","INFO:tensorflow:next_sentence_labels: 1\n","I1204 09:11:45.455455 139694404269952 create_pretraining_data.py:161] next_sentence_labels: 1\n","INFO:tensorflow:*** Example ***\n","I1204 09:11:45.456201 139694404269952 create_pretraining_data.py:149] *** Example ***\n","INFO:tensorflow:tokens: [CLS] 그 ##리 ##고 가 첫 ##번 ##째 벡 ##터 ##력 노 ##름 ##을 의 ##미 ##하는 ##加 ##으로 오 ##용 ##되었 ##다 . [MASK] ##을 입 ##력 ##으로 하 ##고 켓 ##을 출 ##력 ##으로 하 ##는 선 ##형 연 ##산 ##자 ##를 맵 ##이라고 한 ##다 . 다 ##시 말 ##해 ##서 , 만 ##약 가 선 ##형 연 ##산 ##자 ##이 ##고 가 켓 ##일 때 , 은 또 ##다른 켓 ##이 ##다 . 숙 차 ##원 힐 ##베 ##르 ##트 공간 ##에서 , 는 열 ##벡 ##터 ##로 쓰 ##일 수 있 ##으 ##며 , 는 복 ##소 ##수 항 ##목 ##을 포 ##함 ##한 행 ##렬 ##로 쓰 ##일 수 있 ##다 . 켓 는 일 ##반 ##적인 행 ##렬 곱 ##셈 ##으로 계 ##산 ##될 수 있 [MASK] . [SEP] ##를 들 ##어 , 에 ##너지 ##나 운동 ##량 같은 관 ##측 ##가 ##능 ##량 ##은 자 ##기 수 ##반 연 ##산 ##자 ##로 표 ##현 ##되 [MASK] , 변 ##화 과 ##정 ##은 회 ##전 ##이나 시 ##간 ##의 진 ##행 ##과 같은 유 ##니 ##터 ##리 선 ##형 연 ##산 ##자 ##로 표 ##현 ##된 ##다 . 연 ##산 ##자 ##는 브 ##라 ##의 \" 오 ##른 ##쪽 \" [MASK] ##서 작 ##용 ##하는 것 ##으로 표 ##기 ##된 ##다 . [MASK] ##히 , 만 ##약 가 선 ##형 연 ##산 ##자 ##이 ##고 , 가 브 ##라 ##이 ##면 , 는 규 ##칙 ##에 따라 다음과 같 ##이 정의 ##되 ##는 또 다른 브 ##라 ##이 ##다 . - 차 ##원 힐 ##베 ##르 ##트 공간 ##에서 , 는 행 [MASK] ##터 ##로 쓰 ##일 [MASK] 있 ##고 , 는 행 ##렬 ##으로 쓰 ##일 수 있 ##다 . 그러 ##고 나 ##면 [MASK] ##라 는 일 ##반 ##적인 행 ##렬 곱 ##셈 ##으로 계 ##산 ##될 수 있 ##다 . 만 ##약 같은 상 ##태 벡 ##터 ##가 다음과 같 ##이 브 [MASK] ##와 켓 ##쪽 ##에 둘 ##다 나타 ##나 ##면 이 표 ##현 ##은 상 ##태 에 있는 물 ##리 ##학 계 ##에 대해 관 ##측 가 ##능 ##한 표 ##현 연 ##산 ##자 의 기 ##대 ##값 또 ##는 평 ##균 ##을 나타 ##낸 ##다 . 힐 ##베 ##르 ##트 공간 에 [MASK] 선 ##형 연 ##산 ##자 ##를 정의 ##하는 편 ##리 ##한 방 ##법 ##은 외 ##적으로 정의 ##하는 것 ##이 ##다 . 만 ##약 가 브 ##라 ##이 ##고 이 켓 ##이 ##면 , 외 ##적 은 다음과 같은 규 ##칙 ##에 따라 계 ##급 - 1 연 ##산 ##자 ##를 나타 ##낸 ##다 [MASK] [MASK] ##한 ##차 ##원 벡 ##터 공간 ##에 대해 , 외 ##적 ##은 간 ##단 ##한 행 ##렬 곱 ##셈 ##으로 이 ##해 ##할 수 있 ##다 . 이 ##때 외 ##적 ##은 선 ##형 연 ##산 [MASK] ##로 볼 수 [MASK] [MASK] ##렬 ##이 ##다 . 외 ##적 ##의 사용 용 ##도 가 ##운 [MASK] 하 ##나 ##는 사 ##영 ##작 ##용 ##소 ##를 [MASK] ##성 ##하는 것 ##이 ##다 . 노 ##름 ##이 1 ##인 주 ##어 ##진 [SEP]\n","I1204 09:11:45.456541 139694404269952 create_pretraining_data.py:151] tokens: [CLS] 그 ##리 ##고 가 첫 ##번 ##째 벡 ##터 ##력 노 ##름 ##을 의 ##미 ##하는 ##加 ##으로 오 ##용 ##되었 ##다 . [MASK] ##을 입 ##력 ##으로 하 ##고 켓 ##을 출 ##력 ##으로 하 ##는 선 ##형 연 ##산 ##자 ##를 맵 ##이라고 한 ##다 . 다 ##시 말 ##해 ##서 , 만 ##약 가 선 ##형 연 ##산 ##자 ##이 ##고 가 켓 ##일 때 , 은 또 ##다른 켓 ##이 ##다 . 숙 차 ##원 힐 ##베 ##르 ##트 공간 ##에서 , 는 열 ##벡 ##터 ##로 쓰 ##일 수 있 ##으 ##며 , 는 복 ##소 ##수 항 ##목 ##을 포 ##함 ##한 행 ##렬 ##로 쓰 ##일 수 있 ##다 . 켓 는 일 ##반 ##적인 행 ##렬 곱 ##셈 ##으로 계 ##산 ##될 수 있 [MASK] . [SEP] ##를 들 ##어 , 에 ##너지 ##나 운동 ##량 같은 관 ##측 ##가 ##능 ##량 ##은 자 ##기 수 ##반 연 ##산 ##자 ##로 표 ##현 ##되 [MASK] , 변 ##화 과 ##정 ##은 회 ##전 ##이나 시 ##간 ##의 진 ##행 ##과 같은 유 ##니 ##터 ##리 선 ##형 연 ##산 ##자 ##로 표 ##현 ##된 ##다 . 연 ##산 ##자 ##는 브 ##라 ##의 \" 오 ##른 ##쪽 \" [MASK] ##서 작 ##용 ##하는 것 ##으로 표 ##기 ##된 ##다 . [MASK] ##히 , 만 ##약 가 선 ##형 연 ##산 ##자 ##이 ##고 , 가 브 ##라 ##이 ##면 , 는 규 ##칙 ##에 따라 다음과 같 ##이 정의 ##되 ##는 또 다른 브 ##라 ##이 ##다 . - 차 ##원 힐 ##베 ##르 ##트 공간 ##에서 , 는 행 [MASK] ##터 ##로 쓰 ##일 [MASK] 있 ##고 , 는 행 ##렬 ##으로 쓰 ##일 수 있 ##다 . 그러 ##고 나 ##면 [MASK] ##라 는 일 ##반 ##적인 행 ##렬 곱 ##셈 ##으로 계 ##산 ##될 수 있 ##다 . 만 ##약 같은 상 ##태 벡 ##터 ##가 다음과 같 ##이 브 [MASK] ##와 켓 ##쪽 ##에 둘 ##다 나타 ##나 ##면 이 표 ##현 ##은 상 ##태 에 있는 물 ##리 ##학 계 ##에 대해 관 ##측 가 ##능 ##한 표 ##현 연 ##산 ##자 의 기 ##대 ##값 또 ##는 평 ##균 ##을 나타 ##낸 ##다 . 힐 ##베 ##르 ##트 공간 에 [MASK] 선 ##형 연 ##산 ##자 ##를 정의 ##하는 편 ##리 ##한 방 ##법 ##은 외 ##적으로 정의 ##하는 것 ##이 ##다 . 만 ##약 가 브 ##라 ##이 ##고 이 켓 ##이 ##면 , 외 ##적 은 다음과 같은 규 ##칙 ##에 따라 계 ##급 - 1 연 ##산 ##자 ##를 나타 ##낸 ##다 [MASK] [MASK] ##한 ##차 ##원 벡 ##터 공간 ##에 대해 , 외 ##적 ##은 간 ##단 ##한 행 ##렬 곱 ##셈 ##으로 이 ##해 ##할 수 있 ##다 . 이 ##때 외 ##적 ##은 선 ##형 연 ##산 [MASK] ##로 볼 수 [MASK] [MASK] ##렬 ##이 ##다 . 외 ##적 ##의 사용 용 ##도 가 ##운 [MASK] 하 ##나 ##는 사 ##영 ##작 ##용 ##소 ##를 [MASK] ##성 ##하는 것 ##이 ##다 . 노 ##름 ##이 1 ##인 주 ##어 ##진 [SEP]\n","INFO:tensorflow:input_ids: 0 37 19 30 54 777 741 604 521 169 161 199 405 7 124 189 57 2283 24 216 90 452 104 1326 4 7 371 161 24 52 30 857 7 376 161 24 52 8 183 185 126 110 20 11 1379 449 97 104 1326 129 33 334 40 38 947 163 532 54 183 185 126 110 20 6 30 54 857 42 302 947 863 417 1472 857 6 104 1326 1378 363 80 855 472 87 92 373 26 947 750 498 1088 169 15 463 42 22 71 319 190 947 750 426 94 29 566 684 7 377 240 16 412 618 15 463 42 22 71 104 1326 857 750 79 192 153 412 618 660 754 24 204 110 686 22 71 4 1326 2 11 395 23 947 276 427 75 339 267 246 143 643 13 330 267 12 64 21 22 192 126 110 20 15 181 382 127 4 947 271 56 297 47 12 409 61 332 109 141 5 327 249 25 246 77 193 169 19 183 185 126 110 20 15 181 382 177 104 1326 126 110 20 8 677 53 5 170 216 476 609 170 4 38 255 90 57 72 24 181 21 177 104 1326 4 209 947 163 532 54 183 185 126 110 20 6 30 947 54 677 53 6 88 947 750 665 440 10 247 261 223 6 411 127 8 417 408 677 53 6 104 1326 924 363 80 855 472 87 92 373 26 947 750 412 4 169 15 463 42 4 71 30 947 750 412 618 24 463 42 22 71 104 1326 911 30 238 88 4 53 750 79 192 153 412 618 660 754 24 204 110 686 22 71 104 1326 163 532 246 139 285 521 169 13 261 223 6 677 4 39 857 609 10 801 104 374 75 88 14 181 382 12 139 285 276 225 179 19 28 204 10 356 143 643 54 330 16 181 382 126 110 20 124 44 36 622 417 8 359 738 7 374 759 104 1326 855 472 87 92 373 276 4 183 185 126 110 20 11 411 57 554 19 16 178 172 12 418 184 411 57 72 6 104 1326 163 532 54 677 53 6 30 14 857 6 88 947 418 73 863 261 246 665 440 10 247 204 576 924 41 126 110 20 11 374 759 104 4 4 16 213 80 521 169 373 10 356 947 418 73 12 468 228 16 412 618 660 754 24 14 40 117 22 71 104 1326 14 717 418 73 12 183 185 126 110 4 15 813 22 4 4 618 6 104 1326 418 73 5 165 692 18 54 352 4 52 75 8 43 254 394 90 94 11 4 60 57 72 6 104 1326 199 405 6 41 27 101 23 132 2\n","I1204 09:11:45.529273 139694404269952 create_pretraining_data.py:161] input_ids: 0 37 19 30 54 777 741 604 521 169 161 199 405 7 124 189 57 2283 24 216 90 452 104 1326 4 7 371 161 24 52 30 857 7 376 161 24 52 8 183 185 126 110 20 11 1379 449 97 104 1326 129 33 334 40 38 947 163 532 54 183 185 126 110 20 6 30 54 857 42 302 947 863 417 1472 857 6 104 1326 1378 363 80 855 472 87 92 373 26 947 750 498 1088 169 15 463 42 22 71 319 190 947 750 426 94 29 566 684 7 377 240 16 412 618 15 463 42 22 71 104 1326 857 750 79 192 153 412 618 660 754 24 204 110 686 22 71 4 1326 2 11 395 23 947 276 427 75 339 267 246 143 643 13 330 267 12 64 21 22 192 126 110 20 15 181 382 127 4 947 271 56 297 47 12 409 61 332 109 141 5 327 249 25 246 77 193 169 19 183 185 126 110 20 15 181 382 177 104 1326 126 110 20 8 677 53 5 170 216 476 609 170 4 38 255 90 57 72 24 181 21 177 104 1326 4 209 947 163 532 54 183 185 126 110 20 6 30 947 54 677 53 6 88 947 750 665 440 10 247 261 223 6 411 127 8 417 408 677 53 6 104 1326 924 363 80 855 472 87 92 373 26 947 750 412 4 169 15 463 42 4 71 30 947 750 412 618 24 463 42 22 71 104 1326 911 30 238 88 4 53 750 79 192 153 412 618 660 754 24 204 110 686 22 71 104 1326 163 532 246 139 285 521 169 13 261 223 6 677 4 39 857 609 10 801 104 374 75 88 14 181 382 12 139 285 276 225 179 19 28 204 10 356 143 643 54 330 16 181 382 126 110 20 124 44 36 622 417 8 359 738 7 374 759 104 1326 855 472 87 92 373 276 4 183 185 126 110 20 11 411 57 554 19 16 178 172 12 418 184 411 57 72 6 104 1326 163 532 54 677 53 6 30 14 857 6 88 947 418 73 863 261 246 665 440 10 247 204 576 924 41 126 110 20 11 374 759 104 4 4 16 213 80 521 169 373 10 356 947 418 73 12 468 228 16 412 618 660 754 24 14 40 117 22 71 104 1326 14 717 418 73 12 183 185 126 110 4 15 813 22 4 4 618 6 104 1326 418 73 5 165 692 18 54 352 4 52 75 8 43 254 394 90 94 11 4 60 57 72 6 104 1326 199 405 6 41 27 101 23 132 2\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","I1204 09:11:45.529745 139694404269952 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","I1204 09:11:45.530260 139694404269952 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","INFO:tensorflow:masked_lm_positions: 10 17 24 77 133 163 207 219 269 274 292 322 375 430 431 468 472 473 486 496\n","I1204 09:11:45.530497 139694404269952 create_pretraining_data.py:161] masked_lm_positions: 10 17 24 77 133 163 207 219 269 274 292 322 375 430 431 468 472 473 486 496\n","INFO:tensorflow:masked_lm_ids: 5 72 857 924 104 190 276 305 1088 22 677 53 38 1326 77 20 225 412 194 112\n","I1204 09:11:45.530715 139694404269952 create_pretraining_data.py:161] masked_lm_ids: 5 72 857 924 104 190 276 305 1088 22 677 53 38 1326 77 20 225 412 194 112\n","INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","I1204 09:11:45.530943 139694404269952 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","INFO:tensorflow:next_sentence_labels: 0\n","I1204 09:11:45.531138 139694404269952 create_pretraining_data.py:161] next_sentence_labels: 0\n","INFO:tensorflow:*** Example ***\n","I1204 09:11:45.532257 139694404269952 create_pretraining_data.py:149] *** Example ***\n","INFO:tensorflow:tokens: [CLS] 십 ##5 [MASK] [MASK] ' [MASK] ##각 [MASK] 백 [MASK] ##이 ##라 ##야 산 ##다 ' 는 견 ##해 ##를 발 ##표 ##하 ##면서 정 ##부 ##의 정 [MASK] ##에 비 ##평 ##을 가 ##하기 시작 ##하였 ##고 , 19 ##5 ##8 ##년 5 ##월 잡 ##지 < 사 ##상 [MASK] > 에 발 ##표 ##한 칼 ##럼 하 ##나 [MASK] 화 ##제 ##가 되 ##었 ##다 . 이 일 ##로 그 ##는 우 ##익 인 ##사 ##들 ##로 ##부터 [MASK] ##판 ##을 받 ##았 [MASK] . [SEP] 그 ##는 또 19 ##5 ##9 ##년 6 . 2 ##5 전 ##쟁 관 ##련 ##자 ##들 ##에 대한 훈 ##장 서 ##훈 이 ##야 ##기 ##가 [MASK] ##오 ##자 \" 형 ##제 [MASK] 죽 [MASK] [MASK] ##도 [MASK] [MASK] 훈 ##장 [MASK] ##냐 \" 라 ##고 비 ##판 ##하였 ##다 . [SEP]\n","I1204 09:11:45.532568 139694404269952 create_pretraining_data.py:151] tokens: [CLS] 십 ##5 [MASK] [MASK] ' [MASK] ##각 [MASK] 백 [MASK] ##이 ##라 ##야 산 ##다 ' 는 견 ##해 ##를 발 ##표 ##하 ##면서 정 ##부 ##의 정 [MASK] ##에 비 ##평 ##을 가 ##하기 시작 ##하였 ##고 , 19 ##5 ##8 ##년 5 ##월 잡 ##지 < 사 ##상 [MASK] > 에 발 ##표 ##한 칼 ##럼 하 ##나 [MASK] 화 ##제 ##가 되 ##었 ##다 . 이 일 ##로 그 ##는 우 ##익 인 ##사 ##들 ##로 ##부터 [MASK] ##판 ##을 받 ##았 [MASK] . [SEP] 그 ##는 또 19 ##5 ##9 ##년 6 . 2 ##5 전 ##쟁 관 ##련 ##자 ##들 ##에 대한 훈 ##장 서 ##훈 이 ##야 ##기 ##가 [MASK] ##오 ##자 \" 형 ##제 [MASK] 죽 [MASK] [MASK] ##도 [MASK] [MASK] 훈 ##장 [MASK] ##냐 \" 라 ##고 비 ##판 ##하였 ##다 . [SEP]\n","INFO:tensorflow:input_ids: 0 1380 102 4 4 203 4 212 4 619 4 6 53 214 484 104 203 750 1008 40 11 134 264 48 304 49 67 5 49 4 10 116 649 7 54 269 414 328 30 947 65 102 103 34 290 91 959 31 913 43 59 4 1432 276 134 264 16 1054 763 52 75 4 442 62 13 174 251 104 1326 14 79 15 37 8 324 873 83 35 99 15 224 4 347 7 308 296 4 1326 2 37 8 417 65 102 217 34 480 1326 157 102 51 488 143 385 20 99 10 241 1148 50 135 1067 14 214 21 13 4 393 20 170 378 62 4 998 4 4 18 4 4 1148 50 4 908 170 478 30 116 347 328 104 1326 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","I1204 09:11:45.532964 139694404269952 create_pretraining_data.py:161] input_ids: 0 1380 102 4 4 203 4 212 4 619 4 6 53 214 484 104 203 750 1008 40 11 134 264 48 304 49 67 5 49 4 10 116 649 7 54 269 414 328 30 947 65 102 103 34 290 91 959 31 913 43 59 4 1432 276 134 264 16 1054 763 52 75 4 442 62 13 174 251 104 1326 14 79 15 37 8 324 873 83 35 99 15 224 4 347 7 308 296 4 1326 2 37 8 417 65 102 217 34 480 1326 157 102 51 488 143 385 20 99 10 241 1148 50 135 1067 14 214 21 13 4 393 20 170 378 62 4 998 4 4 18 4 4 1148 50 4 908 170 478 30 116 347 328 104 1326 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","I1204 09:11:45.533271 139694404269952 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","I1204 09:11:45.533572 139694404269952 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:masked_lm_positions: 1 3 4 6 8 10 29 33 51 61 81 86 116 122 124 125 127 128 131 138\n","I1204 09:11:45.533739 139694404269952 create_pretraining_data.py:161] masked_lm_positions: 1 3 4 6 8 10 29 33 51 61 81 86 116 122 124 125 127 128 131 138\n","INFO:tensorflow:masked_lm_ids: 65 103 34 244 57 60 598 7 58 8 116 104 238 11 6 30 253 932 6 328\n","I1204 09:11:45.533936 139694404269952 create_pretraining_data.py:161] masked_lm_ids: 65 103 34 244 57 60 598 7 58 8 116 104 238 11 6 30 253 932 6 328\n","INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","I1204 09:11:45.534096 139694404269952 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","INFO:tensorflow:next_sentence_labels: 0\n","I1204 09:11:45.534256 139694404269952 create_pretraining_data.py:161] next_sentence_labels: 0\n","INFO:tensorflow:*** Example ***\n","I1204 09:11:45.535239 139694404269952 create_pretraining_data.py:149] *** Example ***\n","INFO:tensorflow:tokens: [CLS] 그 ##렇 ##다 ##면 , formula [UNK] 4 ##8 사 ##이 [MASK] 각 ##도 ##는 formula [UNK] 7 ##이 ##다 . 또한 , formula [UNK] 5 ##3 [MASK] 각 ##각 평 [MASK] formula [UNK] 5 ##4 ##의 정 ##규 직 ##교 기 ##저 ##를 이 ##루 ##므 ##로 , formula [UNK] 5 ##5 ##를 각 ##각 다음과 같 ##이 분 ##해 ##할 수 있 ##다 [MASK] [SEP] 단 ##위 구 ##생 ##의 중 ##심 ##을 formula [UNK] 5 ##9 ##라고 하 ##자 . 또한 , 다음과 같은 세 벡 ##터 ##를 정의 ##하 ##자 . 그 ##렇 ##다 ##면 , formula [UNK] 3 ##3 ##의 길 ##이 ##는 모 ##두 1 ##이 ##며 , formula [UNK] 6 ##2 [MASK] ##이 ##의 각 ##도 ##는 formula [UNK] 6 ##3 ##이 [MASK] , formula [UNK] 6 ##4 사 ##이 ##의 각 ##도 ##는 formula [UNK] 6 ##5 ##이 ##며 , formula [UNK] 6 ##6 사 ##이 ##의 각 ##도 ##는 formula [MASK] [MASK] ##7 ##이 ##다 . 따라 ##서 , 벡 ##터 ##곱 formula [UNK] 6 ##8 , formula [UNK] 6 [MASK] , formula [UNK] 7 ##0 ##의 길 ##이 ##는 각 ##각 formula [UNK] 7 ##1 , formula [UNK] 7 ##2 , formula [UNK] 7 ##3 ##이 ##다 . 또한 , formula [UNK] 6 ##8 ##와 formula [UNK] 6 ##9 사 ##이 ##의 각 ##도 ##는 formula [UNK] 7 ##6 ##이 [MASK] , formula [UNK] 처 ##7 ##와 formula [UNK] 7 ##0 사 ##이 ##의 각 ##도 ##는 formula [UNK] 7 ##9 ##이 ##며 , formula [UNK] 8 [MASK] ##와 formula [UNK] 8 ##1 사 ##이 ##의 각 ##도 ##는 formula [UNK] 7 ##이 ##다 . 이 ##제 , 비 ##네 - 코 ##시 [MASK] ##등 ##식 ##에 따라 다음 ##이 성 ##립 ##함 ##에 주 ##의 ##하 ##자 . 여 ##기 ##에 위 ##의 결 ##과 ##들 ##을 대 ##입 ##하 ##면 다음 ##을 얻 ##는 ##다 . 이 ##로 ##써 제 ##1 구 ##면 코 ##사 ##인 법 ##칙 ##이 증 ##명 ##된 ##다 . 구 ##면 삼 ##각 ##형 formula [UNK] 1 ##의 극 ##삼 ##각 ##형 ##을 formula [UNK] 8 ##6 ##라고 하 ##자 . 그 ##렇 ##다 ##면 , 다음 ##이 성 ##립 ##한 ##다 . 따라 ##서 제 ##1 구 ##면 코 ##사 ##인 법 ##칙 ##을 극 ##삼 ##각 ##형 formula [UNK] 8 ##6 ##에 적 ##용 ##하 ##면 , 구 ##면 삼 ##각 ##형 formula [UNK] 1 ##에 대한 제 ##2 구 ##면 코 ##사 ##인 법 ##칙 ##을 얻 ##는 ##다 . 가 [MASK] ##스 곡 [MASK] - 1 ##의 [MASK] ##곡 ##면 위 ##의 쌍 ##곡 삼 ##각 ##형 formula [UNK] 1 ##의 세 각 formula [UNK] 2 ##이 마 ##주 ##하는 변 ##이 각 ##각 formula [UNK] 3 ##라고 하 ##면 , 다음 ##이 성 ##립 ##한 ##다 . 여 ##기 ##서 formula [UNK] [MASK] ##5 ##는 각 ##각 쌍 ##곡 코 ##사 ##인 , 쌍 ##곡 사 ##인 ##이 ##다 . 이 ##를 쌍 ##곡 코 ##사 ##인 법 [MASK] [UNK] [UNK] c ##o ##s ##i ##n ##e [UNK] [SEP]\n","I1204 09:11:45.535634 139694404269952 create_pretraining_data.py:151] tokens: [CLS] 그 ##렇 ##다 ##면 , formula [UNK] 4 ##8 사 ##이 [MASK] 각 ##도 ##는 formula [UNK] 7 ##이 ##다 . 또한 , formula [UNK] 5 ##3 [MASK] 각 ##각 평 [MASK] formula [UNK] 5 ##4 ##의 정 ##규 직 ##교 기 ##저 ##를 이 ##루 ##므 ##로 , formula [UNK] 5 ##5 ##를 각 ##각 다음과 같 ##이 분 ##해 ##할 수 있 ##다 [MASK] [SEP] 단 ##위 구 ##생 ##의 중 ##심 ##을 formula [UNK] 5 ##9 ##라고 하 ##자 . 또한 , 다음과 같은 세 벡 ##터 ##를 정의 ##하 ##자 . 그 ##렇 ##다 ##면 , formula [UNK] 3 ##3 ##의 길 ##이 ##는 모 ##두 1 ##이 ##며 , formula [UNK] 6 ##2 [MASK] ##이 ##의 각 ##도 ##는 formula [UNK] 6 ##3 ##이 [MASK] , formula [UNK] 6 ##4 사 ##이 ##의 각 ##도 ##는 formula [UNK] 6 ##5 ##이 ##며 , formula [UNK] 6 ##6 사 ##이 ##의 각 ##도 ##는 formula [MASK] [MASK] ##7 ##이 ##다 . 따라 ##서 , 벡 ##터 ##곱 formula [UNK] 6 ##8 , formula [UNK] 6 [MASK] , formula [UNK] 7 ##0 ##의 길 ##이 ##는 각 ##각 formula [UNK] 7 ##1 , formula [UNK] 7 ##2 , formula [UNK] 7 ##3 ##이 ##다 . 또한 , formula [UNK] 6 ##8 ##와 formula [UNK] 6 ##9 사 ##이 ##의 각 ##도 ##는 formula [UNK] 7 ##6 ##이 [MASK] , formula [UNK] 처 ##7 ##와 formula [UNK] 7 ##0 사 ##이 ##의 각 ##도 ##는 formula [UNK] 7 ##9 ##이 ##며 , formula [UNK] 8 [MASK] ##와 formula [UNK] 8 ##1 사 ##이 ##의 각 ##도 ##는 formula [UNK] 7 ##이 ##다 . 이 ##제 , 비 ##네 - 코 ##시 [MASK] ##등 ##식 ##에 따라 다음 ##이 성 ##립 ##함 ##에 주 ##의 ##하 ##자 . 여 ##기 ##에 위 ##의 결 ##과 ##들 ##을 대 ##입 ##하 ##면 다음 ##을 얻 ##는 ##다 . 이 ##로 ##써 제 ##1 구 ##면 코 ##사 ##인 법 ##칙 ##이 증 ##명 ##된 ##다 . 구 ##면 삼 ##각 ##형 formula [UNK] 1 ##의 극 ##삼 ##각 ##형 ##을 formula [UNK] 8 ##6 ##라고 하 ##자 . 그 ##렇 ##다 ##면 , 다음 ##이 성 ##립 ##한 ##다 . 따라 ##서 제 ##1 구 ##면 코 ##사 ##인 법 ##칙 ##을 극 ##삼 ##각 ##형 formula [UNK] 8 ##6 ##에 적 ##용 ##하 ##면 , 구 ##면 삼 ##각 ##형 formula [UNK] 1 ##에 대한 제 ##2 구 ##면 코 ##사 ##인 법 ##칙 ##을 얻 ##는 ##다 . 가 [MASK] ##스 곡 [MASK] - 1 ##의 [MASK] ##곡 ##면 위 ##의 쌍 ##곡 삼 ##각 ##형 formula [UNK] 1 ##의 세 각 formula [UNK] 2 ##이 마 ##주 ##하는 변 ##이 각 ##각 formula [UNK] 3 ##라고 하 ##면 , 다음 ##이 성 ##립 ##한 ##다 . 여 ##기 ##서 formula [UNK] [MASK] ##5 ##는 각 ##각 쌍 ##곡 코 ##사 ##인 , 쌍 ##곡 사 ##인 ##이 ##다 . 이 ##를 쌍 ##곡 코 ##사 ##인 법 [MASK] [UNK] [UNK] c ##o ##s ##i ##n ##e [UNK] [SEP]\n","INFO:tensorflow:input_ids: 0 37 753 104 88 947 96 1 320 103 43 6 4 292 18 8 96 1 524 6 104 1326 282 947 96 1 290 95 4 292 212 359 4 96 1 290 106 5 49 707 443 145 44 560 11 14 298 559 15 947 96 1 290 102 11 292 212 261 223 6 148 40 117 22 71 104 4 2 252 142 112 312 5 69 345 7 96 1 290 217 311 52 20 1326 282 947 261 246 198 521 169 11 411 48 20 1326 37 753 104 88 947 96 1 180 95 5 729 6 8 120 470 41 6 190 947 96 1 480 66 4 6 5 292 18 8 96 1 480 95 6 4 947 96 1 480 106 43 6 5 292 18 8 96 1 480 102 6 190 947 96 1 480 108 43 6 5 292 18 8 96 4 4 113 6 104 1326 247 38 947 521 169 676 96 1 480 103 947 96 1 480 4 947 96 1 524 121 5 729 6 8 292 212 96 1 524 85 947 96 1 524 66 947 96 1 524 95 6 104 1326 282 947 96 1 480 103 39 96 1 480 217 43 6 5 292 18 8 96 1 524 108 6 4 947 96 1 550 113 39 96 1 524 121 43 6 5 292 18 8 96 1 524 217 6 190 947 96 1 517 4 39 96 1 517 85 43 6 5 292 18 8 96 1 524 6 104 1326 14 62 947 116 789 924 549 33 4 455 122 10 247 499 6 195 207 240 10 101 5 48 20 1326 229 21 10 138 5 219 25 99 7 45 387 48 88 499 7 556 8 104 1326 14 15 668 76 85 112 88 549 35 27 437 440 6 448 105 177 104 1326 112 88 493 212 185 96 1 41 5 711 926 212 185 7 96 1 517 108 311 52 20 1326 37 753 104 88 947 499 6 195 207 16 104 1326 247 38 76 85 112 88 549 35 27 437 440 7 711 926 212 185 96 1 517 108 10 403 90 48 88 947 112 88 493 212 185 96 1 41 10 241 76 66 112 88 549 35 27 437 440 7 556 8 104 1326 54 4 32 1195 4 924 41 5 4 728 88 138 5 864 728 493 212 185 96 1 41 5 198 292 96 1 157 6 286 89 57 271 6 292 212 96 1 180 311 52 88 947 499 6 195 207 16 104 1326 229 21 38 96 1 4 102 8 292 212 864 728 549 35 27 947 864 728 43 27 6 104 1326 14 11 864 728 549 35 27 437 4 1 1 1251 494 541 425 466 257 1 2\n","I1204 09:11:45.536080 139694404269952 create_pretraining_data.py:161] input_ids: 0 37 753 104 88 947 96 1 320 103 43 6 4 292 18 8 96 1 524 6 104 1326 282 947 96 1 290 95 4 292 212 359 4 96 1 290 106 5 49 707 443 145 44 560 11 14 298 559 15 947 96 1 290 102 11 292 212 261 223 6 148 40 117 22 71 104 4 2 252 142 112 312 5 69 345 7 96 1 290 217 311 52 20 1326 282 947 261 246 198 521 169 11 411 48 20 1326 37 753 104 88 947 96 1 180 95 5 729 6 8 120 470 41 6 190 947 96 1 480 66 4 6 5 292 18 8 96 1 480 95 6 4 947 96 1 480 106 43 6 5 292 18 8 96 1 480 102 6 190 947 96 1 480 108 43 6 5 292 18 8 96 4 4 113 6 104 1326 247 38 947 521 169 676 96 1 480 103 947 96 1 480 4 947 96 1 524 121 5 729 6 8 292 212 96 1 524 85 947 96 1 524 66 947 96 1 524 95 6 104 1326 282 947 96 1 480 103 39 96 1 480 217 43 6 5 292 18 8 96 1 524 108 6 4 947 96 1 550 113 39 96 1 524 121 43 6 5 292 18 8 96 1 524 217 6 190 947 96 1 517 4 39 96 1 517 85 43 6 5 292 18 8 96 1 524 6 104 1326 14 62 947 116 789 924 549 33 4 455 122 10 247 499 6 195 207 240 10 101 5 48 20 1326 229 21 10 138 5 219 25 99 7 45 387 48 88 499 7 556 8 104 1326 14 15 668 76 85 112 88 549 35 27 437 440 6 448 105 177 104 1326 112 88 493 212 185 96 1 41 5 711 926 212 185 7 96 1 517 108 311 52 20 1326 37 753 104 88 947 499 6 195 207 16 104 1326 247 38 76 85 112 88 549 35 27 437 440 7 711 926 212 185 96 1 517 108 10 403 90 48 88 947 112 88 493 212 185 96 1 41 10 241 76 66 112 88 549 35 27 437 440 7 556 8 104 1326 54 4 32 1195 4 924 41 5 4 728 88 138 5 864 728 493 212 185 96 1 41 5 198 292 96 1 157 6 286 89 57 271 6 292 212 96 1 180 311 52 88 947 499 6 195 207 16 104 1326 229 21 38 96 1 4 102 8 292 212 864 728 549 35 27 947 864 728 43 27 6 104 1326 14 11 864 728 549 35 27 437 4 1 1 1251 494 541 425 466 257 1 2\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","I1204 09:11:45.632213 139694404269952 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","I1204 09:11:45.632707 139694404269952 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","INFO:tensorflow:masked_lm_positions: 12 28 32 66 70 71 119 130 160 161 180 231 235 258 284 422 425 429 475 501\n","I1204 09:11:45.633000 139694404269952 create_pretraining_data.py:161] masked_lm_positions: 12 28 32 66 70 71 119 130 160 161 180 231 235 258 284 422 425 429 475 501\n","INFO:tensorflow:masked_lm_ids: 5 8 88 1326 112 88 43 190 1 480 217 190 524 121 566 221 696 864 570 440\n","I1204 09:11:45.633256 139694404269952 create_pretraining_data.py:161] masked_lm_ids: 5 8 88 1326 112 88 43 190 1 480 217 190 524 121 566 221 696 864 570 440\n","INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","I1204 09:11:45.633481 139694404269952 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","INFO:tensorflow:next_sentence_labels: 0\n","I1204 09:11:45.633674 139694404269952 create_pretraining_data.py:161] next_sentence_labels: 0\n","INFO:tensorflow:*** Example ***\n","I1204 09:11:45.634932 139694404269952 create_pretraining_data.py:149] *** Example ***\n","INFO:tensorflow:tokens: [CLS] 그 ##라 ##스 ##는 전 ##후 독 ##일 사 ##회 ##민 ##주 ##당 ##의 주 ##요 지 ##지 ##자 ##가 되 ##어 외 ##국 ##인 혐 ##오 ##증 , 신 ##나 ##치 ##주의 등 ##에 반 ##대 ##하는 사 ##회 ##활 ##동 ##에 적 ##극 참 ##여 ##하였 ##다 . [SEP] 만 ##약 추 ##가 ##로 formula [UNK] 1 ##6 ##가 완 ##전 곱 ##셈 ##적 함 ##수 ##일 경우 , 다음 ##이 성 ##립 ##한 ##다 . 즉 , 곱 ##셈 ##적 함 ##수 ##는 소 ##수의 거 ##듭 ##제 ##곱 ##의 상 ##에 의 ##하여 결 ##정 ##되 ##며 , [MASK] ##전 곱 ##셈 ##적 함 ##수 ##는 소 ##수의 [MASK] ##에 의 ##하여 [MASK] ##정 ##된 ##다 . 곱 ##셈 ##적 함 ##수 formula [UNK] 1 [MASK] ##에 대 ##하여 [MASK] 다음과 같은 항 ##등 ##식 ##이 성 ##립 ##한 ##다 . 여 ##기 ##서 formula [UNK] 2 ##3 ##는 뫼 ##비 ##우 ##스 함 ##수 ##이 ##다 . 곱 ##셈 ##적 함 ##수 formula [UNK] 2 ##4 ##의 정의 ##역 formula [UNK] 2 ##5 ##이 formula [UNK] 2 ##6 ##를 만 ##족 ##한 ##다 ##면 , 이 [MASK] . 곱 ##셈 ##적 함 ##수 ##는 디 ##리 ##클 ##레 합 ##성 ##곱 ##에 대 ##하여 아 ##벨 군 ##을 이 ##룬 ##다 . 즉 , 곱 ##셈 ##적 함 ##수 formula [UNK] 1 ##8 ##의 디 ##리 ##클 ##레 합 ##성 ##곱 와 디 ##리 ##클 ##레 역 ##원 은 곱 ##셈 ##적 함 ##수 ##이 ##다 . 곱 ##셈 ##적 함 ##수 formula [UNK] 1 ##에 대 ##하여 , [MASK] ##약 formula [UNK] 1 ##3 ##의 소 ##인 ##수 분 ##해 ##가 일 경우 [MASK] 다음 ##이 성 ##립 ##한 ##다 . 만 ##약 추 ##가 ##로 formula [UNK] 1 ##6 ##가 완 ##전 곱 ##셈 ##적 함 ##수 ##일 경우 , 다음 ##이 성 ##립 ##한 ##다 . 200 같은 수 ##론 ##적 함 ##수 [MASK] 완 ##전 곱 ##셈 ##적 함 ##수 ##이 ##다 . 다음과 같은 수 ##론 ##적 함 ##수 ##들은 곱 ##셈 ##적 함 ##수 ##이나 , 완 쥬 곱 ##셈 ##적 함 ##수 ##가 아 ##니 ##다 . 양 [MASK] 정 ##수 ##를 두 정 ##수의 제 ##곱 ##의 합 ##으로 나타 ##내 ##는 방 ##법 ##의 가 ##짓 ##수 ##를 구 ##하는 함 ##수 는 곱 ##셈 ##적 함 ##수 ##가 아 ##니 ##다 . 예 ##를 들 ##어 , 1 ##을 [MASK] ##곱 ##수 ##로 나타 ##내 ##는 방 ##법 ##은 다음과 같 ##이 4 ##가지 ##가 있 ##다 . 즉 , 이 ##다 . 폰 망 ##골 ##트 함 ##수 는 formula [UNK] 4 ##6 ##이 어 ##떤 소 ##수 formula [UNK] 4 ##8 ##의 양 ##의 정 ##수 제 ##곱 ##일 경우 formula [UNK] 7 ##5 ##를 , 소 ##수의 거 ##듭 [MASK] ##곱 ##이 아 ##닐 경우 [MASK] ##을 [MASK] ##으로 취 ##한 ##다 . 이 ##므 ##로 , 이 ##는 곱 ##셈 ##적 함 ##수 ##가 아 ##니 ##다 . [SEP]\n","I1204 09:11:45.635370 139694404269952 create_pretraining_data.py:151] tokens: [CLS] 그 ##라 ##스 ##는 전 ##후 독 ##일 사 ##회 ##민 ##주 ##당 ##의 주 ##요 지 ##지 ##자 ##가 되 ##어 외 ##국 ##인 혐 ##오 ##증 , 신 ##나 ##치 ##주의 등 ##에 반 ##대 ##하는 사 ##회 ##활 ##동 ##에 적 ##극 참 ##여 ##하였 ##다 . [SEP] 만 ##약 추 ##가 ##로 formula [UNK] 1 ##6 ##가 완 ##전 곱 ##셈 ##적 함 ##수 ##일 경우 , 다음 ##이 성 ##립 ##한 ##다 . 즉 , 곱 ##셈 ##적 함 ##수 ##는 소 ##수의 거 ##듭 ##제 ##곱 ##의 상 ##에 의 ##하여 결 ##정 ##되 ##며 , [MASK] ##전 곱 ##셈 ##적 함 ##수 ##는 소 ##수의 [MASK] ##에 의 ##하여 [MASK] ##정 ##된 ##다 . 곱 ##셈 ##적 함 ##수 formula [UNK] 1 [MASK] ##에 대 ##하여 [MASK] 다음과 같은 항 ##등 ##식 ##이 성 ##립 ##한 ##다 . 여 ##기 ##서 formula [UNK] 2 ##3 ##는 뫼 ##비 ##우 ##스 함 ##수 ##이 ##다 . 곱 ##셈 ##적 함 ##수 formula [UNK] 2 ##4 ##의 정의 ##역 formula [UNK] 2 ##5 ##이 formula [UNK] 2 ##6 ##를 만 ##족 ##한 ##다 ##면 , 이 [MASK] . 곱 ##셈 ##적 함 ##수 ##는 디 ##리 ##클 ##레 합 ##성 ##곱 ##에 대 ##하여 아 ##벨 군 ##을 이 ##룬 ##다 . 즉 , 곱 ##셈 ##적 함 ##수 formula [UNK] 1 ##8 ##의 디 ##리 ##클 ##레 합 ##성 ##곱 와 디 ##리 ##클 ##레 역 ##원 은 곱 ##셈 ##적 함 ##수 ##이 ##다 . 곱 ##셈 ##적 함 ##수 formula [UNK] 1 ##에 대 ##하여 , [MASK] ##약 formula [UNK] 1 ##3 ##의 소 ##인 ##수 분 ##해 ##가 일 경우 [MASK] 다음 ##이 성 ##립 ##한 ##다 . 만 ##약 추 ##가 ##로 formula [UNK] 1 ##6 ##가 완 ##전 곱 ##셈 ##적 함 ##수 ##일 경우 , 다음 ##이 성 ##립 ##한 ##다 . 200 같은 수 ##론 ##적 함 ##수 [MASK] 완 ##전 곱 ##셈 ##적 함 ##수 ##이 ##다 . 다음과 같은 수 ##론 ##적 함 ##수 ##들은 곱 ##셈 ##적 함 ##수 ##이나 , 완 쥬 곱 ##셈 ##적 함 ##수 ##가 아 ##니 ##다 . 양 [MASK] 정 ##수 ##를 두 정 ##수의 제 ##곱 ##의 합 ##으로 나타 ##내 ##는 방 ##법 ##의 가 ##짓 ##수 ##를 구 ##하는 함 ##수 는 곱 ##셈 ##적 함 ##수 ##가 아 ##니 ##다 . 예 ##를 들 ##어 , 1 ##을 [MASK] ##곱 ##수 ##로 나타 ##내 ##는 방 ##법 ##은 다음과 같 ##이 4 ##가지 ##가 있 ##다 . 즉 , 이 ##다 . 폰 망 ##골 ##트 함 ##수 는 formula [UNK] 4 ##6 ##이 어 ##떤 소 ##수 formula [UNK] 4 ##8 ##의 양 ##의 정 ##수 제 ##곱 ##일 경우 formula [UNK] 7 ##5 ##를 , 소 ##수의 거 ##듭 [MASK] ##곱 ##이 아 ##닐 경우 [MASK] ##을 [MASK] ##으로 취 ##한 ##다 . 이 ##므 ##로 , 이 ##는 곱 ##셈 ##적 함 ##수 ##가 아 ##니 ##다 . [SEP]\n","INFO:tensorflow:input_ids: 0 37 53 32 8 51 578 384 42 43 114 162 89 131 5 101 283 63 31 20 13 174 23 418 70 27 1014 393 722 947 357 75 82 396 68 10 231 36 57 43 114 705 86 10 403 783 505 215 328 104 1326 2 163 532 326 13 15 96 1 41 108 13 637 61 660 754 73 197 29 42 335 947 499 6 195 207 16 104 1326 479 947 660 754 73 197 29 8 158 368 291 1320 62 676 5 139 10 124 98 219 47 127 190 947 4 61 660 754 73 197 29 8 158 368 4 10 124 98 4 47 177 104 1326 660 754 73 197 29 96 1 41 4 10 45 98 4 261 246 566 455 122 6 195 207 16 104 1326 229 21 38 96 1 157 95 8 1557 232 221 32 197 29 6 104 1326 660 754 73 197 29 96 1 157 106 5 411 182 96 1 157 102 6 96 1 157 108 11 163 288 16 104 88 947 14 4 1326 660 754 73 197 29 8 650 19 672 365 561 60 676 10 45 98 78 772 603 7 14 910 104 1326 479 947 660 754 73 197 29 96 1 41 103 5 650 19 672 365 561 60 676 739 650 19 672 365 358 80 863 660 754 73 197 29 6 104 1326 660 754 73 197 29 96 1 41 10 45 98 947 4 532 96 1 41 95 5 158 27 29 148 40 13 79 335 4 499 6 195 207 16 104 1326 163 532 326 13 15 96 1 41 108 13 637 61 660 754 73 197 29 42 335 947 499 6 195 207 16 104 1326 210 246 22 123 73 197 29 4 637 61 660 754 73 197 29 6 104 1326 261 246 22 123 73 197 29 300 660 754 73 197 29 332 947 637 2535 660 754 73 197 29 13 78 193 104 1326 243 4 49 29 11 266 49 368 76 676 5 561 24 374 343 8 178 172 5 54 1047 29 11 112 57 197 29 750 660 754 73 197 29 13 78 193 104 1326 322 11 395 23 947 41 7 4 676 29 15 374 343 8 178 172 12 261 223 6 320 641 13 71 104 1326 479 947 14 104 1326 1345 1013 951 92 197 29 750 96 1 320 108 6 281 644 158 29 96 1 320 103 5 243 5 49 29 76 676 42 335 96 1 524 102 11 947 158 368 291 1320 4 676 6 78 1622 335 4 7 4 24 600 16 104 1326 14 559 15 947 14 8 660 754 73 197 29 13 78 193 104 1326 2 0 0 0 0 0 0 0 0 0 0 0 0 0\n","I1204 09:11:45.635742 139694404269952 create_pretraining_data.py:161] input_ids: 0 37 53 32 8 51 578 384 42 43 114 162 89 131 5 101 283 63 31 20 13 174 23 418 70 27 1014 393 722 947 357 75 82 396 68 10 231 36 57 43 114 705 86 10 403 783 505 215 328 104 1326 2 163 532 326 13 15 96 1 41 108 13 637 61 660 754 73 197 29 42 335 947 499 6 195 207 16 104 1326 479 947 660 754 73 197 29 8 158 368 291 1320 62 676 5 139 10 124 98 219 47 127 190 947 4 61 660 754 73 197 29 8 158 368 4 10 124 98 4 47 177 104 1326 660 754 73 197 29 96 1 41 4 10 45 98 4 261 246 566 455 122 6 195 207 16 104 1326 229 21 38 96 1 157 95 8 1557 232 221 32 197 29 6 104 1326 660 754 73 197 29 96 1 157 106 5 411 182 96 1 157 102 6 96 1 157 108 11 163 288 16 104 88 947 14 4 1326 660 754 73 197 29 8 650 19 672 365 561 60 676 10 45 98 78 772 603 7 14 910 104 1326 479 947 660 754 73 197 29 96 1 41 103 5 650 19 672 365 561 60 676 739 650 19 672 365 358 80 863 660 754 73 197 29 6 104 1326 660 754 73 197 29 96 1 41 10 45 98 947 4 532 96 1 41 95 5 158 27 29 148 40 13 79 335 4 499 6 195 207 16 104 1326 163 532 326 13 15 96 1 41 108 13 637 61 660 754 73 197 29 42 335 947 499 6 195 207 16 104 1326 210 246 22 123 73 197 29 4 637 61 660 754 73 197 29 6 104 1326 261 246 22 123 73 197 29 300 660 754 73 197 29 332 947 637 2535 660 754 73 197 29 13 78 193 104 1326 243 4 49 29 11 266 49 368 76 676 5 561 24 374 343 8 178 172 5 54 1047 29 11 112 57 197 29 750 660 754 73 197 29 13 78 193 104 1326 322 11 395 23 947 41 7 4 676 29 15 374 343 8 178 172 12 261 223 6 320 641 13 71 104 1326 479 947 14 104 1326 1345 1013 951 92 197 29 750 96 1 320 108 6 281 644 158 29 96 1 320 103 5 243 5 49 29 76 676 42 335 96 1 524 102 11 947 158 368 291 1320 4 676 6 78 1622 335 4 7 4 24 600 16 104 1326 14 559 15 947 14 8 660 754 73 197 29 13 78 193 104 1326 2 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n","I1204 09:11:45.636115 139694404269952 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n","I1204 09:11:45.636521 139694404269952 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:masked_lm_positions: 103 113 117 130 134 192 251 258 265 280 315 322 349 361 400 405 468 474 476 487\n","I1204 09:11:45.636719 139694404269952 create_pretraining_data.py:161] masked_lm_positions: 103 113 117 130 134 192 251 258 265 280 315 322 349 361 400 405 468 474 476 487\n","INFO:tensorflow:masked_lm_ids: 637 139 219 103 947 104 104 96 163 947 261 300 61 5 395 76 62 636 614 8\n","I1204 09:11:45.636879 139694404269952 create_pretraining_data.py:161] masked_lm_ids: 637 139 219 103 947 104 104 96 163 947 261 300 61 5 395 76 62 636 614 8\n","INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","I1204 09:11:45.637093 139694404269952 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","INFO:tensorflow:next_sentence_labels: 1\n","I1204 09:11:45.637237 139694404269952 create_pretraining_data.py:161] next_sentence_labels: 1\n","INFO:tensorflow:*** Example ***\n","I1204 09:11:45.638036 139694404269952 create_pretraining_data.py:149] *** Example ***\n","INFO:tensorflow:tokens: [CLS] ##용 ##과 로 ##봇 공 ##학 [MASK] 의 ##미 ##한 ##다 . 이 말 ##은 미국 과 ##학 ##자 ##이 ##면서 작 ##가 [MASK] 아 ##이 ##작 아 ##시 ##모 ##프 [MASK] 19 ##4 ##2 ##년에 발 ##간 ##한 단 ##편 R ##u ##n ##a ##r ##o ##u ##n ##d ##에서 최 ##초 ##로 [MASK] ##하였 ##다 . 명 ##사 ##로 ##서 로 ##봇 ##은 다음 ##의 의 ##미 ##를 지 ##닌 ##다 . 공 ##포 ##를 주 ##거 ##나 유 ##머 ##스 ##런 행 ##동 ##을 하 ##는 융 ##통 ##성 ##이 없 ##는 기 ##계 인 ##간 일 ##할 수 있는 능 ##력 ##은 있 ##어 ##도 생 ##각 ##할 수 있는 능 ##력 ##이 없 ##는 인 ##간 ##을 [MASK] ##은 것 . 팔 ##과 손 ##을 가지 ##고 , 인 ##간 ##에게 프로 ##그 ##래 ##밍 ##되어 여러 가지 연 ##속 동 ##작 ##이나 운 ##반 작 ##업 ##을 하 ##고 , 주 ##위 ##를 잘 보 ##고 , 애 ##초 ##부터 결 ##정 ##된 방 ##법 [MASK] 자 ##기 ##의 운동 ##을 조 ##절 ##하여 움 ##직 ##일 수 있는 기 ##계 ##이 ##다 . 아 ##이 ##작 아 ##시 ##모 ##프 ##가 19 ##5 ##0년 발 ##간 ##한 소 ##설 ##인 ' I ' R ##o ##b ##o ##t ' 에 ##서 제 ##안 ##된 로 ##봇 ##의 행 ##동 ##에 관 ##한 3 ##가지 [MASK] ##칙 ##이 ##다 . 제 ##1 ##법 ##칙 : 로 ##봇 [MASK] 인 ##간 ##에게 해 ##를 끼 ##쳐 ##서 ##는 안 되 [MASK] , 위 ##험 [MASK] 처 ##해 있는 인 ##간 ##을 방 ##관 [MASK] ##서 ##도 안 된 ##다 . 제 ##2 ##법 ##칙 : 로 ##봇 ##은 인 ##간 ##의 명 ##령 ##에 반 ##드 [SEP] 단 , 제 ##1 ##법 ##칙 ##을 거 ##스 ##를 경우 ##에는 제 ##외 ##다 . [MASK] ##3 ##법 [MASK] : 로 ##봇 ##은 자 ##기 자 ##신 ##을 보 [MASK] ##해 ##야 ##만 한 ##다 . 단 , 제 ##1 ##법 ##칙 ##과 제 ##2 ##법 ##칙 ##을 거 ##스 ##를 경우 ##는 예 ##외 ##다 . 군 ##사용 로 ##봇 ##이 공 ##격 ##의 기 ##능 ##을 [MASK] ##출 경우 , 첫 번 ##째 원 ##칙 ##에 위 ##배 ##되 ##게 된 ##다 . 그 ##동 ##안 인 ##간 ##이 해 오 ##던 많 ##은 일 ##들 ##을 지 ##금 ##은 로 ##봇 ##이 대 ##신 ##하고 있 ##다 . 산 ##업 현 ##장 ##에는 단 ##조 ##로 ##운 반 ##복 작 ##A ##이나 따 ##분 ##한 작 ##업 , 불 ##쾌 ##한 작 ##업 ##들이 많 ##은 ##데 , 이 ##와 같은 작 ##업 ##은 특 ##히 로 ##봇 ##에게 맡 ##기 ##기 ##에 적 ##합 ##하 [MASK] . [MASK] ##립 공 ##장 ##에서 리 ##벳 박 ##는 일 , 용 ##접 , 자 ##동 ##차 차 ##체 ##를 칠 ##하는 일 등 ##은 그 좋 ##은 예 ##이 ##다 . 이 ##런 종 ##류 [MASK] 작 ##업 ##은 로 ##봇 쪽 ##이 인 ##간 ##보 ##다 더 잘 해 ##낼 수 있 ##다 . [SEP]\n","I1204 09:11:45.638386 139694404269952 create_pretraining_data.py:151] tokens: [CLS] ##용 ##과 로 ##봇 공 ##학 [MASK] 의 ##미 ##한 ##다 . 이 말 ##은 미국 과 ##학 ##자 ##이 ##면서 작 ##가 [MASK] 아 ##이 ##작 아 ##시 ##모 ##프 [MASK] 19 ##4 ##2 ##년에 발 ##간 ##한 단 ##편 R ##u ##n ##a ##r ##o ##u ##n ##d ##에서 최 ##초 ##로 [MASK] ##하였 ##다 . 명 ##사 ##로 ##서 로 ##봇 ##은 다음 ##의 의 ##미 ##를 지 ##닌 ##다 . 공 ##포 ##를 주 ##거 ##나 유 ##머 ##스 ##런 행 ##동 ##을 하 ##는 융 ##통 ##성 ##이 없 ##는 기 ##계 인 ##간 일 ##할 수 있는 능 ##력 ##은 있 ##어 ##도 생 ##각 ##할 수 있는 능 ##력 ##이 없 ##는 인 ##간 ##을 [MASK] ##은 것 . 팔 ##과 손 ##을 가지 ##고 , 인 ##간 ##에게 프로 ##그 ##래 ##밍 ##되어 여러 가지 연 ##속 동 ##작 ##이나 운 ##반 작 ##업 ##을 하 ##고 , 주 ##위 ##를 잘 보 ##고 , 애 ##초 ##부터 결 ##정 ##된 방 ##법 [MASK] 자 ##기 ##의 운동 ##을 조 ##절 ##하여 움 ##직 ##일 수 있는 기 ##계 ##이 ##다 . 아 ##이 ##작 아 ##시 ##모 ##프 ##가 19 ##5 ##0년 발 ##간 ##한 소 ##설 ##인 ' I ' R ##o ##b ##o ##t ' 에 ##서 제 ##안 ##된 로 ##봇 ##의 행 ##동 ##에 관 ##한 3 ##가지 [MASK] ##칙 ##이 ##다 . 제 ##1 ##법 ##칙 : 로 ##봇 [MASK] 인 ##간 ##에게 해 ##를 끼 ##쳐 ##서 ##는 안 되 [MASK] , 위 ##험 [MASK] 처 ##해 있는 인 ##간 ##을 방 ##관 [MASK] ##서 ##도 안 된 ##다 . 제 ##2 ##법 ##칙 : 로 ##봇 ##은 인 ##간 ##의 명 ##령 ##에 반 ##드 [SEP] 단 , 제 ##1 ##법 ##칙 ##을 거 ##스 ##를 경우 ##에는 제 ##외 ##다 . [MASK] ##3 ##법 [MASK] : 로 ##봇 ##은 자 ##기 자 ##신 ##을 보 [MASK] ##해 ##야 ##만 한 ##다 . 단 , 제 ##1 ##법 ##칙 ##과 제 ##2 ##법 ##칙 ##을 거 ##스 ##를 경우 ##는 예 ##외 ##다 . 군 ##사용 로 ##봇 ##이 공 ##격 ##의 기 ##능 ##을 [MASK] ##출 경우 , 첫 번 ##째 원 ##칙 ##에 위 ##배 ##되 ##게 된 ##다 . 그 ##동 ##안 인 ##간 ##이 해 오 ##던 많 ##은 일 ##들 ##을 지 ##금 ##은 로 ##봇 ##이 대 ##신 ##하고 있 ##다 . 산 ##업 현 ##장 ##에는 단 ##조 ##로 ##운 반 ##복 작 ##A ##이나 따 ##분 ##한 작 ##업 , 불 ##쾌 ##한 작 ##업 ##들이 많 ##은 ##데 , 이 ##와 같은 작 ##업 ##은 특 ##히 로 ##봇 ##에게 맡 ##기 ##기 ##에 적 ##합 ##하 [MASK] . [MASK] ##립 공 ##장 ##에서 리 ##벳 박 ##는 일 , 용 ##접 , 자 ##동 ##차 차 ##체 ##를 칠 ##하는 일 등 ##은 그 좋 ##은 예 ##이 ##다 . 이 ##런 종 ##류 [MASK] 작 ##업 ##은 로 ##봇 쪽 ##이 인 ##간 ##보 ##다 더 잘 해 ##낼 수 있 ##다 . [SEP]\n","INFO:tensorflow:input_ids: 0 90 25 439 830 93 28 4 124 189 16 104 1326 14 334 12 456 297 28 20 6 304 255 13 4 78 6 394 78 33 383 423 4 65 106 66 458 134 141 16 252 483 1009 727 466 424 548 494 727 466 791 26 301 507 15 4 328 104 1326 389 35 15 38 439 830 12 499 5 124 189 11 63 617 104 1326 93 355 11 101 206 75 77 745 32 646 412 86 7 52 8 1615 333 60 6 273 8 44 58 83 141 79 117 22 225 1125 161 12 71 23 18 244 212 117 22 225 1125 161 6 273 8 83 141 7 4 12 72 1326 1136 25 936 7 446 30 947 83 141 422 430 307 250 1322 354 447 446 126 201 175 394 332 500 192 255 168 7 52 30 947 101 142 11 807 107 30 947 583 507 224 219 47 177 178 172 4 64 21 5 339 7 119 592 98 1020 372 42 22 225 44 58 6 104 1326 78 6 394 78 33 383 423 13 65 102 268 134 141 16 158 381 27 203 721 203 1009 494 950 494 509 203 276 38 76 275 177 439 830 5 412 86 10 143 16 180 641 4 440 6 104 1326 76 85 172 440 1545 439 830 4 83 141 422 202 11 1192 702 38 8 474 174 4 947 138 495 4 550 40 225 83 141 7 178 265 4 38 18 474 340 104 1326 76 66 172 440 1545 439 830 12 83 141 5 389 698 10 231 160 2 252 947 76 85 172 440 7 291 32 11 335 159 76 522 104 1326 4 95 172 4 1545 439 830 12 64 21 64 187 7 107 4 40 214 125 97 104 1326 252 947 76 85 172 440 25 76 66 172 440 7 291 32 11 335 8 322 522 104 1326 603 1621 439 830 6 93 515 5 44 330 7 4 512 335 947 777 562 604 171 440 10 138 571 127 147 340 104 1326 37 86 275 83 141 6 202 216 233 287 12 79 99 7 63 462 12 439 830 6 45 187 154 71 104 1326 484 168 242 50 159 252 146 15 352 231 574 255 546 332 491 130 16 255 168 947 205 1854 16 255 168 295 287 12 194 947 14 39 246 255 168 12 305 209 439 830 422 1060 21 21 10 403 220 48 4 1326 4 207 93 50 26 557 1633 606 8 79 947 692 667 947 64 86 213 363 115 11 1815 57 79 68 12 37 964 12 322 6 104 1326 14 646 419 349 4 255 168 12 439 830 1411 6 83 141 100 104 392 807 202 831 22 71 104 1326 2\n","I1204 09:11:45.736999 139694404269952 create_pretraining_data.py:161] input_ids: 0 90 25 439 830 93 28 4 124 189 16 104 1326 14 334 12 456 297 28 20 6 304 255 13 4 78 6 394 78 33 383 423 4 65 106 66 458 134 141 16 252 483 1009 727 466 424 548 494 727 466 791 26 301 507 15 4 328 104 1326 389 35 15 38 439 830 12 499 5 124 189 11 63 617 104 1326 93 355 11 101 206 75 77 745 32 646 412 86 7 52 8 1615 333 60 6 273 8 44 58 83 141 79 117 22 225 1125 161 12 71 23 18 244 212 117 22 225 1125 161 6 273 8 83 141 7 4 12 72 1326 1136 25 936 7 446 30 947 83 141 422 430 307 250 1322 354 447 446 126 201 175 394 332 500 192 255 168 7 52 30 947 101 142 11 807 107 30 947 583 507 224 219 47 177 178 172 4 64 21 5 339 7 119 592 98 1020 372 42 22 225 44 58 6 104 1326 78 6 394 78 33 383 423 13 65 102 268 134 141 16 158 381 27 203 721 203 1009 494 950 494 509 203 276 38 76 275 177 439 830 5 412 86 10 143 16 180 641 4 440 6 104 1326 76 85 172 440 1545 439 830 4 83 141 422 202 11 1192 702 38 8 474 174 4 947 138 495 4 550 40 225 83 141 7 178 265 4 38 18 474 340 104 1326 76 66 172 440 1545 439 830 12 83 141 5 389 698 10 231 160 2 252 947 76 85 172 440 7 291 32 11 335 159 76 522 104 1326 4 95 172 4 1545 439 830 12 64 21 64 187 7 107 4 40 214 125 97 104 1326 252 947 76 85 172 440 25 76 66 172 440 7 291 32 11 335 8 322 522 104 1326 603 1621 439 830 6 93 515 5 44 330 7 4 512 335 947 777 562 604 171 440 10 138 571 127 147 340 104 1326 37 86 275 83 141 6 202 216 233 287 12 79 99 7 63 462 12 439 830 6 45 187 154 71 104 1326 484 168 242 50 159 252 146 15 352 231 574 255 546 332 491 130 16 255 168 947 205 1854 16 255 168 295 287 12 194 947 14 39 246 255 168 12 305 209 439 830 422 1060 21 21 10 403 220 48 4 1326 4 207 93 50 26 557 1633 606 8 79 947 692 667 947 64 86 213 363 115 11 1815 57 79 68 12 37 964 12 322 6 104 1326 14 646 419 349 4 255 168 12 439 830 1411 6 83 141 100 104 392 807 202 831 22 71 104 1326 2\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","I1204 09:11:45.737473 139694404269952 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","I1204 09:11:45.737937 139694404269952 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","INFO:tensorflow:masked_lm_positions: 7 24 32 55 123 172 232 244 256 260 269 309 312 323 362 380 417 453 455 491\n","I1204 09:11:45.738132 139694404269952 create_pretraining_data.py:161] masked_lm_positions: 7 24 32 55 123 172 232 244 256 260 269 309 312 323 362 380 417 453 455 491\n","INFO:tensorflow:masked_lm_ids: 7 27 13 165 1567 24 171 12 190 10 40 76 440 208 624 86 168 104 119 5\n","I1204 09:11:45.738315 139694404269952 create_pretraining_data.py:161] masked_lm_ids: 7 27 13 165 1567 24 171 12 190 10 40 76 440 208 624 86 168 104 119 5\n","INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","I1204 09:11:45.738499 139694404269952 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","INFO:tensorflow:next_sentence_labels: 0\n","I1204 09:11:45.738697 139694404269952 create_pretraining_data.py:161] next_sentence_labels: 0\n","INFO:tensorflow:*** Example ***\n","I1204 09:11:45.740118 139694404269952 create_pretraining_data.py:149] *** Example ***\n","INFO:tensorflow:tokens: [CLS] 도 ##스 ##는 디 ##스 ##크 운 ##영 체 ##제 ##의 일 ##종 ##으로 ##서 디 ##스 ##크 [MASK] 읽 ##고 쓰 ##기 등 ##의 명 ##령 ##을 수 ##행 [MASK] 프로 ##그 ##램 ##이 ##다 . 명 ##령 ##어 ##를 직 ##접 치 ##는 명 ##령 줄 기 ##반 ##이 ##다 . 19 ##8 ##1 ##년 ##부터 199 ##5 ##년 [MASK] , d 부 ##분 ##적으로 M ##S - D ##O ##S 기 ##반 ##인 마 ##이 ##크 ##로 ##소 ##프트 윈 ##도 ##우 ##를 [MASK] ##함 ##한 200 ##0년 ##까지 ##는 M ##S - D ##O ##S ##가 I ##B ##M P ##C 호 ##환 ##기 ##종 시 ##장 ##을 [MASK] ##악 ##하였 ##다 . [SEP] ##C D ##O ##S , D ##R - D ##O ##S , 프 ##리 ##도 ##스 [MASK] R ##O ##M - D ##O ##S , P ##T ##S - D ##O ##S ##를 포 ##함 ##한 비 ##슷 ##한 명 ##령 줄 시 ##스 ##템 ##의 계 ##열 ##이 ##다 . [MASK] 시 ##스 ##템 ##들 중 어 ##느 것 ##도 간 ##단 ##히 \" 도 ##스 \" 라 ##고 불 ##리 ##진 않 ##았 [MASK] . 이 ##와 무 ##관 [MASK] [MASK] ##많 ##은 비 ##x ##8 ##6 마 ##이 ##크 ##로 ##컴 ##퓨터 디 ##스 ##크 운 ##영 체 ##제 ##는 \" 도 ##스 \" 라 ##는 이 ##름 ##을 그 ##대 ##로 사용 ##하였 ##으 ##며 이 ##들 ##을 사용 ##하는 컴 ##퓨터 ##에 대해 논 ##할 [MASK] 단 ##순 ##히 \" 도 ##스 \" 라 ##고 부 ##르 ##곤 했 ##다 . 디 ##지 ##털 리 ##서 ##치 ##의 C ##P / M ##이 가 ##장 대 ##표 ##적인 도 ##스 ##의 원 ##형 ##이 ##다 . 8 ##비 ##트 개 ##인 ##용 컴 ##퓨터 ##에는 C ##P / 더 ##이 널 ##리 사용 ##되었 ##으나 애 ##플 I ##I ##는 독 ##자 ##적인 애 ##플 도 ##스 [MASK] , M ##S ##X ##는 M ##S ##X - D ##O ##S ##를 썼 ##다 . 이 ##들 컴 ##퓨터 ##도 나 ##중 ##에 C ##P / M ##을 지 ##원 ##하지만 디 ##스 ##크 ##의 포 ##맷 ##이 달 ##라 ##서 서 ##로 바 ##꾸 ##어 쓸 수 ##는 없 ##었 ##다 . I ##B ##M - P ##C ##에서는 이 ##를 모 ##방 ##한 Q ##D [MASK] ##S ##로 ##부터 P ##C - D ##O ##S ##와 M ##S - D ##O ##S ##가 나 ##왔 ##으 ##며 , 나 ##중 ##에 C ##P / M ##은 1 ##6 ##비 ##트 버 ##전 ##인 C ##P / [MASK] - 8 ##6 바 ##탕 ##으로 D ##R - D ##O ##S ##로 나 ##왔 [MASK] . 현 ##재 ##는 D ##R - D ##O ##S ##의 후 ##기 ##작 ##인 오 ##픈 ##도 ##스 ##와 , N ##T ##F ##S 등 ##을 지 ##원 ##하는 공 ##개 도 ##스 프로 ##젝 ##트 ##인 프 ##리 ##도 ##스 ##가 있 [MASK] . M ##S - D ##O ##S ##는 마 ##이 ##크 ##로 ##소 ##프트 ##가 만 ##든 가 [SEP]\n","I1204 09:11:45.740618 139694404269952 create_pretraining_data.py:151] tokens: [CLS] 도 ##스 ##는 디 ##스 ##크 운 ##영 체 ##제 ##의 일 ##종 ##으로 ##서 디 ##스 ##크 [MASK] 읽 ##고 쓰 ##기 등 ##의 명 ##령 ##을 수 ##행 [MASK] 프로 ##그 ##램 ##이 ##다 . 명 ##령 ##어 ##를 직 ##접 치 ##는 명 ##령 줄 기 ##반 ##이 ##다 . 19 ##8 ##1 ##년 ##부터 199 ##5 ##년 [MASK] , d 부 ##분 ##적으로 M ##S - D ##O ##S 기 ##반 ##인 마 ##이 ##크 ##로 ##소 ##프트 윈 ##도 ##우 ##를 [MASK] ##함 ##한 200 ##0년 ##까지 ##는 M ##S - D ##O ##S ##가 I ##B ##M P ##C 호 ##환 ##기 ##종 시 ##장 ##을 [MASK] ##악 ##하였 ##다 . [SEP] ##C D ##O ##S , D ##R - D ##O ##S , 프 ##리 ##도 ##스 [MASK] R ##O ##M - D ##O ##S , P ##T ##S - D ##O ##S ##를 포 ##함 ##한 비 ##슷 ##한 명 ##령 줄 시 ##스 ##템 ##의 계 ##열 ##이 ##다 . [MASK] 시 ##스 ##템 ##들 중 어 ##느 것 ##도 간 ##단 ##히 \" 도 ##스 \" 라 ##고 불 ##리 ##진 않 ##았 [MASK] . 이 ##와 무 ##관 [MASK] [MASK] ##많 ##은 비 ##x ##8 ##6 마 ##이 ##크 ##로 ##컴 ##퓨터 디 ##스 ##크 운 ##영 체 ##제 ##는 \" 도 ##스 \" 라 ##는 이 ##름 ##을 그 ##대 ##로 사용 ##하였 ##으 ##며 이 ##들 ##을 사용 ##하는 컴 ##퓨터 ##에 대해 논 ##할 [MASK] 단 ##순 ##히 \" 도 ##스 \" 라 ##고 부 ##르 ##곤 했 ##다 . 디 ##지 ##털 리 ##서 ##치 ##의 C ##P / M ##이 가 ##장 대 ##표 ##적인 도 ##스 ##의 원 ##형 ##이 ##다 . 8 ##비 ##트 개 ##인 ##용 컴 ##퓨터 ##에는 C ##P / 더 ##이 널 ##리 사용 ##되었 ##으나 애 ##플 I ##I ##는 독 ##자 ##적인 애 ##플 도 ##스 [MASK] , M ##S ##X ##는 M ##S ##X - D ##O ##S ##를 썼 ##다 . 이 ##들 컴 ##퓨터 ##도 나 ##중 ##에 C ##P / M ##을 지 ##원 ##하지만 디 ##스 ##크 ##의 포 ##맷 ##이 달 ##라 ##서 서 ##로 바 ##꾸 ##어 쓸 수 ##는 없 ##었 ##다 . I ##B ##M - P ##C ##에서는 이 ##를 모 ##방 ##한 Q ##D [MASK] ##S ##로 ##부터 P ##C - D ##O ##S ##와 M ##S - D ##O ##S ##가 나 ##왔 ##으 ##며 , 나 ##중 ##에 C ##P / M ##은 1 ##6 ##비 ##트 버 ##전 ##인 C ##P / [MASK] - 8 ##6 바 ##탕 ##으로 D ##R - D ##O ##S ##로 나 ##왔 [MASK] . 현 ##재 ##는 D ##R - D ##O ##S ##의 후 ##기 ##작 ##인 오 ##픈 ##도 ##스 ##와 , N ##T ##F ##S 등 ##을 지 ##원 ##하는 공 ##개 도 ##스 프로 ##젝 ##트 ##인 프 ##리 ##도 ##스 ##가 있 [MASK] . M ##S - D ##O ##S ##는 마 ##이 ##크 ##로 ##소 ##프트 ##가 만 ##든 가 [SEP]\n","INFO:tensorflow:input_ids: 0 191 32 8 650 32 149 500 254 388 62 5 79 469 24 38 650 32 149 4 1022 30 463 21 68 5 389 698 7 22 249 4 430 307 611 6 104 1326 389 698 23 11 443 667 730 8 389 698 756 44 192 6 104 1326 65 103 85 34 224 386 102 34 4 947 1315 144 130 184 795 460 924 757 635 460 44 192 27 286 6 149 15 94 436 972 18 221 11 4 240 16 210 268 289 8 795 460 924 757 635 460 13 721 627 651 429 413 629 473 21 469 109 50 7 4 567 328 104 1326 2 413 757 635 460 947 757 861 924 757 635 460 947 555 19 18 32 4 1009 635 651 924 757 635 460 947 429 599 460 924 757 635 460 11 377 240 16 116 1006 16 389 698 756 109 32 669 5 204 582 6 104 1326 4 109 32 669 99 69 281 875 72 18 468 228 209 170 191 32 170 478 30 205 19 132 188 296 4 1326 14 39 253 265 4 4 916 12 116 1050 103 108 286 6 149 15 1323 454 650 32 149 500 254 388 62 8 170 191 32 170 478 8 14 405 7 37 36 15 165 328 319 190 14 99 7 165 57 445 454 10 356 475 117 4 252 678 209 170 191 32 170 478 30 144 87 1295 407 104 1326 650 31 1034 557 38 82 5 594 529 1199 795 6 54 50 45 264 153 191 32 5 171 185 6 104 1326 517 232 92 140 27 90 445 454 159 594 529 1199 392 6 938 19 165 452 351 583 653 721 839 8 384 20 153 583 653 191 32 4 947 795 460 1158 8 795 460 1158 924 757 635 460 11 1151 104 1326 14 99 445 454 18 238 299 10 594 529 1199 795 7 63 80 948 650 32 149 5 377 2326 6 534 53 38 135 15 336 1279 23 1177 22 8 273 251 104 1326 721 627 651 924 429 413 293 14 11 120 315 16 1826 538 4 460 15 224 429 413 924 757 635 460 39 795 460 924 757 635 460 13 238 844 319 190 947 238 299 10 594 529 1199 795 12 41 108 232 92 710 61 27 594 529 1199 4 924 517 108 336 1015 24 757 861 924 757 635 460 15 238 844 4 1326 242 173 8 757 861 924 757 635 460 5 196 21 394 27 216 1367 18 32 39 947 920 599 886 460 68 7 63 80 57 93 235 191 32 430 847 92 27 555 19 18 32 13 71 4 1326 795 460 924 757 635 460 8 286 6 149 15 94 436 13 163 338 54 2\n","I1204 09:11:45.742840 139694404269952 create_pretraining_data.py:161] input_ids: 0 191 32 8 650 32 149 500 254 388 62 5 79 469 24 38 650 32 149 4 1022 30 463 21 68 5 389 698 7 22 249 4 430 307 611 6 104 1326 389 698 23 11 443 667 730 8 389 698 756 44 192 6 104 1326 65 103 85 34 224 386 102 34 4 947 1315 144 130 184 795 460 924 757 635 460 44 192 27 286 6 149 15 94 436 972 18 221 11 4 240 16 210 268 289 8 795 460 924 757 635 460 13 721 627 651 429 413 629 473 21 469 109 50 7 4 567 328 104 1326 2 413 757 635 460 947 757 861 924 757 635 460 947 555 19 18 32 4 1009 635 651 924 757 635 460 947 429 599 460 924 757 635 460 11 377 240 16 116 1006 16 389 698 756 109 32 669 5 204 582 6 104 1326 4 109 32 669 99 69 281 875 72 18 468 228 209 170 191 32 170 478 30 205 19 132 188 296 4 1326 14 39 253 265 4 4 916 12 116 1050 103 108 286 6 149 15 1323 454 650 32 149 500 254 388 62 8 170 191 32 170 478 8 14 405 7 37 36 15 165 328 319 190 14 99 7 165 57 445 454 10 356 475 117 4 252 678 209 170 191 32 170 478 30 144 87 1295 407 104 1326 650 31 1034 557 38 82 5 594 529 1199 795 6 54 50 45 264 153 191 32 5 171 185 6 104 1326 517 232 92 140 27 90 445 454 159 594 529 1199 392 6 938 19 165 452 351 583 653 721 839 8 384 20 153 583 653 191 32 4 947 795 460 1158 8 795 460 1158 924 757 635 460 11 1151 104 1326 14 99 445 454 18 238 299 10 594 529 1199 795 7 63 80 948 650 32 149 5 377 2326 6 534 53 38 135 15 336 1279 23 1177 22 8 273 251 104 1326 721 627 651 924 429 413 293 14 11 120 315 16 1826 538 4 460 15 224 429 413 924 757 635 460 39 795 460 924 757 635 460 13 238 844 319 190 947 238 299 10 594 529 1199 795 12 41 108 232 92 710 61 27 594 529 1199 4 924 517 108 336 1015 24 757 861 924 757 635 460 15 238 844 4 1326 242 173 8 757 861 924 757 635 460 5 196 21 394 27 216 1367 18 32 39 947 920 599 886 460 68 7 63 80 57 93 235 191 32 430 847 92 27 555 19 18 32 13 71 4 1326 795 460 924 757 635 460 8 286 6 149 15 94 436 13 163 338 54 2\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","I1204 09:11:45.743320 139694404269952 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","I1204 09:11:45.743753 139694404269952 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","INFO:tensorflow:masked_lm_positions: 19 31 62 64 87 113 121 135 170 194 197 200 201 249 302 321 390 431 447 492\n","I1204 09:11:45.743955 139694404269952 create_pretraining_data.py:161] masked_lm_positions: 19 31 62 64 87 113 121 135 170 194 197 200 201 249 302 321 390 431 447 492\n","INFO:tensorflow:masked_lm_ids: 10 57 289 417 377 421 635 947 14 104 39 16 22 302 795 11 635 795 104 104\n","I1204 09:11:45.744122 139694404269952 create_pretraining_data.py:161] masked_lm_ids: 10 57 289 417 377 421 635 947 14 104 39 16 22 302 795 11 635 795 104 104\n","INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","I1204 09:11:45.744290 139694404269952 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","INFO:tensorflow:next_sentence_labels: 0\n","I1204 09:11:45.744454 139694404269952 create_pretraining_data.py:161] next_sentence_labels: 0\n","INFO:tensorflow:*** Example ***\n","I1204 09:11:45.746009 139694404269952 create_pretraining_data.py:149] *** Example ***\n","INFO:tensorflow:tokens: [CLS] 레 ##오 ##나 ##르 ##도 다 ##빈 ##치 ##는 르 ##네 ##상 ##스 ##기 ##의 예 ##술 ##가 겸 기 ##술 ##자 ##로 유 ##명 ##하 ##다 . [SEP] 대 [MASK] ##얼 올 ##스 ##턴 ‘ 몇 ##몇 ##을 [MASK] ##함 ##한 위키 ##백 ##과 사용 ##자 ##들이 현 ##재 ##의 [MASK] ##양 [MASK] ##를 [MASK] ##춘 프로 ##젝 ##트 ##를 처 ##음 출 [MASK] ##시 ##켰 [MASK] . 위키 [MASK] [MASK] ##사 ##전 프로 ##젝 ##트 ##는 200 [MASK] [MASK] 1 ##2 ##월 1 ##2 ##일 시작 ##되었 ##고 , 200 ##2 ##년 1 ##2 ##월 2 ##6 ##일 공 ##식 주 ##소 ##를 얻 ##어 , 200 ##3 ##년 6 ##월 20 ##일 위키 ##미 ##디 ##어 재 ##단 ##의 일 ##원 ##이 되 ##었 ##다 . 201 ##6 ##년 2 ##월 , 한국 ##어 위키 ##낱 ##말 ##사 ##전 ##은 20 ##번 [MASK] 훈 [MASK] ##제 ##어 수 ##가 많 ##은 위키 ##낱 ##말 ##사 ##전 ##이 ##었 ##으나 201 ##8 ##년 7 ##월 [MASK] 2 ##1 ##번 ##째 ##로 표 ##제 ##어 [MASK] ##가 많 ##은 위키 ##낱 [MASK] ##사 ##전 ##이 되 ##었 ##다 [MASK] [SEP]\n","I1204 09:11:45.746316 139694404269952 create_pretraining_data.py:151] tokens: [CLS] 레 ##오 ##나 ##르 ##도 다 ##빈 ##치 ##는 르 ##네 ##상 ##스 ##기 ##의 예 ##술 ##가 겸 기 ##술 ##자 ##로 유 ##명 ##하 ##다 . [SEP] 대 [MASK] ##얼 올 ##스 ##턴 ‘ 몇 ##몇 ##을 [MASK] ##함 ##한 위키 ##백 ##과 사용 ##자 ##들이 현 ##재 ##의 [MASK] ##양 [MASK] ##를 [MASK] ##춘 프로 ##젝 ##트 ##를 처 ##음 출 [MASK] ##시 ##켰 [MASK] . 위키 [MASK] [MASK] ##사 ##전 프로 ##젝 ##트 ##는 200 [MASK] [MASK] 1 ##2 ##월 1 ##2 ##일 시작 ##되었 ##고 , 200 ##2 ##년 1 ##2 ##월 2 ##6 ##일 공 ##식 주 ##소 ##를 얻 ##어 , 200 ##3 ##년 6 ##월 20 ##일 위키 ##미 ##디 ##어 재 ##단 ##의 일 ##원 ##이 되 ##었 ##다 . 201 ##6 ##년 2 ##월 , 한국 ##어 위키 ##낱 ##말 ##사 ##전 ##은 20 ##번 [MASK] 훈 [MASK] ##제 ##어 수 ##가 많 ##은 위키 ##낱 ##말 ##사 ##전 ##이 ##었 ##으나 201 ##8 ##년 7 ##월 [MASK] 2 ##1 ##번 ##째 ##로 표 ##제 ##어 [MASK] ##가 많 ##은 위키 ##낱 [MASK] ##사 ##전 ##이 되 ##었 ##다 [MASK] [SEP]\n","INFO:tensorflow:input_ids: 0 812 393 75 87 18 129 1208 82 8 1038 789 59 32 21 5 322 342 13 1291 44 342 20 15 77 105 48 104 1326 2 45 4 1383 709 32 670 595 793 1130 7 4 240 16 457 406 25 165 20 295 242 173 5 4 321 4 11 4 1072 430 847 92 11 550 329 376 4 33 914 4 1326 457 4 4 35 61 430 847 92 8 210 4 4 41 66 91 41 66 42 414 452 30 947 210 66 34 41 66 91 157 108 42 93 122 101 94 11 556 23 947 210 95 34 480 91 673 42 457 189 432 23 391 228 5 79 80 6 174 251 104 1326 431 108 34 157 91 947 362 23 457 1536 952 35 61 12 673 741 4 1148 4 62 23 22 13 287 12 457 1536 952 35 61 6 251 351 431 103 34 524 91 4 157 85 741 604 15 181 62 23 4 13 287 12 457 1536 4 35 61 6 174 251 104 4 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","I1204 09:11:45.843029 139694404269952 create_pretraining_data.py:161] input_ids: 0 812 393 75 87 18 129 1208 82 8 1038 789 59 32 21 5 322 342 13 1291 44 342 20 15 77 105 48 104 1326 2 45 4 1383 709 32 670 595 793 1130 7 4 240 16 457 406 25 165 20 295 242 173 5 4 321 4 11 4 1072 430 847 92 11 550 329 376 4 33 914 4 1326 457 4 4 35 61 430 847 92 8 210 4 4 41 66 91 41 66 42 414 452 30 947 210 66 34 41 66 91 157 108 42 93 122 101 94 11 556 23 947 210 95 34 480 91 673 42 457 189 432 23 391 228 5 79 80 6 174 251 104 1326 431 108 34 157 91 947 362 23 457 1536 952 35 61 12 673 741 4 1148 4 62 23 22 13 287 12 457 1536 952 35 61 6 251 351 431 103 34 524 91 4 157 85 741 604 15 181 62 23 4 13 287 12 457 1536 4 35 61 6 174 251 104 4 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","I1204 09:11:45.843487 139694404269952 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","I1204 09:11:45.843830 139694404269952 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:masked_lm_positions: 31 36 38 40 52 54 56 65 68 71 72 80 81 146 147 148 168 177 183 190\n","I1204 09:11:45.844049 139694404269952 create_pretraining_data.py:161] masked_lm_positions: 31 36 38 40 52 54 56 65 68 71 72 80 81 146 147 148 168 177 183 190\n","INFO:tensorflow:masked_lm_ids: 193 25 1130 377 120 1226 624 679 104 1536 952 66 34 604 15 181 947 22 952 1326\n","I1204 09:11:45.844220 139694404269952 create_pretraining_data.py:161] masked_lm_ids: 193 25 1130 377 120 1226 624 679 104 1536 952 66 34 604 15 181 947 22 952 1326\n","INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","I1204 09:11:45.844383 139694404269952 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","INFO:tensorflow:next_sentence_labels: 1\n","I1204 09:11:45.844530 139694404269952 create_pretraining_data.py:161] next_sentence_labels: 1\n","INFO:tensorflow:*** Example ***\n","I1204 09:11:45.845429 139694404269952 create_pretraining_data.py:149] *** Example ***\n","INFO:tensorflow:tokens: [CLS] 대한민국 ##은 미국 ##에 이 ##어 세 ##계 ##에서 두 번 ##째 ##로 인 ##터 ##넷 ##이 연 ##결 ##된 나 ##라 ##이 ##며 , 세 ##계 최 ##고 속 ##도 ##의 인 ##터 ##넷 속 ##도 ##를 보 ##유 ##하고 있 ##다 . 높 ##은 초 ##고 ##속 인 ##터 ##넷 보 ##급 ##률 ##과 인 ##터 ##넷 이 [MASK] ##률 ##을 보 [MASK] ##는 대한민국 ##은 200 ##0년 초 ##중 ##반 인 ##터 ##넷 신 ##문 ##을 표 ##방 ##한 오 ##마 ##이 ##뉴 ##스 , 프 ##레 ##시 ##안 등 ##의 등 ##장 ##과 함 ##께 인 ##터 ##넷 신 ##문 ##과 포 ##털 ##사 ##이 ##트 ##를 중 ##심 ##으로 한 인 ##터 ##넷 언 ##론 매 ##체 ##가 두 ##각 ##을 ##쳐 ##내 ##고 있 ##다 . 이 ##런 인 ##터 ##넷 [MASK] ##론 매 ##체 ##들은 인 ##터 ##넷 매 ##체 [MASK] ##유 ##의 신 ##속 ##성 ##과 높 ##은 접 ##근 ##성 등 ##을 강 ##점 ##으로 대한민국 사 ##회 ##에서 여 ##론 형 ##성 [MASK] 상 ##당 ##한 위 ##력 ##을 보 ##이 ##고 있 ##다 . [SEP] ##화 ##를 보 ##임 ##에 따라 , 대한민국 정 [MASK] ##는 인 ##터 ##넷 신 ##문 ##사 , 포 ##저 ##사 ##이 ##트 ##를 언 ##론 기 ##관 ##으로 보 ##고 [MASK] ##적 규 ##제 ##를 마 항 ##했 ##다 . 대한민국 ##에는 고 ##대 ##로 ##부터 ##의 전 ##통 ##적인 토 ##착 ##신 ##앙 ##으로 ##서 무 ##교 ##이 있 ##다 . 불 ##교 ##와 유 ##교 ##는 오 ##래 ##전 삼 ##국 ##시 ##대 ##부터 유 ##입 ##되었 ##으 [MASK] , 불 ##교 ##는 5 ##세 ##기 ##부터 1 ##4 ##세 ##기 말 ##에 이 ##르 ##는 약 1 ##천 년 동 ##안 한 ##반 ##도 ##에서 융 ##성 ##하여 많 ##은 사 ##찰 ##과 ##교 ##화 ##유 ##산 ##을 남 ##기 ##고 현 ##재 단 ##일 종 ##교 ##로 ##는 대한민국 ##에서 가 ##장 [MASK] ##도 ##수 ##가 [MASK] ##다 . 1 람 ##세 ##기 말 조 ##선 ##에서는 유 ##교 ##가 국 ##교 ##로 지 ##정 ##되었 ##다 . 그러나 현 ##재 ##는 유 ##교 ##를 학 ##문 ##과 사 ##상 , 가 ##치 ##관 그 ##리 ##고 철 ##학 ##으로 ##서 배 ##우 ##는 사 ##람 ##은 있 ##으나 신 ##앙 ##의 대 ##상 ##으로 삼 ##는 사 ##람 ##은 그 ##다 ##지 많 ##지 않 ##다 . 유 ##교 ##는 현 ##재 ##까지 ##도 한국 ##인 ##들의 풍 ##습 ##이나 습 ##관 , 습 ##성 , [MASK] ##치 ##관 , 사 ##상 , 생 ##활 방 ##식 등 ##에 많 ##은 [MASK] ##향 ##을 미 ##치 ##고 있 ##다 . 기 ##독 ##점 ##의 경우 천 ##주 ##교 ##는 조 ##선 후 ##기 ##에 이 ##승 ##훈 등 ##에 의 ##해 서 ##학 ##이 ##라는 이 [MASK] ##으로 전 ##파 ##되었 ##으 ##며 , 그 교 ##세 ##가 확 ##장 ##되 ##자 병 ##인 ##박 ##해 , 신 ##유 ##박 ##해 등 대 ##규 ##모 박 ##해 사 ##건 ##이 일 ##어 ##난 일 때문 ##에 프 ##랑 [SEP]\n","I1204 09:11:45.845789 139694404269952 create_pretraining_data.py:151] tokens: [CLS] 대한민국 ##은 미국 ##에 이 ##어 세 ##계 ##에서 두 번 ##째 ##로 인 ##터 ##넷 ##이 연 ##결 ##된 나 ##라 ##이 ##며 , 세 ##계 최 ##고 속 ##도 ##의 인 ##터 ##넷 속 ##도 ##를 보 ##유 ##하고 있 ##다 . 높 ##은 초 ##고 ##속 인 ##터 ##넷 보 ##급 ##률 ##과 인 ##터 ##넷 이 [MASK] ##률 ##을 보 [MASK] ##는 대한민국 ##은 200 ##0년 초 ##중 ##반 인 ##터 ##넷 신 ##문 ##을 표 ##방 ##한 오 ##마 ##이 ##뉴 ##스 , 프 ##레 ##시 ##안 등 ##의 등 ##장 ##과 함 ##께 인 ##터 ##넷 신 ##문 ##과 포 ##털 ##사 ##이 ##트 ##를 중 ##심 ##으로 한 인 ##터 ##넷 언 ##론 매 ##체 ##가 두 ##각 ##을 ##쳐 ##내 ##고 있 ##다 . 이 ##런 인 ##터 ##넷 [MASK] ##론 매 ##체 ##들은 인 ##터 ##넷 매 ##체 [MASK] ##유 ##의 신 ##속 ##성 ##과 높 ##은 접 ##근 ##성 등 ##을 강 ##점 ##으로 대한민국 사 ##회 ##에서 여 ##론 형 ##성 [MASK] 상 ##당 ##한 위 ##력 ##을 보 ##이 ##고 있 ##다 . [SEP] ##화 ##를 보 ##임 ##에 따라 , 대한민국 정 [MASK] ##는 인 ##터 ##넷 신 ##문 ##사 , 포 ##저 ##사 ##이 ##트 ##를 언 ##론 기 ##관 ##으로 보 ##고 [MASK] ##적 규 ##제 ##를 마 항 ##했 ##다 . 대한민국 ##에는 고 ##대 ##로 ##부터 ##의 전 ##통 ##적인 토 ##착 ##신 ##앙 ##으로 ##서 무 ##교 ##이 있 ##다 . 불 ##교 ##와 유 ##교 ##는 오 ##래 ##전 삼 ##국 ##시 ##대 ##부터 유 ##입 ##되었 ##으 [MASK] , 불 ##교 ##는 5 ##세 ##기 ##부터 1 ##4 ##세 ##기 말 ##에 이 ##르 ##는 약 1 ##천 년 동 ##안 한 ##반 ##도 ##에서 융 ##성 ##하여 많 ##은 사 ##찰 ##과 ##교 ##화 ##유 ##산 ##을 남 ##기 ##고 현 ##재 단 ##일 종 ##교 ##로 ##는 대한민국 ##에서 가 ##장 [MASK] ##도 ##수 ##가 [MASK] ##다 . 1 람 ##세 ##기 말 조 ##선 ##에서는 유 ##교 ##가 국 ##교 ##로 지 ##정 ##되었 ##다 . 그러나 현 ##재 ##는 유 ##교 ##를 학 ##문 ##과 사 ##상 , 가 ##치 ##관 그 ##리 ##고 철 ##학 ##으로 ##서 배 ##우 ##는 사 ##람 ##은 있 ##으나 신 ##앙 ##의 대 ##상 ##으로 삼 ##는 사 ##람 ##은 그 ##다 ##지 많 ##지 않 ##다 . 유 ##교 ##는 현 ##재 ##까지 ##도 한국 ##인 ##들의 풍 ##습 ##이나 습 ##관 , 습 ##성 , [MASK] ##치 ##관 , 사 ##상 , 생 ##활 방 ##식 등 ##에 많 ##은 [MASK] ##향 ##을 미 ##치 ##고 있 ##다 . 기 ##독 ##점 ##의 경우 천 ##주 ##교 ##는 조 ##선 후 ##기 ##에 이 ##승 ##훈 등 ##에 의 ##해 서 ##학 ##이 ##라는 이 [MASK] ##으로 전 ##파 ##되었 ##으 ##며 , 그 교 ##세 ##가 확 ##장 ##되 ##자 병 ##인 ##박 ##해 , 신 ##유 ##박 ##해 등 대 ##규 ##모 박 ##해 사 ##건 ##이 일 ##어 ##난 일 때문 ##에 프 ##랑 [SEP]\n","INFO:tensorflow:input_ids: 0 318 12 456 10 14 23 198 58 26 266 562 604 15 83 169 681 6 126 361 177 238 53 6 190 947 198 58 301 30 441 18 5 83 169 681 441 18 11 107 200 154 71 104 1326 657 12 323 30 201 83 169 681 107 576 696 25 83 169 681 14 4 696 7 107 4 8 318 12 210 268 323 299 192 83 169 681 357 155 7 181 315 16 216 256 6 1184 32 947 555 365 33 275 68 5 68 50 25 197 514 83 169 681 357 155 25 377 1034 35 6 92 11 69 345 24 97 83 169 681 453 123 461 115 13 266 212 7 702 343 30 71 104 1326 14 646 83 169 681 4 123 461 115 300 83 169 681 461 115 4 200 5 357 201 60 25 657 12 785 528 60 68 7 353 346 24 318 43 114 26 229 123 378 60 4 139 131 16 138 161 7 107 6 30 71 104 1326 2 56 11 107 226 10 247 947 318 49 4 8 83 169 681 357 155 35 947 377 560 35 6 92 11 453 123 44 265 24 107 30 4 73 665 62 11 286 566 222 104 1326 318 159 176 36 15 224 5 51 333 153 663 928 187 693 24 38 253 145 6 71 104 1326 205 145 39 77 145 8 216 250 61 493 70 33 36 224 77 387 452 319 4 947 205 145 8 290 211 21 224 41 106 211 21 334 10 14 87 8 490 41 487 1042 175 275 97 192 18 26 1615 60 98 287 12 43 510 25 145 56 200 110 7 375 21 30 242 173 252 42 419 145 15 8 318 26 54 50 4 18 29 13 4 104 1326 41 1944 211 21 334 119 84 293 77 145 13 133 145 15 63 47 452 104 1326 451 242 173 8 77 145 11 435 155 25 43 59 947 54 82 265 37 19 30 691 28 24 38 496 221 8 43 390 12 71 351 357 693 5 45 59 24 493 8 43 390 12 37 104 31 287 31 188 104 1326 77 145 8 242 173 289 18 362 27 433 1197 714 332 1311 265 947 1311 60 947 4 82 265 947 43 59 947 244 705 178 122 68 10 287 12 4 379 7 310 82 30 71 104 1326 44 720 346 5 335 748 89 145 8 119 84 196 21 10 14 640 1067 68 10 124 40 135 28 6 258 14 4 24 51 420 452 319 190 947 37 398 211 13 428 50 127 20 848 27 752 40 947 357 200 752 40 68 45 707 383 606 40 43 262 6 79 23 543 79 380 10 555 597 2\n","I1204 09:11:45.846179 139694404269952 create_pretraining_data.py:161] input_ids: 0 318 12 456 10 14 23 198 58 26 266 562 604 15 83 169 681 6 126 361 177 238 53 6 190 947 198 58 301 30 441 18 5 83 169 681 441 18 11 107 200 154 71 104 1326 657 12 323 30 201 83 169 681 107 576 696 25 83 169 681 14 4 696 7 107 4 8 318 12 210 268 323 299 192 83 169 681 357 155 7 181 315 16 216 256 6 1184 32 947 555 365 33 275 68 5 68 50 25 197 514 83 169 681 357 155 25 377 1034 35 6 92 11 69 345 24 97 83 169 681 453 123 461 115 13 266 212 7 702 343 30 71 104 1326 14 646 83 169 681 4 123 461 115 300 83 169 681 461 115 4 200 5 357 201 60 25 657 12 785 528 60 68 7 353 346 24 318 43 114 26 229 123 378 60 4 139 131 16 138 161 7 107 6 30 71 104 1326 2 56 11 107 226 10 247 947 318 49 4 8 83 169 681 357 155 35 947 377 560 35 6 92 11 453 123 44 265 24 107 30 4 73 665 62 11 286 566 222 104 1326 318 159 176 36 15 224 5 51 333 153 663 928 187 693 24 38 253 145 6 71 104 1326 205 145 39 77 145 8 216 250 61 493 70 33 36 224 77 387 452 319 4 947 205 145 8 290 211 21 224 41 106 211 21 334 10 14 87 8 490 41 487 1042 175 275 97 192 18 26 1615 60 98 287 12 43 510 25 145 56 200 110 7 375 21 30 242 173 252 42 419 145 15 8 318 26 54 50 4 18 29 13 4 104 1326 41 1944 211 21 334 119 84 293 77 145 13 133 145 15 63 47 452 104 1326 451 242 173 8 77 145 11 435 155 25 43 59 947 54 82 265 37 19 30 691 28 24 38 496 221 8 43 390 12 71 351 357 693 5 45 59 24 493 8 43 390 12 37 104 31 287 31 188 104 1326 77 145 8 242 173 289 18 362 27 433 1197 714 332 1311 265 947 1311 60 947 4 82 265 947 43 59 947 244 705 178 122 68 10 287 12 4 379 7 310 82 30 71 104 1326 44 720 346 5 335 748 89 145 8 119 84 196 21 10 14 640 1067 68 10 124 40 135 28 6 258 14 4 24 51 420 452 319 190 947 37 398 211 13 428 50 127 20 848 27 752 40 947 357 200 752 40 68 45 707 383 606 40 43 262 6 79 23 543 79 380 10 555 597 2\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","I1204 09:11:45.944972 139694404269952 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","I1204 09:11:45.945678 139694404269952 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","INFO:tensorflow:masked_lm_positions: 61 65 127 138 148 173 196 206 218 224 268 304 324 328 332 341 419 434 445 469\n","I1204 09:11:45.945981 139694404269952 create_pretraining_data.py:161] masked_lm_positions: 61 65 127 138 148 173 196 206 218 224 268 304 324 328 332 341 419 434 445 469\n","INFO:tensorflow:masked_lm_ids: 90 6 374 453 305 10 67 1034 437 385 190 136 357 287 106 13 54 236 145 405\n","I1204 09:11:45.946207 139694404269952 create_pretraining_data.py:161] masked_lm_ids: 90 6 374 453 305 10 67 1034 437 385 190 136 357 287 106 13 54 236 145 405\n","INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","I1204 09:11:45.946416 139694404269952 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","INFO:tensorflow:next_sentence_labels: 0\n","I1204 09:11:45.946599 139694404269952 create_pretraining_data.py:161] next_sentence_labels: 0\n","INFO:tensorflow:*** Example ***\n","I1204 09:11:45.947979 139694404269952 create_pretraining_data.py:149] *** Example ***\n","INFO:tensorflow:tokens: [CLS] ##다고 치 ##고 , 공 ##기 [MASK] ##항 [MASK] 공 ##의 속 ##도 ##에 비 ##례 ##한 ##다고 하 [MASK] . 이 ##것 ##은 공 ##의 가 ##속 ##도 , 즉 공 ##의 속 ##도 ##의 도 ##함 ##수 ##가 공 ##의 속 ##도 ##에 따라 결 ##정 ##된 ##다는 것 ##을 의 ##미 ##한 ##다 . 속 ##도 ##를 시 ##간 ##에 대한 함 [MASK] ##로 나타 ##내 ##면 이 미 ##분 방정식 ##을 풀 수 있 ##다 . 수 ##학 ##에서 미 ##분 방정식 ##은 여러 [MASK] 다른 관 ##점 ##에서 연 ##구 ##되 ##고 있는 ##데 , 대 ##개 그 해 [UNK] [MASK] ##을 만 ##족 ##시 ##키 ##는 함 ##수의 집합 [UNK] 에 대한 연 ##구 ##가 흔 ##하 ##다 . 명 ##쾌 ##한 함 ##수의 형 ##태 ##로 해 ##가 구 ##해 [MASK] ##는 것 ##은 가 ##장 간 ##단 ##한 미 ##분 방정식 ##들 뿐 ##으로 , 어 ##떤 미 ##분 방정식 ##은 명 ##확 ##한 해 ##를 구 ##하지 않 ##고 , 그 특 ##징 ##만 밝 ##혀 ##지 ##는 [MASK] ##도 있 ##다 . 만 ##약 해 ##를 독 ##립 ##적으로 구 ##하는 것 ##이 불 ##가 ##능 ##하 ##다 ##면 , 컴 ##퓨터 ##를 이 ##용 [MASK] 수 ##적 근 ##사 ##값 ##을 구 ##할 수 ##도 있 ##다 . 동 ##역 ##학 ##계 이 ##론 ##에서는 미 ##분 방정식 ##으로 표 ##현 ##되 ##는 계 ##의 질 ##적 분 ##석 ##을 중 ##요 ##하게 여 ##기 ##는 ##데 , 주 ##어 ##진 정 ##확 ##도 안 ##에서 해 ##를 구 ##하기 위 ##한 많 ##은 수 ##치 해 ##석 방 ##법 ##이 개 ##발 ##되 [SEP] 미 ##분 방정식 ##의 목 ##표 ##는 다음 세 ##가지 이 ##다 . 미 ##분 방정식 ##에 대해 해 ##가 있 ##어 ##야 ##만 하 ##는 ##지 , 아 ##니 ##면 해 ##가 유 ##일 ##한 ##지 등 ##의 문 ##제 ##도 중 ##요 ##한 관 ##심 ##사 ##이 ##다 . 그러나 응 ##용 ##수 ##학 ##자 , 물 ##리 ##학 ##자 , 엔 [MASK] ##니 ##어 [MASK] 대 ##개 주 ##어 ##진 미 ##분 방정식 ##을 푸 ##는 데 ##에 관 ##심 ##을 쥬 ##기 마 ##련 ##이 ##고 , 여 ##기 ##서 얻 [MASK] ##진 해 ##는 전 ##기 ##회 ##로 , 다 ##리 , 자 ##동 ##차 , 쌀 ##행 ##기 , 하 ##수 ##도 등 ##을 만 ##드 ##는 데 ##에 이 ##용 ##되 ##고 [MASK] ##다 . 미 ##분 방정식 이 ##론 ##은 잘 발 ##전 ##되어 왔 ##으 ##며 , 학 ##습 ##을 위해 방정식 ##의 형 ##태 ##에 따라 그 ##것 ##을 의 ##미 ##있 ##게 분 ##류 ##시 ##키 ##기도 한 ##다 . 상 ##미 ##분 방정식 ##은 미 ##지 함 ##수 ##와 종 ##속 ##변 ##수 ##가 하 ##나 ##의 독 ##립 ##변 ##수 ##를 가지 ##는 함 ##수 ##인 미 ##분 [MASK] ##을 말 ##한 ##다 . 간 ##단 ##한 형 ##태 ##로 미 ##지 ##함 ##수 ##가 실 ##수 또 [MASK] 복 ##소 ##수 함 ##수 형 ##태 ##를 [MASK] ##진 ##다 . [SEP]\n","I1204 09:11:45.948627 139694404269952 create_pretraining_data.py:151] tokens: [CLS] ##다고 치 ##고 , 공 ##기 [MASK] ##항 [MASK] 공 ##의 속 ##도 ##에 비 ##례 ##한 ##다고 하 [MASK] . 이 ##것 ##은 공 ##의 가 ##속 ##도 , 즉 공 ##의 속 ##도 ##의 도 ##함 ##수 ##가 공 ##의 속 ##도 ##에 따라 결 ##정 ##된 ##다는 것 ##을 의 ##미 ##한 ##다 . 속 ##도 ##를 시 ##간 ##에 대한 함 [MASK] ##로 나타 ##내 ##면 이 미 ##분 방정식 ##을 풀 수 있 ##다 . 수 ##학 ##에서 미 ##분 방정식 ##은 여러 [MASK] 다른 관 ##점 ##에서 연 ##구 ##되 ##고 있는 ##데 , 대 ##개 그 해 [UNK] [MASK] ##을 만 ##족 ##시 ##키 ##는 함 ##수의 집합 [UNK] 에 대한 연 ##구 ##가 흔 ##하 ##다 . 명 ##쾌 ##한 함 ##수의 형 ##태 ##로 해 ##가 구 ##해 [MASK] ##는 것 ##은 가 ##장 간 ##단 ##한 미 ##분 방정식 ##들 뿐 ##으로 , 어 ##떤 미 ##분 방정식 ##은 명 ##확 ##한 해 ##를 구 ##하지 않 ##고 , 그 특 ##징 ##만 밝 ##혀 ##지 ##는 [MASK] ##도 있 ##다 . 만 ##약 해 ##를 독 ##립 ##적으로 구 ##하는 것 ##이 불 ##가 ##능 ##하 ##다 ##면 , 컴 ##퓨터 ##를 이 ##용 [MASK] 수 ##적 근 ##사 ##값 ##을 구 ##할 수 ##도 있 ##다 . 동 ##역 ##학 ##계 이 ##론 ##에서는 미 ##분 방정식 ##으로 표 ##현 ##되 ##는 계 ##의 질 ##적 분 ##석 ##을 중 ##요 ##하게 여 ##기 ##는 ##데 , 주 ##어 ##진 정 ##확 ##도 안 ##에서 해 ##를 구 ##하기 위 ##한 많 ##은 수 ##치 해 ##석 방 ##법 ##이 개 ##발 ##되 [SEP] 미 ##분 방정식 ##의 목 ##표 ##는 다음 세 ##가지 이 ##다 . 미 ##분 방정식 ##에 대해 해 ##가 있 ##어 ##야 ##만 하 ##는 ##지 , 아 ##니 ##면 해 ##가 유 ##일 ##한 ##지 등 ##의 문 ##제 ##도 중 ##요 ##한 관 ##심 ##사 ##이 ##다 . 그러나 응 ##용 ##수 ##학 ##자 , 물 ##리 ##학 ##자 , 엔 [MASK] ##니 ##어 [MASK] 대 ##개 주 ##어 ##진 미 ##분 방정식 ##을 푸 ##는 데 ##에 관 ##심 ##을 쥬 ##기 마 ##련 ##이 ##고 , 여 ##기 ##서 얻 [MASK] ##진 해 ##는 전 ##기 ##회 ##로 , 다 ##리 , 자 ##동 ##차 , 쌀 ##행 ##기 , 하 ##수 ##도 등 ##을 만 ##드 ##는 데 ##에 이 ##용 ##되 ##고 [MASK] ##다 . 미 ##분 방정식 이 ##론 ##은 잘 발 ##전 ##되어 왔 ##으 ##며 , 학 ##습 ##을 위해 방정식 ##의 형 ##태 ##에 따라 그 ##것 ##을 의 ##미 ##있 ##게 분 ##류 ##시 ##키 ##기도 한 ##다 . 상 ##미 ##분 방정식 ##은 미 ##지 함 ##수 ##와 종 ##속 ##변 ##수 ##가 하 ##나 ##의 독 ##립 ##변 ##수 ##를 가지 ##는 함 ##수 ##인 미 ##분 [MASK] ##을 말 ##한 ##다 . 간 ##단 ##한 형 ##태 ##로 미 ##지 ##함 ##수 ##가 실 ##수 또 [MASK] 복 ##소 ##수 함 ##수 형 ##태 ##를 [MASK] ##진 ##다 . [SEP]\n","INFO:tensorflow:input_ids: 0 277 730 30 947 93 21 4 467 4 93 5 441 18 10 116 601 16 277 52 4 1326 14 558 12 93 5 54 201 18 947 479 93 5 441 18 5 191 240 29 13 93 5 441 18 10 247 219 47 177 245 72 7 124 189 16 104 1326 441 18 11 109 141 10 241 197 4 15 374 343 88 14 310 130 399 7 977 22 71 104 1326 22 28 26 310 130 399 12 447 4 408 143 346 26 126 81 127 30 225 194 947 45 235 37 202 1 4 7 163 288 33 316 8 197 368 400 1 276 241 126 81 13 1041 48 104 1326 389 1854 16 197 368 378 285 15 202 13 112 40 4 8 72 12 54 50 468 228 16 310 130 399 99 1010 24 947 281 644 310 130 399 12 389 695 16 202 11 112 444 188 30 947 37 305 803 125 697 834 31 8 4 18 71 104 1326 163 532 202 11 384 207 184 112 57 72 6 205 13 330 48 104 88 947 445 454 11 14 90 4 22 73 523 35 622 7 112 117 22 18 71 104 1326 175 182 28 58 14 123 293 310 130 399 24 181 382 127 8 204 5 589 73 148 314 7 69 283 350 229 21 8 194 947 101 23 132 49 695 18 474 26 202 11 112 269 138 16 287 12 22 82 202 314 178 172 6 140 366 127 2 310 130 399 5 587 264 8 499 198 641 14 104 1326 310 130 399 10 356 202 13 71 23 214 125 52 8 31 947 78 193 88 202 13 77 42 16 31 68 5 136 62 18 69 283 16 143 345 35 6 104 1326 451 755 90 29 28 20 947 179 19 28 20 947 664 4 193 23 4 45 235 101 23 132 310 130 399 7 1040 8 497 10 143 345 7 2535 21 286 385 6 30 947 229 21 38 556 4 132 202 8 51 21 114 15 947 129 19 947 64 86 213 947 1821 249 21 947 52 29 18 68 7 163 160 8 497 10 14 90 127 30 4 104 1326 310 130 399 14 123 12 807 134 61 354 942 319 190 947 435 714 7 415 399 5 378 285 10 247 37 558 7 124 189 1017 147 148 349 33 316 438 97 104 1326 139 189 130 399 12 310 31 197 29 39 419 201 542 29 13 52 75 5 384 207 542 29 11 446 8 197 29 27 310 130 4 7 334 16 104 1326 468 228 16 378 285 15 310 31 240 29 13 150 29 417 4 426 94 29 197 29 378 285 11 4 132 104 1326 2\n","I1204 09:11:45.949220 139694404269952 create_pretraining_data.py:161] input_ids: 0 277 730 30 947 93 21 4 467 4 93 5 441 18 10 116 601 16 277 52 4 1326 14 558 12 93 5 54 201 18 947 479 93 5 441 18 5 191 240 29 13 93 5 441 18 10 247 219 47 177 245 72 7 124 189 16 104 1326 441 18 11 109 141 10 241 197 4 15 374 343 88 14 310 130 399 7 977 22 71 104 1326 22 28 26 310 130 399 12 447 4 408 143 346 26 126 81 127 30 225 194 947 45 235 37 202 1 4 7 163 288 33 316 8 197 368 400 1 276 241 126 81 13 1041 48 104 1326 389 1854 16 197 368 378 285 15 202 13 112 40 4 8 72 12 54 50 468 228 16 310 130 399 99 1010 24 947 281 644 310 130 399 12 389 695 16 202 11 112 444 188 30 947 37 305 803 125 697 834 31 8 4 18 71 104 1326 163 532 202 11 384 207 184 112 57 72 6 205 13 330 48 104 88 947 445 454 11 14 90 4 22 73 523 35 622 7 112 117 22 18 71 104 1326 175 182 28 58 14 123 293 310 130 399 24 181 382 127 8 204 5 589 73 148 314 7 69 283 350 229 21 8 194 947 101 23 132 49 695 18 474 26 202 11 112 269 138 16 287 12 22 82 202 314 178 172 6 140 366 127 2 310 130 399 5 587 264 8 499 198 641 14 104 1326 310 130 399 10 356 202 13 71 23 214 125 52 8 31 947 78 193 88 202 13 77 42 16 31 68 5 136 62 18 69 283 16 143 345 35 6 104 1326 451 755 90 29 28 20 947 179 19 28 20 947 664 4 193 23 4 45 235 101 23 132 310 130 399 7 1040 8 497 10 143 345 7 2535 21 286 385 6 30 947 229 21 38 556 4 132 202 8 51 21 114 15 947 129 19 947 64 86 213 947 1821 249 21 947 52 29 18 68 7 163 160 8 497 10 14 90 127 30 4 104 1326 310 130 399 14 123 12 807 134 61 354 942 319 190 947 435 714 7 415 399 5 378 285 10 247 37 558 7 124 189 1017 147 148 349 33 316 438 97 104 1326 139 189 130 399 12 310 31 197 29 39 419 201 542 29 13 52 75 5 384 207 542 29 11 446 8 197 29 27 310 130 4 7 334 16 104 1326 468 228 16 378 285 15 310 31 240 29 13 150 29 417 4 426 94 29 197 29 378 285 11 4 132 104 1326 2\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","I1204 09:11:45.949656 139694404269952 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","I1204 09:11:46.046010 139694404269952 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","INFO:tensorflow:masked_lm_positions: 7 9 20 66 89 106 138 178 206 315 341 344 361 372 388 406 478 495 498 507\n","I1204 09:11:46.046512 139694404269952 create_pretraining_data.py:161] masked_lm_positions: 7 9 20 66 89 106 138 178 206 315 341 344 361 372 388 406 478 495 498 507\n","INFO:tensorflow:masked_lm_ids: 560 12 20 29 446 399 31 335 40 5 31 300 266 23 116 71 399 150 8 54\n","I1204 09:11:46.046982 139694404269952 create_pretraining_data.py:161] masked_lm_ids: 560 12 20 29 446 399 31 335 40 5 31 300 266 23 116 71 399 150 8 54\n","INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","I1204 09:11:46.047637 139694404269952 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","INFO:tensorflow:next_sentence_labels: 0\n","I1204 09:11:46.048028 139694404269952 create_pretraining_data.py:161] next_sentence_labels: 0\n","INFO:tensorflow:*** Example ***\n","I1204 09:11:46.049511 139694404269952 create_pretraining_data.py:149] *** Example ***\n","INFO:tensorflow:tokens: [CLS] 5 ##월 ##은 그 ##레 ##고 ##리 ##력 ##에서 한 해 ##의 다 ##섯 번 ##째 달 ##이 ##며 [MASK] 3 ##1 ##일 ##까지 있는 7 ##개 ##의 달 ##중 하 ##나 ##이 ##다 . [SEP] 대한민국 ##에서는 5 ##월 ##이 가 ##정의 [MASK] ##이 ##다 . 이 달 ##과 다음 해 ##의 1 ##월 ##은 항 ##상 같은 요 ##일 ##로 시작 ##하고 같은 요 ##일 ##로 끝 ##난 ##다 . 4 ##00 ##년 동 ##안 이 달 ##은 화 ##요 ##일 [MASK] 금 ##요 ##일 , 일 ##요 ##일 ##에 5 ##8 ##번 , 수 ##요 [MASK] ##과 목 ##요 ##일 ##에 5 ##7 ##번 , 월 ##요 ##일 ##과 [MASK] ##요 ##일 ##에는 [MASK] ##6 ##번 시작 ##한 ##다 . 음 ##력 3 ##월 ##과 음 ##력 4 ##월 ##이 이 달 ##에 있 ##으 ##며 5 ##월 ##에는 [MASK] ##력 3 ##월 1 ##5 ~ 1 ##6 ##일 [MASK] 4 ##월 1 ##5 ~ 1 ##6 ##일 ##의 보 ##름 ##달 ##을 [MASK] [MASK] [MASK] 수 있 ##다 . [MASK] 달 ##에 윤 [MASK] ##이 끼 ##는 경우 ##는 윤 ##3 ##월 혹 ##은 윤 ##4 ##월 ##인 ##데 소 ##만 이 ##전 ##은 [MASK] [MASK] ##월 , 소 ##만 이후 ##는 윤 ##4 [MASK] ##이 ##다 . 메 ##이 ##저 리 ##그 베 ##이 ##스 [MASK] 등 ##의 리 ##그 ##는 5 ##월 ##이 시 ##즌 초 ##에 해 ##당 ##한 ##다 . [SEP]\n","I1204 09:11:46.049778 139694404269952 create_pretraining_data.py:151] tokens: [CLS] 5 ##월 ##은 그 ##레 ##고 ##리 ##력 ##에서 한 해 ##의 다 ##섯 번 ##째 달 ##이 ##며 [MASK] 3 ##1 ##일 ##까지 있는 7 ##개 ##의 달 ##중 하 ##나 ##이 ##다 . [SEP] 대한민국 ##에서는 5 ##월 ##이 가 ##정의 [MASK] ##이 ##다 . 이 달 ##과 다음 해 ##의 1 ##월 ##은 항 ##상 같은 요 ##일 ##로 시작 ##하고 같은 요 ##일 ##로 끝 ##난 ##다 . 4 ##00 ##년 동 ##안 이 달 ##은 화 ##요 ##일 [MASK] 금 ##요 ##일 , 일 ##요 ##일 ##에 5 ##8 ##번 , 수 ##요 [MASK] ##과 목 ##요 ##일 ##에 5 ##7 ##번 , 월 ##요 ##일 ##과 [MASK] ##요 ##일 ##에는 [MASK] ##6 ##번 시작 ##한 ##다 . 음 ##력 3 ##월 ##과 음 ##력 4 ##월 ##이 이 달 ##에 있 ##으 ##며 5 ##월 ##에는 [MASK] ##력 3 ##월 1 ##5 ~ 1 ##6 ##일 [MASK] 4 ##월 1 ##5 ~ 1 ##6 ##일 ##의 보 ##름 ##달 ##을 [MASK] [MASK] [MASK] 수 있 ##다 . [MASK] 달 ##에 윤 [MASK] ##이 끼 ##는 경우 ##는 윤 ##3 ##월 혹 ##은 윤 ##4 ##월 ##인 ##데 소 ##만 이 ##전 ##은 [MASK] [MASK] ##월 , 소 ##만 이후 ##는 윤 ##4 [MASK] ##이 ##다 . 메 ##이 ##저 리 ##그 베 ##이 ##스 [MASK] 등 ##의 리 ##그 ##는 5 ##월 ##이 시 ##즌 초 ##에 해 ##당 ##한 ##다 . [SEP]\n","INFO:tensorflow:input_ids: 0 290 91 12 37 365 30 19 161 26 97 202 5 129 1361 562 604 534 6 190 4 180 85 42 289 225 524 235 5 534 299 52 75 6 104 1326 2 318 293 290 91 6 54 1200 4 6 104 1326 14 534 25 499 202 5 41 91 12 566 59 246 511 42 15 414 154 246 511 42 15 856 543 104 1326 320 464 34 175 275 14 534 12 442 283 42 4 685 283 42 947 79 283 42 10 290 103 741 947 22 283 4 25 587 283 42 10 290 113 741 947 1039 283 42 25 4 283 42 159 4 108 741 414 16 104 1326 471 161 180 91 25 471 161 320 91 6 14 534 10 71 319 190 290 91 159 4 161 180 91 41 102 1211 41 108 42 4 320 91 41 102 1211 41 108 42 5 107 405 544 7 4 4 4 22 71 104 1326 4 534 10 849 4 6 1192 8 335 8 849 95 91 944 12 849 106 91 27 194 158 125 14 61 12 4 4 91 947 158 125 313 8 849 106 4 6 104 1326 747 6 560 557 307 674 6 32 4 68 5 557 307 8 290 91 6 109 1359 323 10 202 131 16 104 1326 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","I1204 09:11:46.050226 139694404269952 create_pretraining_data.py:161] input_ids: 0 290 91 12 37 365 30 19 161 26 97 202 5 129 1361 562 604 534 6 190 4 180 85 42 289 225 524 235 5 534 299 52 75 6 104 1326 2 318 293 290 91 6 54 1200 4 6 104 1326 14 534 25 499 202 5 41 91 12 566 59 246 511 42 15 414 154 246 511 42 15 856 543 104 1326 320 464 34 175 275 14 534 12 442 283 42 4 685 283 42 947 79 283 42 10 290 103 741 947 22 283 4 25 587 283 42 10 290 113 741 947 1039 283 42 25 4 283 42 159 4 108 741 414 16 104 1326 471 161 180 91 25 471 161 320 91 6 14 534 10 71 319 190 290 91 159 4 161 180 91 41 102 1211 41 108 42 4 320 91 41 102 1211 41 108 42 5 107 405 544 7 4 4 4 22 71 104 1326 4 534 10 849 4 6 1192 8 335 8 849 95 91 944 12 849 106 91 27 194 158 125 14 61 12 4 4 91 947 158 125 313 8 849 106 4 6 104 1326 747 6 560 557 307 674 6 32 4 68 5 557 307 8 290 91 6 109 1359 323 10 202 131 16 104 1326 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","I1204 09:11:46.050547 139694404269952 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","I1204 09:11:46.050846 139694404269952 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:masked_lm_positions: 20 44 63 84 99 113 117 140 143 153 167 168 169 174 178 199 200 209 217 221\n","I1204 09:11:46.051052 139694404269952 create_pretraining_data.py:161] masked_lm_positions: 20 44 63 84 99 113 117 140 143 153 167 168 169 174 178 199 200 209 217 221\n","INFO:tensorflow:masked_lm_ids: 947 534 414 947 42 663 290 290 471 947 143 643 117 14 544 849 95 91 307 1202\n","I1204 09:11:46.051227 139694404269952 create_pretraining_data.py:161] masked_lm_ids: 947 534 414 947 42 663 290 290 471 947 143 643 117 14 544 849 95 91 307 1202\n","INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","I1204 09:11:46.051421 139694404269952 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","INFO:tensorflow:next_sentence_labels: 0\n","I1204 09:11:46.051594 139694404269952 create_pretraining_data.py:161] next_sentence_labels: 0\n","INFO:tensorflow:*** Example ***\n","I1204 09:11:46.052796 139694404269952 create_pretraining_data.py:149] *** Example ***\n","INFO:tensorflow:tokens: [CLS] 201 ##1 ##년 4 ##월 2 ##6 ##일 ##부터 2 ##9 ##일 ##까지 북 ##한 ##을 3 ##일 ##간 방 ##문 ##했 ##다 . 경 ##제 ##문 ##제 ##를 해 ##결 ##하지 못 ##하고 주 이 ##란 미국 대 ##사 ##관 인 ##질 사 ##건 ##에 발 ##목 ##이 잡 ##혀 실 ##패 ##한 대통령 ##으로 평 ##가 ##를 받 ##지만 이 ##란 사 ##태 ##는 미국 [MASK] 이 ##란 재 ##산 [MASK] 풀 ##어 ##주 ##겠 ##다는 조 ##건 ##을 내 ##세 ##워 ##서 사 ##실 ##상 카 ##터 ##가 해 ##결 ##한 것 ##이 ##었 ##고 , 사 ##랑 ##의 집 ##짓 ##기 운동 등 ##으로 퇴 ##임 후 ##에 훨 ##씬 더 존 ##경 ##받 ##는 미국 대통령 중 ##에 특 ##이 ##한 인 ##물 ##로 남 ##았 ##다 . [SEP] [MASK] ##여 ##한 사용 ##자 ##를 포 ##함 ##하여 어 ##느 누 ##구 ##도 [MASK] ##유 ##권 ##을 주 ##장 ##할 수 없 ##다 [MASK] 위키 ##백 ##과 ##의 이 ##러 ##한 은 커 ##뮤 ##니 ##티 ##가 공 ##동 ##으로 소 ##유 ##하는 가 ##치 ##에 대한 사 ##적 이 ##익 추 ##구 ##를 억 ##제 ##함 ##으로 ##써 공 ##유 ##지 ##의 비 ##극 ##을 방 ##지 ##하고 ##자 만 ##들 ##어 ##졌 ##다 . 위키 ##백 ##과 ##의 [MASK] ##리 ##는 의 정 [MASK] ##과 이 ##를 구 ##현 ##하기 위 ##한 에 따라 이 ##루 ##어 ##진 ##다 . [MASK] ##책 ##과 지 ##침 ##은 커 ##뮤 ##니 ##티 ##의 에 [MASK] ##해 수 ##립 ##되 ##거 ##나 수 ##정 ##된 ##다 . 총 ##의 ##의 개 ##념 ##은 200 ##5 ##년 찰 ##스 메 ##튜 [MASK] 위키 ##미 ##디 ##어 메 ##일 ##링 리 ##스 ##트 ##에서 설 ##명 ##된 바 ##와 같 ##이 단 ##순 ##한 만 ##장 ##일 ##치 [MASK] 아 ##닌 현 ##시 ##점 [MASK] 커 ##뮤 ##니 ##티 ##가 내 ##릴 수 있는 최 ##선 ##의 타 ##협 ##이 ##다 . 위키 ##백 ##과 ##의 커 ##뮤 ##니 ##티 ##는 각 ##각 ##의 [MASK] ##어 ##마 ##다 독 ##립 ##되어 있 ##기 때문 ##에 , 언 ##어 ##판 ##마 ##다 총 ##의 ##는 다 [MASK] 수 있 ##다 . 위키 ##백 ##과 초 ##창 ##기 가 ##장 큰 논 ##란 ##은 문 ##서 ##의 중 ##립 ##성 확 ##보 ##였 ##고 , 이 ##에 따라 위키 ##백 ##과 ##가 시작 ##된 ##지 한 달 만 ##에 이 정 ##책 ##으로 지 ##정 ##되었 ##다 . 한국 ##어 위키 ##백 ##과 역 ##시 200 ##4 ##년 중 ##립 [MASK] 시 ##각 정 ##책 ##을 도 ##입 ##하였 ##다 . 문 ##서 ##와 [MASK] ##뮤 ##니 ##티 ##의 성 ##장 ##에 따라 지 ##침 ##이 필 ##요 ##한 다 ##양 ##한 사 ##안 ##이 발 ##생 ##하였 ##기 때문 ##에 위키 ##백 ##과 ##의 정 ##책 ##과 지 ##침 역 ##시 이 ##에 대 ##응 ##할 수 있 ##도 ##록 다 ##양 ##하게 늘 ##어 ##났 ##다 . 위키 ##백 ##과 [MASK] ##자 ##들 사 ##이 [MASK] 논 ##쟁 또 ##는 분 ##쟁 ##은 모 ##두 [MASK] ##백 ##과 [SEP]\n","I1204 09:11:46.053132 139694404269952 create_pretraining_data.py:151] tokens: [CLS] 201 ##1 ##년 4 ##월 2 ##6 ##일 ##부터 2 ##9 ##일 ##까지 북 ##한 ##을 3 ##일 ##간 방 ##문 ##했 ##다 . 경 ##제 ##문 ##제 ##를 해 ##결 ##하지 못 ##하고 주 이 ##란 미국 대 ##사 ##관 인 ##질 사 ##건 ##에 발 ##목 ##이 잡 ##혀 실 ##패 ##한 대통령 ##으로 평 ##가 ##를 받 ##지만 이 ##란 사 ##태 ##는 미국 [MASK] 이 ##란 재 ##산 [MASK] 풀 ##어 ##주 ##겠 ##다는 조 ##건 ##을 내 ##세 ##워 ##서 사 ##실 ##상 카 ##터 ##가 해 ##결 ##한 것 ##이 ##었 ##고 , 사 ##랑 ##의 집 ##짓 ##기 운동 등 ##으로 퇴 ##임 후 ##에 훨 ##씬 더 존 ##경 ##받 ##는 미국 대통령 중 ##에 특 ##이 ##한 인 ##물 ##로 남 ##았 ##다 . [SEP] [MASK] ##여 ##한 사용 ##자 ##를 포 ##함 ##하여 어 ##느 누 ##구 ##도 [MASK] ##유 ##권 ##을 주 ##장 ##할 수 없 ##다 [MASK] 위키 ##백 ##과 ##의 이 ##러 ##한 은 커 ##뮤 ##니 ##티 ##가 공 ##동 ##으로 소 ##유 ##하는 가 ##치 ##에 대한 사 ##적 이 ##익 추 ##구 ##를 억 ##제 ##함 ##으로 ##써 공 ##유 ##지 ##의 비 ##극 ##을 방 ##지 ##하고 ##자 만 ##들 ##어 ##졌 ##다 . 위키 ##백 ##과 ##의 [MASK] ##리 ##는 의 정 [MASK] ##과 이 ##를 구 ##현 ##하기 위 ##한 에 따라 이 ##루 ##어 ##진 ##다 . [MASK] ##책 ##과 지 ##침 ##은 커 ##뮤 ##니 ##티 ##의 에 [MASK] ##해 수 ##립 ##되 ##거 ##나 수 ##정 ##된 ##다 . 총 ##의 ##의 개 ##념 ##은 200 ##5 ##년 찰 ##스 메 ##튜 [MASK] 위키 ##미 ##디 ##어 메 ##일 ##링 리 ##스 ##트 ##에서 설 ##명 ##된 바 ##와 같 ##이 단 ##순 ##한 만 ##장 ##일 ##치 [MASK] 아 ##닌 현 ##시 ##점 [MASK] 커 ##뮤 ##니 ##티 ##가 내 ##릴 수 있는 최 ##선 ##의 타 ##협 ##이 ##다 . 위키 ##백 ##과 ##의 커 ##뮤 ##니 ##티 ##는 각 ##각 ##의 [MASK] ##어 ##마 ##다 독 ##립 ##되어 있 ##기 때문 ##에 , 언 ##어 ##판 ##마 ##다 총 ##의 ##는 다 [MASK] 수 있 ##다 . 위키 ##백 ##과 초 ##창 ##기 가 ##장 큰 논 ##란 ##은 문 ##서 ##의 중 ##립 ##성 확 ##보 ##였 ##고 , 이 ##에 따라 위키 ##백 ##과 ##가 시작 ##된 ##지 한 달 만 ##에 이 정 ##책 ##으로 지 ##정 ##되었 ##다 . 한국 ##어 위키 ##백 ##과 역 ##시 200 ##4 ##년 중 ##립 [MASK] 시 ##각 정 ##책 ##을 도 ##입 ##하였 ##다 . 문 ##서 ##와 [MASK] ##뮤 ##니 ##티 ##의 성 ##장 ##에 따라 지 ##침 ##이 필 ##요 ##한 다 ##양 ##한 사 ##안 ##이 발 ##생 ##하였 ##기 때문 ##에 위키 ##백 ##과 ##의 정 ##책 ##과 지 ##침 역 ##시 이 ##에 대 ##응 ##할 수 있 ##도 ##록 다 ##양 ##하게 늘 ##어 ##났 ##다 . 위키 ##백 ##과 [MASK] ##자 ##들 사 ##이 [MASK] 논 ##쟁 또 ##는 분 ##쟁 ##은 모 ##두 [MASK] ##백 ##과 [SEP]\n","INFO:tensorflow:input_ids: 0 431 85 34 320 91 157 108 42 224 157 217 42 289 568 16 7 180 42 141 178 155 222 104 1326 218 62 155 62 11 202 361 444 590 154 101 14 434 456 45 35 265 83 309 43 262 10 134 684 6 959 834 150 751 16 337 24 359 13 11 308 272 14 434 43 285 8 456 4 14 434 391 110 4 977 23 89 949 245 119 262 7 237 211 642 38 43 402 59 682 169 13 202 361 16 72 6 251 30 947 43 597 5 516 1047 21 339 68 24 1028 226 196 10 1341 1317 392 401 325 704 8 456 337 69 10 305 6 16 83 259 15 375 296 104 1326 2 4 215 16 165 20 11 377 240 98 281 875 811 81 18 4 200 274 7 101 50 117 22 273 104 4 457 406 25 5 14 151 16 863 616 1057 193 591 13 93 86 24 158 200 57 54 82 10 241 43 73 14 873 326 81 11 1465 62 240 24 668 93 200 31 5 116 783 7 178 31 154 20 163 99 23 482 104 1326 457 406 25 5 4 19 8 124 49 4 25 14 11 112 382 269 138 16 276 247 14 298 23 132 104 1326 4 598 25 63 941 12 616 1057 193 591 5 276 4 40 22 207 127 206 75 22 47 177 104 1326 564 5 5 140 537 12 210 102 34 1649 32 747 1685 4 457 189 432 23 747 42 520 557 32 92 26 303 105 177 336 39 223 6 252 678 16 163 50 42 82 4 78 617 242 33 346 4 616 1057 193 591 13 237 1074 22 225 301 84 5 744 768 6 104 1326 457 406 25 5 616 1057 193 591 8 292 212 5 4 23 256 104 384 207 354 71 21 380 10 947 453 23 347 256 104 564 5 8 129 4 22 71 104 1326 457 406 25 323 700 21 54 50 607 475 434 12 136 38 5 69 207 60 428 100 263 30 947 14 10 247 457 406 25 13 414 177 31 97 534 163 10 14 49 598 24 63 47 452 104 1326 362 23 457 406 25 358 33 210 106 34 69 207 4 109 212 49 598 7 191 387 328 104 1326 136 38 39 4 1057 193 591 5 195 50 10 247 63 941 6 579 283 16 129 321 16 43 275 6 134 312 328 21 380 10 457 406 25 5 49 598 25 63 941 358 33 14 10 45 575 117 22 71 18 348 129 321 350 921 23 610 104 1326 457 406 25 4 20 99 43 6 4 475 488 417 8 148 488 12 120 470 4 406 25 2\n","I1204 09:11:46.149941 139694404269952 create_pretraining_data.py:161] input_ids: 0 431 85 34 320 91 157 108 42 224 157 217 42 289 568 16 7 180 42 141 178 155 222 104 1326 218 62 155 62 11 202 361 444 590 154 101 14 434 456 45 35 265 83 309 43 262 10 134 684 6 959 834 150 751 16 337 24 359 13 11 308 272 14 434 43 285 8 456 4 14 434 391 110 4 977 23 89 949 245 119 262 7 237 211 642 38 43 402 59 682 169 13 202 361 16 72 6 251 30 947 43 597 5 516 1047 21 339 68 24 1028 226 196 10 1341 1317 392 401 325 704 8 456 337 69 10 305 6 16 83 259 15 375 296 104 1326 2 4 215 16 165 20 11 377 240 98 281 875 811 81 18 4 200 274 7 101 50 117 22 273 104 4 457 406 25 5 14 151 16 863 616 1057 193 591 13 93 86 24 158 200 57 54 82 10 241 43 73 14 873 326 81 11 1465 62 240 24 668 93 200 31 5 116 783 7 178 31 154 20 163 99 23 482 104 1326 457 406 25 5 4 19 8 124 49 4 25 14 11 112 382 269 138 16 276 247 14 298 23 132 104 1326 4 598 25 63 941 12 616 1057 193 591 5 276 4 40 22 207 127 206 75 22 47 177 104 1326 564 5 5 140 537 12 210 102 34 1649 32 747 1685 4 457 189 432 23 747 42 520 557 32 92 26 303 105 177 336 39 223 6 252 678 16 163 50 42 82 4 78 617 242 33 346 4 616 1057 193 591 13 237 1074 22 225 301 84 5 744 768 6 104 1326 457 406 25 5 616 1057 193 591 8 292 212 5 4 23 256 104 384 207 354 71 21 380 10 947 453 23 347 256 104 564 5 8 129 4 22 71 104 1326 457 406 25 323 700 21 54 50 607 475 434 12 136 38 5 69 207 60 428 100 263 30 947 14 10 247 457 406 25 13 414 177 31 97 534 163 10 14 49 598 24 63 47 452 104 1326 362 23 457 406 25 358 33 210 106 34 69 207 4 109 212 49 598 7 191 387 328 104 1326 136 38 39 4 1057 193 591 5 195 50 10 247 63 941 6 579 283 16 129 321 16 43 275 6 134 312 328 21 380 10 457 406 25 5 49 598 25 63 941 358 33 14 10 45 575 117 22 71 18 348 129 321 350 921 23 610 104 1326 457 406 25 4 20 99 43 6 4 475 488 417 8 148 488 12 120 470 4 406 25 2\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","I1204 09:11:46.150926 139694404269952 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","I1204 09:11:46.151380 139694404269952 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","INFO:tensorflow:masked_lm_positions: 55 68 73 135 149 159 216 221 238 250 275 301 307 337 358 421 435 493 498 508\n","I1204 09:11:46.151564 139694404269952 create_pretraining_data.py:161] masked_lm_positions: 55 68 73 135 149 159 216 221 238 250 275 301 307 337 358 421 435 493 498 508\n","INFO:tensorflow:masked_lm_ids: 337 237 7 505 158 1326 143 187 49 124 5 13 26 453 11 73 616 165 5 457\n","I1204 09:11:46.151731 139694404269952 create_pretraining_data.py:161] masked_lm_ids: 337 237 7 505 158 1326 143 187 49 124 5 13 26 453 11 73 616 165 5 457\n","INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","I1204 09:11:46.151920 139694404269952 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","INFO:tensorflow:next_sentence_labels: 1\n","I1204 09:11:46.152112 139694404269952 create_pretraining_data.py:161] next_sentence_labels: 1\n","INFO:tensorflow:*** Example ***\n","I1204 09:11:46.153338 139694404269952 create_pretraining_data.py:149] *** Example ***\n","INFO:tensorflow:tokens: [CLS] 이 ##러 ##한 소 ##득 불 ##평 ##등 ##도 ##는 이후 보 ##수 정 ##권 [MASK] ##년 [MASK] 완 ##화 ##되 ##다 ##가 문 ##재 ##인 정 ##부 들 ##어 역 ##대 최 ##악 ##의 수 ##치 ##를 기 ##록 ##했 ##다 . 게 ##다 ##가 반 [MASK] ##적 입 ##장 [MASK] 편 ##협 ##한 국 ##수 ##주의 , 친 ##북 ##적 정 ##책 ##으로 인 ##한 외 ##교 ##적 모 ##순 ##으로 국 ##제 ##사 [MASK] ##에서 신 ##뢰 ##를 잃 ##었 ##다는 분 ##석 ##도 존 ##재 ##한 ##다 . [MASK] ##렇 ##듯 서 ##민 생 ##활 ##과 직 ##결 ##되 ##는 분 ##야 ##에서 ##의 정 ##책 ##적 과 ##오 ##와 외 ##교 · 안 ##보 ##에서 ##의 실 ##책 ##으로 인 ##해 , 대통령 직 ##무 ##수 ##행 ##에 대한 여 ##론 조 ##사 ##가 정 ##례 ##화 된 제 ##6 ##공 ##화 ##국 이 ##래 노 ##태 ##우 ##를 제 ##치 ##고 임 ##기 평 ##균 국 [MASK] 지 ##지 ##율 최 ##하 ##위 ##를 차 ##지 ##할 정 ##도 ##로 대 ##중 ##적인 지 ##지 [MASK] 부 ##족 ##했 ##던 대통령 ##으로 , \" 이 ##게 다 노무현 [MASK] ##이 ##다 \" 같은 유 ##행 ##어 ##가 나 ##올 정 [MASK] ##로 재 ##임 시 국 ##민 ##들 ##에게 많 ##은 원 ##성 ##을 듣 ##고 대 ##중 ##적 인 ##기 ##가 부 ##족 ##했 ##으 ##며 적 ##이 많 ##았 ##던 대통령 ##으로 평 ##가 ##받 ##는 ##다 . [SEP] 직 ##설 ##적인 화 맺 ##으로 청 ##문 웅 스 ##타 자 ##리 ##에 오 ##르 ##기도 하 ##였 ##으 ##며 , 이 ##는 대 ##중 ##적 인 ##지 ##도 ##를 크 ##게 끌 ##어 ##올 [MASK] 대통령 당 ##선 ##의 밑 ##바 ##탕 ##이 [MASK] ##었 ##다 . 그러나 임 ##기 중 ##에는 \" 대통령 못 해 ##먹 ##겠 ##다 \" , \" 미국 엉 ##덩 ##이 뒤 ##에 숨 [MASK] ##서 \" 등 그 ##의 화 ##법 ##이 논 ##란 ##이 되 ##며 보 ##수 언 ##론 ##으로 ##부터 비 ##판 ##을 받 ##기도 했 ##다 . 한국 ##대 ##학 ##총 ##학 ##생 ##회 [MASK] ##합 합 ##법 ##화 , 국 ##가 ##보 ##안 ##법 폐 ##지 검 ##토 , 200 [MASK] ##년 1 ##0 ##월 4 ##일 남 ##북 ##정 ##상 ##회 ##담 당 ##시 김 ##정 ##일 ##과 ##의 회 ##담 ##에서 N ##L ##L ##에 관 ##한 발 ##언 ##이 오 ##해 ##를 불 ##러 일 ##으 ##켜 보 ##수 언 ##론 ##의 공 ##격 ##을 받 ##았 ##다 . 보 ##수 언 ##론 ##들은 노무현 ##을 반 ##미 ##주의 ##자 ##이 ##며 좌 ##파 ##로 규 ##정 ##하고 공 ##격 ##을 가 ##했 ##으나 , 실 ##제 임 ##기 중 ##에 펼 ##친 정 ##책 ##은 그러 ##한 노 ##선 ##과 ##는 거 ##리 ##가 멀 ##었 ##으 ##며 , 진 ##보 진 ##영 ##으로 ##부터 ##는 한 ##미 F ##T ##A 추 ##진 ##과 이 ##라 ##크 파 ##병 등 노무현 [MASK] ##부 ##의 정 ##책 ##이 신 ##자 ##유 ##주의 우 ##파 ##에 가 ##깝 [SEP]\n","I1204 09:11:46.153806 139694404269952 create_pretraining_data.py:151] tokens: [CLS] 이 ##러 ##한 소 ##득 불 ##평 ##등 ##도 ##는 이후 보 ##수 정 ##권 [MASK] ##년 [MASK] 완 ##화 ##되 ##다 ##가 문 ##재 ##인 정 ##부 들 ##어 역 ##대 최 ##악 ##의 수 ##치 ##를 기 ##록 ##했 ##다 . 게 ##다 ##가 반 [MASK] ##적 입 ##장 [MASK] 편 ##협 ##한 국 ##수 ##주의 , 친 ##북 ##적 정 ##책 ##으로 인 ##한 외 ##교 ##적 모 ##순 ##으로 국 ##제 ##사 [MASK] ##에서 신 ##뢰 ##를 잃 ##었 ##다는 분 ##석 ##도 존 ##재 ##한 ##다 . [MASK] ##렇 ##듯 서 ##민 생 ##활 ##과 직 ##결 ##되 ##는 분 ##야 ##에서 ##의 정 ##책 ##적 과 ##오 ##와 외 ##교 · 안 ##보 ##에서 ##의 실 ##책 ##으로 인 ##해 , 대통령 직 ##무 ##수 ##행 ##에 대한 여 ##론 조 ##사 ##가 정 ##례 ##화 된 제 ##6 ##공 ##화 ##국 이 ##래 노 ##태 ##우 ##를 제 ##치 ##고 임 ##기 평 ##균 국 [MASK] 지 ##지 ##율 최 ##하 ##위 ##를 차 ##지 ##할 정 ##도 ##로 대 ##중 ##적인 지 ##지 [MASK] 부 ##족 ##했 ##던 대통령 ##으로 , \" 이 ##게 다 노무현 [MASK] ##이 ##다 \" 같은 유 ##행 ##어 ##가 나 ##올 정 [MASK] ##로 재 ##임 시 국 ##민 ##들 ##에게 많 ##은 원 ##성 ##을 듣 ##고 대 ##중 ##적 인 ##기 ##가 부 ##족 ##했 ##으 ##며 적 ##이 많 ##았 ##던 대통령 ##으로 평 ##가 ##받 ##는 ##다 . [SEP] 직 ##설 ##적인 화 맺 ##으로 청 ##문 웅 스 ##타 자 ##리 ##에 오 ##르 ##기도 하 ##였 ##으 ##며 , 이 ##는 대 ##중 ##적 인 ##지 ##도 ##를 크 ##게 끌 ##어 ##올 [MASK] 대통령 당 ##선 ##의 밑 ##바 ##탕 ##이 [MASK] ##었 ##다 . 그러나 임 ##기 중 ##에는 \" 대통령 못 해 ##먹 ##겠 ##다 \" , \" 미국 엉 ##덩 ##이 뒤 ##에 숨 [MASK] ##서 \" 등 그 ##의 화 ##법 ##이 논 ##란 ##이 되 ##며 보 ##수 언 ##론 ##으로 ##부터 비 ##판 ##을 받 ##기도 했 ##다 . 한국 ##대 ##학 ##총 ##학 ##생 ##회 [MASK] ##합 합 ##법 ##화 , 국 ##가 ##보 ##안 ##법 폐 ##지 검 ##토 , 200 [MASK] ##년 1 ##0 ##월 4 ##일 남 ##북 ##정 ##상 ##회 ##담 당 ##시 김 ##정 ##일 ##과 ##의 회 ##담 ##에서 N ##L ##L ##에 관 ##한 발 ##언 ##이 오 ##해 ##를 불 ##러 일 ##으 ##켜 보 ##수 언 ##론 ##의 공 ##격 ##을 받 ##았 ##다 . 보 ##수 언 ##론 ##들은 노무현 ##을 반 ##미 ##주의 ##자 ##이 ##며 좌 ##파 ##로 규 ##정 ##하고 공 ##격 ##을 가 ##했 ##으나 , 실 ##제 임 ##기 중 ##에 펼 ##친 정 ##책 ##은 그러 ##한 노 ##선 ##과 ##는 거 ##리 ##가 멀 ##었 ##으 ##며 , 진 ##보 진 ##영 ##으로 ##부터 ##는 한 ##미 F ##T ##A 추 ##진 ##과 이 ##라 ##크 파 ##병 등 노무현 [MASK] ##부 ##의 정 ##책 ##이 신 ##자 ##유 ##주의 우 ##파 ##에 가 ##깝 [SEP]\n","INFO:tensorflow:input_ids: 0 14 151 16 158 868 205 649 455 18 8 313 107 29 49 274 4 34 4 637 56 127 104 13 136 173 27 49 67 395 23 358 36 301 567 5 22 82 11 44 348 222 104 1326 502 104 13 231 4 73 371 50 4 554 768 16 133 29 396 947 794 588 73 49 598 24 83 16 418 145 73 120 678 24 133 62 35 4 26 357 929 11 1178 251 245 148 314 18 401 173 16 104 1326 4 753 1297 135 162 244 705 25 443 361 127 8 148 214 26 5 49 598 73 297 393 39 418 145 970 474 100 26 5 150 598 24 83 40 947 337 443 369 29 249 10 241 229 123 119 35 13 49 601 56 340 76 108 156 56 70 14 250 199 285 221 11 76 82 30 477 21 359 738 133 4 63 31 503 301 48 142 11 363 31 117 49 18 15 45 299 153 63 31 4 144 288 222 233 337 24 947 170 14 147 129 284 4 6 104 170 246 77 249 23 13 238 931 49 4 15 391 226 109 133 162 99 422 287 12 171 60 7 1556 30 45 299 73 83 21 13 144 288 222 319 190 403 6 287 296 233 337 24 359 13 704 8 104 1326 2 443 381 153 442 1397 24 623 155 2135 294 248 64 19 10 216 87 438 52 263 319 190 947 14 8 45 299 73 83 31 18 11 416 147 1149 23 931 4 337 317 84 5 1179 602 1015 6 4 251 104 1326 451 477 21 69 159 170 337 590 202 1577 949 104 170 947 170 456 2083 1770 6 671 10 1502 4 38 170 68 37 5 442 172 6 475 434 6 174 190 107 29 453 123 24 224 116 347 7 308 438 407 104 1326 362 36 28 647 28 312 114 4 220 561 172 56 947 133 13 100 275 172 978 31 539 364 947 210 4 34 41 121 91 320 42 375 588 47 59 114 788 317 33 481 47 42 25 5 409 788 26 920 639 639 10 143 16 134 465 6 216 40 11 205 151 79 319 852 107 29 453 123 5 93 515 7 308 296 104 1326 107 29 453 123 300 284 7 231 189 396 20 6 190 780 420 15 665 47 154 93 515 7 54 222 351 947 150 62 477 21 69 10 1243 825 49 598 12 911 16 199 84 25 8 291 19 13 1171 251 319 190 947 327 100 327 254 24 224 8 97 189 827 599 546 326 132 25 14 53 149 360 703 68 284 4 67 5 49 598 6 357 20 200 396 324 420 10 54 1443 2\n","I1204 09:11:46.154556 139694404269952 create_pretraining_data.py:161] input_ids: 0 14 151 16 158 868 205 649 455 18 8 313 107 29 49 274 4 34 4 637 56 127 104 13 136 173 27 49 67 395 23 358 36 301 567 5 22 82 11 44 348 222 104 1326 502 104 13 231 4 73 371 50 4 554 768 16 133 29 396 947 794 588 73 49 598 24 83 16 418 145 73 120 678 24 133 62 35 4 26 357 929 11 1178 251 245 148 314 18 401 173 16 104 1326 4 753 1297 135 162 244 705 25 443 361 127 8 148 214 26 5 49 598 73 297 393 39 418 145 970 474 100 26 5 150 598 24 83 40 947 337 443 369 29 249 10 241 229 123 119 35 13 49 601 56 340 76 108 156 56 70 14 250 199 285 221 11 76 82 30 477 21 359 738 133 4 63 31 503 301 48 142 11 363 31 117 49 18 15 45 299 153 63 31 4 144 288 222 233 337 24 947 170 14 147 129 284 4 6 104 170 246 77 249 23 13 238 931 49 4 15 391 226 109 133 162 99 422 287 12 171 60 7 1556 30 45 299 73 83 21 13 144 288 222 319 190 403 6 287 296 233 337 24 359 13 704 8 104 1326 2 443 381 153 442 1397 24 623 155 2135 294 248 64 19 10 216 87 438 52 263 319 190 947 14 8 45 299 73 83 31 18 11 416 147 1149 23 931 4 337 317 84 5 1179 602 1015 6 4 251 104 1326 451 477 21 69 159 170 337 590 202 1577 949 104 170 947 170 456 2083 1770 6 671 10 1502 4 38 170 68 37 5 442 172 6 475 434 6 174 190 107 29 453 123 24 224 116 347 7 308 438 407 104 1326 362 36 28 647 28 312 114 4 220 561 172 56 947 133 13 100 275 172 978 31 539 364 947 210 4 34 41 121 91 320 42 375 588 47 59 114 788 317 33 481 47 42 25 5 409 788 26 920 639 639 10 143 16 134 465 6 216 40 11 205 151 79 319 852 107 29 453 123 5 93 515 7 308 296 104 1326 107 29 453 123 300 284 7 231 189 396 20 6 190 780 420 15 665 47 154 93 515 7 54 222 351 947 150 62 477 21 69 10 1243 825 49 598 12 911 16 199 84 25 8 291 19 13 1171 251 319 190 947 327 100 327 254 24 224 8 97 189 827 599 546 326 132 25 14 53 149 360 703 68 284 4 67 5 49 598 6 357 20 200 396 324 420 10 54 1443 2\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","I1204 09:11:46.155221 139694404269952 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","I1204 09:11:46.251882 139694404269952 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","INFO:tensorflow:masked_lm_positions: 16 18 25 48 52 77 93 163 182 195 207 252 256 284 293 319 354 371 435 496\n","I1204 09:11:46.252183 139694404269952 create_pretraining_data.py:161] masked_lm_positions: 16 18 25 48 52 77 93 163 182 195 207 252 256 284 293 319 354 371 435 496\n","INFO:tensorflow:masked_lm_ids: 570 468 173 189 947 114 14 47 13 380 18 172 114 227 174 23 230 113 190 49\n","I1204 09:11:46.252414 139694404269952 create_pretraining_data.py:161] masked_lm_ids: 570 468 173 189 947 114 14 47 13 380 18 172 114 227 174 23 230 113 190 49\n","INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","I1204 09:11:46.252628 139694404269952 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","INFO:tensorflow:next_sentence_labels: 0\n","I1204 09:11:46.252840 139694404269952 create_pretraining_data.py:161] next_sentence_labels: 0\n","INFO:tensorflow:*** Example ***\n","I1204 09:11:46.254305 139694404269952 create_pretraining_data.py:149] *** Example ***\n","INFO:tensorflow:tokens: [CLS] , 조 ##성 , 구 ##조 , 변 ##화 및 그 ##에 수 ##반 ##하는 에 ##너지 ##의 변 ##화 ##를 연 ##구 ##하는 자 ##연 ##과 ##학 ##의 한 분 ##야 ##이 ##다 . 물 ##리 ##학 ##도 역 ##시 물 ##질 ##을 다 ##루 ##는 학 [MASK] ##이 ##지만 , 물 ##리 ##학 ##이 원 ##소 ##와 화 ##합 ##물 ##을 모 ##두 포 ##함 ##한 물 ##체 ##의 운동 ##과 에 ##너지 , 열 ##적 · 전 ##기 [MASK] · 광 ##학 ##적 · 기 ##계 ##적 속 ##성 ##을 다 ##루 ##고 이 ##러 ##한 현 ##상 ##으로 ##부터 통 ##일 ##된 이 ##론 ##을 구 ##축 ##하 ##려 [MASK] 것 ##과 ##는 달 ##리 화 ##학 ##에서는 물 ##질 자 ##체 ##를 [MASK] ##구 대 ##상 ##으로 한 ##다 . 화 ##학 ##은 이 ##미 존 ##재 ##하는 물 ##질 ##을 이 ##용 ##하여 특 ##정 ##한 목 ##적 ##에 맞 ##는 새 ##로 ##운 물 ##질 ##을 합 ##성 ##하는 길 ##을 제 ##공 ##하 ##며 , [MASK] ##는 농 ##작 ##물 ##마 증 ##산 , 질 ##병 ##의 치 ##료 및 예 ##방 , 에 ##너지 효 ##율 증 ##대 , 환 ##경 ##오 ##염 감 ##소 등 여러 가지 이 ##점 ##을 제 ##공 ##한 ##다 . 고 ##대 화 ##학 \" 초 ##기 야 ##금 \" 인 ##간 ##에 의 ##해 발 ##견 ##된 [MASK] ##초 ##의 기 ##록 ##된 금 ##속 ##은 금 ##인 것 ##으로 보 ##이 ##며 구 ##석 ##기 후 ##기 ##에 스 ##페 ##인 동 ##굴 ##에서 소 ##량 ##의 천 ##연 금 ##이 발 ##견 ##되었 [MASK] 한 ##다 . [MASK] , 구 ##리 , 주 ##석 및 유 ##성 철 또한 고 ##대 문 ##화 ##에서 제 ##한 ##된 양 ##의 금 ##속 가 ##공 ##을 허 ##용 ##하 ##면서 고 ##대 ##문 ##화 바 [SEP] 그 ##리 ##고 199 ##0년 ##대 [MASK] 이 ##르 ##러 소 ##프트 ##웨 ##어 라 ##이 [MASK] ##러 ##리 ##에 대해 ##서 [MASK] 조 ##금 약 ##화 ##된 G ##P ##L 쥘 ##이 ##선 ##스 ##가 전 ##략 ##적으로 더 ##욱 유 ##용 ##하 ##다는 의 ##견 ##이 많 ##아 ##졌 ##다 . 이 ##에 대한 내 ##용 ##을 L ##G ##P ##L ##이라고 하 ##여 , 199 ##1 ##년 6 ##월 ##에 발 ##표 ##된 G ##P ##L ##v ##2 ##와 동 ##시 ##에 같 ##이 발 ##표 ##되었 ##다 . 이 두 가지 ##의 내 ##용 ##은 199 ##9 ##년 L ##G ##P ##L v ##2 . 1 ##로 발 ##전 ##되었 ##고 L ##G ##P ##L ##이라고 불 ##렀 ##다 . G ##P ##L 버 ##전 3 ##은 200 ##7 ##년 6 ##월 2 ##9 ##일 ##에 발 ##표 ##L ##다 . 200 ##5 ##년 후 ##반 ##에 자 ##유 소 ##프트 ##웨 ##어 재 ##단 ##에서 G ##P ##L ##의 세 [MASK] ##째 판 ##을 개 ##발 ##할 것 ##이라고 발 ##표 ##했 ##다 . 200 ##6 ##년 1 ##월 1 ##6 ##일 첫 번 ##째 초 ##안 ##이 발 ##표 ##되었 ##다 . [SEP]\n","I1204 09:11:46.254787 139694404269952 create_pretraining_data.py:151] tokens: [CLS] , 조 ##성 , 구 ##조 , 변 ##화 및 그 ##에 수 ##반 ##하는 에 ##너지 ##의 변 ##화 ##를 연 ##구 ##하는 자 ##연 ##과 ##학 ##의 한 분 ##야 ##이 ##다 . 물 ##리 ##학 ##도 역 ##시 물 ##질 ##을 다 ##루 ##는 학 [MASK] ##이 ##지만 , 물 ##리 ##학 ##이 원 ##소 ##와 화 ##합 ##물 ##을 모 ##두 포 ##함 ##한 물 ##체 ##의 운동 ##과 에 ##너지 , 열 ##적 · 전 ##기 [MASK] · 광 ##학 ##적 · 기 ##계 ##적 속 ##성 ##을 다 ##루 ##고 이 ##러 ##한 현 ##상 ##으로 ##부터 통 ##일 ##된 이 ##론 ##을 구 ##축 ##하 ##려 [MASK] 것 ##과 ##는 달 ##리 화 ##학 ##에서는 물 ##질 자 ##체 ##를 [MASK] ##구 대 ##상 ##으로 한 ##다 . 화 ##학 ##은 이 ##미 존 ##재 ##하는 물 ##질 ##을 이 ##용 ##하여 특 ##정 ##한 목 ##적 ##에 맞 ##는 새 ##로 ##운 물 ##질 ##을 합 ##성 ##하는 길 ##을 제 ##공 ##하 ##며 , [MASK] ##는 농 ##작 ##물 ##마 증 ##산 , 질 ##병 ##의 치 ##료 및 예 ##방 , 에 ##너지 효 ##율 증 ##대 , 환 ##경 ##오 ##염 감 ##소 등 여러 가지 이 ##점 ##을 제 ##공 ##한 ##다 . 고 ##대 화 ##학 \" 초 ##기 야 ##금 \" 인 ##간 ##에 의 ##해 발 ##견 ##된 [MASK] ##초 ##의 기 ##록 ##된 금 ##속 ##은 금 ##인 것 ##으로 보 ##이 ##며 구 ##석 ##기 후 ##기 ##에 스 ##페 ##인 동 ##굴 ##에서 소 ##량 ##의 천 ##연 금 ##이 발 ##견 ##되었 [MASK] 한 ##다 . [MASK] , 구 ##리 , 주 ##석 및 유 ##성 철 또한 고 ##대 문 ##화 ##에서 제 ##한 ##된 양 ##의 금 ##속 가 ##공 ##을 허 ##용 ##하 ##면서 고 ##대 ##문 ##화 바 [SEP] 그 ##리 ##고 199 ##0년 ##대 [MASK] 이 ##르 ##러 소 ##프트 ##웨 ##어 라 ##이 [MASK] ##러 ##리 ##에 대해 ##서 [MASK] 조 ##금 약 ##화 ##된 G ##P ##L 쥘 ##이 ##선 ##스 ##가 전 ##략 ##적으로 더 ##욱 유 ##용 ##하 ##다는 의 ##견 ##이 많 ##아 ##졌 ##다 . 이 ##에 대한 내 ##용 ##을 L ##G ##P ##L ##이라고 하 ##여 , 199 ##1 ##년 6 ##월 ##에 발 ##표 ##된 G ##P ##L ##v ##2 ##와 동 ##시 ##에 같 ##이 발 ##표 ##되었 ##다 . 이 두 가지 ##의 내 ##용 ##은 199 ##9 ##년 L ##G ##P ##L v ##2 . 1 ##로 발 ##전 ##되었 ##고 L ##G ##P ##L ##이라고 불 ##렀 ##다 . G ##P ##L 버 ##전 3 ##은 200 ##7 ##년 6 ##월 2 ##9 ##일 ##에 발 ##표 ##L ##다 . 200 ##5 ##년 후 ##반 ##에 자 ##유 소 ##프트 ##웨 ##어 재 ##단 ##에서 G ##P ##L ##의 세 [MASK] ##째 판 ##을 개 ##발 ##할 것 ##이라고 발 ##표 ##했 ##다 . 200 ##6 ##년 1 ##월 1 ##6 ##일 첫 번 ##째 초 ##안 ##이 발 ##표 ##되었 ##다 . [SEP]\n","INFO:tensorflow:input_ids: 0 947 119 60 947 112 146 947 271 56 489 37 10 22 192 57 276 427 5 271 56 11 126 81 57 64 230 25 28 5 97 148 214 6 104 1326 179 19 28 18 358 33 179 309 7 129 298 8 435 4 6 272 947 179 19 28 6 171 94 39 442 220 259 7 120 470 377 240 16 179 115 5 339 25 276 427 947 498 73 970 51 21 4 970 535 28 73 970 44 58 73 441 60 7 129 298 30 14 151 16 242 59 24 224 164 42 177 14 123 7 112 706 48 227 4 72 25 8 534 19 442 28 293 179 309 64 115 11 4 81 45 59 24 97 104 1326 442 28 12 14 189 401 173 57 179 309 7 14 90 98 305 47 16 587 73 10 736 8 518 15 352 179 309 7 561 60 57 729 7 76 156 48 190 947 4 8 799 394 259 256 448 110 947 589 703 5 730 459 489 322 315 947 276 427 888 503 448 36 947 771 325 393 1204 586 94 68 447 446 14 346 7 76 156 16 104 1326 176 36 442 28 170 323 21 767 462 170 83 141 10 124 40 134 540 177 4 507 5 44 348 177 685 201 12 685 27 72 24 107 6 190 112 314 21 196 21 10 294 661 27 175 1271 26 158 267 5 748 230 685 6 134 540 452 4 97 104 1326 4 947 112 19 947 101 314 489 77 60 691 282 176 36 136 56 26 76 16 177 243 5 685 201 54 156 7 634 90 48 304 176 36 155 56 336 2 37 19 30 386 268 36 4 14 87 151 158 436 504 23 478 6 4 151 19 10 356 38 4 119 462 490 56 177 625 529 639 1316 6 84 32 13 51 874 184 392 871 77 90 48 245 124 540 6 287 74 482 104 1326 14 10 241 237 90 7 923 1003 529 639 449 52 215 947 386 85 34 480 91 10 134 264 177 625 529 639 1019 66 39 175 33 10 223 6 134 264 452 104 1326 14 266 446 5 237 90 12 386 217 34 923 1003 529 639 1510 66 1326 41 15 134 61 452 30 923 1003 529 639 449 205 1157 104 1326 625 529 639 710 61 180 12 210 113 34 480 91 157 217 42 10 134 264 639 104 1326 210 102 34 196 192 10 64 200 158 436 504 23 391 228 26 625 529 639 5 198 4 604 620 7 140 366 117 72 449 134 264 222 104 1326 210 108 34 41 91 41 108 42 777 562 604 323 275 6 134 264 452 104 1326 2\n","I1204 09:11:46.255338 139694404269952 create_pretraining_data.py:161] input_ids: 0 947 119 60 947 112 146 947 271 56 489 37 10 22 192 57 276 427 5 271 56 11 126 81 57 64 230 25 28 5 97 148 214 6 104 1326 179 19 28 18 358 33 179 309 7 129 298 8 435 4 6 272 947 179 19 28 6 171 94 39 442 220 259 7 120 470 377 240 16 179 115 5 339 25 276 427 947 498 73 970 51 21 4 970 535 28 73 970 44 58 73 441 60 7 129 298 30 14 151 16 242 59 24 224 164 42 177 14 123 7 112 706 48 227 4 72 25 8 534 19 442 28 293 179 309 64 115 11 4 81 45 59 24 97 104 1326 442 28 12 14 189 401 173 57 179 309 7 14 90 98 305 47 16 587 73 10 736 8 518 15 352 179 309 7 561 60 57 729 7 76 156 48 190 947 4 8 799 394 259 256 448 110 947 589 703 5 730 459 489 322 315 947 276 427 888 503 448 36 947 771 325 393 1204 586 94 68 447 446 14 346 7 76 156 16 104 1326 176 36 442 28 170 323 21 767 462 170 83 141 10 124 40 134 540 177 4 507 5 44 348 177 685 201 12 685 27 72 24 107 6 190 112 314 21 196 21 10 294 661 27 175 1271 26 158 267 5 748 230 685 6 134 540 452 4 97 104 1326 4 947 112 19 947 101 314 489 77 60 691 282 176 36 136 56 26 76 16 177 243 5 685 201 54 156 7 634 90 48 304 176 36 155 56 336 2 37 19 30 386 268 36 4 14 87 151 158 436 504 23 478 6 4 151 19 10 356 38 4 119 462 490 56 177 625 529 639 1316 6 84 32 13 51 874 184 392 871 77 90 48 245 124 540 6 287 74 482 104 1326 14 10 241 237 90 7 923 1003 529 639 449 52 215 947 386 85 34 480 91 10 134 264 177 625 529 639 1019 66 39 175 33 10 223 6 134 264 452 104 1326 14 266 446 5 237 90 12 386 217 34 923 1003 529 639 1510 66 1326 41 15 134 61 452 30 923 1003 529 639 449 205 1157 104 1326 625 529 639 710 61 180 12 210 113 34 480 91 157 217 42 10 134 264 639 104 1326 210 102 34 196 192 10 64 200 158 436 504 23 391 228 26 625 529 639 5 198 4 604 620 7 140 366 117 72 449 134 264 222 104 1326 210 108 34 41 91 41 108 42 777 562 604 323 275 6 134 264 452 104 1326 2\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","I1204 09:11:46.255850 139694404269952 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","I1204 09:11:46.256332 139694404269952 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","INFO:tensorflow:masked_lm_positions: 49 81 82 114 128 133 174 179 234 260 272 276 311 319 329 335 344 455 478 486\n","I1204 09:11:46.256513 139694404269952 create_pretraining_data.py:161] masked_lm_positions: 49 81 82 114 128 133 174 179 234 260 272 276 311 319 329 335 344 455 478 486\n","INFO:tensorflow:masked_lm_ids: 155 21 73 8 126 97 14 5 301 1271 277 863 15 10 632 8 478 452 562 449\n","I1204 09:11:46.256680 139694404269952 create_pretraining_data.py:161] masked_lm_ids: 155 21 73 8 126 97 14 5 301 1271 277 863 15 10 632 8 478 452 562 449\n","INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","I1204 09:11:46.256854 139694404269952 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","INFO:tensorflow:next_sentence_labels: 1\n","I1204 09:11:46.257023 139694404269952 create_pretraining_data.py:161] next_sentence_labels: 1\n","INFO:tensorflow:*** Example ***\n","I1204 09:11:46.258295 139694404269952 create_pretraining_data.py:149] *** Example ***\n","INFO:tensorflow:tokens: [CLS] 냉 ##전 ##체 ##제 ##가 강 ##화 ##되 ##고 국 ##가 ##적으로 반 ##공 ##주의 ##가 대 ##세 ##였 ##던 19 ##5 ##0년 ##대 ##에 ##도 그 ##는 반 ##핵 ##연 ##설 ##을 계 ##속 ##하였 ##다 . 그 때문 ##에 F ##B ##I [MASK] 조 ##사 ##를 받 ##기도 하 ##고 , 미 정 ##부 ##로 ##부터 여 ##권 ##발 ##급 ##을 거 ##절 ##당 ##하기 ##도 아 ##였 ##다 . 그 ##의 여 ##권 ##은 19 ##5 ##4 ##년 그 ##의 첫 [MASK] ##벨 ##상 수 [MASK] ##에 앞 ##서 잠 ##시 재 ##발 ##급 ##되었 ##다 . 칼 ##텍 ##의 많 ##은 친 ##구 ##들 ##도 그 ##를 외 ##면 ##하기 시작 ##했 ##고 총 ##장 두 ##브 ##리 ##지 ##는 폴 ##링 ##에게 정 ##치 ##적 연 ##설 ##을 그 ##만 ##둘 것 ##을 요 ##청 ##하였 ##다 . 그 ##는 19 ##5 ##1 ##준 논 ##란 ##이 되 ##는 단 ##체 ##들 ##을 탈 ##퇴 ##하고 연 ##설 ##들 ##을 중 ##지 ##하였 ##으 ##며 연 ##구 ##에 ##만 전 ##념 ##하였 ##으나 , 언 ##론 ##의 비 ##난 ##과 국 ##회 ##의 의 ##심 ##은 계 ##속 ##되었 ##빛 . 19 ##5 ##4 ##년 노 ##벨 화 [MASK] ##상 ##을 수 ##상 ##한 후 ##에는 대 [MASK] ##6 지 ##인 ##의 의 ##심 ##이 많 ##이 풀 [MASK] ##고 폴 ##링 ##은 세 ##계 곳 ##곳 ##을 돌 ##아 ##다 ##니 ##며 원 ##자 ##폭 ##탄 사용 ##에 반 ##대 ##하는 연 ##설 ##을 하 ##였 ##다 . [SEP] ##폭 ##과 낙 ##진 ##에 관 ##심 ##을 가지 ##기 시작 ##하였 ##다 . 19 ##5 ##8 ##년 폴 ##링 ##은 배 ##리 커 ##머 ##너 등 ##과 함 ##께 방 ##사 ##성 동 ##위 ##원 ##소 [MASK] ##r - 9 ##0 ##의 유 [MASK] 치 ##아 ##에 어 ##떤 영 ##향 ##을 끼 ##치 ##는 ##지 연 ##구 ##하였 ##고 19 ##6 ##2 ##년에는 루 ##이 ##스 라 ##이 ##스 등 ##과 함 ##께 낙 ##진 ##으로 떨 [MASK] ##진 S ##r - 9 ##0 ##을 젖 ##소 ##가 먹 ##고 젖 ##소 ##로 ##부터 우 ##유 ##를 먹 ##는 사 ##람 ##의 뼈 ##에 축 ##적 ##된 ##다는 연 ##구 ##결 ##과 ##를 발 ##표 ##하였 ##다 . 또한 물 ##리 ##학 ##자 ##이 ##자 반 ##공 ##주의 ##자 ##인 텔 ##러 ##와 방 ##사 ##능 낙 ##진 ##의 위 ##험 ##에 대한 T ##V ##토 ##론 ##에 ##도 참 ##여 ##하였 ##다 . 또한 폴 ##링 ##은 19 ##5 ##8 ##년 s ##계 각 ##국 ##의 과 ##학 ##자 ##들 ##로 ##부터 핵 ##실 ##험 중 ##지 ##를 청 ##원 [MASK] 서 ##명 ##을 받 ##아 서 ##명 ##목 ##록 ##을 U ##N ##에 제 ##출 ##하였 ##다 . 대 ##중 ##의 압 ##박 ##과 낙 ##진 ##의 위 ##험 ##에 관 ##한 연 ##구 ##결 ##과 ##는 19 ##6 ##3 ##년 미국 ##과 소 ##련 ##이 지 ##하 ##를 제 ##외 ##한 모 ##든 곳 ##에서 핵 ##실 ##험 ##을 금 ##지 ##하는 부 ##분 ##적 핵 ##실 ##험 금 ##지 [SEP]\n","I1204 09:11:46.258713 139694404269952 create_pretraining_data.py:151] tokens: [CLS] 냉 ##전 ##체 ##제 ##가 강 ##화 ##되 ##고 국 ##가 ##적으로 반 ##공 ##주의 ##가 대 ##세 ##였 ##던 19 ##5 ##0년 ##대 ##에 ##도 그 ##는 반 ##핵 ##연 ##설 ##을 계 ##속 ##하였 ##다 . 그 때문 ##에 F ##B ##I [MASK] 조 ##사 ##를 받 ##기도 하 ##고 , 미 정 ##부 ##로 ##부터 여 ##권 ##발 ##급 ##을 거 ##절 ##당 ##하기 ##도 아 ##였 ##다 . 그 ##의 여 ##권 ##은 19 ##5 ##4 ##년 그 ##의 첫 [MASK] ##벨 ##상 수 [MASK] ##에 앞 ##서 잠 ##시 재 ##발 ##급 ##되었 ##다 . 칼 ##텍 ##의 많 ##은 친 ##구 ##들 ##도 그 ##를 외 ##면 ##하기 시작 ##했 ##고 총 ##장 두 ##브 ##리 ##지 ##는 폴 ##링 ##에게 정 ##치 ##적 연 ##설 ##을 그 ##만 ##둘 것 ##을 요 ##청 ##하였 ##다 . 그 ##는 19 ##5 ##1 ##준 논 ##란 ##이 되 ##는 단 ##체 ##들 ##을 탈 ##퇴 ##하고 연 ##설 ##들 ##을 중 ##지 ##하였 ##으 ##며 연 ##구 ##에 ##만 전 ##념 ##하였 ##으나 , 언 ##론 ##의 비 ##난 ##과 국 ##회 ##의 의 ##심 ##은 계 ##속 ##되었 ##빛 . 19 ##5 ##4 ##년 노 ##벨 화 [MASK] ##상 ##을 수 ##상 ##한 후 ##에는 대 [MASK] ##6 지 ##인 ##의 의 ##심 ##이 많 ##이 풀 [MASK] ##고 폴 ##링 ##은 세 ##계 곳 ##곳 ##을 돌 ##아 ##다 ##니 ##며 원 ##자 ##폭 ##탄 사용 ##에 반 ##대 ##하는 연 ##설 ##을 하 ##였 ##다 . [SEP] ##폭 ##과 낙 ##진 ##에 관 ##심 ##을 가지 ##기 시작 ##하였 ##다 . 19 ##5 ##8 ##년 폴 ##링 ##은 배 ##리 커 ##머 ##너 등 ##과 함 ##께 방 ##사 ##성 동 ##위 ##원 ##소 [MASK] ##r - 9 ##0 ##의 유 [MASK] 치 ##아 ##에 어 ##떤 영 ##향 ##을 끼 ##치 ##는 ##지 연 ##구 ##하였 ##고 19 ##6 ##2 ##년에는 루 ##이 ##스 라 ##이 ##스 등 ##과 함 ##께 낙 ##진 ##으로 떨 [MASK] ##진 S ##r - 9 ##0 ##을 젖 ##소 ##가 먹 ##고 젖 ##소 ##로 ##부터 우 ##유 ##를 먹 ##는 사 ##람 ##의 뼈 ##에 축 ##적 ##된 ##다는 연 ##구 ##결 ##과 ##를 발 ##표 ##하였 ##다 . 또한 물 ##리 ##학 ##자 ##이 ##자 반 ##공 ##주의 ##자 ##인 텔 ##러 ##와 방 ##사 ##능 낙 ##진 ##의 위 ##험 ##에 대한 T ##V ##토 ##론 ##에 ##도 참 ##여 ##하였 ##다 . 또한 폴 ##링 ##은 19 ##5 ##8 ##년 s ##계 각 ##국 ##의 과 ##학 ##자 ##들 ##로 ##부터 핵 ##실 ##험 중 ##지 ##를 청 ##원 [MASK] 서 ##명 ##을 받 ##아 서 ##명 ##목 ##록 ##을 U ##N ##에 제 ##출 ##하였 ##다 . 대 ##중 ##의 압 ##박 ##과 낙 ##진 ##의 위 ##험 ##에 관 ##한 연 ##구 ##결 ##과 ##는 19 ##6 ##3 ##년 미국 ##과 소 ##련 ##이 지 ##하 ##를 제 ##외 ##한 모 ##든 곳 ##에서 핵 ##실 ##험 ##을 금 ##지 ##하는 부 ##분 ##적 핵 ##실 ##험 금 ##지 [SEP]\n","INFO:tensorflow:input_ids: 0 1354 61 115 62 13 353 56 127 30 133 13 184 231 156 396 13 45 211 263 233 65 102 268 36 10 18 37 8 231 885 230 381 7 204 201 328 104 1326 37 380 10 827 627 839 4 119 35 11 308 438 52 30 947 310 49 67 15 224 229 274 366 576 7 291 592 131 269 18 78 263 104 1326 37 5 229 274 12 65 102 106 34 37 5 777 4 772 59 22 4 10 800 38 1061 33 391 366 576 452 104 1326 1054 1492 5 287 12 794 81 99 18 37 11 418 88 269 414 222 30 564 50 266 632 19 31 8 573 520 422 49 82 73 126 381 7 37 125 1588 72 7 511 621 328 104 1326 37 8 65 102 85 260 475 434 6 174 8 252 115 99 7 902 1025 154 126 381 99 7 69 31 328 319 190 126 81 10 125 51 537 328 351 947 453 123 5 116 543 25 133 114 5 124 345 12 204 201 452 1841 1326 65 102 106 34 199 772 442 4 59 7 22 59 16 196 159 45 4 108 63 27 5 124 345 6 287 6 977 4 30 573 520 12 198 58 980 1036 7 731 74 104 193 190 171 20 1095 778 165 10 231 36 57 126 381 7 52 263 104 1326 2 1095 25 1027 132 10 143 345 7 446 21 414 328 104 1326 65 102 103 34 573 520 12 496 19 616 745 762 68 25 197 514 178 35 60 175 142 80 94 4 548 924 570 121 5 77 4 730 74 10 281 644 236 379 7 1192 82 8 31 126 81 328 30 65 108 66 666 961 6 32 478 6 32 68 25 197 514 1027 132 24 985 4 132 761 548 924 570 121 7 1716 94 13 1430 30 1716 94 15 224 324 200 11 1430 8 43 390 5 2113 10 979 73 177 245 126 81 361 25 11 134 264 328 104 1326 282 179 19 28 20 6 20 231 156 396 20 27 1428 151 39 178 35 330 1027 132 5 138 495 10 241 893 934 364 123 10 18 505 215 328 104 1326 282 573 520 12 65 102 103 34 1222 58 292 70 5 297 28 20 99 15 224 840 402 495 69 31 11 623 80 4 135 105 7 308 74 135 105 684 348 7 1080 605 10 76 512 328 104 1326 45 299 5 1029 752 25 1027 132 5 138 495 10 143 16 126 81 361 25 8 65 108 95 34 456 25 158 385 6 63 48 11 76 522 16 120 338 980 26 840 402 495 7 685 31 57 144 130 73 840 402 495 685 31 2\n","I1204 09:11:46.354473 139694404269952 create_pretraining_data.py:161] input_ids: 0 1354 61 115 62 13 353 56 127 30 133 13 184 231 156 396 13 45 211 263 233 65 102 268 36 10 18 37 8 231 885 230 381 7 204 201 328 104 1326 37 380 10 827 627 839 4 119 35 11 308 438 52 30 947 310 49 67 15 224 229 274 366 576 7 291 592 131 269 18 78 263 104 1326 37 5 229 274 12 65 102 106 34 37 5 777 4 772 59 22 4 10 800 38 1061 33 391 366 576 452 104 1326 1054 1492 5 287 12 794 81 99 18 37 11 418 88 269 414 222 30 564 50 266 632 19 31 8 573 520 422 49 82 73 126 381 7 37 125 1588 72 7 511 621 328 104 1326 37 8 65 102 85 260 475 434 6 174 8 252 115 99 7 902 1025 154 126 381 99 7 69 31 328 319 190 126 81 10 125 51 537 328 351 947 453 123 5 116 543 25 133 114 5 124 345 12 204 201 452 1841 1326 65 102 106 34 199 772 442 4 59 7 22 59 16 196 159 45 4 108 63 27 5 124 345 6 287 6 977 4 30 573 520 12 198 58 980 1036 7 731 74 104 193 190 171 20 1095 778 165 10 231 36 57 126 381 7 52 263 104 1326 2 1095 25 1027 132 10 143 345 7 446 21 414 328 104 1326 65 102 103 34 573 520 12 496 19 616 745 762 68 25 197 514 178 35 60 175 142 80 94 4 548 924 570 121 5 77 4 730 74 10 281 644 236 379 7 1192 82 8 31 126 81 328 30 65 108 66 666 961 6 32 478 6 32 68 25 197 514 1027 132 24 985 4 132 761 548 924 570 121 7 1716 94 13 1430 30 1716 94 15 224 324 200 11 1430 8 43 390 5 2113 10 979 73 177 245 126 81 361 25 11 134 264 328 104 1326 282 179 19 28 20 6 20 231 156 396 20 27 1428 151 39 178 35 330 1027 132 5 138 495 10 241 893 934 364 123 10 18 505 215 328 104 1326 282 573 520 12 65 102 103 34 1222 58 292 70 5 297 28 20 99 15 224 840 402 495 69 31 11 623 80 4 135 105 7 308 74 135 105 684 348 7 1080 605 10 76 512 328 104 1326 45 299 5 1029 752 25 1027 132 5 138 495 10 143 16 126 81 361 25 8 65 108 95 34 456 25 158 385 6 63 48 11 76 522 16 120 338 980 26 840 402 495 7 685 31 57 144 130 73 840 402 495 685 31 2\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","I1204 09:11:46.355947 139694404269952 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","I1204 09:11:46.356631 139694404269952 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","INFO:tensorflow:masked_lm_positions: 45 85 89 115 123 125 149 184 195 204 213 214 224 293 300 335 410 420 439 440\n","I1204 09:11:46.357185 139694404269952 create_pretraining_data.py:161] masked_lm_positions: 45 85 89 115 123 125 149 184 195 204 213 214 224 293 300 335 410 420 439 440\n","INFO:tensorflow:masked_lm_ids: 5 199 59 414 31 573 34 543 104 28 299 25 773 761 74 23 104 198 57 135\n","I1204 09:11:46.357701 139694404269952 create_pretraining_data.py:161] masked_lm_ids: 5 199 59 414 31 573 34 543 104 28 299 25 773 761 74 23 104 198 57 135\n","INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","I1204 09:11:46.358183 139694404269952 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","INFO:tensorflow:next_sentence_labels: 0\n","I1204 09:11:46.358776 139694404269952 create_pretraining_data.py:161] next_sentence_labels: 0\n","INFO:tensorflow:*** Example ***\n","I1204 09:11:46.360623 139694404269952 create_pretraining_data.py:149] *** Example ***\n","INFO:tensorflow:tokens: [CLS] 기 ##온 ##의 [MASK] ##교 ##차 ##가 큰 대 ##륙 ##성 기 ##후 ##이 ##다 . 최 ##근 기 ##온 상 ##승 ##으로 인 ##해 최 ##한 ##월 평 ##균 ##기 ##온 ##이 영 ##하 3 ° ##C ##보 ##다 [MASK] ##은 - 2 . 4 ° ##C ##로 높 ##아 [MASK] 200 ##9 ##년 ##부터 대한민국 기 ##상 ##청 ##은 온 ##대 하 ##우 기 ##후 [MASK] 변 ##경 ##했 ##다 . 그러나 이 ##는 열 ##섬 현 ##상 ##으로 인 ##한 것 ##으로 외 ##곽 지 ##역 ##은 여 ##전 ##히 - 3 ° ##C 미 ##만 ##으로 내 ##려 ##간 ##다는 점 ##과 냉 ##대 기 [MASK] ##의 [MASK] ##한 ##월 평 ##균 ##기 ##온 기 ##준 ##을 0 ° ##C 미 ##만 ##으로 간 ##주 ##하는 경우 ##도 많 ##다는 점 ##에서 논 ##란 ##의 여 ##지 ##가 있 ##다 . 여 ##름 기 ##온 ##과 겨 ##울 기 ##온 ##의 연 ##교 ##차 ##가 2 ##8 . [MASK] ° ##C ##로 매 ##우 크 ##기 때문 ##에 , 겨 ##울 ##은 매 ##우 춥 ##고 , 여 ##름 ##은 몹 ##시 무 ##덥 ##다 . 최 ##근 3 ##0년 기 ##준 ##으로 서 ##울 ##의 연 ##평 ##균 기 ##놓 ##은 1 ##2 . 5 ° [MASK] 이 ##고 , 최 ##난 ##월 ##인 8 ##월 평 ##균 기 ##온 ##은 2 ##5 . 7 ° ##C , 최 ##한 ##월 ##인 1 ##월 평 ##균 기 ##온 ##은 - 2 . 4 ° ##C ##이 ##다 . 특 ##히 최 ##한 ##월 ##의 평 ##균 기 ##온 ##은 같은 위 ##도 상 ##의 다른 도 ##시 ##에 비 ##해 낮 ##은 편 ##이 ##다 . [MASK] ##내 ##의 기 ##온 분 ##포 ##는 중 ##구 ##와 같 ##이 가 ##옥 ##이 [MASK] ##집 ##한 곳 ##과 많 ##은 자 ##동 ##차 ##가 배 ##기 [MASK] ##스 ##를 뿜 ##으 ##며 지 ##나 ##는 간 ##선 [MASK] ##로 , 그 ##리 ##고 도 ##심 ##부 ##의 포 ##장 ##도 ##로 ##가 지 ##나 ##는 지 ##역 ##이 가 ##장 기 ##온 ##이 높 ##고 , 한 ##강 연 ##안 ##과 가 [MASK] ##의 밀 ##집 [MASK] ##가 낮 ##은 지 ##역 ##은 기 ##온 ##이 낮 ##게 나타 ##나 ##고 있 ##다 [MASK] 도 ##심 ##의 기 ##온 [MASK] 여 ##름 ##철 ##의 6 , 7 , 8 ##월 3 ##개 ##월 ##을 제 ##외 ##하고 [MASK] 해 ##가 거 ##듭 ##될 ##수 ##록 [SEP] 따라 ##서 이 상 ##태 ##로 계 ##속 기 ##온 ##이 높 ##아 ##진 ##다고 가 ##정 ##하 ##면 약 1 ##00 ##년 ##간 ##에 평 ##균 ##기 ##온 ##은 1 . 8 ° ##C , 일 최 ##저 기 ##온 ##의 연 ##평 ##균 ##치 ##는 4 . 1 ° ##C ##씩 높 ##아 ##질 것 ##으로 예 ##상 ##된 ##다 . 반 ##면 시 ##내 ##의 습 ##도 ##는 점 ##점 줄 ##어 ##들 ##고 있 ##다 . 계 ##절 ##은 여 ##름 ##과 겨 ##울 ##이 길 ##고 , 봄 ##과 가 [MASK] ##이 짧 ##다 . [SEP]\n","I1204 09:11:46.361051 139694404269952 create_pretraining_data.py:151] tokens: [CLS] 기 ##온 ##의 [MASK] ##교 ##차 ##가 큰 대 ##륙 ##성 기 ##후 ##이 ##다 . 최 ##근 기 ##온 상 ##승 ##으로 인 ##해 최 ##한 ##월 평 ##균 ##기 ##온 ##이 영 ##하 3 ° ##C ##보 ##다 [MASK] ##은 - 2 . 4 ° ##C ##로 높 ##아 [MASK] 200 ##9 ##년 ##부터 대한민국 기 ##상 ##청 ##은 온 ##대 하 ##우 기 ##후 [MASK] 변 ##경 ##했 ##다 . 그러나 이 ##는 열 ##섬 현 ##상 ##으로 인 ##한 것 ##으로 외 ##곽 지 ##역 ##은 여 ##전 ##히 - 3 ° ##C 미 ##만 ##으로 내 ##려 ##간 ##다는 점 ##과 냉 ##대 기 [MASK] ##의 [MASK] ##한 ##월 평 ##균 ##기 ##온 기 ##준 ##을 0 ° ##C 미 ##만 ##으로 간 ##주 ##하는 경우 ##도 많 ##다는 점 ##에서 논 ##란 ##의 여 ##지 ##가 있 ##다 . 여 ##름 기 ##온 ##과 겨 ##울 기 ##온 ##의 연 ##교 ##차 ##가 2 ##8 . [MASK] ° ##C ##로 매 ##우 크 ##기 때문 ##에 , 겨 ##울 ##은 매 ##우 춥 ##고 , 여 ##름 ##은 몹 ##시 무 ##덥 ##다 . 최 ##근 3 ##0년 기 ##준 ##으로 서 ##울 ##의 연 ##평 ##균 기 ##놓 ##은 1 ##2 . 5 ° [MASK] 이 ##고 , 최 ##난 ##월 ##인 8 ##월 평 ##균 기 ##온 ##은 2 ##5 . 7 ° ##C , 최 ##한 ##월 ##인 1 ##월 평 ##균 기 ##온 ##은 - 2 . 4 ° ##C ##이 ##다 . 특 ##히 최 ##한 ##월 ##의 평 ##균 기 ##온 ##은 같은 위 ##도 상 ##의 다른 도 ##시 ##에 비 ##해 낮 ##은 편 ##이 ##다 . [MASK] ##내 ##의 기 ##온 분 ##포 ##는 중 ##구 ##와 같 ##이 가 ##옥 ##이 [MASK] ##집 ##한 곳 ##과 많 ##은 자 ##동 ##차 ##가 배 ##기 [MASK] ##스 ##를 뿜 ##으 ##며 지 ##나 ##는 간 ##선 [MASK] ##로 , 그 ##리 ##고 도 ##심 ##부 ##의 포 ##장 ##도 ##로 ##가 지 ##나 ##는 지 ##역 ##이 가 ##장 기 ##온 ##이 높 ##고 , 한 ##강 연 ##안 ##과 가 [MASK] ##의 밀 ##집 [MASK] ##가 낮 ##은 지 ##역 ##은 기 ##온 ##이 낮 ##게 나타 ##나 ##고 있 ##다 [MASK] 도 ##심 ##의 기 ##온 [MASK] 여 ##름 ##철 ##의 6 , 7 , 8 ##월 3 ##개 ##월 ##을 제 ##외 ##하고 [MASK] 해 ##가 거 ##듭 ##될 ##수 ##록 [SEP] 따라 ##서 이 상 ##태 ##로 계 ##속 기 ##온 ##이 높 ##아 ##진 ##다고 가 ##정 ##하 ##면 약 1 ##00 ##년 ##간 ##에 평 ##균 ##기 ##온 ##은 1 . 8 ° ##C , 일 최 ##저 기 ##온 ##의 연 ##평 ##균 ##치 ##는 4 . 1 ° ##C ##씩 높 ##아 ##질 것 ##으로 예 ##상 ##된 ##다 . 반 ##면 시 ##내 ##의 습 ##도 ##는 점 ##점 줄 ##어 ##들 ##고 있 ##다 . 계 ##절 ##은 여 ##름 ##과 겨 ##울 ##이 길 ##고 , 봄 ##과 가 [MASK] ##이 짧 ##다 . [SEP]\n","INFO:tensorflow:input_ids: 0 44 547 5 4 145 213 13 607 45 1076 60 44 578 6 104 1326 301 528 44 547 139 640 24 83 40 301 16 91 359 738 21 547 6 236 48 180 1294 413 100 104 4 12 924 157 1326 320 1294 413 15 657 74 4 210 217 34 224 318 44 59 621 12 613 36 52 221 44 578 4 271 325 222 104 1326 451 14 8 498 1575 242 59 24 83 16 72 24 418 1644 63 182 12 229 61 209 924 180 1294 413 310 125 24 237 227 141 245 501 25 1354 36 44 4 5 4 16 91 359 738 21 547 44 260 7 636 1294 413 310 125 24 468 89 57 335 18 287 245 501 26 475 434 5 229 31 13 71 104 1326 229 405 44 547 25 1138 341 44 547 5 126 145 213 13 157 103 1326 4 1294 413 15 461 221 416 21 380 10 947 1138 341 12 461 221 1938 30 947 229 405 12 2094 33 253 1973 104 1326 301 528 180 268 44 260 24 135 341 5 126 649 738 44 1134 12 41 66 1326 290 1294 4 14 30 947 301 543 91 27 517 91 359 738 44 547 12 157 102 1326 524 1294 413 947 301 16 91 27 41 91 359 738 44 547 12 924 157 1326 320 1294 413 6 104 1326 305 209 301 16 91 5 359 738 44 547 12 246 138 18 139 5 408 191 33 10 116 40 1071 12 554 6 104 1326 4 343 5 44 547 148 355 8 69 81 39 223 6 54 1227 6 4 508 16 980 25 287 12 64 86 213 13 496 21 4 32 11 2116 319 190 63 75 8 468 84 4 15 947 37 19 30 191 345 67 5 377 50 18 15 13 63 75 8 63 182 6 54 50 44 547 6 657 30 947 97 553 126 275 25 54 4 5 749 508 4 13 1071 12 63 182 12 44 547 6 1071 147 374 75 30 71 104 4 191 345 5 44 547 4 229 405 689 5 480 947 524 947 517 91 180 235 91 7 76 522 154 4 202 13 291 1320 686 29 348 2 247 38 14 139 285 15 204 201 44 547 6 657 74 132 277 54 47 48 88 490 41 464 34 141 10 359 738 21 547 12 41 1326 517 1294 413 947 79 301 560 44 547 5 126 649 738 82 8 320 1326 41 1294 413 1209 657 74 309 72 24 322 59 177 104 1326 231 88 109 343 5 1311 18 8 501 346 756 23 99 30 71 104 1326 204 592 12 229 405 25 1138 341 6 729 30 947 1570 25 54 4 6 1287 104 1326 2\n","I1204 09:11:46.361441 139694404269952 create_pretraining_data.py:161] input_ids: 0 44 547 5 4 145 213 13 607 45 1076 60 44 578 6 104 1326 301 528 44 547 139 640 24 83 40 301 16 91 359 738 21 547 6 236 48 180 1294 413 100 104 4 12 924 157 1326 320 1294 413 15 657 74 4 210 217 34 224 318 44 59 621 12 613 36 52 221 44 578 4 271 325 222 104 1326 451 14 8 498 1575 242 59 24 83 16 72 24 418 1644 63 182 12 229 61 209 924 180 1294 413 310 125 24 237 227 141 245 501 25 1354 36 44 4 5 4 16 91 359 738 21 547 44 260 7 636 1294 413 310 125 24 468 89 57 335 18 287 245 501 26 475 434 5 229 31 13 71 104 1326 229 405 44 547 25 1138 341 44 547 5 126 145 213 13 157 103 1326 4 1294 413 15 461 221 416 21 380 10 947 1138 341 12 461 221 1938 30 947 229 405 12 2094 33 253 1973 104 1326 301 528 180 268 44 260 24 135 341 5 126 649 738 44 1134 12 41 66 1326 290 1294 4 14 30 947 301 543 91 27 517 91 359 738 44 547 12 157 102 1326 524 1294 413 947 301 16 91 27 41 91 359 738 44 547 12 924 157 1326 320 1294 413 6 104 1326 305 209 301 16 91 5 359 738 44 547 12 246 138 18 139 5 408 191 33 10 116 40 1071 12 554 6 104 1326 4 343 5 44 547 148 355 8 69 81 39 223 6 54 1227 6 4 508 16 980 25 287 12 64 86 213 13 496 21 4 32 11 2116 319 190 63 75 8 468 84 4 15 947 37 19 30 191 345 67 5 377 50 18 15 13 63 75 8 63 182 6 54 50 44 547 6 657 30 947 97 553 126 275 25 54 4 5 749 508 4 13 1071 12 63 182 12 44 547 6 1071 147 374 75 30 71 104 4 191 345 5 44 547 4 229 405 689 5 480 947 524 947 517 91 180 235 91 7 76 522 154 4 202 13 291 1320 686 29 348 2 247 38 14 139 285 15 204 201 44 547 6 657 74 132 277 54 47 48 88 490 41 464 34 141 10 359 738 21 547 12 41 1326 517 1294 413 947 79 301 560 44 547 5 126 649 738 82 8 320 1326 41 1294 413 1209 657 74 309 72 24 322 59 177 104 1326 231 88 109 343 5 1311 18 8 501 346 756 23 99 30 71 104 1326 204 592 12 229 405 25 1138 341 6 729 30 947 1570 25 54 4 6 1287 104 1326 2\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","I1204 09:11:46.361780 139694404269952 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","I1204 09:11:46.362101 139694404269952 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","INFO:tensorflow:masked_lm_positions: 4 41 52 68 110 112 163 205 212 282 298 311 322 357 361 378 384 402 460 506\n","I1204 09:11:46.362294 139694404269952 create_pretraining_data.py:161] masked_lm_positions: 4 41 52 68 110 112 163 205 212 282 298 311 322 357 361 378 384 402 460 506\n","INFO:tensorflow:masked_lm_ids: 126 657 526 15 578 301 41 547 413 109 749 13 18 1227 18 1326 12 8 41 7\n","I1204 09:11:46.362444 139694404269952 create_pretraining_data.py:161] masked_lm_ids: 126 657 526 15 578 301 41 547 413 109 749 13 18 1227 18 1326 12 8 41 7\n","INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","I1204 09:11:46.362596 139694404269952 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","INFO:tensorflow:next_sentence_labels: 0\n","I1204 09:11:46.362758 139694404269952 create_pretraining_data.py:161] next_sentence_labels: 0\n","INFO:tensorflow:*** Example ***\n","I1204 09:11:46.365599 139694404269952 create_pretraining_data.py:149] *** Example ***\n","INFO:tensorflow:tokens: [CLS] [MASK] ##잡 ##한 우 ##주 ##에서 [MASK] ##칼 ##라는 우 ##주 전 ##체 ##에 대해 효 ##과 ##적인 좌 ##표 ##계 ##를 산 ##출 ##하지 [MASK] ##하기 ##도 한 ##다 [MASK] 이 경우 그 ##래 ##프로 이 좌 ##표 ##계 ##를 우 ##주 지 ##도 책 ##에 함 ##께 수 ##집 ##하여 둔 ##다 . [SEP] \" ≥ \" 와 \" [UNK] \" 는 두 수 [MASK] 같은 경우 ##를 포 ##함 ##하는 부 ##등 ##호 ##이 ##다 . 또한 , \" \" a \" > \" b \" > \" c \" [MASK] 는 \" a \" > \" b \" 이 ##며 \" b \" > \" c \" 인 것 ##을 줄 ##여 쓴 것 ##이 ##며 , 물 ##론 이 경우 \" a \" > \" c \" [MASK] ##기도 하 ##다 . \" 부 ##등 ##식 \" 은 한 ##자 ##나 영 ##어 ##나 문 ##자 겉 ##으로 ##는 \" 같 ##지 않 ##음 \" 을 뜻 ##한 ##다 . 실 ##수 집합 formula [UNK] [MASK] ##에서 , 두 실 ##수 formula [UNK] 2 ##에 대한 부 [MASK] ##식 ##은 다음과 같 ##다 . 절 ##대 부 ##등 ##식 ##은 모 ##든 변 ##수의 값 ##에 대 ##하여 [MASK] ##상 성 ##립 ##하는 , 변 ##수 있는 부 ##등 ##식 [MASK] 말 ##한 ##다 . 반 ##면 [MASK] 조 ##건 부 ##등 ##식 ##은 특 ##정 ##한 범 ##위 ##의 변 ##수의 값 ##아 ##래 ##에서 ##만 [MASK] ##립 ##하는 , 변 ##수 있는 부 ##등 ##식 ##이 ##다 . 어 [MASK] 부 ##등 ##식 ##이 [MASK] ##대 부 ##등 ##식 ##인 것 ##을 보 ##이 ##는 과 ##정 ##을 그 부 ##등 ##식 ##에 대한 증 ##명 ##이라고 [MASK] ##다 . 어 ##떤 부 ##등 ##식 ##이 성 ##립 ##할 조 ##건 ##을 구 ##하는 과 ##정 ##을 그 부 ##등 ##식 ##에 대한 풀 ##이라고 한 ##다 . 예 ##를 들 ##어 , 실 ##수 부 ##등 ##식 이 성 ##립 ##할 필 ##요 충 ##분 조 [MASK] ##은 이 ##므 ##로 , 이 [MASK] 조 ##건 부 ##등 ##식 ##이 ##다 . 실 ##수 부 ##등 ##식 가 성 ##립 ##할 필 ##요 충 ##분 조 ##건 ##은 이 ##므 ##로 , 이 ##는 절 ##대 부 ##등 ##식 ##이 ##다 . 토 ##머 ##스 해 ##리 ##엇 ##이 기 ##호 \" > \" 및 \" < \" 를 도 ##입 ##하였 ##다 . [SEP]\n","I1204 09:11:46.366032 139694404269952 create_pretraining_data.py:151] tokens: [CLS] [MASK] ##잡 ##한 우 ##주 ##에서 [MASK] ##칼 ##라는 우 ##주 전 ##체 ##에 대해 효 ##과 ##적인 좌 ##표 ##계 ##를 산 ##출 ##하지 [MASK] ##하기 ##도 한 ##다 [MASK] 이 경우 그 ##래 ##프로 이 좌 ##표 ##계 ##를 우 ##주 지 ##도 책 ##에 함 ##께 수 ##집 ##하여 둔 ##다 . [SEP] \" ≥ \" 와 \" [UNK] \" 는 두 수 [MASK] 같은 경우 ##를 포 ##함 ##하는 부 ##등 ##호 ##이 ##다 . 또한 , \" \" a \" > \" b \" > \" c \" [MASK] 는 \" a \" > \" b \" 이 ##며 \" b \" > \" c \" 인 것 ##을 줄 ##여 쓴 것 ##이 ##며 , 물 ##론 이 경우 \" a \" > \" c \" [MASK] ##기도 하 ##다 . \" 부 ##등 ##식 \" 은 한 ##자 ##나 영 ##어 ##나 문 ##자 겉 ##으로 ##는 \" 같 ##지 않 ##음 \" 을 뜻 ##한 ##다 . 실 ##수 집합 formula [UNK] [MASK] ##에서 , 두 실 ##수 formula [UNK] 2 ##에 대한 부 [MASK] ##식 ##은 다음과 같 ##다 . 절 ##대 부 ##등 ##식 ##은 모 ##든 변 ##수의 값 ##에 대 ##하여 [MASK] ##상 성 ##립 ##하는 , 변 ##수 있는 부 ##등 ##식 [MASK] 말 ##한 ##다 . 반 ##면 [MASK] 조 ##건 부 ##등 ##식 ##은 특 ##정 ##한 범 ##위 ##의 변 ##수의 값 ##아 ##래 ##에서 ##만 [MASK] ##립 ##하는 , 변 ##수 있는 부 ##등 ##식 ##이 ##다 . 어 [MASK] 부 ##등 ##식 ##이 [MASK] ##대 부 ##등 ##식 ##인 것 ##을 보 ##이 ##는 과 ##정 ##을 그 부 ##등 ##식 ##에 대한 증 ##명 ##이라고 [MASK] ##다 . 어 ##떤 부 ##등 ##식 ##이 성 ##립 ##할 조 ##건 ##을 구 ##하는 과 ##정 ##을 그 부 ##등 ##식 ##에 대한 풀 ##이라고 한 ##다 . 예 ##를 들 ##어 , 실 ##수 부 ##등 ##식 이 성 ##립 ##할 필 ##요 충 ##분 조 [MASK] ##은 이 ##므 ##로 , 이 [MASK] 조 ##건 부 ##등 ##식 ##이 ##다 . 실 ##수 부 ##등 ##식 가 성 ##립 ##할 필 ##요 충 ##분 조 ##건 ##은 이 ##므 ##로 , 이 ##는 절 ##대 부 ##등 ##식 ##이 ##다 . 토 ##머 ##스 해 ##리 ##엇 ##이 기 ##호 \" > \" 및 \" < \" 를 도 ##입 ##하였 ##다 . [SEP]\n","INFO:tensorflow:input_ids: 0 4 872 16 324 89 26 4 906 258 324 89 51 115 10 356 888 25 153 780 264 58 11 484 512 444 4 269 18 97 104 4 14 335 37 250 1473 14 780 264 58 11 324 89 63 18 743 10 197 514 22 508 98 1124 104 1326 2 170 2545 170 739 170 1 170 750 266 22 4 246 335 11 377 240 57 144 455 208 6 104 1326 282 947 170 170 1376 170 1432 170 1431 170 1432 170 1251 170 4 750 170 1376 170 1432 170 1431 170 14 190 170 1431 170 1432 170 1251 170 83 72 7 756 215 1021 72 6 190 947 179 123 14 335 170 1376 170 1432 170 1251 170 4 438 52 104 1326 170 144 455 122 170 863 97 20 75 236 23 75 136 20 2557 24 8 170 223 31 188 329 170 987 715 16 104 1326 150 29 400 96 1 4 26 947 266 150 29 96 1 157 10 241 144 4 122 12 261 223 104 1326 841 36 144 455 122 12 120 338 271 368 614 10 45 98 4 59 195 207 57 947 271 29 225 144 455 122 4 334 16 104 1326 231 88 4 119 262 144 455 122 12 305 47 16 792 142 5 271 368 614 74 250 26 125 4 207 57 947 271 29 225 144 455 122 6 104 1326 281 4 144 455 122 6 4 36 144 455 122 27 72 7 107 6 8 297 47 7 37 144 455 122 10 241 448 105 449 4 104 1326 281 644 144 455 122 6 195 207 117 119 262 7 112 57 297 47 7 37 144 455 122 10 241 977 449 97 104 1326 322 11 395 23 947 150 29 144 455 122 14 195 207 117 579 283 648 130 119 4 12 14 559 15 947 14 4 119 262 144 455 122 6 104 1326 150 29 144 455 122 54 195 207 117 579 283 648 130 119 262 12 14 559 15 947 14 8 841 36 144 455 122 6 104 1326 663 745 32 202 19 1111 6 44 208 170 1432 170 489 170 913 170 937 191 387 328 104 1326 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","I1204 09:11:46.464731 139694404269952 create_pretraining_data.py:161] input_ids: 0 4 872 16 324 89 26 4 906 258 324 89 51 115 10 356 888 25 153 780 264 58 11 484 512 444 4 269 18 97 104 4 14 335 37 250 1473 14 780 264 58 11 324 89 63 18 743 10 197 514 22 508 98 1124 104 1326 2 170 2545 170 739 170 1 170 750 266 22 4 246 335 11 377 240 57 144 455 208 6 104 1326 282 947 170 170 1376 170 1432 170 1431 170 1432 170 1251 170 4 750 170 1376 170 1432 170 1431 170 14 190 170 1431 170 1432 170 1251 170 83 72 7 756 215 1021 72 6 190 947 179 123 14 335 170 1376 170 1432 170 1251 170 4 438 52 104 1326 170 144 455 122 170 863 97 20 75 236 23 75 136 20 2557 24 8 170 223 31 188 329 170 987 715 16 104 1326 150 29 400 96 1 4 26 947 266 150 29 96 1 157 10 241 144 4 122 12 261 223 104 1326 841 36 144 455 122 12 120 338 271 368 614 10 45 98 4 59 195 207 57 947 271 29 225 144 455 122 4 334 16 104 1326 231 88 4 119 262 144 455 122 12 305 47 16 792 142 5 271 368 614 74 250 26 125 4 207 57 947 271 29 225 144 455 122 6 104 1326 281 4 144 455 122 6 4 36 144 455 122 27 72 7 107 6 8 297 47 7 37 144 455 122 10 241 448 105 449 4 104 1326 281 644 144 455 122 6 195 207 117 119 262 7 112 57 297 47 7 37 144 455 122 10 241 977 449 97 104 1326 322 11 395 23 947 150 29 144 455 122 14 195 207 117 579 283 648 130 119 4 12 14 559 15 947 14 4 119 262 144 455 122 6 104 1326 150 29 144 455 122 54 195 207 117 579 283 648 130 119 262 12 14 559 15 947 14 8 841 36 144 455 122 6 104 1326 663 745 32 202 19 1111 6 44 208 170 1432 170 489 170 913 170 937 191 387 328 104 1326 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","I1204 09:11:46.465311 139694404269952 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","I1204 09:11:46.465836 139694404269952 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:masked_lm_positions: 1 7 26 31 67 94 133 159 164 171 183 204 216 223 243 257 262 285 335 342\n","I1204 09:11:46.466102 139694404269952 create_pretraining_data.py:161] masked_lm_positions: 1 7 26 31 67 94 133 159 164 171 183 204 216 223 243 257 262 285 335 342\n","INFO:tensorflow:masked_lm_ids: 426 294 590 1326 13 170 14 329 104 41 455 566 7 947 195 644 841 97 262 8\n","I1204 09:11:46.466287 139694404269952 create_pretraining_data.py:161] masked_lm_ids: 426 294 590 1326 13 170 14 329 104 41 455 566 7 947 195 644 841 97 262 8\n","INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","I1204 09:11:46.466460 139694404269952 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","INFO:tensorflow:next_sentence_labels: 1\n","I1204 09:11:46.466615 139694404269952 create_pretraining_data.py:161] next_sentence_labels: 1\n","INFO:tensorflow:*** Example ***\n","I1204 09:11:46.467975 139694404269952 create_pretraining_data.py:149] *** Example ***\n","INFO:tensorflow:tokens: [CLS] 그 ##는 하 ##지만 \" 전 ##직 대통령 ##을 사 ##법 ##처 ##리 ##까지 하 ##는 것 ##은 잘 ##못 ##된 것 \" 이 ##라고 지 ##적 ##했 ##다 . 200 ##7 ##년 남 ##북 ##정 ##상 ##회 ##담 ##에서 N ##L ##L ##을 포 ##기 ##했 ##다는 주 ##장 ##이 있 ##었 ##다 . 이 ##에 따 ##르 ##면 노무현 대통령 ##이 \" 실 ##질 ##적으로 ##는 거 ##의 아 ##무 이 ##해 [MASK] ##계 ##가 없 [MASK] 문 ##제 ##를 놓 ##고 괜 ##히 어 ##릴 적 땅 ##따 ##먹 ##기 . 할 때 땅 ##에 줄 그 ##어 ##놓 ##고 니 땅 내 땅 그러 ##는 것 같 ##다 \" 면 ##서 N ##L ##L ##이 안 ##보 ##상 ##의 실 ##질 ##적 문 ##제 ##가 아 ##닌 정 ##서 ##적인 문 ##제 ##라고 발 ##언 ##했 ##다고 한 ##다 . 이 ##어 \" 대 ##강 그 ##려 ##도 아 ##무 문 ##제 ##가 없 [MASK] ##데 어 ##느 쪽 ##도 대 ##강 ##그 ##릴 수 없 ##는 심 ##리 ##적 상 ##태 , 이 ##것 ##이 우 ##리 ##의 비 ##극 \" 이 ##라고 덧 [MASK] ##였 ##다고 한 ##다 . [SEP] ##의 문 ##제 ##들 ##에 집 ##중 ##하여 [MASK] ##히 불 ##경 ##기 ##에 대한 이 ##슈 ##를 제 ##기 ##했 ##다 . 그 ##의 선 ##거 운동 본 ##부 ##의 캠 ##페 ##인 문 ##구 ##는 \" [MASK] ##제 ##는 경 ##제 ##야 , 바 ##보 ##야 \" 였 ##다 . 클 ##린 ##턴 ##은 프 ##랭 ##클 ##린 루 ##스 ##벨 ##트 이후 ##로 두 ##번 ##의 임 ##기 ##를 모 ##두 채 ##운 첫 번 ##정 민 ##주 ##당 대통령 [MASK] ##었 ##다 . 그 ##의 당 ##선 ##으로 인 ##해 1 ##2 ##년 간 ##의 연 ##속 ##된 공 ##화 ##당 정 ##권 , 조 ##지 H . W . 부 ##시 ) 이 막 ##을 내 ##렸 ##다 . 그 선 ##거 이후 민 ##주 ##당 ##은 지 ##미 카 ##터 ##의 통 ##치 이 [MASK] 최 ##초 ##로 의 ##회 및 행 ##정 [MASK] ##를 [MASK] ##함 ##한 연 ##방 ##정 ##부 ##의 실 ##권 ##을 완 ##벽 ##하게 장 [MASK] ##했 ##다 . 그러나 재 ##임 펼 ##기 계 ##속 ##된 실 ##책 ##으로 인 ##기 ##가 급 ##격 ##히 떨 ##어 ##지 ##면서 199 ##4 ##년 중 ##간 ##선 ##거 ##에서 민 ##주 ##당 ##에 크 ##나 ##큰 패 ##배 ##를 안 ##겨 ##주 ##었 ##다 . 특 ##히 하 ##원 ##에서는 4 ##0년 만 ##에 [MASK] ##화 ##당 ##에 [MASK] ##수 ##당 ##의 지 ##위 ##를 넘 ##겨 ##주 ##었 ##다 . 즉 ##각 ##적으로 정 ##권 ##을 인 ##수 ##받 ##은 후 클 ##린 ##턴 ##은 199 ##3 ##년 가 ##족 ##의 ##료 ##법 ##안 ##에 관 ##한 대 ##선 공 ##약 ##에 즉 [MASK] 서 ##명 ##하게 된 ##다 . 본 법 ##안 ##은 고 ##용 ##인 ##에게 종 ##업 ##원 ##의 의 ##료 ##문 ##제 발 ##생 ##상 ##황 ##시 의 ##료 ##보 ##호 ##İ 받 ##을 수 있 ##도 ##록 근 [SEP]\n","I1204 09:11:46.468449 139694404269952 create_pretraining_data.py:151] tokens: [CLS] 그 ##는 하 ##지만 \" 전 ##직 대통령 ##을 사 ##법 ##처 ##리 ##까지 하 ##는 것 ##은 잘 ##못 ##된 것 \" 이 ##라고 지 ##적 ##했 ##다 . 200 ##7 ##년 남 ##북 ##정 ##상 ##회 ##담 ##에서 N ##L ##L ##을 포 ##기 ##했 ##다는 주 ##장 ##이 있 ##었 ##다 . 이 ##에 따 ##르 ##면 노무현 대통령 ##이 \" 실 ##질 ##적으로 ##는 거 ##의 아 ##무 이 ##해 [MASK] ##계 ##가 없 [MASK] 문 ##제 ##를 놓 ##고 괜 ##히 어 ##릴 적 땅 ##따 ##먹 ##기 . 할 때 땅 ##에 줄 그 ##어 ##놓 ##고 니 땅 내 땅 그러 ##는 것 같 ##다 \" 면 ##서 N ##L ##L ##이 안 ##보 ##상 ##의 실 ##질 ##적 문 ##제 ##가 아 ##닌 정 ##서 ##적인 문 ##제 ##라고 발 ##언 ##했 ##다고 한 ##다 . 이 ##어 \" 대 ##강 그 ##려 ##도 아 ##무 문 ##제 ##가 없 [MASK] ##데 어 ##느 쪽 ##도 대 ##강 ##그 ##릴 수 없 ##는 심 ##리 ##적 상 ##태 , 이 ##것 ##이 우 ##리 ##의 비 ##극 \" 이 ##라고 덧 [MASK] ##였 ##다고 한 ##다 . [SEP] ##의 문 ##제 ##들 ##에 집 ##중 ##하여 [MASK] ##히 불 ##경 ##기 ##에 대한 이 ##슈 ##를 제 ##기 ##했 ##다 . 그 ##의 선 ##거 운동 본 ##부 ##의 캠 ##페 ##인 문 ##구 ##는 \" [MASK] ##제 ##는 경 ##제 ##야 , 바 ##보 ##야 \" 였 ##다 . 클 ##린 ##턴 ##은 프 ##랭 ##클 ##린 루 ##스 ##벨 ##트 이후 ##로 두 ##번 ##의 임 ##기 ##를 모 ##두 채 ##운 첫 번 ##정 민 ##주 ##당 대통령 [MASK] ##었 ##다 . 그 ##의 당 ##선 ##으로 인 ##해 1 ##2 ##년 간 ##의 연 ##속 ##된 공 ##화 ##당 정 ##권 , 조 ##지 H . W . 부 ##시 ) 이 막 ##을 내 ##렸 ##다 . 그 선 ##거 이후 민 ##주 ##당 ##은 지 ##미 카 ##터 ##의 통 ##치 이 [MASK] 최 ##초 ##로 의 ##회 및 행 ##정 [MASK] ##를 [MASK] ##함 ##한 연 ##방 ##정 ##부 ##의 실 ##권 ##을 완 ##벽 ##하게 장 [MASK] ##했 ##다 . 그러나 재 ##임 펼 ##기 계 ##속 ##된 실 ##책 ##으로 인 ##기 ##가 급 ##격 ##히 떨 ##어 ##지 ##면서 199 ##4 ##년 중 ##간 ##선 ##거 ##에서 민 ##주 ##당 ##에 크 ##나 ##큰 패 ##배 ##를 안 ##겨 ##주 ##었 ##다 . 특 ##히 하 ##원 ##에서는 4 ##0년 만 ##에 [MASK] ##화 ##당 ##에 [MASK] ##수 ##당 ##의 지 ##위 ##를 넘 ##겨 ##주 ##었 ##다 . 즉 ##각 ##적으로 정 ##권 ##을 인 ##수 ##받 ##은 후 클 ##린 ##턴 ##은 199 ##3 ##년 가 ##족 ##의 ##료 ##법 ##안 ##에 관 ##한 대 ##선 공 ##약 ##에 즉 [MASK] 서 ##명 ##하게 된 ##다 . 본 법 ##안 ##은 고 ##용 ##인 ##에게 종 ##업 ##원 ##의 의 ##료 ##문 ##제 발 ##생 ##상 ##황 ##시 의 ##료 ##보 ##호 ##İ 받 ##을 수 있 ##도 ##록 근 [SEP]\n","INFO:tensorflow:input_ids: 0 37 8 52 272 170 51 372 337 7 43 172 638 19 289 52 8 72 12 807 1234 177 72 170 14 311 63 73 222 104 1326 210 113 34 375 588 47 59 114 788 26 920 639 639 7 377 21 222 245 101 50 6 71 251 104 1326 14 10 491 87 88 284 337 6 170 150 309 184 8 291 5 78 369 14 40 4 58 13 273 4 136 62 11 999 30 2088 209 281 1074 403 1159 1417 1577 21 1326 565 302 1159 10 756 37 23 1134 30 1150 1159 237 1159 911 8 72 223 104 170 912 38 920 639 639 6 474 100 59 5 150 309 73 136 62 13 78 617 49 38 153 136 62 311 134 465 222 277 97 104 1326 14 23 170 45 553 37 227 18 78 369 136 62 13 273 4 194 281 875 1411 18 45 553 307 1074 22 273 8 740 19 73 139 285 947 14 558 6 324 19 5 116 783 170 14 311 1091 4 263 277 97 104 1326 2 5 136 62 99 10 516 299 98 4 209 205 325 21 10 241 14 804 11 76 21 222 104 1326 37 5 183 206 339 615 67 5 967 661 27 136 81 8 170 4 62 8 218 62 214 947 336 100 214 170 1710 104 1326 742 404 670 12 555 1368 672 404 961 32 772 92 313 15 266 741 5 477 21 11 120 470 735 352 777 562 47 397 89 131 337 4 251 104 1326 37 5 317 84 24 83 40 41 66 34 468 5 126 201 177 93 56 131 49 274 947 119 31 990 1326 1123 1326 144 33 1613 14 787 7 237 773 104 1326 37 183 206 313 397 89 131 12 63 189 682 169 5 164 82 14 4 301 507 15 124 114 489 412 47 4 11 4 240 16 126 315 47 67 5 150 274 7 637 1146 350 421 4 222 104 1326 451 391 226 1243 21 204 201 177 150 598 24 83 21 13 802 515 209 985 23 31 304 386 106 34 69 141 84 206 26 397 89 131 10 416 75 1623 808 571 11 474 708 89 251 104 1326 305 209 52 80 293 320 268 163 10 4 56 131 10 4 29 131 5 63 142 11 866 708 89 251 104 1326 479 212 184 49 274 7 83 29 704 12 196 742 404 670 12 386 95 34 54 288 5 459 172 275 10 143 16 45 84 93 532 10 479 4 135 105 350 340 104 1326 615 437 275 12 176 90 27 422 419 168 80 5 124 459 155 62 134 312 59 818 33 124 459 100 208 2031 308 7 22 71 18 348 523 2\n","I1204 09:11:46.468981 139694404269952 create_pretraining_data.py:161] input_ids: 0 37 8 52 272 170 51 372 337 7 43 172 638 19 289 52 8 72 12 807 1234 177 72 170 14 311 63 73 222 104 1326 210 113 34 375 588 47 59 114 788 26 920 639 639 7 377 21 222 245 101 50 6 71 251 104 1326 14 10 491 87 88 284 337 6 170 150 309 184 8 291 5 78 369 14 40 4 58 13 273 4 136 62 11 999 30 2088 209 281 1074 403 1159 1417 1577 21 1326 565 302 1159 10 756 37 23 1134 30 1150 1159 237 1159 911 8 72 223 104 170 912 38 920 639 639 6 474 100 59 5 150 309 73 136 62 13 78 617 49 38 153 136 62 311 134 465 222 277 97 104 1326 14 23 170 45 553 37 227 18 78 369 136 62 13 273 4 194 281 875 1411 18 45 553 307 1074 22 273 8 740 19 73 139 285 947 14 558 6 324 19 5 116 783 170 14 311 1091 4 263 277 97 104 1326 2 5 136 62 99 10 516 299 98 4 209 205 325 21 10 241 14 804 11 76 21 222 104 1326 37 5 183 206 339 615 67 5 967 661 27 136 81 8 170 4 62 8 218 62 214 947 336 100 214 170 1710 104 1326 742 404 670 12 555 1368 672 404 961 32 772 92 313 15 266 741 5 477 21 11 120 470 735 352 777 562 47 397 89 131 337 4 251 104 1326 37 5 317 84 24 83 40 41 66 34 468 5 126 201 177 93 56 131 49 274 947 119 31 990 1326 1123 1326 144 33 1613 14 787 7 237 773 104 1326 37 183 206 313 397 89 131 12 63 189 682 169 5 164 82 14 4 301 507 15 124 114 489 412 47 4 11 4 240 16 126 315 47 67 5 150 274 7 637 1146 350 421 4 222 104 1326 451 391 226 1243 21 204 201 177 150 598 24 83 21 13 802 515 209 985 23 31 304 386 106 34 69 141 84 206 26 397 89 131 10 416 75 1623 808 571 11 474 708 89 251 104 1326 305 209 52 80 293 320 268 163 10 4 56 131 10 4 29 131 5 63 142 11 866 708 89 251 104 1326 479 212 184 49 274 7 83 29 704 12 196 742 404 670 12 386 95 34 54 288 5 459 172 275 10 143 16 45 84 93 532 10 479 4 135 105 350 340 104 1326 615 437 275 12 176 90 27 422 419 168 80 5 124 459 155 62 134 312 59 818 33 124 459 100 208 2031 308 7 22 71 18 348 523 2\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","I1204 09:11:46.565708 139694404269952 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","I1204 09:11:46.566215 139694404269952 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","INFO:tensorflow:masked_lm_positions: 37 75 76 79 159 190 205 209 235 275 280 337 346 348 363 370 421 425 471 503\n","I1204 09:11:46.566484 139694404269952 create_pretraining_data.py:161] masked_lm_positions: 37 75 76 79 159 190 205 209 235 275 280 337 346 348 363 370 421 425 471 503\n","INFO:tensorflow:masked_lm_ids: 59 265 58 8 8 1298 305 21 136 604 6 250 67 377 567 323 93 129 212 11\n","I1204 09:11:46.566714 139694404269952 create_pretraining_data.py:161] masked_lm_ids: 59 265 58 8 8 1298 305 21 136 604 6 250 67 377 567 323 93 129 212 11\n","INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","I1204 09:11:46.566946 139694404269952 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","INFO:tensorflow:next_sentence_labels: 1\n","I1204 09:11:46.567119 139694404269952 create_pretraining_data.py:161] next_sentence_labels: 1\n","INFO:tensorflow:*** Example ***\n","I1204 09:11:46.567956 139694404269952 create_pretraining_data.py:149] *** Example ***\n","INFO:tensorflow:tokens: [CLS] 시 ##내 ##버 ##스 ##의 경우 시 ##계 ##를 넘 ##어 ##서 ##면 시 ##계 추 ##가 요 ##금 ##이 부 ##과 ##되 ##며 서 ##울 , 경 ##기도 , 인 ##천 ##의 시 ##내 ##버 ##스 ##는 거 ##리 ##에 따 ##른 추 ##가 요 ##금 ##이 부 ##과 ##된 ##다 . [MASK] ##외 ##버 ##스 ##는 시 ##외 ##버 ##스 ##터 ##미 ##널 ##이나 시 ##외 ##버 [MASK] ##정 ##거 ##장 ##에서 주 ##로 승 ##하 ##차 ##가 이 ##절 ##어 ##지 ##며 대 ##부 ##분 교 ##통 ##카 ##드 ##를 사용 ##할 수 없 ##지만 가 ##끔 ##씩 사용 가 ##능 ##한 노 ##선 ##도 있 ##다 . 현 ##재 대한민국 ##의 버 ##스 회 ##사 중 ##에서는 K ##D ##그 ##룹 ##이 가 ##장 규 ##모 ##가 크 ##며 대한민국 [MASK] 여 ##객 ##용 버 ##스 ##의 1 ##0 [UNK] 를 소 ##유 ##하고 있 ##으 ##며 경 ##기도 노 ##선 ##의 절 ##반 ##을 관 ##리 ##한 ##다 . [SEP] ##자 ##들 ##을 대 ##중 ##교 ##통 ##으로 유 ##도 ##하기 위해 버 ##스 ##전 ##용 ##차 ##로 ##제 ##를 도 ##입 ##했 ##다 . 최 ##근 ##에는 장 ##애 [MASK] ##들 ##을 배 ##려 ##하기 위 ##하여 저 ##상 [MASK] ##스 ##를 도 ##입 ##하는 자 ##치 단 ##체 ##들이 생 ##기 ##고 있 ##으 ##며 수 ##도 ##권 ##의 도 ##심 지 ##역 ##의 혼 ##란 ##이 극 ##심 ##한 대한민국 ##의 상 ##황 ##에 걸 ##맞 ##은 굴 ##절 ##버 ##스 ##를 수 ##도 ##권 일 ##부 지 ##역 ##에서 도 ##입 ##하였 ##으나 대 ##부 ##분 비 ##용 문 ##제 등 ##으로 취 ##소 ##되었 ##다 . 대한민국 ##의 철 ##도 및 광 ##역 ##전 [MASK] ##의 총 연 ##장 길 ##이 ##는 3 , 0 ##00 ##k ##m ##에 달 ##한 ##다 . 이 [MASK] ##한 대한민국 ##의 철 ##도 ##시 ##설 ##은 19 ##6 ##3 ##년 9 ##월 1 ##일 교 ##통 ##부 ##줍 ##하 ##에 철 ##도 ##본 ##을 신 ##설 ##하여 이 ##때 ##부터 국 ##가 ##가 [MASK] ##계 ##적으로 관 ##리 ##하였 ##으나 200 ##5 ##년에는 기 ##업 ##체 ##로 전 ##환 ##하여 , 공 ##기 [MASK] ##의 형 ##태 ##인 한국 ##철 ##도 ##공 ##사 ##와 한국 ##철 ##도 ##시 ##설 ##공 ##단 [MASK] 국 ##유 철 ##도 ##를 관 ##리 ##하고 있 ##다 . 특 ##히 경 [MASK] ##선 철 ##도 ##는 평 [MASK] ##선 · 평 ##의 ##선 [MASK] 시 ##베 ##리 ##아 횡 ##단 ##철 ##도 ##와 ##의 연 ##결 ##을 추 ##진 ##하고 있 ##다 . 대한민국 ##의 대 ##표 ##적인 철 ##도 ##선 ##에는 경 ##부 ##선 , 호 ##남 ##선 , 중 ##앙 ##선 , 장 ##항 ##선 , 경 ##전 ##선 , 경 ##춘 ##옷 , 충 ##북 ##선 , 그 ##리 ##고 전 ##라 ##선 ##이 있 [MASK] . 또 201 ##6 ##년 1 ##2 ##월 ##에는 한국 [MASK] ##도 ##공 ##사 ##가 자 [MASK] ##을 출 ##자 ##하여 설 ##립 ##된 민 ##간 ##기 ##업 S ##R ##에서 운 ##행 ##하는 S ##R ##T ##가 개 [SEP]\n","I1204 09:11:46.568299 139694404269952 create_pretraining_data.py:151] tokens: [CLS] 시 ##내 ##버 ##스 ##의 경우 시 ##계 ##를 넘 ##어 ##서 ##면 시 ##계 추 ##가 요 ##금 ##이 부 ##과 ##되 ##며 서 ##울 , 경 ##기도 , 인 ##천 ##의 시 ##내 ##버 ##스 ##는 거 ##리 ##에 따 ##른 추 ##가 요 ##금 ##이 부 ##과 ##된 ##다 . [MASK] ##외 ##버 ##스 ##는 시 ##외 ##버 ##스 ##터 ##미 ##널 ##이나 시 ##외 ##버 [MASK] ##정 ##거 ##장 ##에서 주 ##로 승 ##하 ##차 ##가 이 ##절 ##어 ##지 ##며 대 ##부 ##분 교 ##통 ##카 ##드 ##를 사용 ##할 수 없 ##지만 가 ##끔 ##씩 사용 가 ##능 ##한 노 ##선 ##도 있 ##다 . 현 ##재 대한민국 ##의 버 ##스 회 ##사 중 ##에서는 K ##D ##그 ##룹 ##이 가 ##장 규 ##모 ##가 크 ##며 대한민국 [MASK] 여 ##객 ##용 버 ##스 ##의 1 ##0 [UNK] 를 소 ##유 ##하고 있 ##으 ##며 경 ##기도 노 ##선 ##의 절 ##반 ##을 관 ##리 ##한 ##다 . [SEP] ##자 ##들 ##을 대 ##중 ##교 ##통 ##으로 유 ##도 ##하기 위해 버 ##스 ##전 ##용 ##차 ##로 ##제 ##를 도 ##입 ##했 ##다 . 최 ##근 ##에는 장 ##애 [MASK] ##들 ##을 배 ##려 ##하기 위 ##하여 저 ##상 [MASK] ##스 ##를 도 ##입 ##하는 자 ##치 단 ##체 ##들이 생 ##기 ##고 있 ##으 ##며 수 ##도 ##권 ##의 도 ##심 지 ##역 ##의 혼 ##란 ##이 극 ##심 ##한 대한민국 ##의 상 ##황 ##에 걸 ##맞 ##은 굴 ##절 ##버 ##스 ##를 수 ##도 ##권 일 ##부 지 ##역 ##에서 도 ##입 ##하였 ##으나 대 ##부 ##분 비 ##용 문 ##제 등 ##으로 취 ##소 ##되었 ##다 . 대한민국 ##의 철 ##도 및 광 ##역 ##전 [MASK] ##의 총 연 ##장 길 ##이 ##는 3 , 0 ##00 ##k ##m ##에 달 ##한 ##다 . 이 [MASK] ##한 대한민국 ##의 철 ##도 ##시 ##설 ##은 19 ##6 ##3 ##년 9 ##월 1 ##일 교 ##통 ##부 ##줍 ##하 ##에 철 ##도 ##본 ##을 신 ##설 ##하여 이 ##때 ##부터 국 ##가 ##가 [MASK] ##계 ##적으로 관 ##리 ##하였 ##으나 200 ##5 ##년에는 기 ##업 ##체 ##로 전 ##환 ##하여 , 공 ##기 [MASK] ##의 형 ##태 ##인 한국 ##철 ##도 ##공 ##사 ##와 한국 ##철 ##도 ##시 ##설 ##공 ##단 [MASK] 국 ##유 철 ##도 ##를 관 ##리 ##하고 있 ##다 . 특 ##히 경 [MASK] ##선 철 ##도 ##는 평 [MASK] ##선 · 평 ##의 ##선 [MASK] 시 ##베 ##리 ##아 횡 ##단 ##철 ##도 ##와 ##의 연 ##결 ##을 추 ##진 ##하고 있 ##다 . 대한민국 ##의 대 ##표 ##적인 철 ##도 ##선 ##에는 경 ##부 ##선 , 호 ##남 ##선 , 중 ##앙 ##선 , 장 ##항 ##선 , 경 ##전 ##선 , 경 ##춘 ##옷 , 충 ##북 ##선 , 그 ##리 ##고 전 ##라 ##선 ##이 있 [MASK] . 또 201 ##6 ##년 1 ##2 ##월 ##에는 한국 [MASK] ##도 ##공 ##사 ##가 자 [MASK] ##을 출 ##자 ##하여 설 ##립 ##된 민 ##간 ##기 ##업 S ##R ##에서 운 ##행 ##하는 S ##R ##T ##가 개 [SEP]\n","INFO:tensorflow:input_ids: 0 109 343 450 32 5 335 109 58 11 866 23 38 88 109 58 326 13 511 462 6 144 25 127 190 135 341 947 218 438 947 83 487 5 109 343 450 32 8 291 19 10 491 476 326 13 511 462 6 144 25 177 104 1326 4 522 450 32 8 109 522 450 32 169 189 626 332 109 522 450 4 47 206 50 26 101 15 716 48 213 13 14 592 23 31 190 45 67 130 398 333 344 160 11 165 117 22 273 272 54 1587 1209 165 54 330 16 199 84 18 71 104 1326 242 173 318 5 710 32 409 35 69 293 786 538 307 966 6 54 50 665 383 13 416 190 318 4 229 1109 90 710 32 5 41 121 1 937 158 200 154 71 319 190 218 438 199 84 5 841 192 7 143 19 16 104 1326 2 20 99 7 45 299 145 333 24 77 18 269 415 710 32 61 90 213 15 62 11 191 387 222 104 1326 301 528 159 421 956 4 99 7 496 227 269 138 98 513 59 4 32 11 191 387 57 64 82 252 115 295 244 21 30 71 319 190 22 18 274 5 191 345 63 182 5 766 434 6 711 345 16 318 5 139 818 10 822 1537 12 1611 592 450 32 11 22 18 274 79 67 63 182 26 191 387 328 351 45 67 130 116 90 136 62 68 24 600 94 452 104 1326 318 5 691 18 489 535 182 61 4 5 564 126 50 729 6 8 180 947 636 464 817 519 10 534 16 104 1326 14 4 16 318 5 691 18 33 381 12 65 108 95 34 570 91 41 42 398 333 67 2152 48 10 691 18 486 7 357 381 98 14 717 224 133 13 13 4 58 184 143 19 328 351 210 102 666 44 168 115 15 51 473 98 947 93 21 4 5 378 285 27 362 689 18 156 35 39 362 689 18 33 381 156 228 4 133 200 691 18 11 143 19 154 71 104 1326 305 209 218 4 84 691 18 8 359 4 84 970 359 5 84 4 109 472 19 74 1607 228 689 18 39 5 126 361 7 326 132 154 71 104 1326 318 5 45 264 153 691 18 84 159 218 67 84 947 629 533 84 947 69 693 84 947 421 467 84 947 218 61 84 947 218 1072 1995 947 648 588 84 947 37 19 30 51 53 84 6 71 4 1326 417 431 108 34 41 66 91 159 362 4 18 156 35 13 64 4 7 376 20 98 303 207 177 397 141 21 168 761 861 26 500 249 57 761 861 599 13 140 2\n","I1204 09:11:46.568706 139694404269952 create_pretraining_data.py:161] input_ids: 0 109 343 450 32 5 335 109 58 11 866 23 38 88 109 58 326 13 511 462 6 144 25 127 190 135 341 947 218 438 947 83 487 5 109 343 450 32 8 291 19 10 491 476 326 13 511 462 6 144 25 177 104 1326 4 522 450 32 8 109 522 450 32 169 189 626 332 109 522 450 4 47 206 50 26 101 15 716 48 213 13 14 592 23 31 190 45 67 130 398 333 344 160 11 165 117 22 273 272 54 1587 1209 165 54 330 16 199 84 18 71 104 1326 242 173 318 5 710 32 409 35 69 293 786 538 307 966 6 54 50 665 383 13 416 190 318 4 229 1109 90 710 32 5 41 121 1 937 158 200 154 71 319 190 218 438 199 84 5 841 192 7 143 19 16 104 1326 2 20 99 7 45 299 145 333 24 77 18 269 415 710 32 61 90 213 15 62 11 191 387 222 104 1326 301 528 159 421 956 4 99 7 496 227 269 138 98 513 59 4 32 11 191 387 57 64 82 252 115 295 244 21 30 71 319 190 22 18 274 5 191 345 63 182 5 766 434 6 711 345 16 318 5 139 818 10 822 1537 12 1611 592 450 32 11 22 18 274 79 67 63 182 26 191 387 328 351 45 67 130 116 90 136 62 68 24 600 94 452 104 1326 318 5 691 18 489 535 182 61 4 5 564 126 50 729 6 8 180 947 636 464 817 519 10 534 16 104 1326 14 4 16 318 5 691 18 33 381 12 65 108 95 34 570 91 41 42 398 333 67 2152 48 10 691 18 486 7 357 381 98 14 717 224 133 13 13 4 58 184 143 19 328 351 210 102 666 44 168 115 15 51 473 98 947 93 21 4 5 378 285 27 362 689 18 156 35 39 362 689 18 33 381 156 228 4 133 200 691 18 11 143 19 154 71 104 1326 305 209 218 4 84 691 18 8 359 4 84 970 359 5 84 4 109 472 19 74 1607 228 689 18 39 5 126 361 7 326 132 154 71 104 1326 318 5 45 264 153 691 18 84 159 218 67 84 947 629 533 84 947 69 693 84 947 421 467 84 947 218 61 84 947 218 1072 1995 947 648 588 84 947 37 19 30 51 53 84 6 71 4 1326 417 431 108 34 41 66 91 159 362 4 18 156 35 13 64 4 7 376 20 98 303 207 177 397 141 21 168 761 861 26 500 249 57 761 861 599 13 140 2\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","I1204 09:11:46.569151 139694404269952 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","I1204 09:11:46.672332 139694404269952 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","INFO:tensorflow:masked_lm_positions: 54 70 82 135 196 206 285 305 325 330 341 361 379 394 400 406 457 471 482 488\n","I1204 09:11:46.672719 139694404269952 create_pretraining_data.py:161] masked_lm_positions: 54 70 82 135 196 206 285 305 325 330 341 361 379 394 400 406 457 471 482 488\n","INFO:tensorflow:masked_lm_ids: 109 32 298 343 27 450 689 151 484 621 388 168 26 5 67 25 84 104 689 486\n","I1204 09:11:46.673034 139694404269952 create_pretraining_data.py:161] masked_lm_ids: 109 32 298 343 27 450 689 151 484 621 388 168 26 5 67 25 84 104 689 486\n","INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","I1204 09:11:46.673315 139694404269952 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","INFO:tensorflow:next_sentence_labels: 0\n","I1204 09:11:46.673559 139694404269952 create_pretraining_data.py:161] next_sentence_labels: 0\n","INFO:tensorflow:*** Example ***\n","I1204 09:11:46.676226 139694404269952 create_pretraining_data.py:149] *** Example ***\n","INFO:tensorflow:tokens: [CLS] 1 ##인 ##당 영 ##화 관 ##람 횟 ##수 ##는 201 ##3 ##년 4 . 1 ##2 ##편 ##으로 미국 ##의 3 . 8 ##8 ##편 [MASK] 제 ##치 ##고 세 ##계 ##에서 영 [MASK] ##를 가 ##장 많 ##이 보 ##는 것 ##으로 나타 ##났 ##다 . [MASK] ##신 ##의 여 ##가 ##생 ##활 ##에 대한 불 ##만 ##족 이 ##유 ##들 ##로 ##는 ‘ 시 ##간 부 ##족 ’ 비 ##율 ##이 4 ##5 . 9 [UNK] 였 ##고 , [MASK] 다음 ##으로 ##는 ‘ 경 ##제 ##적 부 ##담 ’ 이 ##라는 이 ##유 ##가 4 ##5 . 6 [UNK] 로 나타 ##났 ##다 . 한국 [MASK] 반 ##도 ##에 있는 지 ##리 ##적 조 ##건 ##으로 대 ##륙 [MASK] ##화 ##와 해 ##양 문 ##화 [MASK] 영 ##향 ##을 모 ##두 받 ##았 ##다 . 고 ##대 ##의 한국 문 ##화 ##는 시 ##베 ##리 ##아 , 중 ##앙 ##아 ##시 ##아 ##의 북 ##방 ##계 ##와 동 ##남 ##아 ##시 ##아 ##의 남 ##방 ##계 ##가 혼 ##합 ##된 바 [MASK] ##에 중 [MASK] 등 이 ##웃 나 ##라 ##에서 들 ##어 ##온 외 ##래 문 ##화 ##와 한국 고 ##유 ##의 독 ##자 ##적 문 ##화 ##와 융 ##합 ##하여 발 ##전 ##했 ##다 . 관 [MASK] ##적인 공 ##용 ##어 ##이 ##자 법 ##적인 공 ##용 ##어 ##는 한국 ##어 ##로 , 그 계 ##통 ##이 학 ##계 ##에서 확 ##증 ##되 ##지 않 ##은 고 ##립 [MASK] 언 ##어 ##이 ##지만 많 ##은 학 ##자 ##들이 알 ##타 ##이 ##어 ##족 ##과 연 ##관 ##성 있 ##음 [MASK] 주 ##장 ##한 바 있 ##고 , 특 ##히 많 ##은 한국 ##인 학 ##자 ##들은 한국 ##어 ##가 알 ##타 ##이 ##어 ##족 ##에 속 ##한 ##다고 보 ##고 있 ##다 . 한국 ##어 표 ##기 ##에 쓰 ##이 ##는 문 ##자 ##인 한 ##글 ##은 세 ##종 ##대 ##왕 ##이 원 ##로 ##대 ##신 ##들의 [MASK] ##대 [MASK] 무 ##릅 ##쓰 ##고 [MASK] ##문 ##청 또 ##는 정 ##음 ##청 ##을 설 ##치 ##하여 , 훈 ##민 ##정 ##음 ##이 ##라는 명 ##칭 ##으로 1 ##4 ##4 ##6 ##년 반 ##포 ##하였 ##다 . 한 ##글 ##은 각 자 ##음 ##과 모 ##음 ##이 하 ##나 ##의 기 ##호 ##로 표 ##시 ##되 ##고 , 그 자 ##음 ##과 모 ##음 ##을 모 ##아 ##써 [MASK] 소 ##리 ##를 나타 ##내 ##는 표 ##음 ##문 ##자 ##이 ##다 . 한 ##글 ##의 자 ##음 ##은 발 ##음 ##기 ##관 ##의 모 ##양 ##을 본 ##뜨 ##고 모 ##음 ##은 천 , 지 , 인 ##을 나타 ##내 ##는 각 부 [MASK] ##의 조 ##합 [MASK] 만 ##든 , 세 ##계 ##에서 유 ##일 ##하게 그 창 [SEP] 여 ##담 ##으로 인 ##터 ##넷 검 ##색 ##엔 ##진 업 ##체 구 ##글 ##은 처 ##음 ##에 구 ##골 ##로 등 ##록 ##하 ##려 ##다 ##가 [MASK] ##수 ##로 사 ##명 ##을 잘 ##못 표 ##기 ##한 것 ##에서 구 ##글 ##로 등 ##록 ##하여 지 ##금 ##까지 쓰 ##이 ##고 있 ##다 . [SEP]\n","I1204 09:11:46.677001 139694404269952 create_pretraining_data.py:151] tokens: [CLS] 1 ##인 ##당 영 ##화 관 ##람 횟 ##수 ##는 201 ##3 ##년 4 . 1 ##2 ##편 ##으로 미국 ##의 3 . 8 ##8 ##편 [MASK] 제 ##치 ##고 세 ##계 ##에서 영 [MASK] ##를 가 ##장 많 ##이 보 ##는 것 ##으로 나타 ##났 ##다 . [MASK] ##신 ##의 여 ##가 ##생 ##활 ##에 대한 불 ##만 ##족 이 ##유 ##들 ##로 ##는 ‘ 시 ##간 부 ##족 ’ 비 ##율 ##이 4 ##5 . 9 [UNK] 였 ##고 , [MASK] 다음 ##으로 ##는 ‘ 경 ##제 ##적 부 ##담 ’ 이 ##라는 이 ##유 ##가 4 ##5 . 6 [UNK] 로 나타 ##났 ##다 . 한국 [MASK] 반 ##도 ##에 있는 지 ##리 ##적 조 ##건 ##으로 대 ##륙 [MASK] ##화 ##와 해 ##양 문 ##화 [MASK] 영 ##향 ##을 모 ##두 받 ##았 ##다 . 고 ##대 ##의 한국 문 ##화 ##는 시 ##베 ##리 ##아 , 중 ##앙 ##아 ##시 ##아 ##의 북 ##방 ##계 ##와 동 ##남 ##아 ##시 ##아 ##의 남 ##방 ##계 ##가 혼 ##합 ##된 바 [MASK] ##에 중 [MASK] 등 이 ##웃 나 ##라 ##에서 들 ##어 ##온 외 ##래 문 ##화 ##와 한국 고 ##유 ##의 독 ##자 ##적 문 ##화 ##와 융 ##합 ##하여 발 ##전 ##했 ##다 . 관 [MASK] ##적인 공 ##용 ##어 ##이 ##자 법 ##적인 공 ##용 ##어 ##는 한국 ##어 ##로 , 그 계 ##통 ##이 학 ##계 ##에서 확 ##증 ##되 ##지 않 ##은 고 ##립 [MASK] 언 ##어 ##이 ##지만 많 ##은 학 ##자 ##들이 알 ##타 ##이 ##어 ##족 ##과 연 ##관 ##성 있 ##음 [MASK] 주 ##장 ##한 바 있 ##고 , 특 ##히 많 ##은 한국 ##인 학 ##자 ##들은 한국 ##어 ##가 알 ##타 ##이 ##어 ##족 ##에 속 ##한 ##다고 보 ##고 있 ##다 . 한국 ##어 표 ##기 ##에 쓰 ##이 ##는 문 ##자 ##인 한 ##글 ##은 세 ##종 ##대 ##왕 ##이 원 ##로 ##대 ##신 ##들의 [MASK] ##대 [MASK] 무 ##릅 ##쓰 ##고 [MASK] ##문 ##청 또 ##는 정 ##음 ##청 ##을 설 ##치 ##하여 , 훈 ##민 ##정 ##음 ##이 ##라는 명 ##칭 ##으로 1 ##4 ##4 ##6 ##년 반 ##포 ##하였 ##다 . 한 ##글 ##은 각 자 ##음 ##과 모 ##음 ##이 하 ##나 ##의 기 ##호 ##로 표 ##시 ##되 ##고 , 그 자 ##음 ##과 모 ##음 ##을 모 ##아 ##써 [MASK] 소 ##리 ##를 나타 ##내 ##는 표 ##음 ##문 ##자 ##이 ##다 . 한 ##글 ##의 자 ##음 ##은 발 ##음 ##기 ##관 ##의 모 ##양 ##을 본 ##뜨 ##고 모 ##음 ##은 천 , 지 , 인 ##을 나타 ##내 ##는 각 부 [MASK] ##의 조 ##합 [MASK] 만 ##든 , 세 ##계 ##에서 유 ##일 ##하게 그 창 [SEP] 여 ##담 ##으로 인 ##터 ##넷 검 ##색 ##엔 ##진 업 ##체 구 ##글 ##은 처 ##음 ##에 구 ##골 ##로 등 ##록 ##하 ##려 ##다 ##가 [MASK] ##수 ##로 사 ##명 ##을 잘 ##못 표 ##기 ##한 것 ##에서 구 ##글 ##로 등 ##록 ##하여 지 ##금 ##까지 쓰 ##이 ##고 있 ##다 . [SEP]\n","INFO:tensorflow:input_ids: 0 41 27 131 236 56 143 390 1377 29 8 431 95 34 320 1326 41 66 483 24 456 5 180 1326 517 103 483 4 76 82 30 198 58 26 236 4 11 54 50 287 6 107 8 72 24 374 610 104 1326 4 187 5 229 13 312 705 10 241 205 125 288 14 200 99 15 8 595 109 141 144 288 1599 116 503 6 320 102 1326 570 1 1710 30 947 4 499 24 8 595 218 62 73 144 788 1599 14 258 14 200 13 320 102 1326 480 1 439 374 610 104 1326 362 4 231 18 10 225 63 19 73 119 262 24 45 1076 4 56 39 202 321 136 56 4 236 379 7 120 470 308 296 104 1326 176 36 5 362 136 56 8 109 472 19 74 947 69 693 74 33 74 5 568 315 58 39 175 533 74 33 74 5 375 315 58 13 766 220 177 336 4 10 69 4 68 14 1394 238 53 26 395 23 547 418 250 136 56 39 362 176 200 5 384 20 73 136 56 39 1615 220 98 134 61 222 104 1326 143 4 153 93 90 23 6 20 437 153 93 90 23 8 362 23 15 947 37 204 333 6 435 58 26 428 722 127 31 188 12 176 207 4 453 23 6 272 287 12 435 20 295 367 248 6 23 288 25 126 265 60 71 329 4 101 50 16 336 71 30 947 305 209 287 12 362 27 435 20 300 362 23 13 367 248 6 23 288 10 441 16 277 107 30 71 104 1326 362 23 181 21 10 463 6 8 136 20 27 97 577 12 198 469 36 940 6 171 15 36 187 433 4 36 4 253 2260 1069 30 4 155 621 417 8 49 329 621 7 303 82 98 947 1148 162 47 329 6 258 389 659 24 41 106 106 108 34 231 355 328 104 1326 97 577 12 292 64 329 25 120 329 6 52 75 5 44 208 15 181 33 127 30 947 37 64 329 25 120 329 7 120 74 668 4 158 19 11 374 343 8 181 329 155 20 6 104 1326 97 577 5 64 329 12 134 329 21 265 5 120 321 7 615 1358 30 120 329 12 748 947 63 947 83 7 374 343 8 292 144 4 5 119 220 4 163 338 947 198 58 26 77 42 350 37 628 2 229 788 24 83 169 681 539 652 810 132 764 115 112 577 12 550 329 10 112 951 15 68 348 48 227 104 13 4 29 15 43 105 7 807 1234 181 21 16 72 26 112 577 15 68 348 98 63 462 289 463 6 30 71 104 1326 2\n","I1204 09:11:46.677648 139694404269952 create_pretraining_data.py:161] input_ids: 0 41 27 131 236 56 143 390 1377 29 8 431 95 34 320 1326 41 66 483 24 456 5 180 1326 517 103 483 4 76 82 30 198 58 26 236 4 11 54 50 287 6 107 8 72 24 374 610 104 1326 4 187 5 229 13 312 705 10 241 205 125 288 14 200 99 15 8 595 109 141 144 288 1599 116 503 6 320 102 1326 570 1 1710 30 947 4 499 24 8 595 218 62 73 144 788 1599 14 258 14 200 13 320 102 1326 480 1 439 374 610 104 1326 362 4 231 18 10 225 63 19 73 119 262 24 45 1076 4 56 39 202 321 136 56 4 236 379 7 120 470 308 296 104 1326 176 36 5 362 136 56 8 109 472 19 74 947 69 693 74 33 74 5 568 315 58 39 175 533 74 33 74 5 375 315 58 13 766 220 177 336 4 10 69 4 68 14 1394 238 53 26 395 23 547 418 250 136 56 39 362 176 200 5 384 20 73 136 56 39 1615 220 98 134 61 222 104 1326 143 4 153 93 90 23 6 20 437 153 93 90 23 8 362 23 15 947 37 204 333 6 435 58 26 428 722 127 31 188 12 176 207 4 453 23 6 272 287 12 435 20 295 367 248 6 23 288 25 126 265 60 71 329 4 101 50 16 336 71 30 947 305 209 287 12 362 27 435 20 300 362 23 13 367 248 6 23 288 10 441 16 277 107 30 71 104 1326 362 23 181 21 10 463 6 8 136 20 27 97 577 12 198 469 36 940 6 171 15 36 187 433 4 36 4 253 2260 1069 30 4 155 621 417 8 49 329 621 7 303 82 98 947 1148 162 47 329 6 258 389 659 24 41 106 106 108 34 231 355 328 104 1326 97 577 12 292 64 329 25 120 329 6 52 75 5 44 208 15 181 33 127 30 947 37 64 329 25 120 329 7 120 74 668 4 158 19 11 374 343 8 181 329 155 20 6 104 1326 97 577 5 64 329 12 134 329 21 265 5 120 321 7 615 1358 30 120 329 12 748 947 63 947 83 7 374 343 8 292 144 4 5 119 220 4 163 338 947 198 58 26 77 42 350 37 628 2 229 788 24 83 169 681 539 652 810 132 764 115 112 577 12 550 329 10 112 951 15 68 348 48 227 104 13 4 29 15 43 105 7 807 1234 181 21 16 72 26 112 577 15 68 348 98 63 462 289 463 6 30 71 104 1326 2\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","I1204 09:11:46.678156 139694404269952 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","I1204 09:11:46.772964 139694404269952 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","INFO:tensorflow:masked_lm_positions: 27 35 49 83 110 123 130 176 179 213 232 245 266 324 326 331 394 439 443 483\n","I1204 09:11:46.774025 139694404269952 create_pretraining_data.py:161] masked_lm_positions: 27 35 49 83 110 123 130 176 179 213 232 245 266 324 326 331 394 439 443 483\n","INFO:tensorflow:masked_lm_ids: 7 56 64 37 12 136 5 1015 70 714 333 177 7 231 11 453 38 208 24 150\n","I1204 09:11:46.774625 139694404269952 create_pretraining_data.py:161] masked_lm_ids: 7 56 64 37 12 136 5 1015 70 714 333 177 7 231 11 453 38 208 24 150\n","INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","I1204 09:11:46.774857 139694404269952 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n","INFO:tensorflow:next_sentence_labels: 1\n","I1204 09:11:46.775287 139694404269952 create_pretraining_data.py:161] next_sentence_labels: 1\n","INFO:tensorflow:Wrote 13341 total instances\n","I1204 09:11:55.776552 139694404269952 create_pretraining_data.py:166] Wrote 13341 total instances\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8KZblGW1Rmcx"},"source":["## 4-1. BERT PRE-TRAIN(small version)\n","- 위 코드에서는 wiki_20190620_small.txt를 전처리하여 wiki_20190620_small_512_tf.record 레코드를 생성하였습니다. 이를 가지고 훈련.\n","- 데이터 : 위 코드에서 전처리한 wiki_20190620_small_512_tf.record\n","- output : 사전훈련된 모델, 저장 위치 : my_pretrained_model/\n","- 파라미터 :<br> train_batch_size=4, max_seq_length=512, max_predidtions_per_seq=20, <br> num_train_steps=10, learning_rate=1e-4, <br>\n","save_checkpoints_steps=5, do_lower_case=False"]},{"cell_type":"code","metadata":{"id":"fLq9AnPYSwk-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607076883230,"user_tz":-540,"elapsed":2726970,"user":{"displayName":"김정인","photoUrl":"","userId":"08669711361714769540"}},"outputId":"9e51a351-d971-448f-9b2c-6376c6747026"},"source":["!python drive/MyDrive/BERT/src/make_bert_model/run_pretraining.py \\\n","--input_file=drive/MyDrive/BERT/rsc/my_preprocessed_training_data/wiki_20190620_small_512_tf.record \\\n","--output_dir=drive/MyDrive/BERT/rsc/my_pretrained_model \\\n","--do_train=True \\\n","--do_eval=True \\\n","--bert_config_file=drive/MyDrive/BERT/rsc/conf/bert_config.json \\\n","--train_batch_size=4 \\\n","--max_seq_length=512 \\\n","--max_predictions_per_seq=20 \\\n","--num_train_steps=10 \\\n","--learning_rate=1e-4 \\\n","--save_checkpoints_steps=5 \\\n","--do_lower_case=False"],"execution_count":26,"outputs":[{"output_type":"stream","text":["/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","WARNING:tensorflow:From /content/drive/MyDrive/BERT/src/make_bert_model/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From drive/MyDrive/BERT/src/make_bert_model/run_pretraining.py:493: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From drive/MyDrive/BERT/src/make_bert_model/run_pretraining.py:407: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n","\n","W1204 09:29:18.847957 140526851262336 deprecation_wrapper.py:119] From drive/MyDrive/BERT/src/make_bert_model/run_pretraining.py:407: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n","\n","WARNING:tensorflow:From drive/MyDrive/BERT/src/make_bert_model/run_pretraining.py:407: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n","\n","W1204 09:29:18.848196 140526851262336 deprecation_wrapper.py:119] From drive/MyDrive/BERT/src/make_bert_model/run_pretraining.py:407: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/BERT/src/make_bert_model/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W1204 09:29:18.848403 140526851262336 deprecation_wrapper.py:119] From /content/drive/MyDrive/BERT/src/make_bert_model/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","WARNING:tensorflow:From drive/MyDrive/BERT/src/make_bert_model/run_pretraining.py:414: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n","\n","W1204 09:29:18.850556 140526851262336 deprecation_wrapper.py:119] From drive/MyDrive/BERT/src/make_bert_model/run_pretraining.py:414: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n","\n","WARNING:tensorflow:From drive/MyDrive/BERT/src/make_bert_model/run_pretraining.py:418: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n","\n","W1204 09:29:18.851125 140526851262336 deprecation_wrapper.py:119] From drive/MyDrive/BERT/src/make_bert_model/run_pretraining.py:418: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n","\n","WARNING:tensorflow:From drive/MyDrive/BERT/src/make_bert_model/run_pretraining.py:420: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","W1204 09:29:18.852365 140526851262336 deprecation_wrapper.py:119] From drive/MyDrive/BERT/src/make_bert_model/run_pretraining.py:420: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","INFO:tensorflow:*** Input Files ***\n","I1204 09:29:18.852546 140526851262336 run_pretraining.py:420] *** Input Files ***\n","INFO:tensorflow:  drive/MyDrive/BERT/rsc/my_preprocessed_training_data/wiki_20190620_small_512_tf.record\n","I1204 09:29:18.852693 140526851262336 run_pretraining.py:422]   drive/MyDrive/BERT/rsc/my_preprocessed_training_data/wiki_20190620_small_512_tf.record\n","I1204 09:29:19.441997 140526851262336 utils.py:141] NumExpr defaulting to 2 threads.\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","W1204 09:29:19.783311 140526851262336 lazy_loader.py:50] \n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fcec9d002f0>) includes params argument, but params are not passed to Estimator.\n","W1204 09:29:19.783941 140526851262336 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fcec9d002f0>) includes params argument, but params are not passed to Estimator.\n","INFO:tensorflow:Using config: {'_model_dir': 'drive/MyDrive/BERT/rsc/my_pretrained_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fcebeb4a780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': None}\n","I1204 09:29:19.785187 140526851262336 estimator.py:209] Using config: {'_model_dir': 'drive/MyDrive/BERT/rsc/my_pretrained_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fcebeb4a780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': None}\n","INFO:tensorflow:_TPUContext: eval_on_tpu True\n","I1204 09:29:19.785487 140526851262336 tpu_context.py:209] _TPUContext: eval_on_tpu True\n","WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n","W1204 09:29:19.786015 140526851262336 tpu_context.py:211] eval_on_tpu ignored because use_tpu is False.\n","INFO:tensorflow:***** Running training *****\n","I1204 09:29:19.786194 140526851262336 run_pretraining.py:459] ***** Running training *****\n","INFO:tensorflow:  Batch size = 4\n","I1204 09:29:19.786340 140526851262336 run_pretraining.py:460]   Batch size = 4\n","WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","W1204 09:29:19.793443 140526851262336 deprecation.py:323] From /root/.local/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","WARNING:tensorflow:From drive/MyDrive/BERT/src/make_bert_model/run_pretraining.py:337: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n","\n","W1204 09:29:19.806289 140526851262336 deprecation_wrapper.py:119] From drive/MyDrive/BERT/src/make_bert_model/run_pretraining.py:337: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n","\n","WARNING:tensorflow:From drive/MyDrive/BERT/src/make_bert_model/run_pretraining.py:368: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.parallel_interleave(...)`.\n","W1204 09:29:19.812151 140526851262336 deprecation.py:323] From drive/MyDrive/BERT/src/make_bert_model/run_pretraining.py:368: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.parallel_interleave(...)`.\n","WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","W1204 09:29:19.812367 140526851262336 deprecation.py:323] From /root/.local/lib/python3.6/site-packages/tensorflow/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","WARNING:tensorflow:From drive/MyDrive/BERT/src/make_bert_model/run_pretraining.py:385: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.map_and_batch(...)`.\n","W1204 09:29:19.836522 140526851262336 deprecation.py:323] From drive/MyDrive/BERT/src/make_bert_model/run_pretraining.py:385: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.map_and_batch(...)`.\n","WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/contrib/data/python/ops/batching.py:273: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n","W1204 09:29:19.836792 140526851262336 deprecation.py:323] From /root/.local/lib/python3.6/site-packages/tensorflow/contrib/data/python/ops/batching.py:273: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n","WARNING:tensorflow:From drive/MyDrive/BERT/src/make_bert_model/run_pretraining.py:393: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n","\n","W1204 09:29:19.838298 140526851262336 deprecation_wrapper.py:119] From drive/MyDrive/BERT/src/make_bert_model/run_pretraining.py:393: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n","\n","WARNING:tensorflow:From drive/MyDrive/BERT/src/make_bert_model/run_pretraining.py:400: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W1204 09:29:19.844722 140526851262336 deprecation.py:323] From drive/MyDrive/BERT/src/make_bert_model/run_pretraining.py:400: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","INFO:tensorflow:Calling model_fn.\n","I1204 09:29:19.871283 140526851262336 estimator.py:1145] Calling model_fn.\n","INFO:tensorflow:Running train on CPU\n","I1204 09:29:19.871554 140526851262336 tpu_estimator.py:2965] Running train on CPU\n","INFO:tensorflow:*** Features ***\n","I1204 09:29:19.871979 140526851262336 run_pretraining.py:117] *** Features ***\n","INFO:tensorflow:  name = input_ids, shape = (4, 512)\n","I1204 09:29:19.872208 140526851262336 run_pretraining.py:119]   name = input_ids, shape = (4, 512)\n","INFO:tensorflow:  name = input_mask, shape = (4, 512)\n","I1204 09:29:19.872400 140526851262336 run_pretraining.py:119]   name = input_mask, shape = (4, 512)\n","INFO:tensorflow:  name = masked_lm_ids, shape = (4, 20)\n","I1204 09:29:19.872578 140526851262336 run_pretraining.py:119]   name = masked_lm_ids, shape = (4, 20)\n","INFO:tensorflow:  name = masked_lm_positions, shape = (4, 20)\n","I1204 09:29:19.872749 140526851262336 run_pretraining.py:119]   name = masked_lm_positions, shape = (4, 20)\n","INFO:tensorflow:  name = masked_lm_weights, shape = (4, 20)\n","I1204 09:29:19.872939 140526851262336 run_pretraining.py:119]   name = masked_lm_weights, shape = (4, 20)\n","INFO:tensorflow:  name = next_sentence_labels, shape = (4, 1)\n","I1204 09:29:19.873134 140526851262336 run_pretraining.py:119]   name = next_sentence_labels, shape = (4, 1)\n","INFO:tensorflow:  name = segment_ids, shape = (4, 512)\n","I1204 09:29:19.873297 140526851262336 run_pretraining.py:119]   name = segment_ids, shape = (4, 512)\n","WARNING:tensorflow:From /content/drive/MyDrive/BERT/src/make_bert_model/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","W1204 09:29:19.873564 140526851262336 deprecation_wrapper.py:119] From /content/drive/MyDrive/BERT/src/make_bert_model/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/BERT/src/make_bert_model/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n","W1204 09:29:19.875375 140526851262336 deprecation_wrapper.py:119] From /content/drive/MyDrive/BERT/src/make_bert_model/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/BERT/src/make_bert_model/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n","\n","W1204 09:29:19.902074 140526851262336 deprecation_wrapper.py:119] From /content/drive/MyDrive/BERT/src/make_bert_model/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/BERT/src/make_bert_model/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","W1204 09:29:19.938769 140526851262336 deprecation.py:506] From /content/drive/MyDrive/BERT/src/make_bert_model/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /content/drive/MyDrive/BERT/src/make_bert_model/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dense instead.\n","W1204 09:29:19.956803 140526851262336 deprecation.py:323] From /content/drive/MyDrive/BERT/src/make_bert_model/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dense instead.\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe164390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe164390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:20.066785 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe164390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe164390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe0f6dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe0f6dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:20.169315 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe0f6dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe0f6dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe0f4d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe0f4d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:20.290560 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe0f4d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe0f4d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe1310b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe1310b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:20.421557 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe1310b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe1310b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe152908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe152908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:20.634378 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe152908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe152908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe152cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe152cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:20.756190 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe152cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe152cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe131b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe131b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:20.896316 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe131b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe131b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe131b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe131b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:20.998951 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe131b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe131b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe131b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe131b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:21.101449 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe131b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe131b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdf89a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdf89a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:21.241043 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdf89a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdf89a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe152908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe152908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:21.376741 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe152908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe152908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe152940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe152940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:21.491331 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe152940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe152940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebddc7a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebddc7a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:21.623213 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebddc7a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebddc7a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebddc7a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebddc7a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:21.730029 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebddc7a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebddc7a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebddc7a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebddc7a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:21.844605 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebddc7a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebddc7a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebde1f860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebde1f860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:21.984526 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebde1f860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebde1f860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebde88ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebde88ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:22.120724 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebde88ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebde88ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe1528d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe1528d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:22.236153 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe1528d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe1528d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdc70518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdc70518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:22.371452 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdc70518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdc70518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdc2cf28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdc2cf28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:22.474398 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdc2cf28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdc2cf28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdc2cf28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdc2cf28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:22.574437 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdc2cf28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdc2cf28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdcc6390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdcc6390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:22.710864 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdcc6390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdcc6390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe152cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe152cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:22.858839 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe152cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe152cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebddc7a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebddc7a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:22.986079 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebddc7a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebddc7a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebda96a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebda96a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:23.119626 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebda96a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebda96a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdae1b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdae1b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:23.221211 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdae1b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdae1b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdae1b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdae1b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:23.324394 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdae1b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdae1b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebda96a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebda96a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:23.456377 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebda96a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebda96a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdb57a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdb57a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:23.595687 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdb57a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdb57a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe152908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe152908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:23.710950 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe152908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe152908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd8e90f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd8e90f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:23.851884 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd8e90f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd8e90f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd8e90f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd8e90f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:23.971339 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd8e90f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd8e90f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd8e90f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd8e90f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:24.075933 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd8e90f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd8e90f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd9d35c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd9d35c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:24.306784 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd9d35c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd9d35c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdd3e9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdd3e9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:24.443072 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdd3e9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdd3e9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe1640b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe1640b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:24.556711 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe1640b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe1640b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd6e8978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd6e8978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:24.698169 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd6e8978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd6e8978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd7815f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd7815f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:24.803924 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd7815f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd7815f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd7815f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd7815f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:24.912673 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd7815f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd7815f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdb09f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdb09f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:25.048193 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdb09f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdb09f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdc596a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdc596a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:25.184714 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdc596a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdc596a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdb57a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdb57a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:25.296534 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdb57a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdb57a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd562c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd562c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:25.424522 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd562c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd562c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd55e588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd55e588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:25.523341 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd55e588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd55e588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd55e588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd55e588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:25.634155 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd55e588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd55e588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd59da90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd59da90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:25.764822 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd59da90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd59da90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdea6b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdea6b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:25.909367 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdea6b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdea6b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdd3e9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdd3e9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:26.028131 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdd3e9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebdd3e9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd38b160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd38b160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:26.168231 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd38b160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd38b160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd3624e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd3624e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:26.273335 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd3624e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd3624e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd38be80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd38be80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:26.373747 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd38be80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd38be80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd4137f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd4137f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:26.510544 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd4137f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd4137f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd3a2860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd3a2860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:26.642208 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd3a2860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd3a2860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd936a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd936a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:26.753194 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd936a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd936a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd1d0198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd1d0198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:26.896547 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd1d0198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd1d0198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd1d0198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd1d0198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:26.997024 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd1d0198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd1d0198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd1d0198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd1d0198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:27.098644 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd1d0198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd1d0198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd3d1f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd3d1f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:27.253720 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd3d1f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd3d1f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd3159e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd3159e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:27.405480 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd3159e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd3159e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd9614e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd9614e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:27.519882 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd9614e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd9614e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd06ae48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd06ae48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:27.653019 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd06ae48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd06ae48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd06ae48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd06ae48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:27.760742 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd06ae48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd06ae48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd06ae48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd06ae48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:27.868844 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd06ae48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd06ae48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd261dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd261dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:28.005388 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd261dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd261dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd3a2860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd3a2860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:28.141312 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd3a2860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd3a2860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd1c5e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd1c5e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:28.255028 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd1c5e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd1c5e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebce4c5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebce4c5f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:28.385355 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebce4c5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebce4c5f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebce4c5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebce4c5f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:28.590965 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebce4c5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebce4c5f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebce4c5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebce4c5f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:28.701667 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebce4c5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebce4c5f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcef8278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcef8278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:28.848714 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcef8278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcef8278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd101390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd101390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:28.988793 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd101390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebd101390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe0aecc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe0aecc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:29.099404 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe0aecc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe0aecc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe21bc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe21bc50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:29.254477 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe21bc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe21bc50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcc719b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcc719b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:29:29.369683 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcc719b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcc719b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:**** Trainable Variables ****\n","I1204 09:29:29.442921 140526851262336 run_pretraining.py:167] **** Trainable Variables ****\n","INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (49541, 768)\n","I1204 09:29:29.443244 140526851262336 run_pretraining.py:173]   name = bert/embeddings/word_embeddings:0, shape = (49541, 768)\n","INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)\n","I1204 09:29:29.443477 140526851262336 run_pretraining.py:173]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)\n","INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768)\n","I1204 09:29:29.443687 140526851262336 run_pretraining.py:173]   name = bert/embeddings/position_embeddings:0, shape = (512, 768)\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,)\n","I1204 09:29:29.443897 140526851262336 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:29:29.444112 140526851262336 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)\n","I1204 09:29:29.444298 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)\n","I1204 09:29:29.444511 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)\n","I1204 09:29:29.444716 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)\n","I1204 09:29:29.444923 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)\n","I1204 09:29:29.445153 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)\n","I1204 09:29:29.445340 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)\n","I1204 09:29:29.445528 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)\n","I1204 09:29:29.445715 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:29:29.445892 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:29:29.446095 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)\n","I1204 09:29:29.446272 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)\n","I1204 09:29:29.446495 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)\n","I1204 09:29:29.446712 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)\n","I1204 09:29:29.446925 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:29:29.447125 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:29:29.447311 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)\n","I1204 09:29:29.447507 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)\n","I1204 09:29:29.447689 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)\n","I1204 09:29:29.447885 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)\n","I1204 09:29:29.448092 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)\n","I1204 09:29:29.448271 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)\n","I1204 09:29:29.448453 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)\n","I1204 09:29:29.448633 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)\n","I1204 09:29:29.448815 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:29:29.449021 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:29:29.449198 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)\n","I1204 09:29:29.449374 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)\n","I1204 09:29:29.449572 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)\n","I1204 09:29:29.449759 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)\n","I1204 09:29:29.449964 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:29:29.450142 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:29:29.450316 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)\n","I1204 09:29:29.450493 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)\n","I1204 09:29:29.450674 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)\n","I1204 09:29:29.450860 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)\n","I1204 09:29:29.451080 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)\n","I1204 09:29:29.451261 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)\n","I1204 09:29:29.451442 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)\n","I1204 09:29:29.451620 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)\n","I1204 09:29:29.451800 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:29:29.452006 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:29:29.452183 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)\n","I1204 09:29:29.452372 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)\n","I1204 09:29:29.452559 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)\n","I1204 09:29:29.452737 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)\n","I1204 09:29:29.452945 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:29:29.453127 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:29:29.453299 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)\n","I1204 09:29:29.453474 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)\n","I1204 09:29:29.453673 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)\n","I1204 09:29:29.453852 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)\n","I1204 09:29:29.454082 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)\n","I1204 09:29:29.454285 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)\n","I1204 09:29:29.454466 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)\n","I1204 09:29:29.454644 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)\n","I1204 09:29:29.454825 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:29:29.455029 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:29:29.455202 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)\n","I1204 09:29:29.455379 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)\n","I1204 09:29:29.455560 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)\n","I1204 09:29:29.455738 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)\n","I1204 09:29:29.455935 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:29:29.456118 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:29:29.456289 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)\n","I1204 09:29:29.456501 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)\n","I1204 09:29:29.456687 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)\n","I1204 09:29:29.456862 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)\n","I1204 09:29:29.457078 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)\n","I1204 09:29:29.457269 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)\n","I1204 09:29:29.457469 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)\n","I1204 09:29:29.457646 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)\n","I1204 09:29:29.457827 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:29:29.458053 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:29:29.458230 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)\n","I1204 09:29:29.507739 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)\n","I1204 09:29:29.508083 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)\n","I1204 09:29:29.508371 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)\n","I1204 09:29:29.508664 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:29:29.508931 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:29:29.509179 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)\n","I1204 09:29:29.509420 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)\n","I1204 09:29:29.509702 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)\n","I1204 09:29:29.509969 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)\n","I1204 09:29:29.510318 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)\n","I1204 09:29:29.510556 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)\n","I1204 09:29:29.510768 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)\n","I1204 09:29:29.511019 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)\n","I1204 09:29:29.511273 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:29:29.511521 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:29:29.511754 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)\n","I1204 09:29:29.512005 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)\n","I1204 09:29:29.512249 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)\n","I1204 09:29:29.512492 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)\n","I1204 09:29:29.512826 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:29:29.513081 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:29:29.513299 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)\n","I1204 09:29:29.513546 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)\n","I1204 09:29:29.513942 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)\n","I1204 09:29:29.514250 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)\n","I1204 09:29:29.514508 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)\n","I1204 09:29:29.514739 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)\n","I1204 09:29:29.514996 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)\n","I1204 09:29:29.515246 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)\n","I1204 09:29:29.516147 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:29:29.516442 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:29:29.516682 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)\n","I1204 09:29:29.516935 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)\n","I1204 09:29:29.517194 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)\n","I1204 09:29:29.518033 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)\n","I1204 09:29:29.518295 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:29:29.518538 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:29:29.518748 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)\n","I1204 09:29:29.519016 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)\n","I1204 09:29:29.519237 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)\n","I1204 09:29:29.519443 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)\n","I1204 09:29:29.519668 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)\n","I1204 09:29:29.519867 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)\n","I1204 09:29:29.520117 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)\n","I1204 09:29:29.520323 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)\n","I1204 09:29:29.520537 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:29:29.520731 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:29:29.520949 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)\n","I1204 09:29:29.521168 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)\n","I1204 09:29:29.521370 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)\n","I1204 09:29:29.521569 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)\n","I1204 09:29:29.521773 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:29:29.522025 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:29:29.522248 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)\n","I1204 09:29:29.522455 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)\n","I1204 09:29:29.522659 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)\n","I1204 09:29:29.522853 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)\n","I1204 09:29:29.523186 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)\n","I1204 09:29:29.523505 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)\n","I1204 09:29:29.523820 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)\n","I1204 09:29:29.524168 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)\n","I1204 09:29:29.524490 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:29:29.524783 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:29:29.525104 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)\n","I1204 09:29:29.525407 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)\n","I1204 09:29:29.525817 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)\n","I1204 09:29:29.526106 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)\n","I1204 09:29:29.526355 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:29:29.526721 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:29:29.527342 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)\n","I1204 09:29:29.527556 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)\n","I1204 09:29:29.527933 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)\n","I1204 09:29:29.528248 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)\n","I1204 09:29:29.528488 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)\n","I1204 09:29:29.528735 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)\n","I1204 09:29:29.528976 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)\n","I1204 09:29:29.529175 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)\n","I1204 09:29:29.529372 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:29:29.529550 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:29:29.529722 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)\n","I1204 09:29:29.529896 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)\n","I1204 09:29:29.530140 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)\n","I1204 09:29:29.530323 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)\n","I1204 09:29:29.530612 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:29:29.530818 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:29:29.531022 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)\n","I1204 09:29:29.531213 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)\n","I1204 09:29:29.531455 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)\n","I1204 09:29:29.610697 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)\n","I1204 09:29:29.611315 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)\n","I1204 09:29:29.611611 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)\n","I1204 09:29:29.611874 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)\n","I1204 09:29:29.612160 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)\n","I1204 09:29:29.612417 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:29:29.612682 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:29:29.612950 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)\n","I1204 09:29:29.613165 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)\n","I1204 09:29:29.613368 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)\n","I1204 09:29:29.613568 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)\n","I1204 09:29:29.613782 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:29:29.614011 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:29:29.614236 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)\n","I1204 09:29:29.614440 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)\n","I1204 09:29:29.614653 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)\n","I1204 09:29:29.614852 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)\n","I1204 09:29:29.615122 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)\n","I1204 09:29:29.615335 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)\n","I1204 09:29:29.615531 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)\n","I1204 09:29:29.615730 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)\n","I1204 09:29:29.615960 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:29:29.616139 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:29:29.616313 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)\n","I1204 09:29:29.616544 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)\n","I1204 09:29:29.616762 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)\n","I1204 09:29:29.617009 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)\n","I1204 09:29:29.617197 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:29:29.617371 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:29:29.617594 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768)\n","I1204 09:29:29.617768 140526851262336 run_pretraining.py:173]   name = bert/pooler/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,)\n","I1204 09:29:29.618039 140526851262336 run_pretraining.py:173]   name = bert/pooler/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = cls/predictions/transform/dense/kernel:0, shape = (768, 768)\n","I1204 09:29:29.618224 140526851262336 run_pretraining.py:173]   name = cls/predictions/transform/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = cls/predictions/transform/dense/bias:0, shape = (768,)\n","I1204 09:29:29.618407 140526851262336 run_pretraining.py:173]   name = cls/predictions/transform/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,)\n","I1204 09:29:29.618599 140526851262336 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:29:29.618782 140526851262336 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = cls/predictions/output_bias:0, shape = (49541,)\n","I1204 09:29:29.619020 140526851262336 run_pretraining.py:173]   name = cls/predictions/output_bias:0, shape = (49541,)\n","INFO:tensorflow:  name = cls/seq_relationship/output_weights:0, shape = (2, 768)\n","I1204 09:29:29.619247 140526851262336 run_pretraining.py:173]   name = cls/seq_relationship/output_weights:0, shape = (2, 768)\n","INFO:tensorflow:  name = cls/seq_relationship/output_bias:0, shape = (2,)\n","I1204 09:29:29.619433 140526851262336 run_pretraining.py:173]   name = cls/seq_relationship/output_bias:0, shape = (2,)\n","WARNING:tensorflow:From /content/drive/MyDrive/BERT/src/make_bert_model/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n","W1204 09:29:29.619681 140526851262336 deprecation_wrapper.py:119] From /content/drive/MyDrive/BERT/src/make_bert_model/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/BERT/src/make_bert_model/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n","\n","W1204 09:29:29.621548 140526851262336 deprecation_wrapper.py:119] From /content/drive/MyDrive/BERT/src/make_bert_model/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n","\n","WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n","W1204 09:29:29.627208 140526851262336 deprecation.py:323] From /root/.local/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n","WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W1204 09:29:29.855566 140526851262336 deprecation.py:323] From /root/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","INFO:tensorflow:Done calling model_fn.\n","I1204 09:29:38.961713 140526851262336 estimator.py:1147] Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","I1204 09:29:38.963478 140526851262336 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","I1204 09:29:42.185157 140526851262336 monitored_session.py:240] Graph was finalized.\n","2020-12-04 09:29:42.185581: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","2020-12-04 09:29:42.189884: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n","2020-12-04 09:29:42.190151: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1e7f9c0 executing computations on platform Host. Devices:\n","2020-12-04 09:29:42.190186: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n","2020-12-04 09:29:44.660208: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n","INFO:tensorflow:Running local_init_op.\n","I1204 09:29:50.437487 140526851262336 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I1204 09:29:50.575051 140526851262336 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Saving checkpoints for 0 into drive/MyDrive/BERT/rsc/my_pretrained_model/model.ckpt.\n","I1204 09:29:57.060056 140526851262336 basic_session_run_hooks.py:606] Saving checkpoints for 0 into drive/MyDrive/BERT/rsc/my_pretrained_model/model.ckpt.\n","INFO:tensorflow:global_step/sec: 0.026543\n","I1204 09:31:25.941653 140526851262336 tpu_estimator.py:2159] global_step/sec: 0.026543\n","INFO:tensorflow:examples/sec: 0.106172\n","I1204 09:31:25.942714 140526851262336 tpu_estimator.py:2160] examples/sec: 0.106172\n","INFO:tensorflow:global_step/sec: 0.0304777\n","I1204 09:31:58.752601 140526851262336 tpu_estimator.py:2159] global_step/sec: 0.0304777\n","INFO:tensorflow:examples/sec: 0.121911\n","I1204 09:31:58.752981 140526851262336 tpu_estimator.py:2160] examples/sec: 0.121911\n","INFO:tensorflow:global_step/sec: 0.0300167\n","I1204 09:32:32.067404 140526851262336 tpu_estimator.py:2159] global_step/sec: 0.0300167\n","INFO:tensorflow:examples/sec: 0.120067\n","I1204 09:32:32.068034 140526851262336 tpu_estimator.py:2160] examples/sec: 0.120067\n","INFO:tensorflow:Saving checkpoints for 5 into drive/MyDrive/BERT/rsc/my_pretrained_model/model.ckpt.\n","I1204 09:33:04.907438 140526851262336 basic_session_run_hooks.py:606] Saving checkpoints for 5 into drive/MyDrive/BERT/rsc/my_pretrained_model/model.ckpt.\n","INFO:tensorflow:global_step/sec: 0.0240435\n","I1204 09:33:13.658592 140526851262336 tpu_estimator.py:2159] global_step/sec: 0.0240435\n","INFO:tensorflow:examples/sec: 0.0961739\n","I1204 09:33:13.658870 140526851262336 tpu_estimator.py:2160] examples/sec: 0.0961739\n","INFO:tensorflow:global_step/sec: 0.026267\n","I1204 09:33:51.729240 140526851262336 tpu_estimator.py:2159] global_step/sec: 0.026267\n","INFO:tensorflow:examples/sec: 0.105068\n","I1204 09:33:51.729568 140526851262336 tpu_estimator.py:2160] examples/sec: 0.105068\n","INFO:tensorflow:global_step/sec: 0.0301222\n","I1204 09:34:24.927333 140526851262336 tpu_estimator.py:2159] global_step/sec: 0.0301222\n","INFO:tensorflow:examples/sec: 0.120489\n","I1204 09:34:24.928843 140526851262336 tpu_estimator.py:2160] examples/sec: 0.120489\n","INFO:tensorflow:global_step/sec: 0.0305122\n","I1204 09:34:57.701126 140526851262336 tpu_estimator.py:2159] global_step/sec: 0.0305122\n","INFO:tensorflow:examples/sec: 0.122049\n","I1204 09:34:57.701587 140526851262336 tpu_estimator.py:2160] examples/sec: 0.122049\n","INFO:tensorflow:global_step/sec: 0.0309903\n","I1204 09:35:29.969402 140526851262336 tpu_estimator.py:2159] global_step/sec: 0.0309903\n","INFO:tensorflow:examples/sec: 0.123961\n","I1204 09:35:29.969924 140526851262336 tpu_estimator.py:2160] examples/sec: 0.123961\n","INFO:tensorflow:Saving checkpoints for 10 into drive/MyDrive/BERT/rsc/my_pretrained_model/model.ckpt.\n","I1204 09:36:02.861295 140526851262336 basic_session_run_hooks.py:606] Saving checkpoints for 10 into drive/MyDrive/BERT/rsc/my_pretrained_model/model.ckpt.\n","INFO:tensorflow:global_step/sec: 0.0222508\n","I1204 09:36:14.911510 140526851262336 tpu_estimator.py:2159] global_step/sec: 0.0222508\n","INFO:tensorflow:examples/sec: 0.0890032\n","I1204 09:36:14.911846 140526851262336 tpu_estimator.py:2160] examples/sec: 0.0890032\n","INFO:tensorflow:Loss for final step: 11.613066.\n","I1204 09:36:15.432336 140526851262336 estimator.py:368] Loss for final step: 11.613066.\n","INFO:tensorflow:training_loop marked as finished\n","I1204 09:36:15.445379 140526851262336 error_handling.py:96] training_loop marked as finished\n","INFO:tensorflow:***** Running evaluation *****\n","I1204 09:36:15.450516 140526851262336 run_pretraining.py:469] ***** Running evaluation *****\n","INFO:tensorflow:  Batch size = 8\n","I1204 09:36:15.450692 140526851262336 run_pretraining.py:470]   Batch size = 8\n","INFO:tensorflow:Calling model_fn.\n","I1204 09:36:15.570363 140526851262336 estimator.py:1145] Calling model_fn.\n","INFO:tensorflow:Running eval on CPU\n","I1204 09:36:15.570615 140526851262336 tpu_estimator.py:2965] Running eval on CPU\n","INFO:tensorflow:*** Features ***\n","I1204 09:36:15.571044 140526851262336 run_pretraining.py:117] *** Features ***\n","INFO:tensorflow:  name = input_ids, shape = (8, 512)\n","I1204 09:36:15.571253 140526851262336 run_pretraining.py:119]   name = input_ids, shape = (8, 512)\n","INFO:tensorflow:  name = input_mask, shape = (8, 512)\n","I1204 09:36:15.571434 140526851262336 run_pretraining.py:119]   name = input_mask, shape = (8, 512)\n","INFO:tensorflow:  name = masked_lm_ids, shape = (8, 20)\n","I1204 09:36:15.571601 140526851262336 run_pretraining.py:119]   name = masked_lm_ids, shape = (8, 20)\n","INFO:tensorflow:  name = masked_lm_positions, shape = (8, 20)\n","I1204 09:36:15.571766 140526851262336 run_pretraining.py:119]   name = masked_lm_positions, shape = (8, 20)\n","INFO:tensorflow:  name = masked_lm_weights, shape = (8, 20)\n","I1204 09:36:15.571955 140526851262336 run_pretraining.py:119]   name = masked_lm_weights, shape = (8, 20)\n","INFO:tensorflow:  name = next_sentence_labels, shape = (8, 1)\n","I1204 09:36:15.572137 140526851262336 run_pretraining.py:119]   name = next_sentence_labels, shape = (8, 1)\n","INFO:tensorflow:  name = segment_ids, shape = (8, 512)\n","I1204 09:36:15.572309 140526851262336 run_pretraining.py:119]   name = segment_ids, shape = (8, 512)\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5793a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5793a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:15.778156 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5793a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5793a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5793a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5793a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:15.893837 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5793a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5793a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5793a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5793a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:15.994667 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5793a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5793a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5793438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5793438>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:16.118093 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5793438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5793438>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcdde4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcdde4e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:16.242562 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcdde4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcdde4e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcf092e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcf092e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:16.368447 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcf092e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcf092e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb577bcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb577bcf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:16.490896 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb577bcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb577bcf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb577bcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb577bcf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:16.592108 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb577bcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb577bcf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb577bcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb577bcf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:16.700105 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb577bcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb577bcf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb57934e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb57934e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:16.820754 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb57934e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb57934e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcf092e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcf092e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:16.947845 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcf092e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcf092e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5715f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5715f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:17.072553 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5715f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5715f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5793160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5793160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:17.190239 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5793160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5793160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5793160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5793160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:17.293964 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5793160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5793160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5793160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5793160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:17.404758 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5793160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5793160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb559d5c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb559d5c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:17.531035 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb559d5c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb559d5c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb55f4160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb55f4160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:17.654800 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb55f4160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb55f4160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5715f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5715f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:17.763656 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5715f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5715f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb538dda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb538dda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:17.882304 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb538dda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb538dda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb538dda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb538dda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:18.000372 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb538dda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb538dda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb538dda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb538dda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:18.101746 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb538dda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb538dda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb54226a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb54226a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:18.221695 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb54226a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb54226a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5715fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5715fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:18.358738 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5715fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5715fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb57b3c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb57b3c18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:18.479789 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb57b3c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb57b3c18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5445cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5445cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:18.599972 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5445cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5445cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5445cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5445cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:18.705303 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5445cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5445cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5445cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5445cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:18.807661 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5445cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5445cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb52821d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb52821d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:18.942402 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb52821d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb52821d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5715f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5715f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:19.068382 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5715f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5715f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb57b37f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb57b37f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:19.179524 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb57b37f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb57b37f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb54226a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb54226a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:19.300271 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb54226a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb54226a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb54226a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb54226a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:19.412367 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb54226a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb54226a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb54226a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb54226a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:19.517780 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb54226a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb54226a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5146a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5146a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:19.640022 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5146a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5146a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcf092e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcf092e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:19.780686 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcf092e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcf092e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb57706a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb57706a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:19.893254 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb57706a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb57706a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb52821d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb52821d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:20.018530 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb52821d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb52821d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb52821d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb52821d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:20.125956 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb52821d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb52821d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb52821d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb52821d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:20.225960 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb52821d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb52821d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb04d6c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb04d6c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:20.343447 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb04d6c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb04d6c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb57b37f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb57b37f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:20.479463 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb57b37f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb57b37f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5622c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5622c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:20.597485 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5622c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5622c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb030c400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb030c400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:20.720450 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb030c400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb030c400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb030c400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb030c400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:20.861974 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb030c400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb030c400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb030c400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb030c400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:20.998015 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb030c400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb030c400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb04d6c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb04d6c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:21.121359 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb04d6c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb04d6c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb0342eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb0342eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:21.246196 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb0342eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb0342eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb54760b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb54760b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:21.354974 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb54760b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb54760b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb03c6cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb03c6cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:21.489518 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb03c6cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb03c6cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb03c6cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb03c6cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:21.590467 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb03c6cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb03c6cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb03c6cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb03c6cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:21.691375 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb03c6cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb03c6cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb04d6f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb04d6f98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:21.815745 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb04d6f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb04d6f98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb57706a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb57706a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:21.935732 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb57706a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb57706a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcf092e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcf092e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:22.063749 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcf092e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcf092e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb0019e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb0019e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:22.185307 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb0019e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb0019e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb0019e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb0019e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:22.286401 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb0019e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb0019e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb0019e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb0019e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:22.922610 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb0019e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb0019e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb00311d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb00311d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:23.049428 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb00311d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb00311d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb0174b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb0174b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:23.175772 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb0174b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb0174b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb0342eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb0342eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:23.305418 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb0342eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb0342eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebebc44a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebebc44a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:23.427667 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebebc44a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebebc44a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceea509e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceea509e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:23.540141 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceea509e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceea509e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceea509e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceea509e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:23.641698 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceea509e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceea509e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcd85c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcd85c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:23.775887 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcd85c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcd85c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb55f4160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb55f4160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:23.907677 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb55f4160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb55f4160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5715fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5715fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:24.021969 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5715fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb5715fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcc08d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcc08d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:24.156368 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcc08d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcc08d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcc08d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcc08d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:24.259509 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcc08d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcc08d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcc08d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcc08d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:24.364814 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcc08d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcc08d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb715a668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb715a668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:24.496109 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb715a668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb715a668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb55f4160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb55f4160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:24.617256 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb55f4160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb55f4160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcf09438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcf09438>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:24.727246 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcf09438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebcf09438>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb57cbf60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb57cbf60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:24.886359 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb57cbf60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fceb57cbf60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe261fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe261fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W1204 09:36:25.002058 140526851262336 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe261fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcebe261fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:**** Trainable Variables ****\n","I1204 09:36:25.072990 140526851262336 run_pretraining.py:167] **** Trainable Variables ****\n","INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (49541, 768)\n","I1204 09:36:25.073212 140526851262336 run_pretraining.py:173]   name = bert/embeddings/word_embeddings:0, shape = (49541, 768)\n","INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)\n","I1204 09:36:25.073432 140526851262336 run_pretraining.py:173]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)\n","INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768)\n","I1204 09:36:25.073637 140526851262336 run_pretraining.py:173]   name = bert/embeddings/position_embeddings:0, shape = (512, 768)\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,)\n","I1204 09:36:25.073848 140526851262336 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:36:25.074059 140526851262336 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)\n","I1204 09:36:25.074248 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)\n","I1204 09:36:25.074441 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)\n","I1204 09:36:25.074625 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)\n","I1204 09:36:25.074829 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)\n","I1204 09:36:25.075035 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)\n","I1204 09:36:25.075222 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)\n","I1204 09:36:25.075406 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)\n","I1204 09:36:25.075593 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:36:25.075779 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:36:25.075970 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)\n","I1204 09:36:25.076182 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)\n","I1204 09:36:25.076377 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)\n","I1204 09:36:25.076551 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)\n","I1204 09:36:25.076756 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:36:25.076959 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:36:25.077175 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)\n","I1204 09:36:25.077423 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)\n","I1204 09:36:25.077669 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)\n","I1204 09:36:25.077997 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)\n","I1204 09:36:25.078175 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)\n","I1204 09:36:25.078388 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)\n","I1204 09:36:25.078626 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)\n","I1204 09:36:25.078871 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)\n","I1204 09:36:25.079078 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:36:25.079253 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:36:25.079502 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)\n","I1204 09:36:25.079768 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)\n","I1204 09:36:25.080043 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)\n","I1204 09:36:25.080240 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)\n","I1204 09:36:25.080471 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:36:25.080694 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:36:25.080881 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)\n","I1204 09:36:25.081127 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)\n","I1204 09:36:25.081348 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)\n","I1204 09:36:25.081630 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)\n","I1204 09:36:25.081859 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)\n","I1204 09:36:25.082057 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)\n","I1204 09:36:25.082270 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)\n","I1204 09:36:25.082530 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)\n","I1204 09:36:25.082715 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:36:25.082929 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:36:25.083156 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)\n","I1204 09:36:25.083406 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)\n","I1204 09:36:25.083605 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)\n","I1204 09:36:25.083830 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)\n","I1204 09:36:25.084102 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:36:25.084277 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:36:25.084451 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)\n","I1204 09:36:25.084651 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)\n","I1204 09:36:25.084926 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)\n","I1204 09:36:25.085108 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)\n","I1204 09:36:25.085292 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)\n","I1204 09:36:25.085520 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)\n","I1204 09:36:25.085700 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)\n","I1204 09:36:25.085889 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)\n","I1204 09:36:25.086093 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:36:25.086268 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:36:25.086441 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)\n","I1204 09:36:25.086622 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)\n","I1204 09:36:25.086826 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)\n","I1204 09:36:25.087054 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)\n","I1204 09:36:25.087241 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:36:25.087438 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:36:25.087680 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)\n","I1204 09:36:25.087946 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)\n","I1204 09:36:25.088132 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)\n","I1204 09:36:25.088421 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)\n","I1204 09:36:25.088693 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)\n","I1204 09:36:25.088936 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)\n","I1204 09:36:25.089146 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)\n","I1204 09:36:25.090986 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)\n","I1204 09:36:25.091252 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:36:25.091532 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:36:25.091773 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)\n","I1204 09:36:25.092022 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)\n","I1204 09:36:25.092291 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)\n","I1204 09:36:25.092526 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)\n","I1204 09:36:25.092816 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:36:25.093086 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:36:25.093329 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)\n","I1204 09:36:25.093588 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)\n","I1204 09:36:25.093920 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)\n","I1204 09:36:25.094165 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)\n","I1204 09:36:25.094521 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)\n","I1204 09:36:25.094770 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)\n","I1204 09:36:25.095082 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)\n","I1204 09:36:25.095371 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)\n","I1204 09:36:25.095640 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:36:25.095938 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:36:25.096192 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)\n","I1204 09:36:25.096422 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)\n","I1204 09:36:25.096655 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)\n","I1204 09:36:25.096934 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)\n","I1204 09:36:25.097213 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:36:25.097471 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:36:25.097698 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)\n","I1204 09:36:25.097963 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)\n","I1204 09:36:25.098204 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)\n","I1204 09:36:25.098437 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)\n","I1204 09:36:25.098684 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)\n","I1204 09:36:25.098947 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)\n","I1204 09:36:25.099159 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)\n","I1204 09:36:25.099349 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)\n","I1204 09:36:25.099538 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:36:25.099720 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:36:25.099939 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)\n","I1204 09:36:25.100136 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)\n","I1204 09:36:25.100320 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)\n","I1204 09:36:25.100498 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)\n","I1204 09:36:25.100679 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:36:25.100860 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:36:25.101050 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)\n","I1204 09:36:25.101232 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)\n","I1204 09:36:25.101428 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)\n","I1204 09:36:25.101610 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)\n","I1204 09:36:25.101793 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)\n","I1204 09:36:25.102023 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)\n","I1204 09:36:25.102200 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)\n","I1204 09:36:25.102412 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)\n","I1204 09:36:25.102662 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:36:25.102859 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:36:25.103094 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)\n","I1204 09:36:25.103276 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)\n","I1204 09:36:25.103476 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)\n","I1204 09:36:25.103678 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)\n","I1204 09:36:25.103876 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:36:25.104091 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:36:25.104287 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)\n","I1204 09:36:25.104477 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)\n","I1204 09:36:25.104665 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)\n","I1204 09:36:25.104867 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)\n","I1204 09:36:25.105157 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)\n","I1204 09:36:25.105360 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)\n","I1204 09:36:25.105535 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)\n","I1204 09:36:25.105707 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)\n","I1204 09:36:25.105892 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:36:25.106083 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:36:25.106253 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)\n","I1204 09:36:25.106428 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)\n","I1204 09:36:25.106606 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)\n","I1204 09:36:25.106787 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)\n","I1204 09:36:25.107009 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:36:25.107213 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:36:25.107382 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)\n","I1204 09:36:25.107587 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)\n","I1204 09:36:25.107776 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)\n","I1204 09:36:25.107975 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)\n","I1204 09:36:25.108151 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)\n","I1204 09:36:25.108323 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)\n","I1204 09:36:25.108531 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)\n","I1204 09:36:25.108723 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)\n","I1204 09:36:25.108943 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:36:25.109196 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:36:25.109428 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)\n","I1204 09:36:25.109601 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)\n","I1204 09:36:25.109787 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)\n","I1204 09:36:25.109987 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)\n","I1204 09:36:25.110170 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:36:25.110362 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:36:25.110536 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)\n","I1204 09:36:25.110708 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)\n","I1204 09:36:25.110916 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)\n","I1204 09:36:25.111110 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)\n","I1204 09:36:25.111291 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)\n","I1204 09:36:25.111468 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)\n","I1204 09:36:25.111647 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)\n","I1204 09:36:25.111832 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)\n","I1204 09:36:25.112049 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:36:25.112221 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:36:25.112391 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)\n","I1204 09:36:25.112563 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)\n","I1204 09:36:25.112751 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)\n","I1204 09:36:25.197359 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)\n","I1204 09:36:25.197654 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:36:25.197965 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:36:25.198244 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)\n","I1204 09:36:25.198496 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)\n","I1204 09:36:25.198775 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)\n","I1204 09:36:25.199084 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)\n","I1204 09:36:25.199374 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)\n","I1204 09:36:25.199622 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)\n","I1204 09:36:25.199883 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)\n","I1204 09:36:25.200151 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)\n","I1204 09:36:25.200415 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:36:25.200645 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:36:25.200855 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)\n","I1204 09:36:25.201113 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)\n","I1204 09:36:25.201302 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)\n","I1204 09:36:25.201484 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)\n","I1204 09:36:25.201671 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)\n","I1204 09:36:25.201864 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:36:25.202076 140526851262336 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768)\n","I1204 09:36:25.202254 140526851262336 run_pretraining.py:173]   name = bert/pooler/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,)\n","I1204 09:36:25.202441 140526851262336 run_pretraining.py:173]   name = bert/pooler/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = cls/predictions/transform/dense/kernel:0, shape = (768, 768)\n","I1204 09:36:25.202648 140526851262336 run_pretraining.py:173]   name = cls/predictions/transform/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = cls/predictions/transform/dense/bias:0, shape = (768,)\n","I1204 09:36:25.202934 140526851262336 run_pretraining.py:173]   name = cls/predictions/transform/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,)\n","I1204 09:36:25.203116 140526851262336 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,)\n","I1204 09:36:25.203322 140526851262336 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = cls/predictions/output_bias:0, shape = (49541,)\n","I1204 09:36:25.203513 140526851262336 run_pretraining.py:173]   name = cls/predictions/output_bias:0, shape = (49541,)\n","INFO:tensorflow:  name = cls/seq_relationship/output_weights:0, shape = (2, 768)\n","I1204 09:36:25.203687 140526851262336 run_pretraining.py:173]   name = cls/seq_relationship/output_weights:0, shape = (2, 768)\n","INFO:tensorflow:  name = cls/seq_relationship/output_bias:0, shape = (2,)\n","I1204 09:36:25.203890 140526851262336 run_pretraining.py:173]   name = cls/seq_relationship/output_bias:0, shape = (2,)\n","WARNING:tensorflow:From drive/MyDrive/BERT/src/make_bert_model/run_pretraining.py:198: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n","\n","W1204 09:36:25.210789 140526851262336 deprecation_wrapper.py:119] From drive/MyDrive/BERT/src/make_bert_model/run_pretraining.py:198: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n","\n","WARNING:tensorflow:From drive/MyDrive/BERT/src/make_bert_model/run_pretraining.py:202: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n","\n","W1204 09:36:25.228544 140526851262336 deprecation_wrapper.py:119] From drive/MyDrive/BERT/src/make_bert_model/run_pretraining.py:202: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n","\n","INFO:tensorflow:Done calling model_fn.\n","I1204 09:36:25.285625 140526851262336 estimator.py:1147] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-12-04T09:36:25Z\n","I1204 09:36:25.314562 140526851262336 evaluation.py:255] Starting evaluation at 2020-12-04T09:36:25Z\n","INFO:tensorflow:Graph was finalized.\n","I1204 09:36:25.944162 140526851262336 monitored_session.py:240] Graph was finalized.\n","WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","W1204 09:36:25.944950 140526851262336 deprecation.py:323] From /root/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","INFO:tensorflow:Restoring parameters from drive/MyDrive/BERT/rsc/my_pretrained_model/model.ckpt-10\n","I1204 09:36:25.947515 140526851262336 saver.py:1280] Restoring parameters from drive/MyDrive/BERT/rsc/my_pretrained_model/model.ckpt-10\n","INFO:tensorflow:Running local_init_op.\n","I1204 09:36:27.223627 140526851262336 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I1204 09:36:27.264384 140526851262336 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Evaluation [10/100]\n","I1204 09:40:17.059730 140526851262336 evaluation.py:167] Evaluation [10/100]\n","INFO:tensorflow:Evaluation [20/100]\n","I1204 09:44:07.386811 140526851262336 evaluation.py:167] Evaluation [20/100]\n","INFO:tensorflow:Evaluation [30/100]\n","I1204 09:47:59.117943 140526851262336 evaluation.py:167] Evaluation [30/100]\n","INFO:tensorflow:Evaluation [40/100]\n","I1204 09:51:48.579267 140526851262336 evaluation.py:167] Evaluation [40/100]\n","INFO:tensorflow:Evaluation [50/100]\n","I1204 09:55:38.147265 140526851262336 evaluation.py:167] Evaluation [50/100]\n","INFO:tensorflow:Evaluation [60/100]\n","I1204 09:59:26.731724 140526851262336 evaluation.py:167] Evaluation [60/100]\n","INFO:tensorflow:Evaluation [70/100]\n","I1204 10:03:14.799647 140526851262336 evaluation.py:167] Evaluation [70/100]\n","INFO:tensorflow:Evaluation [80/100]\n","I1204 10:07:02.365537 140526851262336 evaluation.py:167] Evaluation [80/100]\n","INFO:tensorflow:Evaluation [90/100]\n","I1204 10:10:50.827666 140526851262336 evaluation.py:167] Evaluation [90/100]\n","INFO:tensorflow:Evaluation [100/100]\n","I1204 10:14:40.861892 140526851262336 evaluation.py:167] Evaluation [100/100]\n","INFO:tensorflow:Finished evaluation at 2020-12-04-10:14:40\n","I1204 10:14:40.964641 140526851262336 evaluation.py:275] Finished evaluation at 2020-12-04-10:14:40\n","INFO:tensorflow:Saving dict for global step 10: global_step = 10, loss = 11.640356, masked_lm_accuracy = 6.484243e-05, masked_lm_loss = 10.946833, next_sentence_accuracy = 0.50625, next_sentence_loss = 0.6933648\n","I1204 10:14:40.965150 140526851262336 estimator.py:2039] Saving dict for global step 10: global_step = 10, loss = 11.640356, masked_lm_accuracy = 6.484243e-05, masked_lm_loss = 10.946833, next_sentence_accuracy = 0.50625, next_sentence_loss = 0.6933648\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10: drive/MyDrive/BERT/rsc/my_pretrained_model/model.ckpt-10\n","I1204 10:14:41.501137 140526851262336 estimator.py:2099] Saving 'checkpoint_path' summary for global step 10: drive/MyDrive/BERT/rsc/my_pretrained_model/model.ckpt-10\n","INFO:tensorflow:evaluation_loop marked as finished\n","I1204 10:14:41.502458 140526851262336 error_handling.py:96] evaluation_loop marked as finished\n","INFO:tensorflow:***** Eval results *****\n","I1204 10:14:41.502736 140526851262336 run_pretraining.py:483] ***** Eval results *****\n","INFO:tensorflow:  global_step = 10\n","I1204 10:14:41.502929 140526851262336 run_pretraining.py:485]   global_step = 10\n","INFO:tensorflow:  loss = 11.640356\n","I1204 10:14:41.511966 140526851262336 run_pretraining.py:485]   loss = 11.640356\n","INFO:tensorflow:  masked_lm_accuracy = 6.484243e-05\n","I1204 10:14:41.512156 140526851262336 run_pretraining.py:485]   masked_lm_accuracy = 6.484243e-05\n","INFO:tensorflow:  masked_lm_loss = 10.946833\n","I1204 10:14:41.512312 140526851262336 run_pretraining.py:485]   masked_lm_loss = 10.946833\n","INFO:tensorflow:  next_sentence_accuracy = 0.50625\n","I1204 10:14:41.512462 140526851262336 run_pretraining.py:485]   next_sentence_accuracy = 0.50625\n","INFO:tensorflow:  next_sentence_loss = 0.6933648\n","I1204 10:14:41.512617 140526851262336 run_pretraining.py:485]   next_sentence_loss = 0.6933648\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"em6cmDF9V6_A"},"source":["## my_pretrained_model/ 에 생성된 사전 훈련 모델\n","\n","\n","---\n","<br>\n","\n","\n","![image.png](data:image/png;base64,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)## \n","\n"]},{"cell_type":"markdown","metadata":{"id":"j539oHYiSbeS"},"source":["## 4-2. BERT PRE-TRAIN(big version)\n","- 큰 위키 데이터로 미리 생성해놓은 wiki_20190620_512_tf.record 파일로 훈련.\n","- 파라미터는 위 코드쉘과 동일하며, <br>\n","train_batch_size를 4보다 크게 하면, colab에서 제공하는 GPU로는 메모리가 부족하여 에러가 발생.\n"]},{"cell_type":"code","metadata":{"id":"p70S2H-qVKNK","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1585209070550,"user_tz":-540,"elapsed":77306,"user":{"displayName":"Minkyung Park","photoUrl":"","userId":"13181002600298228191"}},"outputId":"07d38aa2-c9a0-425f-f9b1-3fc9f7df7a83"},"source":["!python drive/My\\ Drive/Colab\\ Notebooks/BERT/src/make_bert_model/run_pretraining.py \\\n","--input_file=drive/My\\ Drive/Colab\\ Notebooks/BERT/rsc/preprocessed_training_data/wiki_20190620_512_tf.record \\\n","--output_dir=drive/My\\ Drive/Colab\\ Notebooks/BERT/rsc/my_pretrained_model_big \\\n","--do_train=True \\\n","--do_eval=True \\\n","--bert_config_file=drive/My\\ Drive/Colab\\ Notebooks/BERT/rsc/conf/bert_config.json \\\n","--train_batch_size=4 \\\n","--max_seq_length=512 \\\n","--max_predictions_per_seq=20 \\\n","--num_train_steps=10 \\\n","--learning_rate=1e-4 \\\n","--save_checkpoints_steps=5 \\\n","--do_lower_case=False"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/run_pretraining.py:493: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/run_pretraining.py:407: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n","\n","W0326 07:49:58.006206 140646457186176 module_wrapper.py:139] From drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/run_pretraining.py:407: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n","\n","WARNING:tensorflow:From drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/run_pretraining.py:407: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n","\n","W0326 07:49:58.006421 140646457186176 module_wrapper.py:139] From drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/run_pretraining.py:407: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0326 07:49:58.006567 140646457186176 module_wrapper.py:139] From /content/drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","WARNING:tensorflow:From drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/run_pretraining.py:414: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n","\n","W0326 07:49:58.008314 140646457186176 module_wrapper.py:139] From drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/run_pretraining.py:414: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n","\n","WARNING:tensorflow:From drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/run_pretraining.py:418: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n","\n","W0326 07:49:58.008764 140646457186176 module_wrapper.py:139] From drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/run_pretraining.py:418: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n","\n","WARNING:tensorflow:From drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/run_pretraining.py:420: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","W0326 07:49:58.009726 140646457186176 module_wrapper.py:139] From drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/run_pretraining.py:420: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","INFO:tensorflow:*** Input Files ***\n","I0326 07:49:58.009836 140646457186176 run_pretraining.py:420] *** Input Files ***\n","INFO:tensorflow:  drive/My Drive/Colab Notebooks/BERT/rsc/preprocessed_training_data/wiki_20190620_512_tf.record\n","I0326 07:49:58.009905 140646457186176 run_pretraining.py:422]   drive/My Drive/Colab Notebooks/BERT/rsc/preprocessed_training_data/wiki_20190620_512_tf.record\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","W0326 07:49:58.009997 140646457186176 lazy_loader.py:50] \n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","I0326 07:49:58.483469 140646457186176 utils.py:141] NumExpr defaulting to 2 threads.\n","WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fea6ae6f6a8>) includes params argument, but params are not passed to Estimator.\n","W0326 07:49:58.905344 140646457186176 estimator.py:1994] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fea6ae6f6a8>) includes params argument, but params are not passed to Estimator.\n","INFO:tensorflow:Using config: {'_model_dir': 'drive/My Drive/Colab Notebooks/BERT/rsc/my_pretrained_model_big', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fea6ae8c9b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n","I0326 07:49:58.906408 140646457186176 estimator.py:212] Using config: {'_model_dir': 'drive/My Drive/Colab Notebooks/BERT/rsc/my_pretrained_model_big', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fea6ae8c9b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n","INFO:tensorflow:_TPUContext: eval_on_tpu True\n","I0326 07:49:58.907049 140646457186176 tpu_context.py:220] _TPUContext: eval_on_tpu True\n","WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n","W0326 07:49:58.907491 140646457186176 tpu_context.py:222] eval_on_tpu ignored because use_tpu is False.\n","INFO:tensorflow:***** Running training *****\n","I0326 07:49:58.907613 140646457186176 run_pretraining.py:459] ***** Running training *****\n","INFO:tensorflow:  Batch size = 4\n","I0326 07:49:58.907723 140646457186176 run_pretraining.py:460]   Batch size = 4\n","WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","W0326 07:49:59.032095 140646457186176 deprecation.py:506] From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","W0326 07:49:59.032517 140646457186176 deprecation.py:323] From /tensorflow-1.15.0/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","WARNING:tensorflow:From drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/run_pretraining.py:337: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n","\n","W0326 07:49:59.042069 140646457186176 module_wrapper.py:139] From drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/run_pretraining.py:337: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n","\n","WARNING:tensorflow:From drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/run_pretraining.py:368: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.parallel_interleave(...)`.\n","W0326 07:49:59.046944 140646457186176 deprecation.py:323] From drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/run_pretraining.py:368: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.parallel_interleave(...)`.\n","WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","W0326 07:49:59.047122 140646457186176 deprecation.py:323] From /tensorflow-1.15.0/python3.6/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","WARNING:tensorflow:From drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/run_pretraining.py:385: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.map_and_batch(...)`.\n","W0326 07:49:59.067275 140646457186176 deprecation.py:323] From drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/run_pretraining.py:385: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.map_and_batch(...)`.\n","WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n","W0326 07:49:59.067462 140646457186176 deprecation.py:323] From /tensorflow-1.15.0/python3.6/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n","WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n","\n","W0326 07:49:59.126997 140646457186176 module_wrapper.py:139] From /tensorflow-1.15.0/python3.6/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n","\n","WARNING:tensorflow:From drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/run_pretraining.py:400: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0326 07:49:59.227700 140646457186176 deprecation.py:323] From drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/run_pretraining.py:400: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","INFO:tensorflow:Calling model_fn.\n","I0326 07:49:59.245968 140646457186176 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Running train on CPU\n","I0326 07:49:59.246195 140646457186176 tpu_estimator.py:3124] Running train on CPU\n","INFO:tensorflow:*** Features ***\n","I0326 07:49:59.246537 140646457186176 run_pretraining.py:117] *** Features ***\n","INFO:tensorflow:  name = input_ids, shape = (4, 512)\n","I0326 07:49:59.246696 140646457186176 run_pretraining.py:119]   name = input_ids, shape = (4, 512)\n","INFO:tensorflow:  name = input_mask, shape = (4, 512)\n","I0326 07:49:59.246818 140646457186176 run_pretraining.py:119]   name = input_mask, shape = (4, 512)\n","INFO:tensorflow:  name = masked_lm_ids, shape = (4, 20)\n","I0326 07:49:59.246939 140646457186176 run_pretraining.py:119]   name = masked_lm_ids, shape = (4, 20)\n","INFO:tensorflow:  name = masked_lm_positions, shape = (4, 20)\n","I0326 07:49:59.247049 140646457186176 run_pretraining.py:119]   name = masked_lm_positions, shape = (4, 20)\n","INFO:tensorflow:  name = masked_lm_weights, shape = (4, 20)\n","I0326 07:49:59.247174 140646457186176 run_pretraining.py:119]   name = masked_lm_weights, shape = (4, 20)\n","INFO:tensorflow:  name = next_sentence_labels, shape = (4, 1)\n","I0326 07:49:59.247269 140646457186176 run_pretraining.py:119]   name = next_sentence_labels, shape = (4, 1)\n","INFO:tensorflow:  name = segment_ids, shape = (4, 512)\n","I0326 07:49:59.247385 140646457186176 run_pretraining.py:119]   name = segment_ids, shape = (4, 512)\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","W0326 07:49:59.247616 140646457186176 module_wrapper.py:139] From /content/drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n","W0326 07:49:59.249053 140646457186176 module_wrapper.py:139] From /content/drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n","\n","W0326 07:49:59.268257 140646457186176 module_wrapper.py:139] From /content/drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","W0326 07:49:59.294966 140646457186176 deprecation.py:506] From /content/drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.Dense instead.\n","W0326 07:49:59.308085 140646457186176 deprecation.py:323] From /content/drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.Dense instead.\n","WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0326 07:49:59.309270 140646457186176 deprecation.py:323] From /tensorflow-1.15.0/python3.6/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/run_pretraining.py:150: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n","W0326 07:50:01.062145 140646457186176 module_wrapper.py:139] From drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/run_pretraining.py:150: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n","INFO:tensorflow:**** Trainable Variables ****\n","I0326 07:50:01.062403 140646457186176 run_pretraining.py:167] **** Trainable Variables ****\n","INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (49541, 768)\n","I0326 07:50:01.062495 140646457186176 run_pretraining.py:173]   name = bert/embeddings/word_embeddings:0, shape = (49541, 768)\n","INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)\n","I0326 07:50:01.062614 140646457186176 run_pretraining.py:173]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)\n","INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768)\n","I0326 07:50:01.062697 140646457186176 run_pretraining.py:173]   name = bert/embeddings/position_embeddings:0, shape = (512, 768)\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,)\n","I0326 07:50:01.062773 140646457186176 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)\n","I0326 07:50:01.062844 140646457186176 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)\n","I0326 07:50:01.062925 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)\n","I0326 07:50:01.062999 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)\n","I0326 07:50:01.063068 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)\n","I0326 07:50:01.063139 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)\n","I0326 07:50:01.063209 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)\n","I0326 07:50:01.063282 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)\n","I0326 07:50:01.063374 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)\n","I0326 07:50:01.063451 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)\n","I0326 07:50:01.063519 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I0326 07:50:01.063605 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)\n","I0326 07:50:01.063677 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)\n","I0326 07:50:01.063806 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)\n","I0326 07:50:01.063888 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)\n","I0326 07:50:01.063966 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)\n","I0326 07:50:01.064039 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)\n","I0326 07:50:01.064115 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)\n","I0326 07:50:01.064186 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)\n","I0326 07:50:01.064259 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)\n","I0326 07:50:01.064345 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)\n","I0326 07:50:01.064424 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)\n","I0326 07:50:01.064499 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)\n","I0326 07:50:01.064574 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)\n","I0326 07:50:01.064646 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)\n","I0326 07:50:01.064720 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)\n","I0326 07:50:01.064789 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I0326 07:50:01.064856 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)\n","I0326 07:50:01.064957 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)\n","I0326 07:50:01.065032 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)\n","I0326 07:50:01.065124 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)\n","I0326 07:50:01.065218 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)\n","I0326 07:50:01.065290 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)\n","I0326 07:50:01.065377 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)\n","I0326 07:50:01.065449 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)\n","I0326 07:50:01.065524 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)\n","I0326 07:50:01.065596 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)\n","I0326 07:50:01.065676 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)\n","I0326 07:50:01.065750 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)\n","I0326 07:50:01.065825 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)\n","I0326 07:50:01.065909 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)\n","I0326 07:50:01.065987 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)\n","I0326 07:50:01.066057 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I0326 07:50:01.066126 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)\n","I0326 07:50:01.066198 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)\n","I0326 07:50:01.066271 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)\n","I0326 07:50:01.066365 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)\n","I0326 07:50:01.066435 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)\n","I0326 07:50:01.066502 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)\n","I0326 07:50:01.066566 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)\n","I0326 07:50:01.066632 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)\n","I0326 07:50:01.066702 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)\n","I0326 07:50:01.066767 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)\n","I0326 07:50:01.066836 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)\n","I0326 07:50:01.066932 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)\n","I0326 07:50:01.067017 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)\n","I0326 07:50:01.067085 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)\n","I0326 07:50:01.067154 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)\n","I0326 07:50:01.067241 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I0326 07:50:01.067309 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)\n","I0326 07:50:01.067399 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)\n","I0326 07:50:01.067475 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)\n","I0326 07:50:01.067547 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)\n","I0326 07:50:01.067621 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)\n","I0326 07:50:01.067698 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)\n","I0326 07:50:01.067770 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)\n","I0326 07:50:01.067842 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)\n","I0326 07:50:01.067931 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)\n","I0326 07:50:01.068017 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)\n","I0326 07:50:01.068088 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)\n","I0326 07:50:01.068193 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)\n","I0326 07:50:01.068287 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)\n","I0326 07:50:01.068410 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)\n","I0326 07:50:01.068514 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)\n","I0326 07:50:01.068583 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I0326 07:50:01.124686 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)\n","I0326 07:50:01.124907 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)\n","I0326 07:50:01.125091 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)\n","I0326 07:50:01.125244 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)\n","I0326 07:50:01.125471 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)\n","I0326 07:50:01.125638 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)\n","I0326 07:50:01.125798 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)\n","I0326 07:50:01.125959 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)\n","I0326 07:50:01.126127 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)\n","I0326 07:50:01.126285 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)\n","I0326 07:50:01.126487 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)\n","I0326 07:50:01.126652 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)\n","I0326 07:50:01.126815 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)\n","I0326 07:50:01.126984 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)\n","I0326 07:50:01.127152 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)\n","I0326 07:50:01.127351 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I0326 07:50:01.127556 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)\n","I0326 07:50:01.127720 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)\n","I0326 07:50:01.127898 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)\n","I0326 07:50:01.128066 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)\n","I0326 07:50:01.128271 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)\n","I0326 07:50:01.128465 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)\n","I0326 07:50:01.128634 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)\n","I0326 07:50:01.128807 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)\n","I0326 07:50:01.129005 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)\n","I0326 07:50:01.129176 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)\n","I0326 07:50:01.129384 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)\n","I0326 07:50:01.129564 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)\n","I0326 07:50:01.129750 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)\n","I0326 07:50:01.129933 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)\n","I0326 07:50:01.130110 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)\n","I0326 07:50:01.130272 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I0326 07:50:01.130490 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)\n","I0326 07:50:01.130660 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)\n","I0326 07:50:01.130839 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)\n","I0326 07:50:01.131034 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)\n","I0326 07:50:01.131224 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)\n","I0326 07:50:01.131419 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)\n","I0326 07:50:01.131593 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)\n","I0326 07:50:01.131762 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)\n","I0326 07:50:01.131939 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)\n","I0326 07:50:01.132108 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)\n","I0326 07:50:01.132295 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)\n","I0326 07:50:01.132491 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)\n","I0326 07:50:01.132668 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)\n","I0326 07:50:01.132829 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)\n","I0326 07:50:01.133005 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)\n","I0326 07:50:01.133162 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I0326 07:50:01.133352 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)\n","I0326 07:50:01.133544 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)\n","I0326 07:50:01.133726 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)\n","I0326 07:50:01.133924 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)\n","I0326 07:50:01.134144 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)\n","I0326 07:50:01.134317 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)\n","I0326 07:50:01.134516 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)\n","I0326 07:50:01.134684 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)\n","I0326 07:50:01.134859 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)\n","I0326 07:50:01.135023 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)\n","I0326 07:50:01.135207 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)\n","I0326 07:50:01.135459 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)\n","I0326 07:50:01.135637 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)\n","I0326 07:50:01.135797 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)\n","I0326 07:50:01.135972 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)\n","I0326 07:50:01.136129 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I0326 07:50:01.136282 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)\n","I0326 07:50:01.136466 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)\n","I0326 07:50:01.136630 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)\n","I0326 07:50:01.136796 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)\n","I0326 07:50:01.136950 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)\n","I0326 07:50:01.137093 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)\n","I0326 07:50:01.137237 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)\n","I0326 07:50:01.137405 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)\n","I0326 07:50:01.137563 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)\n","I0326 07:50:01.137711 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)\n","I0326 07:50:01.137866 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)\n","I0326 07:50:01.138022 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)\n","I0326 07:50:01.138178 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)\n","I0326 07:50:01.138338 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)\n","I0326 07:50:01.138508 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)\n","I0326 07:50:01.138656 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I0326 07:50:01.138801 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)\n","I0326 07:50:01.138968 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)\n","I0326 07:50:01.139133 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)\n","I0326 07:50:01.139293 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)\n","I0326 07:50:01.139518 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)\n","I0326 07:50:01.139674 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)\n","I0326 07:50:01.139826 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)\n","I0326 07:50:01.139982 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)\n","I0326 07:50:01.140146 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)\n","I0326 07:50:01.140300 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)\n","I0326 07:50:01.140514 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)\n","I0326 07:50:01.140671 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)\n","I0326 07:50:01.140833 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)\n","I0326 07:50:01.141026 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)\n","I0326 07:50:01.141200 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)\n","I0326 07:50:01.141393 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I0326 07:50:01.141563 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)\n","I0326 07:50:01.141726 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)\n","I0326 07:50:01.141898 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)\n","I0326 07:50:01.142068 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)\n","I0326 07:50:01.142246 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)\n","I0326 07:50:01.142426 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)\n","I0326 07:50:01.142583 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)\n","I0326 07:50:01.142738 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)\n","I0326 07:50:01.142901 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)\n","I0326 07:50:01.143057 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)\n","I0326 07:50:01.143220 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)\n","I0326 07:50:01.143408 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)\n","I0326 07:50:01.143573 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)\n","I0326 07:50:01.143731 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)\n","I0326 07:50:01.143893 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)\n","I0326 07:50:01.144045 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)\n","I0326 07:50:01.144201 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)\n","I0326 07:50:01.144379 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)\n","INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)\n","I0326 07:50:01.144563 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)\n","INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)\n","I0326 07:50:01.144725 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)\n","INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)\n","I0326 07:50:01.144898 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)\n","I0326 07:50:01.145061 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)\n","I0326 07:50:01.145218 140646457186176 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768)\n","I0326 07:50:01.145398 140646457186176 run_pretraining.py:173]   name = bert/pooler/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,)\n","I0326 07:50:01.145567 140646457186176 run_pretraining.py:173]   name = bert/pooler/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = cls/predictions/transform/dense/kernel:0, shape = (768, 768)\n","I0326 07:50:01.145733 140646457186176 run_pretraining.py:173]   name = cls/predictions/transform/dense/kernel:0, shape = (768, 768)\n","INFO:tensorflow:  name = cls/predictions/transform/dense/bias:0, shape = (768,)\n","I0326 07:50:01.145900 140646457186176 run_pretraining.py:173]   name = cls/predictions/transform/dense/bias:0, shape = (768,)\n","INFO:tensorflow:  name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,)\n","I0326 07:50:01.146057 140646457186176 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,)\n","INFO:tensorflow:  name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,)\n","I0326 07:50:01.146208 140646457186176 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,)\n","INFO:tensorflow:  name = cls/predictions/output_bias:0, shape = (49541,)\n","I0326 07:50:01.146384 140646457186176 run_pretraining.py:173]   name = cls/predictions/output_bias:0, shape = (49541,)\n","INFO:tensorflow:  name = cls/seq_relationship/output_weights:0, shape = (2, 768)\n","I0326 07:50:01.146544 140646457186176 run_pretraining.py:173]   name = cls/seq_relationship/output_weights:0, shape = (2, 768)\n","INFO:tensorflow:  name = cls/seq_relationship/output_bias:0, shape = (2,)\n","I0326 07:50:01.146703 140646457186176 run_pretraining.py:173]   name = cls/seq_relationship/output_bias:0, shape = (2,)\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n","W0326 07:50:01.146914 140646457186176 module_wrapper.py:139] From /content/drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n","\n","W0326 07:50:01.147980 140646457186176 module_wrapper.py:139] From /content/drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n","\n","WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0326 07:50:01.310390 140646457186176 deprecation.py:323] From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","INFO:tensorflow:Done calling model_fn.\n","I0326 07:50:07.154091 140646457186176 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","I0326 07:50:07.155655 140646457186176 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","I0326 07:50:09.699087 140646457186176 monitored_session.py:240] Graph was finalized.\n","2020-03-26 07:50:09.704649: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n","2020-03-26 07:50:09.704877: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3206d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-03-26 07:50:09.704912: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-03-26 07:50:09.721754: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-03-26 07:50:09.851411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-26 07:50:09.851973: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3207800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-03-26 07:50:09.852005: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P4, Compute Capability 6.1\n","2020-03-26 07:50:09.852202: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-26 07:50:09.852652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n","pciBusID: 0000:00:04.0\n","2020-03-26 07:50:09.852995: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-03-26 07:50:09.854716: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-03-26 07:50:09.856384: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-03-26 07:50:09.856739: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-03-26 07:50:09.858385: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-03-26 07:50:09.859132: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-03-26 07:50:09.862564: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-03-26 07:50:09.862709: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-26 07:50:09.863149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-26 07:50:09.863536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-03-26 07:50:09.863605: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-03-26 07:50:09.864712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-03-26 07:50:09.864739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-03-26 07:50:09.864750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-03-26 07:50:09.864864: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-26 07:50:09.865277: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-26 07:50:09.865655: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-03-26 07:50:09.865699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n","INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks/BERT/rsc/my_pretrained_model_big/model.ckpt-0\n","I0326 07:50:09.869665 140646457186176 saver.py:1284] Restoring parameters from drive/My Drive/Colab Notebooks/BERT/rsc/my_pretrained_model_big/model.ckpt-0\n","WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file utilities to get mtimes.\n","W0326 07:50:14.815811 140646457186176 deprecation.py:323] From /tensorflow-1.15.0/python3.6/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file utilities to get mtimes.\n","INFO:tensorflow:Running local_init_op.\n","I0326 07:50:15.485746 140646457186176 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0326 07:50:15.662543 140646457186176 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Saving checkpoints for 0 into drive/My Drive/Colab Notebooks/BERT/rsc/my_pretrained_model_big/model.ckpt.\n","I0326 07:50:20.938248 140646457186176 basic_session_run_hooks.py:606] Saving checkpoints for 0 into drive/My Drive/Colab Notebooks/BERT/rsc/my_pretrained_model_big/model.ckpt.\n","2020-03-26 07:50:38.663685: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-03-26 07:50:49.413256: W tensorflow/core/common_runtime/bfc_allocator.cc:419] Allocator (GPU_0_bfc) ran out of memory trying to allocate 48.00MiB (rounded to 50331648).  Current allocation summary follows.\n","2020-03-26 07:50:49.413383: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (256): \tTotal Chunks: 69, Chunks in use: 66. 17.2KiB allocated for chunks. 16.5KiB in use in bin. 393B client-requested in use in bin.\n","2020-03-26 07:50:49.413401: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (512): \tTotal Chunks: 3, Chunks in use: 3. 1.5KiB allocated for chunks. 1.5KiB in use in bin. 960B client-requested in use in bin.\n","2020-03-26 07:50:49.413410: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n","2020-03-26 07:50:49.413418: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (2048): \tTotal Chunks: 569, Chunks in use: 569. 1.67MiB allocated for chunks. 1.67MiB in use in bin. 1.67MiB client-requested in use in bin.\n","2020-03-26 07:50:49.413426: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (4096): \tTotal Chunks: 13, Chunks in use: 13. 77.0KiB allocated for chunks. 77.0KiB in use in bin. 75.0KiB client-requested in use in bin.\n","2020-03-26 07:50:49.413433: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (8192): \tTotal Chunks: 100, Chunks in use: 100. 1.02MiB allocated for chunks. 1.02MiB in use in bin. 1.02MiB client-requested in use in bin.\n","2020-03-26 07:50:49.413441: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (16384): \tTotal Chunks: 1, Chunks in use: 1. 16.0KiB allocated for chunks. 16.0KiB in use in bin. 16.0KiB client-requested in use in bin.\n","2020-03-26 07:50:49.413448: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n","2020-03-26 07:50:49.413455: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n","2020-03-26 07:50:49.413464: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (131072): \tTotal Chunks: 5, Chunks in use: 5. 968.8KiB allocated for chunks. 968.8KiB in use in bin. 967.6KiB client-requested in use in bin.\n","2020-03-26 07:50:49.413471: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n","2020-03-26 07:50:49.413478: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n","2020-03-26 07:50:49.413485: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (1048576): \tTotal Chunks: 5, Chunks in use: 5. 7.50MiB allocated for chunks. 7.50MiB in use in bin. 7.50MiB client-requested in use in bin.\n","2020-03-26 07:50:49.413494: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (2097152): \tTotal Chunks: 298, Chunks in use: 298. 670.43MiB allocated for chunks. 670.43MiB in use in bin. 669.75MiB client-requested in use in bin.\n","2020-03-26 07:50:49.413503: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (4194304): \tTotal Chunks: 132, Chunks in use: 130. 783.97MiB allocated for chunks. 772.25MiB in use in bin. 766.75MiB client-requested in use in bin.\n","2020-03-26 07:50:49.413511: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (8388608): \tTotal Chunks: 145, Chunks in use: 145. 1.30GiB allocated for chunks. 1.30GiB in use in bin. 1.28GiB client-requested in use in bin.\n","2020-03-26 07:50:49.413518: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (16777216): \tTotal Chunks: 47, Chunks in use: 47. 1.09GiB allocated for chunks. 1.09GiB in use in bin. 1.07GiB client-requested in use in bin.\n","2020-03-26 07:50:49.413526: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (33554432): \tTotal Chunks: 40, Chunks in use: 40. 1.88GiB allocated for chunks. 1.88GiB in use in bin. 1.88GiB client-requested in use in bin.\n","2020-03-26 07:50:49.413534: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (67108864): \tTotal Chunks: 3, Chunks in use: 3. 204.56MiB allocated for chunks. 204.56MiB in use in bin. 144.00MiB client-requested in use in bin.\n","2020-03-26 07:50:49.413543: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (134217728): \tTotal Chunks: 5, Chunks in use: 5. 827.56MiB allocated for chunks. 827.56MiB in use in bin. 725.70MiB client-requested in use in bin.\n","2020-03-26 07:50:49.413551: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (268435456): \tTotal Chunks: 1, Chunks in use: 1. 265.25MiB allocated for chunks. 265.25MiB in use in bin. 145.14MiB client-requested in use in bin.\n","2020-03-26 07:50:49.413559: I tensorflow/core/common_runtime/bfc_allocator.cc:885] Bin for 48.00MiB was 32.00MiB, Chunk State: \n","2020-03-26 07:50:49.413565: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 3165640960\n","2020-03-26 07:50:49.413574: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7bc000000 next 1246 of size 50331648\n","2020-03-26 07:50:49.413580: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7bf000000 next 1247 of size 8192\n","2020-03-26 07:50:49.413587: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7bf002000 next 1248 of size 6291456\n","2020-03-26 07:50:49.413592: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7bf602000 next 1249 of size 8192\n","2020-03-26 07:50:49.413598: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7bf604000 next 1250 of size 6291456\n","2020-03-26 07:50:49.413604: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7bfc04000 next 1251 of size 6291456\n","2020-03-26 07:50:49.413610: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c0204000 next 1252 of size 6291456\n","2020-03-26 07:50:49.413615: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c0804000 next 1259 of size 8192\n","2020-03-26 07:50:49.413621: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c0806000 next 1260 of size 8192\n","2020-03-26 07:50:49.413627: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c0808000 next 1267 of size 8192\n","2020-03-26 07:50:49.413633: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c080a000 next 1269 of size 8192\n","2020-03-26 07:50:49.413639: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c080c000 next 1289 of size 8192\n","2020-03-26 07:50:49.413645: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c080e000 next 1287 of size 8192\n","2020-03-26 07:50:49.413650: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c0810000 next 1296 of size 8192\n","2020-03-26 07:50:49.413656: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c0812000 next 1298 of size 8192\n","2020-03-26 07:50:49.413663: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c0814000 next 1308 of size 8192\n","2020-03-26 07:50:49.413672: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c0816000 next 1307 of size 8192\n","2020-03-26 07:50:49.413681: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c0818000 next 1315 of size 8192\n","2020-03-26 07:50:49.413689: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c081a000 next 1317 of size 8192\n","2020-03-26 07:50:49.413698: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c081c000 next 1327 of size 8192\n","2020-03-26 07:50:49.413704: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c081e000 next 1326 of size 8192\n","2020-03-26 07:50:49.413710: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c0820000 next 1334 of size 8192\n","2020-03-26 07:50:49.413716: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c0822000 next 1336 of size 8192\n","2020-03-26 07:50:49.413722: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c0824000 next 1346 of size 8192\n","2020-03-26 07:50:49.413727: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c0826000 next 1345 of size 8192\n","2020-03-26 07:50:49.413733: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c0828000 next 1353 of size 8192\n","2020-03-26 07:50:49.413739: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c082a000 next 1355 of size 8192\n","2020-03-26 07:50:49.413745: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c082c000 next 1365 of size 8192\n","2020-03-26 07:50:49.413750: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c082e000 next 1364 of size 8192\n","2020-03-26 07:50:49.413756: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c0830000 next 1372 of size 8192\n","2020-03-26 07:50:49.413762: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c0832000 next 1374 of size 8192\n","2020-03-26 07:50:49.413768: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c0834000 next 1384 of size 8192\n","2020-03-26 07:50:49.413773: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c0836000 next 1383 of size 8192\n","2020-03-26 07:50:49.413779: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c0838000 next 1391 of size 8192\n","2020-03-26 07:50:49.413785: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c083a000 next 1393 of size 8192\n","2020-03-26 07:50:49.413790: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c083c000 next 1403 of size 8192\n","2020-03-26 07:50:49.413798: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c083e000 next 1402 of size 8192\n","2020-03-26 07:50:49.413807: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c0840000 next 1410 of size 8192\n","2020-03-26 07:50:49.413815: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c0842000 next 1412 of size 8192\n","2020-03-26 07:50:49.413824: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c0844000 next 1422 of size 8192\n","2020-03-26 07:50:49.413831: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c0846000 next 1421 of size 8192\n","2020-03-26 07:50:49.413852: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c0848000 next 1429 of size 8192\n","2020-03-26 07:50:49.413862: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c084a000 next 1431 of size 8192\n","2020-03-26 07:50:49.413870: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0x7fe7c084c000 next 1253 of size 5996544\n","2020-03-26 07:50:49.413878: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c0e04000 next 1254 of size 6291456\n","2020-03-26 07:50:49.413887: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c1404000 next 1255 of size 50331648\n","2020-03-26 07:50:49.413895: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c4404000 next 1257 of size 50331648\n","2020-03-26 07:50:49.413902: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c7404000 next 1256 of size 6291456\n","2020-03-26 07:50:49.413911: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c7a04000 next 1258 of size 6291456\n","2020-03-26 07:50:49.413919: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c8004000 next 1261 of size 6291456\n","2020-03-26 07:50:49.413931: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c8604000 next 1262 of size 25165824\n","2020-03-26 07:50:49.413945: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7c9e04000 next 1263 of size 25165824\n","2020-03-26 07:50:49.413955: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7cb604000 next 1264 of size 25165824\n","2020-03-26 07:50:49.413963: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7cce04000 next 1265 of size 25165824\n","2020-03-26 07:50:49.413979: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7ce604000 next 1266 of size 25165824\n","2020-03-26 07:50:49.413997: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7cfe04000 next 1268 of size 6291456\n","2020-03-26 07:50:49.414007: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7d0404000 next 1270 of size 6291456\n","2020-03-26 07:50:49.414017: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7d0a04000 next 1271 of size 6291456\n","2020-03-26 07:50:49.414027: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7d1004000 next 1272 of size 6291456\n","2020-03-26 07:50:49.414040: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7d1604000 next 1273 of size 6291456\n","2020-03-26 07:50:49.414051: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7d1c04000 next 1274 of size 6291456\n","2020-03-26 07:50:49.414070: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7d2204000 next 1275 of size 50331648\n","2020-03-26 07:50:49.414080: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7d5204000 next 1277 of size 50331648\n","2020-03-26 07:50:49.414097: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7d8204000 next 1278 of size 50331648\n","2020-03-26 07:50:49.414107: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7db204000 next 1276 of size 50331648\n","2020-03-26 07:50:49.414124: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7de204000 next 1279 of size 50331648\n","2020-03-26 07:50:49.414134: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7e1204000 next 1280 of size 50331648\n","2020-03-26 07:50:49.414150: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7e4204000 next 1281 of size 50331648\n","2020-03-26 07:50:49.414160: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7e7204000 next 1282 of size 50331648\n","2020-03-26 07:50:49.414177: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7ea204000 next 1283 of size 50331648\n","2020-03-26 07:50:49.414187: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7ed204000 next 1284 of size 50331648\n","2020-03-26 07:50:49.414202: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7f0204000 next 1285 of size 50331648\n","2020-03-26 07:50:49.414212: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7f3204000 next 1286 of size 50331648\n","2020-03-26 07:50:49.414381: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7f6204000 next 1288 of size 6291456\n","2020-03-26 07:50:49.414396: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7f6804000 next 1290 of size 6291456\n","2020-03-26 07:50:49.414405: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7f6e04000 next 1291 of size 25165824\n","2020-03-26 07:50:49.414415: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7f8604000 next 1292 of size 25165824\n","2020-03-26 07:50:49.414425: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7f9e04000 next 1293 of size 25165824\n","2020-03-26 07:50:49.414436: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7fb604000 next 1294 of size 25165824\n","2020-03-26 07:50:49.414446: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7fce04000 next 1295 of size 25165824\n","2020-03-26 07:50:49.414456: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7fe604000 next 1297 of size 6291456\n","2020-03-26 07:50:49.414466: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7fec04000 next 1299 of size 6291456\n","2020-03-26 07:50:49.414477: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7ff204000 next 1300 of size 6291456\n","2020-03-26 07:50:49.414487: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7ff804000 next 1301 of size 6291456\n","2020-03-26 07:50:49.414505: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe7ffe04000 next 1302 of size 6291456\n","2020-03-26 07:50:49.414515: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe800404000 next 1303 of size 6291456\n","2020-03-26 07:50:49.414530: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe800a04000 next 1304 of size 50331648\n","2020-03-26 07:50:49.414540: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe803a04000 next 1306 of size 50331648\n","2020-03-26 07:50:49.432686: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe806a04000 next 1305 of size 6291456\n","2020-03-26 07:50:49.432735: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe807004000 next 1309 of size 6291456\n","2020-03-26 07:50:49.432746: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe807604000 next 1310 of size 25165824\n","2020-03-26 07:50:49.432754: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe808e04000 next 1311 of size 25165824\n","2020-03-26 07:50:49.432762: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe80a604000 next 1312 of size 25165824\n","2020-03-26 07:50:49.432770: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe80be04000 next 1313 of size 25165824\n","2020-03-26 07:50:49.432779: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe80d604000 next 1314 of size 25165824\n","2020-03-26 07:50:49.432787: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe80ee04000 next 1316 of size 6291456\n","2020-03-26 07:50:49.432796: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe80f404000 next 1318 of size 6291456\n","2020-03-26 07:50:49.432804: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe80fa04000 next 1319 of size 6291456\n","2020-03-26 07:50:49.432813: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe810004000 next 1320 of size 6291456\n","2020-03-26 07:50:49.432822: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe810604000 next 1321 of size 6291456\n","2020-03-26 07:50:49.432830: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe810c04000 next 1322 of size 6291456\n","2020-03-26 07:50:49.432838: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe811204000 next 1323 of size 50331648\n","2020-03-26 07:50:49.432847: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe814204000 next 1325 of size 50331648\n","2020-03-26 07:50:49.432855: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe817204000 next 1324 of size 6291456\n","2020-03-26 07:50:49.432864: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe817804000 next 1328 of size 6291456\n","2020-03-26 07:50:49.432873: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe817e04000 next 1329 of size 25165824\n","2020-03-26 07:50:49.432882: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe819604000 next 1330 of size 25165824\n","2020-03-26 07:50:49.432890: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe81ae04000 next 1331 of size 25165824\n","2020-03-26 07:50:49.432899: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe81c604000 next 1332 of size 25165824\n","2020-03-26 07:50:49.432907: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe81de04000 next 1333 of size 25165824\n","2020-03-26 07:50:49.432915: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe81f604000 next 1335 of size 6291456\n","2020-03-26 07:50:49.432924: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe81fc04000 next 1337 of size 6291456\n","2020-03-26 07:50:49.432933: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe820204000 next 1338 of size 6291456\n","2020-03-26 07:50:49.432942: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe820804000 next 1339 of size 6291456\n","2020-03-26 07:50:49.432951: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe820e04000 next 1340 of size 6291456\n","2020-03-26 07:50:49.433147: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe821404000 next 1341 of size 6291456\n","2020-03-26 07:50:49.433172: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe821a04000 next 1342 of size 50331648\n","2020-03-26 07:50:49.433182: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe824a04000 next 1344 of size 50331648\n","2020-03-26 07:50:49.433191: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe827a04000 next 1343 of size 6291456\n","2020-03-26 07:50:49.433200: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe828004000 next 1347 of size 6291456\n","2020-03-26 07:50:49.433209: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe828604000 next 1348 of size 25165824\n","2020-03-26 07:50:49.433218: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe829e04000 next 1349 of size 25165824\n","2020-03-26 07:50:49.433227: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe82b604000 next 1350 of size 25165824\n","2020-03-26 07:50:49.433236: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe82ce04000 next 1351 of size 25165824\n","2020-03-26 07:50:49.433244: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe82e604000 next 1352 of size 25165824\n","2020-03-26 07:50:49.433252: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe82fe04000 next 1354 of size 6291456\n","2020-03-26 07:50:49.433261: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe830404000 next 1356 of size 6291456\n","2020-03-26 07:50:49.433269: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe830a04000 next 1357 of size 6291456\n","2020-03-26 07:50:49.433277: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe831004000 next 1358 of size 6291456\n","2020-03-26 07:50:49.433286: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe831604000 next 1359 of size 6291456\n","2020-03-26 07:50:49.433294: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe831c04000 next 1360 of size 6291456\n","2020-03-26 07:50:49.433303: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe832204000 next 1361 of size 50331648\n","2020-03-26 07:50:49.433312: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe835204000 next 1363 of size 50331648\n","2020-03-26 07:50:49.433338: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe838204000 next 1362 of size 6291456\n","2020-03-26 07:50:49.433348: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe838804000 next 1366 of size 6291456\n","2020-03-26 07:50:49.433365: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe838e04000 next 1367 of size 25165824\n","2020-03-26 07:50:49.433374: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe83a604000 next 1368 of size 25165824\n","2020-03-26 07:50:49.433383: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe83be04000 next 1369 of size 25165824\n","2020-03-26 07:50:49.433393: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe83d604000 next 1370 of size 25165824\n","2020-03-26 07:50:49.433401: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe83ee04000 next 1371 of size 25165824\n","2020-03-26 07:50:49.433410: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe840604000 next 1373 of size 6291456\n","2020-03-26 07:50:49.433419: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe840c04000 next 1375 of size 6291456\n","2020-03-26 07:50:49.433428: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe841204000 next 1376 of size 6291456\n","2020-03-26 07:50:49.433436: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe841804000 next 1377 of size 6291456\n","2020-03-26 07:50:49.433445: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe841e04000 next 1378 of size 6291456\n","2020-03-26 07:50:49.433453: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe842404000 next 1379 of size 6291456\n","2020-03-26 07:50:49.433461: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe842a04000 next 1380 of size 50331648\n","2020-03-26 07:50:49.433470: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe845a04000 next 1382 of size 50331648\n","2020-03-26 07:50:49.433517: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe848a04000 next 1381 of size 6291456\n","2020-03-26 07:50:49.433529: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe849004000 next 1385 of size 6291456\n","2020-03-26 07:50:49.433538: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe849604000 next 1386 of size 25165824\n","2020-03-26 07:50:49.433546: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe84ae04000 next 1387 of size 25165824\n","2020-03-26 07:50:49.433554: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe84c604000 next 1388 of size 25165824\n","2020-03-26 07:50:49.433563: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe84de04000 next 1389 of size 25165824\n","2020-03-26 07:50:49.433572: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe84f604000 next 1390 of size 25165824\n","2020-03-26 07:50:49.433580: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe850e04000 next 1392 of size 6291456\n","2020-03-26 07:50:49.433589: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe851404000 next 1394 of size 6291456\n","2020-03-26 07:50:49.433598: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe851a04000 next 1395 of size 6291456\n","2020-03-26 07:50:49.433606: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe852004000 next 1396 of size 6291456\n","2020-03-26 07:50:49.433615: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe852604000 next 1397 of size 6291456\n","2020-03-26 07:50:49.433624: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe852c04000 next 1398 of size 6291456\n","2020-03-26 07:50:49.433633: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe853204000 next 1399 of size 50331648\n","2020-03-26 07:50:49.433642: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe856204000 next 1401 of size 50331648\n","2020-03-26 07:50:49.433650: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe859204000 next 1400 of size 6291456\n","2020-03-26 07:50:49.433658: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe859804000 next 1404 of size 6291456\n","2020-03-26 07:50:49.433667: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe859e04000 next 1405 of size 25165824\n","2020-03-26 07:50:49.433676: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe85b604000 next 1406 of size 25165824\n","2020-03-26 07:50:49.433685: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe85ce04000 next 1407 of size 25165824\n","2020-03-26 07:50:49.433694: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe85e604000 next 1408 of size 25165824\n","2020-03-26 07:50:49.433703: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe85fe04000 next 1409 of size 25165824\n","2020-03-26 07:50:49.433712: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe861604000 next 1411 of size 6291456\n","2020-03-26 07:50:49.433721: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe861c04000 next 1413 of size 6291456\n","2020-03-26 07:50:49.433730: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe862204000 next 1414 of size 6291456\n","2020-03-26 07:50:49.433738: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe862804000 next 1415 of size 6291456\n","2020-03-26 07:50:49.433748: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe862e04000 next 1416 of size 6291456\n","2020-03-26 07:50:49.433757: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe863404000 next 1417 of size 6291456\n","2020-03-26 07:50:49.433766: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe863a04000 next 1418 of size 50331648\n","2020-03-26 07:50:49.433775: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe866a04000 next 1420 of size 50331648\n","2020-03-26 07:50:49.433982: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe869a04000 next 1419 of size 6291456\n","2020-03-26 07:50:49.434002: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe86a004000 next 1423 of size 6291456\n","2020-03-26 07:50:49.434008: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe86a604000 next 1424 of size 25165824\n","2020-03-26 07:50:49.434014: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe86be04000 next 1425 of size 25165824\n","2020-03-26 07:50:49.434020: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe86d604000 next 1426 of size 25165824\n","2020-03-26 07:50:49.434026: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe86ee04000 next 1427 of size 25165824\n","2020-03-26 07:50:49.434032: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe870604000 next 1428 of size 25165824\n","2020-03-26 07:50:49.434037: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe871e04000 next 1430 of size 6291456\n","2020-03-26 07:50:49.434043: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe872404000 next 1432 of size 6291456\n","2020-03-26 07:50:49.434049: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe872a04000 next 1433 of size 6291456\n","2020-03-26 07:50:49.434055: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe873004000 next 1434 of size 6291456\n","2020-03-26 07:50:49.434060: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0x7fe873604000 next 1435 of size 6291456\n","2020-03-26 07:50:49.434066: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe873c04000 next 1436 of size 6291456\n","2020-03-26 07:50:49.434073: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe874204000 next 18446744073709551615 of size 76519680\n","2020-03-26 07:50:49.434080: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 2147483648\n","2020-03-26 07:50:49.434086: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe87a000000 next 707 of size 50331648\n","2020-03-26 07:50:49.434093: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe87d000000 next 711 of size 4194304\n","2020-03-26 07:50:49.434099: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe87d400000 next 720 of size 15853312\n","2020-03-26 07:50:49.434104: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe87e31e700 next 718 of size 6291456\n","2020-03-26 07:50:49.434110: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe87e91e700 next 721 of size 15853312\n","2020-03-26 07:50:49.434116: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe87f83ce00 next 704 of size 50331648\n","2020-03-26 07:50:49.434122: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe88283ce00 next 1223 of size 50331648\n","2020-03-26 07:50:49.434128: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe88583ce00 next 1224 of size 50331648\n","2020-03-26 07:50:49.434133: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe88883ce00 next 705 of size 50331648\n","2020-03-26 07:50:49.434139: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe88b83ce00 next 1232 of size 6291456\n","2020-03-26 07:50:49.434145: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe88be3ce00 next 1233 of size 6291456\n","2020-03-26 07:50:49.434151: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe88c43ce00 next 1234 of size 6291456\n","2020-03-26 07:50:49.434156: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe88ca3ce00 next 1235 of size 6291456\n","2020-03-26 07:50:49.434162: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe88d03ce00 next 1236 of size 6291456\n","2020-03-26 07:50:49.434168: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe88d63ce00 next 1237 of size 6291456\n","2020-03-26 07:50:49.434362: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe88dc3ce00 next 1238 of size 6291456\n","2020-03-26 07:50:49.434378: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe88e23ce00 next 1239 of size 6291456\n","2020-03-26 07:50:49.434386: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe88e83ce00 next 1240 of size 6291456\n","2020-03-26 07:50:49.434395: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe88ee3ce00 next 1241 of size 6291456\n","2020-03-26 07:50:49.434403: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe88f43ce00 next 1242 of size 6291456\n","2020-03-26 07:50:49.434411: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe88fa3ce00 next 1243 of size 6291456\n","2020-03-26 07:50:49.434420: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe89003ce00 next 1244 of size 6291456\n","2020-03-26 07:50:49.434429: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe89063ce00 next 728 of size 69206016\n","2020-03-26 07:50:49.434437: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe89483ce00 next 729 of size 152189952\n","2020-03-26 07:50:49.434446: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe89d960a00 next 730 of size 2359296\n","2020-03-26 07:50:49.434454: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe89dba0a00 next 731 of size 2359296\n","2020-03-26 07:50:49.434462: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe89dde0a00 next 733 of size 2359296\n","2020-03-26 07:50:49.434471: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe89e020a00 next 734 of size 2359296\n","2020-03-26 07:50:49.434479: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe89e260a00 next 735 of size 2359296\n","2020-03-26 07:50:49.434487: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe89e4a0a00 next 736 of size 2359296\n","2020-03-26 07:50:49.434495: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe89e6e0a00 next 737 of size 2359296\n","2020-03-26 07:50:49.434504: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe89e920a00 next 738 of size 9437184\n","2020-03-26 07:50:49.434512: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe89f220a00 next 739 of size 9437184\n","2020-03-26 07:50:49.434521: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe89fb20a00 next 740 of size 2359296\n","2020-03-26 07:50:49.434529: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe89fd60a00 next 742 of size 2359296\n","2020-03-26 07:50:49.434537: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe89ffa0a00 next 744 of size 2359296\n","2020-03-26 07:50:49.434545: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a01e0a00 next 745 of size 2359296\n","2020-03-26 07:50:49.434554: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a0420a00 next 746 of size 9437184\n","2020-03-26 07:50:49.434562: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a0d20a00 next 747 of size 2359296\n","2020-03-26 07:50:49.434570: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a0f60a00 next 749 of size 2359296\n","2020-03-26 07:50:49.434578: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a11a0a00 next 751 of size 9437184\n","2020-03-26 07:50:49.434587: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a1aa0a00 next 752 of size 2359296\n","2020-03-26 07:50:49.434595: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a1ce0a00 next 753 of size 9437184\n","2020-03-26 07:50:49.434603: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a25e0a00 next 754 of size 3072\n","2020-03-26 07:50:49.434612: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a25e1600 next 755 of size 2359296\n","2020-03-26 07:50:49.434620: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a2821600 next 756 of size 2359296\n","2020-03-26 07:50:49.434628: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a2a61600 next 757 of size 9437184\n","2020-03-26 07:50:49.434637: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a3361600 next 758 of size 3072\n","2020-03-26 07:50:49.434645: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a3362200 next 759 of size 2359296\n","2020-03-26 07:50:49.434653: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a35a2200 next 760 of size 2359296\n","2020-03-26 07:50:49.434662: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a37e2200 next 761 of size 3072\n","2020-03-26 07:50:49.434670: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a37e2e00 next 762 of size 2359296\n","2020-03-26 07:50:49.434678: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a3a22e00 next 763 of size 2359296\n","2020-03-26 07:50:49.434686: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a3c62e00 next 764 of size 2359296\n","2020-03-26 07:50:49.434695: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a3ea2e00 next 765 of size 2359296\n","2020-03-26 07:50:49.434703: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a40e2e00 next 766 of size 6144\n","2020-03-26 07:50:49.434712: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a40e4600 next 767 of size 3072\n","2020-03-26 07:50:49.434720: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a40e5200 next 768 of size 12288\n","2020-03-26 07:50:49.434729: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a40e8200 next 769 of size 3072\n","2020-03-26 07:50:49.434737: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a40e8e00 next 770 of size 2359296\n","2020-03-26 07:50:49.434745: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a4328e00 next 771 of size 2359296\n","2020-03-26 07:50:49.434753: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a4568e00 next 772 of size 2359296\n","2020-03-26 07:50:49.434762: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a47a8e00 next 773 of size 3072\n","2020-03-26 07:50:49.434770: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a47a9a00 next 774 of size 9437184\n","2020-03-26 07:50:49.434779: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a50a9a00 next 775 of size 2359296\n","2020-03-26 07:50:49.434787: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a52e9a00 next 776 of size 2359296\n","2020-03-26 07:50:49.434795: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a5529a00 next 777 of size 9437184\n","2020-03-26 07:50:49.434803: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a5e29a00 next 778 of size 2359296\n","2020-03-26 07:50:49.434812: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a6069a00 next 779 of size 198400\n","2020-03-26 07:50:49.434820: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a609a100 next 780 of size 3072\n","2020-03-26 07:50:49.434829: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a609ad00 next 781 of size 9437184\n","2020-03-26 07:50:49.434837: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a699ad00 next 782 of size 3072\n","2020-03-26 07:50:49.434845: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a699b900 next 783 of size 2359296\n","2020-03-26 07:50:49.434854: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a6bdb900 next 784 of size 12288\n","2020-03-26 07:50:49.434868: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a6bde900 next 785 of size 2359296\n","2020-03-26 07:50:49.434876: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a6e1e900 next 786 of size 3072\n","2020-03-26 07:50:49.434884: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a6e1f500 next 787 of size 2359296\n","2020-03-26 07:50:49.434893: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a705f500 next 788 of size 2359296\n","2020-03-26 07:50:49.435148: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a729f500 next 789 of size 3072\n","2020-03-26 07:50:49.435164: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a72a0100 next 790 of size 3072\n","2020-03-26 07:50:49.435173: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a72a0d00 next 791 of size 9437184\n","2020-03-26 07:50:49.435181: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a7ba0d00 next 792 of size 9437184\n","2020-03-26 07:50:49.435190: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a84a0d00 next 793 of size 3072\n","2020-03-26 07:50:49.435198: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a84a1900 next 794 of size 3072\n","2020-03-26 07:50:49.435206: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a84a2500 next 795 of size 2359296\n","2020-03-26 07:50:49.435214: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a86e2500 next 796 of size 3072\n","2020-03-26 07:50:49.435222: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a86e3100 next 797 of size 3072\n","2020-03-26 07:50:49.435231: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a86e3d00 next 798 of size 2359296\n","2020-03-26 07:50:49.435239: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a8923d00 next 799 of size 9437184\n","2020-03-26 07:50:49.435247: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a9223d00 next 800 of size 2359296\n","2020-03-26 07:50:49.435255: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a9463d00 next 801 of size 9437184\n","2020-03-26 07:50:49.435263: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a9d63d00 next 802 of size 2359296\n","2020-03-26 07:50:49.435271: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8a9fa3d00 next 803 of size 9437184\n","2020-03-26 07:50:49.435280: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8aa8a3d00 next 804 of size 9437184\n","2020-03-26 07:50:49.435288: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ab1a3d00 next 805 of size 2359296\n","2020-03-26 07:50:49.435296: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ab3e3d00 next 806 of size 2359296\n","2020-03-26 07:50:49.435304: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ab623d00 next 807 of size 2359296\n","2020-03-26 07:50:49.435312: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ab863d00 next 808 of size 9437184\n","2020-03-26 07:50:49.435343: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ac163d00 next 809 of size 3072\n","2020-03-26 07:50:49.435357: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ac164900 next 810 of size 3072\n","2020-03-26 07:50:49.435369: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ac165500 next 811 of size 3072\n","2020-03-26 07:50:49.435381: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ac166100 next 812 of size 2359296\n","2020-03-26 07:50:49.435538: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ac3a6100 next 813 of size 3072\n","2020-03-26 07:50:49.435561: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ac3a6d00 next 814 of size 2359296\n","2020-03-26 07:50:49.435575: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ac5e6d00 next 815 of size 2359296\n","2020-03-26 07:50:49.435589: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ac826d00 next 816 of size 2359296\n","2020-03-26 07:50:49.435845: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8aca66d00 next 817 of size 9437184\n","2020-03-26 07:50:49.435883: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ad366d00 next 818 of size 2359296\n","2020-03-26 07:50:49.435897: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ad5a6d00 next 819 of size 198400\n","2020-03-26 07:50:49.435911: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ad5d7400 next 820 of size 9437184\n","2020-03-26 07:50:49.435925: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8aded7400 next 821 of size 2359296\n","2020-03-26 07:50:49.435938: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ae117400 next 822 of size 2359296\n","2020-03-26 07:50:49.435951: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ae357400 next 823 of size 3072\n","2020-03-26 07:50:49.435965: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ae358000 next 824 of size 2359296\n","2020-03-26 07:50:49.435978: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ae598000 next 825 of size 9437184\n","2020-03-26 07:50:49.435991: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8aee98000 next 826 of size 2359296\n","2020-03-26 07:50:49.436005: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8af0d8000 next 827 of size 3072\n","2020-03-26 07:50:49.436018: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8af0d8c00 next 828 of size 2359296\n","2020-03-26 07:50:49.436031: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8af318c00 next 829 of size 9437184\n","2020-03-26 07:50:49.436045: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8afc18c00 next 830 of size 3072\n","2020-03-26 07:50:49.436059: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8afc19800 next 831 of size 9437184\n","2020-03-26 07:50:49.436072: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b0519800 next 832 of size 9437184\n","2020-03-26 07:50:49.436086: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b0e19800 next 833 of size 2359296\n","2020-03-26 07:50:49.436099: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b1059800 next 834 of size 2359296\n","2020-03-26 07:50:49.436263: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b1299800 next 835 of size 9437184\n","2020-03-26 07:50:49.436285: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b1b99800 next 836 of size 3072\n","2020-03-26 07:50:49.436298: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b1b9a400 next 837 of size 9437184\n","2020-03-26 07:50:49.436309: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b249a400 next 838 of size 9437184\n","2020-03-26 07:50:49.436318: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b2d9a400 next 839 of size 9437184\n","2020-03-26 07:50:49.436525: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b369a400 next 840 of size 3072\n","2020-03-26 07:50:49.436540: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b369b000 next 841 of size 3072\n","2020-03-26 07:50:49.436549: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b369bc00 next 842 of size 3072\n","2020-03-26 07:50:49.436557: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b369c800 next 843 of size 3072\n","2020-03-26 07:50:49.436565: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b369d400 next 844 of size 2359296\n","2020-03-26 07:50:49.436574: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b38dd400 next 845 of size 3072\n","2020-03-26 07:50:49.436582: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b38de000 next 846 of size 2359296\n","2020-03-26 07:50:49.436590: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b3b1e000 next 847 of size 3072\n","2020-03-26 07:50:49.436598: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b3b1ec00 next 848 of size 2359296\n","2020-03-26 07:50:49.436607: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b3d5ec00 next 849 of size 3072\n","2020-03-26 07:50:49.436615: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b3d5f800 next 850 of size 2359296\n","2020-03-26 07:50:49.436623: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b3f9f800 next 851 of size 2359296\n","2020-03-26 07:50:49.436632: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b41df800 next 852 of size 9437184\n","2020-03-26 07:50:49.436640: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b4adf800 next 853 of size 2359296\n","2020-03-26 07:50:49.436648: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b4d1f800 next 854 of size 9437184\n","2020-03-26 07:50:49.436656: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b561f800 next 855 of size 2359296\n","2020-03-26 07:50:49.436665: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b585f800 next 856 of size 2359296\n","2020-03-26 07:50:49.436673: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b5a9f800 next 857 of size 3072\n","2020-03-26 07:50:49.436778: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b5aa0400 next 858 of size 3072\n","2020-03-26 07:50:49.436791: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b5aa1000 next 859 of size 2359296\n","2020-03-26 07:50:49.436799: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b5ce1000 next 860 of size 3072\n","2020-03-26 07:50:49.436807: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b5ce1c00 next 861 of size 3072\n","2020-03-26 07:50:49.436816: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b5ce2800 next 862 of size 2359296\n","2020-03-26 07:50:49.436980: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b5f22800 next 863 of size 2359296\n","2020-03-26 07:50:49.436994: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b6162800 next 864 of size 9437184\n","2020-03-26 07:50:49.437003: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b6a62800 next 865 of size 2359296\n","2020-03-26 07:50:49.437012: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b6ca2800 next 866 of size 3072\n","2020-03-26 07:50:49.437020: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b6ca3400 next 867 of size 3072\n","2020-03-26 07:50:49.437029: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b6ca4000 next 868 of size 3072\n","2020-03-26 07:50:49.437037: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b6ca4c00 next 869 of size 2359296\n","2020-03-26 07:50:49.437045: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b6ee4c00 next 870 of size 3072\n","2020-03-26 07:50:49.437054: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b6ee5800 next 871 of size 2359296\n","2020-03-26 07:50:49.437062: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b7125800 next 872 of size 3072\n","2020-03-26 07:50:49.437070: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b7126400 next 873 of size 9437184\n","2020-03-26 07:50:49.437078: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b7a26400 next 874 of size 3072\n","2020-03-26 07:50:49.437087: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b7a27000 next 875 of size 3072\n","2020-03-26 07:50:49.437095: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b7a27c00 next 876 of size 2359296\n","2020-03-26 07:50:49.437103: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b7c67c00 next 877 of size 9437184\n","2020-03-26 07:50:49.437112: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b8567c00 next 878 of size 9437184\n","2020-03-26 07:50:49.437120: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b8e67c00 next 879 of size 12288\n","2020-03-26 07:50:49.437128: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b8e6ac00 next 880 of size 3072\n","2020-03-26 07:50:49.437136: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b8e6b800 next 881 of size 9437184\n","2020-03-26 07:50:49.437145: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b976b800 next 882 of size 3072\n","2020-03-26 07:50:49.437238: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b976c400 next 883 of size 3072\n","2020-03-26 07:50:49.437250: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b976d000 next 884 of size 3072\n","2020-03-26 07:50:49.437259: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b976dc00 next 885 of size 3072\n","2020-03-26 07:50:49.437267: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b976e800 next 886 of size 3072\n","2020-03-26 07:50:49.437464: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b976f400 next 887 of size 2359296\n","2020-03-26 07:50:49.437481: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b99af400 next 888 of size 3072\n","2020-03-26 07:50:49.437490: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8b99b0000 next 889 of size 9437184\n","2020-03-26 07:50:49.437498: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ba2b0000 next 890 of size 9437184\n","2020-03-26 07:50:49.437506: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8babb0000 next 891 of size 2359296\n","2020-03-26 07:50:49.437515: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8badf0000 next 892 of size 3072\n","2020-03-26 07:50:49.437523: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8badf0c00 next 893 of size 3072\n","2020-03-26 07:50:49.437531: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8badf1800 next 894 of size 2359296\n","2020-03-26 07:50:49.437539: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8bb031800 next 895 of size 152189952\n","2020-03-26 07:50:49.437547: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c4155400 next 896 of size 3072\n","2020-03-26 07:50:49.437556: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c4156000 next 897 of size 2359296\n","2020-03-26 07:50:49.437564: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c4396000 next 898 of size 3072\n","2020-03-26 07:50:49.437572: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c4396c00 next 899 of size 3072\n","2020-03-26 07:50:49.437580: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c4397800 next 900 of size 12288\n","2020-03-26 07:50:49.437589: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c439a800 next 901 of size 3072\n","2020-03-26 07:50:49.437597: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c439b400 next 902 of size 3072\n","2020-03-26 07:50:49.437605: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c439c000 next 903 of size 2359296\n","2020-03-26 07:50:49.437613: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c45dc000 next 904 of size 3072\n","2020-03-26 07:50:49.437621: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c45dcc00 next 905 of size 9437184\n","2020-03-26 07:50:49.437630: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c4edcc00 next 906 of size 3072\n","2020-03-26 07:50:49.437638: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c4edd800 next 907 of size 3072\n","2020-03-26 07:50:49.437646: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c4ede400 next 908 of size 2359296\n","2020-03-26 07:50:49.437654: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c511e400 next 909 of size 3072\n","2020-03-26 07:50:49.437753: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c511f000 next 910 of size 2359296\n","2020-03-26 07:50:49.437766: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c535f000 next 911 of size 2359296\n","2020-03-26 07:50:49.437774: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c559f000 next 912 of size 12288\n","2020-03-26 07:50:49.437783: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c55a2000 next 913 of size 3072\n","2020-03-26 07:50:49.437945: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c55a2c00 next 914 of size 9437184\n","2020-03-26 07:50:49.437959: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c5ea2c00 next 915 of size 2359296\n","2020-03-26 07:50:49.437968: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c60e2c00 next 916 of size 3072\n","2020-03-26 07:50:49.437976: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c60e3800 next 917 of size 2359296\n","2020-03-26 07:50:49.437984: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c6323800 next 918 of size 3072\n","2020-03-26 07:50:49.437992: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c6324400 next 919 of size 2359296\n","2020-03-26 07:50:49.438001: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c6564400 next 920 of size 3072\n","2020-03-26 07:50:49.438009: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c6565000 next 921 of size 12288\n","2020-03-26 07:50:49.438017: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c6568000 next 922 of size 3072\n","2020-03-26 07:50:49.438025: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c6568c00 next 923 of size 3072\n","2020-03-26 07:50:49.438033: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c6569800 next 924 of size 3072\n","2020-03-26 07:50:49.438041: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c656a400 next 925 of size 3072\n","2020-03-26 07:50:49.438050: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c656b000 next 926 of size 12288\n","2020-03-26 07:50:49.438058: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c656e000 next 927 of size 3072\n","2020-03-26 07:50:49.438066: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c656ec00 next 928 of size 2359296\n","2020-03-26 07:50:49.438075: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c67aec00 next 929 of size 3072\n","2020-03-26 07:50:49.438083: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c67af800 next 930 of size 9437184\n","2020-03-26 07:50:49.438091: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c70af800 next 931 of size 6144\n","2020-03-26 07:50:49.438099: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c70b1000 next 932 of size 3072\n","2020-03-26 07:50:49.438107: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c70b1c00 next 933 of size 2359296\n","2020-03-26 07:50:49.438202: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c72f1c00 next 934 of size 12288\n","2020-03-26 07:50:49.438215: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c72f4c00 next 935 of size 6144\n","2020-03-26 07:50:49.438223: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c72f6400 next 936 of size 9437184\n","2020-03-26 07:50:49.438231: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c7bf6400 next 937 of size 3072\n","2020-03-26 07:50:49.438453: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c7bf7000 next 938 of size 2359296\n","2020-03-26 07:50:49.438472: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c7e37000 next 939 of size 2359296\n","2020-03-26 07:50:49.438480: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c8077000 next 940 of size 3072\n","2020-03-26 07:50:49.438507: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c8077c00 next 941 of size 3072\n","2020-03-26 07:50:49.438516: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c8078800 next 942 of size 3072\n","2020-03-26 07:50:49.438524: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c8079400 next 943 of size 3072\n","2020-03-26 07:50:49.438533: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c807a000 next 944 of size 2359296\n","2020-03-26 07:50:49.438541: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c82ba000 next 945 of size 2359296\n","2020-03-26 07:50:49.438549: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c84fa000 next 946 of size 12288\n","2020-03-26 07:50:49.438558: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c84fd000 next 947 of size 3072\n","2020-03-26 07:50:49.438566: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c84fdc00 next 948 of size 2359296\n","2020-03-26 07:50:49.438574: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c873dc00 next 949 of size 9437184\n","2020-03-26 07:50:49.438583: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c903dc00 next 950 of size 3072\n","2020-03-26 07:50:49.438591: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c903e800 next 951 of size 3072\n","2020-03-26 07:50:49.438599: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c903f400 next 952 of size 3072\n","2020-03-26 07:50:49.438608: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c9040000 next 953 of size 2359296\n","2020-03-26 07:50:49.438616: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c9280000 next 954 of size 2359296\n","2020-03-26 07:50:49.438624: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c94c0000 next 955 of size 3072\n","2020-03-26 07:50:49.438632: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c94c0c00 next 956 of size 9437184\n","2020-03-26 07:50:49.438641: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c9dc0c00 next 957 of size 3072\n","2020-03-26 07:50:49.438649: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c9dc1800 next 958 of size 3072\n","2020-03-26 07:50:49.438657: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8c9dc2400 next 959 of size 2359296\n","2020-03-26 07:50:49.438666: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ca002400 next 960 of size 3072\n","2020-03-26 07:50:49.438771: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ca003000 next 961 of size 3072\n","2020-03-26 07:50:49.438784: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ca003c00 next 962 of size 3072\n","2020-03-26 07:50:49.438792: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ca004800 next 963 of size 2359296\n","2020-03-26 07:50:49.438801: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ca244800 next 964 of size 2359296\n","2020-03-26 07:50:49.438809: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ca484800 next 965 of size 3072\n","2020-03-26 07:50:49.439002: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ca485400 next 966 of size 3072\n","2020-03-26 07:50:49.439018: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ca486000 next 967 of size 9437184\n","2020-03-26 07:50:49.439027: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cad86000 next 968 of size 3072\n","2020-03-26 07:50:49.439035: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cad86c00 next 969 of size 2359296\n","2020-03-26 07:50:49.439044: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cafc6c00 next 970 of size 9437184\n","2020-03-26 07:50:49.439052: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cb8c6c00 next 971 of size 3072\n","2020-03-26 07:50:49.439061: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cb8c7800 next 972 of size 6144\n","2020-03-26 07:50:49.439069: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cb8c9000 next 973 of size 2359296\n","2020-03-26 07:50:49.439078: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cbb09000 next 974 of size 2359296\n","2020-03-26 07:50:49.439086: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cbd49000 next 975 of size 2359296\n","2020-03-26 07:50:49.439094: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cbf89000 next 976 of size 3072\n","2020-03-26 07:50:49.439103: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cbf89c00 next 977 of size 9437184\n","2020-03-26 07:50:49.439111: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cc889c00 next 978 of size 2359296\n","2020-03-26 07:50:49.439119: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ccac9c00 next 979 of size 3072\n","2020-03-26 07:50:49.439129: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ccaca800 next 980 of size 256\n","2020-03-26 07:50:49.439137: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ccaca900 next 981 of size 3072\n","2020-03-26 07:50:49.439145: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ccacb500 next 982 of size 12288\n","2020-03-26 07:50:49.439154: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ccace500 next 983 of size 3072\n","2020-03-26 07:50:49.439162: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ccacf100 next 984 of size 3072\n","2020-03-26 07:50:49.439170: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ccacfd00 next 985 of size 6144\n","2020-03-26 07:50:49.439179: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ccad1500 next 986 of size 12288\n","2020-03-26 07:50:49.439187: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ccad4500 next 987 of size 3072\n","2020-03-26 07:50:49.439195: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ccad5100 next 988 of size 12288\n","2020-03-26 07:50:49.439293: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ccad8100 next 989 of size 2359296\n","2020-03-26 07:50:49.439307: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ccd18100 next 990 of size 2359296\n","2020-03-26 07:50:49.439315: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ccf58100 next 991 of size 6144\n","2020-03-26 07:50:49.439512: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ccf59900 next 992 of size 2359296\n","2020-03-26 07:50:49.439528: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cd199900 next 993 of size 256\n","2020-03-26 07:50:49.439537: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cd199a00 next 994 of size 12288\n","2020-03-26 07:50:49.439545: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cd19ca00 next 995 of size 3072\n","2020-03-26 07:50:49.439554: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cd19d600 next 996 of size 2359296\n","2020-03-26 07:50:49.439562: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cd3dd600 next 997 of size 2359296\n","2020-03-26 07:50:49.439570: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cd61d600 next 998 of size 3072\n","2020-03-26 07:50:49.439578: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cd61e200 next 999 of size 3072\n","2020-03-26 07:50:49.439587: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cd61ee00 next 1000 of size 3072\n","2020-03-26 07:50:49.439595: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cd61fa00 next 1001 of size 2359296\n","2020-03-26 07:50:49.439603: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cd85fa00 next 1002 of size 2359296\n","2020-03-26 07:50:49.439611: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cda9fa00 next 1003 of size 3072\n","2020-03-26 07:50:49.439619: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cdaa0600 next 1004 of size 2359296\n","2020-03-26 07:50:49.439628: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cdce0600 next 1005 of size 3072\n","2020-03-26 07:50:49.439636: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cdce1200 next 1006 of size 3072\n","2020-03-26 07:50:49.439651: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cdce1e00 next 1007 of size 3072\n","2020-03-26 07:50:49.439660: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cdce2a00 next 1008 of size 3072\n","2020-03-26 07:50:49.439761: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cdce3600 next 1009 of size 3072\n","2020-03-26 07:50:49.439795: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cdce4200 next 1010 of size 3072\n","2020-03-26 07:50:49.439963: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cdce4e00 next 1011 of size 9437184\n","2020-03-26 07:50:49.439977: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ce5e4e00 next 1012 of size 3072\n","2020-03-26 07:50:49.439986: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ce5e5a00 next 1013 of size 3072\n","2020-03-26 07:50:49.439994: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ce5e6600 next 1014 of size 2359296\n","2020-03-26 07:50:49.440003: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ce826600 next 1015 of size 3072\n","2020-03-26 07:50:49.440011: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ce827200 next 1016 of size 3072\n","2020-03-26 07:50:49.440019: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ce827e00 next 1017 of size 2359296\n","2020-03-26 07:50:49.440027: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cea67e00 next 1018 of size 12288\n","2020-03-26 07:50:49.440036: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cea6ae00 next 1019 of size 3072\n","2020-03-26 07:50:49.440044: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cea6ba00 next 1020 of size 3072\n","2020-03-26 07:50:49.440052: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cea6c600 next 1021 of size 3072\n","2020-03-26 07:50:49.440060: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cea6d200 next 1022 of size 3072\n","2020-03-26 07:50:49.440068: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cea6de00 next 1023 of size 3072\n","2020-03-26 07:50:49.440077: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cea6ea00 next 1024 of size 9437184\n","2020-03-26 07:50:49.440085: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cf36ea00 next 1025 of size 3072\n","2020-03-26 07:50:49.440093: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cf36f600 next 1026 of size 3072\n","2020-03-26 07:50:49.440101: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cf370200 next 1027 of size 2359296\n","2020-03-26 07:50:49.440110: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cf5b0200 next 1028 of size 3072\n","2020-03-26 07:50:49.440118: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cf5b0e00 next 1029 of size 3072\n","2020-03-26 07:50:49.440126: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cf5b1a00 next 1030 of size 3072\n","2020-03-26 07:50:49.440229: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cf5b2600 next 1031 of size 3072\n","2020-03-26 07:50:49.440242: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cf5b3200 next 1032 of size 2359296\n","2020-03-26 07:50:49.440251: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cf7f3200 next 1033 of size 2359296\n","2020-03-26 07:50:49.440259: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cfa33200 next 1034 of size 2359296\n","2020-03-26 07:50:49.440452: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cfc73200 next 1035 of size 3072\n","2020-03-26 07:50:49.440470: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8cfc73e00 next 1036 of size 9437184\n","2020-03-26 07:50:49.440479: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d0573e00 next 1037 of size 3072\n","2020-03-26 07:50:49.440487: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d0574a00 next 1038 of size 2359296\n","2020-03-26 07:50:49.440496: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d07b4a00 next 1039 of size 3072\n","2020-03-26 07:50:49.440504: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d07b5600 next 1040 of size 9437184\n","2020-03-26 07:50:49.440513: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d10b5600 next 1041 of size 9437184\n","2020-03-26 07:50:49.440521: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d19b5600 next 1042 of size 3072\n","2020-03-26 07:50:49.440529: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d19b6200 next 1043 of size 9437184\n","2020-03-26 07:50:49.440538: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d22b6200 next 1044 of size 3072\n","2020-03-26 07:50:49.440551: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d22b6e00 next 1045 of size 1572864\n","2020-03-26 07:50:49.440563: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d2436e00 next 1046 of size 3072\n","2020-03-26 07:50:49.440574: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d2437a00 next 1047 of size 2359296\n","2020-03-26 07:50:49.440586: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d2677a00 next 1048 of size 3072\n","2020-03-26 07:50:49.440597: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d2678600 next 1049 of size 9437184\n","2020-03-26 07:50:49.440605: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d2f78600 next 1050 of size 3072\n","2020-03-26 07:50:49.440614: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d2f79200 next 1051 of size 3072\n","2020-03-26 07:50:49.440622: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d2f79e00 next 1052 of size 2359296\n","2020-03-26 07:50:49.440630: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d31b9e00 next 1053 of size 3072\n","2020-03-26 07:50:49.440638: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d31baa00 next 1054 of size 3072\n","2020-03-26 07:50:49.440769: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d31bb600 next 1055 of size 9437184\n","2020-03-26 07:50:49.440784: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d3abb600 next 1056 of size 3072\n","2020-03-26 07:50:49.440792: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d3abc200 next 1057 of size 9437184\n","2020-03-26 07:50:49.440801: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d43bc200 next 1058 of size 3072\n","2020-03-26 07:50:49.440809: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d43bce00 next 1059 of size 3072\n","2020-03-26 07:50:49.440818: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d43bda00 next 1060 of size 12288\n","2020-03-26 07:50:49.440826: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d43c0a00 next 1061 of size 3072\n","2020-03-26 07:50:49.440834: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d43c1600 next 1062 of size 2359296\n","2020-03-26 07:50:49.441007: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d4601600 next 1063 of size 2359296\n","2020-03-26 07:50:49.441021: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d4841600 next 1064 of size 3072\n","2020-03-26 07:50:49.441030: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d4842200 next 1065 of size 12288\n","2020-03-26 07:50:49.441038: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d4845200 next 1066 of size 9437184\n","2020-03-26 07:50:49.441047: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d5145200 next 1067 of size 3072\n","2020-03-26 07:50:49.441055: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d5145e00 next 1068 of size 3072\n","2020-03-26 07:50:49.441064: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d5146a00 next 1069 of size 3072\n","2020-03-26 07:50:49.441072: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d5147600 next 1070 of size 1572864\n","2020-03-26 07:50:49.441081: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d52c7600 next 1071 of size 2359296\n","2020-03-26 07:50:49.441089: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d5507600 next 1072 of size 3072\n","2020-03-26 07:50:49.441097: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d5508200 next 1073 of size 12288\n","2020-03-26 07:50:49.441105: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d550b200 next 1074 of size 3072\n","2020-03-26 07:50:49.441114: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d550be00 next 1075 of size 2359296\n","2020-03-26 07:50:49.441122: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d574be00 next 1076 of size 3072\n","2020-03-26 07:50:49.441130: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d574ca00 next 1077 of size 3072\n","2020-03-26 07:50:49.441138: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d574d600 next 1078 of size 9437184\n","2020-03-26 07:50:49.441147: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d604d600 next 1079 of size 3072\n","2020-03-26 07:50:49.441155: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d604e200 next 1080 of size 2359296\n","2020-03-26 07:50:49.441163: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d628e200 next 1081 of size 2359296\n","2020-03-26 07:50:49.441171: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d64ce200 next 1082 of size 3072\n","2020-03-26 07:50:49.441179: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d64cee00 next 1083 of size 12288\n","2020-03-26 07:50:49.441276: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d64d1e00 next 1084 of size 9437184\n","2020-03-26 07:50:49.441288: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d6dd1e00 next 1085 of size 3072\n","2020-03-26 07:50:49.441297: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d6dd2a00 next 1086 of size 3072\n","2020-03-26 07:50:49.441305: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d6dd3600 next 1087 of size 3072\n","2020-03-26 07:50:49.441497: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d6dd4200 next 1088 of size 3072\n","2020-03-26 07:50:49.441514: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d6dd4e00 next 1089 of size 3072\n","2020-03-26 07:50:49.441523: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d6dd5a00 next 1090 of size 3072\n","2020-03-26 07:50:49.441532: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8d6dd6600 next 1091 of size 152189952\n","2020-03-26 07:50:49.441563: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8dfefa200 next 1092 of size 3072\n","2020-03-26 07:50:49.441573: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8dfefae00 next 1093 of size 9437184\n","2020-03-26 07:50:49.441581: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e07fae00 next 1094 of size 9437184\n","2020-03-26 07:50:49.441590: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e10fae00 next 1095 of size 2359296\n","2020-03-26 07:50:49.441599: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e133ae00 next 1096 of size 3072\n","2020-03-26 07:50:49.441607: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e133ba00 next 1097 of size 2359296\n","2020-03-26 07:50:49.441615: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e157ba00 next 1098 of size 3072\n","2020-03-26 07:50:49.441624: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e157c600 next 1099 of size 9437184\n","2020-03-26 07:50:49.441632: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e1e7c600 next 1100 of size 3072\n","2020-03-26 07:50:49.441641: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e1e7d200 next 1101 of size 3072\n","2020-03-26 07:50:49.441649: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e1e7de00 next 1102 of size 3072\n","2020-03-26 07:50:49.441658: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e1e7ea00 next 1103 of size 3072\n","2020-03-26 07:50:49.441666: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e1e7f600 next 1104 of size 9437184\n","2020-03-26 07:50:49.441674: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e277f600 next 1105 of size 3072\n","2020-03-26 07:50:49.441682: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e2780200 next 1106 of size 12288\n","2020-03-26 07:50:49.441690: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e2783200 next 1107 of size 3072\n","2020-03-26 07:50:49.441794: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e2783e00 next 1108 of size 3072\n","2020-03-26 07:50:49.441807: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e2784a00 next 1109 of size 3072\n","2020-03-26 07:50:49.441815: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e2785600 next 1110 of size 2359296\n","2020-03-26 07:50:49.441824: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e29c5600 next 1111 of size 3072\n","2020-03-26 07:50:49.441832: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e29c6200 next 1112 of size 9437184\n","2020-03-26 07:50:49.441996: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e32c6200 next 1113 of size 3072\n","2020-03-26 07:50:49.442010: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e32c6e00 next 1114 of size 2359296\n","2020-03-26 07:50:49.442019: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e3506e00 next 1115 of size 2359296\n","2020-03-26 07:50:49.442028: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e3746e00 next 1116 of size 3072\n","2020-03-26 07:50:49.442037: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e3747a00 next 1117 of size 3072\n","2020-03-26 07:50:49.442045: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e3748600 next 1118 of size 9437184\n","2020-03-26 07:50:49.442054: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e4048600 next 1119 of size 2359296\n","2020-03-26 07:50:49.442062: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e4288600 next 1120 of size 12288\n","2020-03-26 07:50:49.442071: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e428b600 next 1121 of size 3072\n","2020-03-26 07:50:49.442079: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e428c200 next 1122 of size 3072\n","2020-03-26 07:50:49.442087: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e428ce00 next 1123 of size 2359296\n","2020-03-26 07:50:49.442096: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e44cce00 next 1124 of size 3072\n","2020-03-26 07:50:49.442104: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e44cda00 next 1125 of size 2359296\n","2020-03-26 07:50:49.442113: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e470da00 next 1126 of size 3072\n","2020-03-26 07:50:49.442121: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e470e600 next 1127 of size 3072\n","2020-03-26 07:50:49.442130: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e470f200 next 1128 of size 9437184\n","2020-03-26 07:50:49.442138: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e500f200 next 1129 of size 3072\n","2020-03-26 07:50:49.442147: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e500fe00 next 1130 of size 2359296\n","2020-03-26 07:50:49.442155: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e524fe00 next 1131 of size 3072\n","2020-03-26 07:50:49.442163: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e5250a00 next 1132 of size 3072\n","2020-03-26 07:50:49.442259: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e5251600 next 1133 of size 3072\n","2020-03-26 07:50:49.442272: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e5252200 next 1134 of size 3072\n","2020-03-26 07:50:49.442280: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e5252e00 next 1135 of size 9437184\n","2020-03-26 07:50:49.442288: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e5b52e00 next 1136 of size 9437184\n","2020-03-26 07:50:49.442537: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e6452e00 next 1137 of size 3072\n","2020-03-26 07:50:49.442557: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e6453a00 next 1138 of size 3072\n","2020-03-26 07:50:49.442566: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e6454600 next 1139 of size 3072\n","2020-03-26 07:50:49.442575: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e6455200 next 1140 of size 9437184\n","2020-03-26 07:50:49.442583: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e6d55200 next 1141 of size 12288\n","2020-03-26 07:50:49.442592: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e6d58200 next 1142 of size 3072\n","2020-03-26 07:50:49.442600: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e6d58e00 next 1143 of size 3072\n","2020-03-26 07:50:49.442609: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e6d59a00 next 1144 of size 2359296\n","2020-03-26 07:50:49.442617: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e6f99a00 next 1145 of size 3072\n","2020-03-26 07:50:49.442626: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e6f9a600 next 1146 of size 9437184\n","2020-03-26 07:50:49.442634: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e789a600 next 1147 of size 12288\n","2020-03-26 07:50:49.442643: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e789d600 next 1148 of size 3072\n","2020-03-26 07:50:49.442651: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e789e200 next 1149 of size 9437184\n","2020-03-26 07:50:49.442660: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e819e200 next 1150 of size 3072\n","2020-03-26 07:50:49.442668: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e819ee00 next 1151 of size 3072\n","2020-03-26 07:50:49.442676: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e819fa00 next 1152 of size 3072\n","2020-03-26 07:50:49.442685: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e81a0600 next 1153 of size 2359296\n","2020-03-26 07:50:49.442693: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e83e0600 next 1154 of size 3072\n","2020-03-26 07:50:49.442702: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e83e1200 next 1155 of size 3072\n","2020-03-26 07:50:49.442710: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e83e1e00 next 1156 of size 2359296\n","2020-03-26 07:50:49.442719: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e8621e00 next 1157 of size 3072\n","2020-03-26 07:50:49.442727: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e8622a00 next 1158 of size 3072\n","2020-03-26 07:50:49.442735: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e8623600 next 1159 of size 3072\n","2020-03-26 07:50:49.442744: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e8624200 next 1160 of size 2359296\n","2020-03-26 07:50:49.442752: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e8864200 next 1161 of size 3072\n","2020-03-26 07:50:49.442761: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e8864e00 next 1162 of size 3072\n","2020-03-26 07:50:49.442769: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e8865a00 next 1163 of size 3072\n","2020-03-26 07:50:49.442777: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e8866600 next 1164 of size 2359296\n","2020-03-26 07:50:49.442786: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e8aa6600 next 1165 of size 2359296\n","2020-03-26 07:50:49.442794: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e8ce6600 next 1166 of size 2359296\n","2020-03-26 07:50:49.442906: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e8f26600 next 1167 of size 3072\n","2020-03-26 07:50:49.442920: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e8f27200 next 1168 of size 2359296\n","2020-03-26 07:50:49.442928: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e9167200 next 1169 of size 3072\n","2020-03-26 07:50:49.442936: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e9167e00 next 1170 of size 2359296\n","2020-03-26 07:50:49.442945: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e93a7e00 next 1171 of size 3072\n","2020-03-26 07:50:49.443096: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e93a8a00 next 1172 of size 2359296\n","2020-03-26 07:50:49.443109: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e95e8a00 next 1173 of size 3072\n","2020-03-26 07:50:49.443118: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e95e9600 next 1174 of size 9437184\n","2020-03-26 07:50:49.443127: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e9ee9600 next 1175 of size 3072\n","2020-03-26 07:50:49.443136: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8e9eea200 next 1176 of size 2359296\n","2020-03-26 07:50:49.443144: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ea12a200 next 1177 of size 3072\n","2020-03-26 07:50:49.443153: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ea12ae00 next 1178 of size 3072\n","2020-03-26 07:50:49.443162: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ea12ba00 next 1179 of size 3072\n","2020-03-26 07:50:49.443170: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ea12c600 next 1180 of size 9437184\n","2020-03-26 07:50:49.443179: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8eaa2c600 next 1181 of size 3072\n","2020-03-26 07:50:49.443187: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8eaa2d200 next 1182 of size 3072\n","2020-03-26 07:50:49.443196: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8eaa2de00 next 1183 of size 3072\n","2020-03-26 07:50:49.443204: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8eaa2ea00 next 1184 of size 3072\n","2020-03-26 07:50:49.443213: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8eaa2f600 next 1185 of size 3072\n","2020-03-26 07:50:49.443221: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8eaa30200 next 1186 of size 2359296\n","2020-03-26 07:50:49.443230: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8eac70200 next 1187 of size 3072\n","2020-03-26 07:50:49.443238: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8eac70e00 next 1188 of size 9437184\n","2020-03-26 07:50:49.443247: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8eb570e00 next 1189 of size 9437184\n","2020-03-26 07:50:49.443399: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ebe70e00 next 1190 of size 3072\n","2020-03-26 07:50:49.443418: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ebe71a00 next 1191 of size 2359296\n","2020-03-26 07:50:49.443427: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ec0b1a00 next 1192 of size 3072\n","2020-03-26 07:50:49.443436: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ec0b2600 next 1193 of size 2359296\n","2020-03-26 07:50:49.443444: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ec2f2600 next 1194 of size 3072\n","2020-03-26 07:50:49.443453: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ec2f3200 next 1195 of size 12288\n","2020-03-26 07:50:49.443609: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ec2f6200 next 1196 of size 2359296\n","2020-03-26 07:50:49.443623: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ec536200 next 1197 of size 2359296\n","2020-03-26 07:50:49.443632: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ec776200 next 1198 of size 3072\n","2020-03-26 07:50:49.443641: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ec776e00 next 1199 of size 2359296\n","2020-03-26 07:50:49.443649: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ec9b6e00 next 1200 of size 3072\n","2020-03-26 07:50:49.443658: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ec9b7a00 next 1201 of size 12288\n","2020-03-26 07:50:49.443667: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ec9baa00 next 1202 of size 3072\n","2020-03-26 07:50:49.443675: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ec9bb600 next 1203 of size 2359296\n","2020-03-26 07:50:49.443684: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ecbfb600 next 1204 of size 3072\n","2020-03-26 07:50:49.443692: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ecbfc200 next 1205 of size 2359296\n","2020-03-26 07:50:49.443701: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ece3c200 next 1206 of size 3072\n","2020-03-26 07:50:49.443709: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ece3ce00 next 1207 of size 3072\n","2020-03-26 07:50:49.443718: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ece3da00 next 1208 of size 3072\n","2020-03-26 07:50:49.443726: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ece3e600 next 1209 of size 3072\n","2020-03-26 07:50:49.443735: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ece3f200 next 1210 of size 3072\n","2020-03-26 07:50:49.443743: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ece3fe00 next 1211 of size 2359296\n","2020-03-26 07:50:49.443752: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ed07fe00 next 1212 of size 2359296\n","2020-03-26 07:50:49.443760: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ed2bfe00 next 1213 of size 2359296\n","2020-03-26 07:50:49.443769: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ed4ffe00 next 1214 of size 3072\n","2020-03-26 07:50:49.443874: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0x7fe8ed500a00 next 1215 of size 256\n","2020-03-26 07:50:49.443888: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ed500b00 next 1216 of size 256\n","2020-03-26 07:50:49.443897: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ed500c00 next 1217 of size 256\n","2020-03-26 07:50:49.443906: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ed500d00 next 1218 of size 2359296\n","2020-03-26 07:50:49.444129: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ed740d00 next 1219 of size 2359296\n","2020-03-26 07:50:49.444169: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0x7fe8ed980d00 next 1220 of size 256\n","2020-03-26 07:50:49.444181: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ed980e00 next 725 of size 51904512\n","2020-03-26 07:50:49.444190: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8f0b00e00 next 724 of size 6291456\n","2020-03-26 07:50:49.444198: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8f1100e00 next 726 of size 6291456\n","2020-03-26 07:50:49.444207: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8f1700e00 next 727 of size 6291456\n","2020-03-26 07:50:49.444215: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8f1d00e00 next 723 of size 6291456\n","2020-03-26 07:50:49.444224: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8f2300e00 next 1225 of size 6291456\n","2020-03-26 07:50:49.444232: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8f2900e00 next 1222 of size 6291456\n","2020-03-26 07:50:49.444241: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8f2f00e00 next 678 of size 6291456\n","2020-03-26 07:50:49.444249: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8f3500e00 next 679 of size 6291456\n","2020-03-26 07:50:49.444258: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8f3b00e00 next 681 of size 6291456\n","2020-03-26 07:50:49.444266: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8f4100e00 next 682 of size 6291456\n","2020-03-26 07:50:49.444275: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8f4700e00 next 683 of size 6291456\n","2020-03-26 07:50:49.444283: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8f4d00e00 next 685 of size 6291456\n","2020-03-26 07:50:49.444292: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8f5300e00 next 686 of size 6291456\n","2020-03-26 07:50:49.444300: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8f5900e00 next 687 of size 6291456\n","2020-03-26 07:50:49.444308: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8f5f00e00 next 689 of size 6291456\n","2020-03-26 07:50:49.444587: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8f6500e00 next 690 of size 6291456\n","2020-03-26 07:50:49.444608: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8f6b00e00 next 691 of size 6291456\n","2020-03-26 07:50:49.444617: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8f7100e00 next 693 of size 6291456\n","2020-03-26 07:50:49.444626: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8f7700e00 next 694 of size 6291456\n","2020-03-26 07:50:49.444634: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8f7d00e00 next 695 of size 6291456\n","2020-03-26 07:50:49.444643: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8f8300e00 next 697 of size 6291456\n","2020-03-26 07:50:49.444651: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8f8900e00 next 698 of size 6291456\n","2020-03-26 07:50:49.444660: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8f8f00e00 next 722 of size 6291456\n","2020-03-26 07:50:49.444669: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8f9500e00 next 18446744073709551615 of size 11530752\n","2020-03-26 07:50:49.444678: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 1073741824\n","2020-03-26 07:50:49.444688: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fa000000 next 313 of size 2359296\n","2020-03-26 07:50:49.444696: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fa240000 next 314 of size 2359296\n","2020-03-26 07:50:49.444705: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fa480000 next 317 of size 9437184\n","2020-03-26 07:50:49.444713: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fad80000 next 318 of size 198400\n","2020-03-26 07:50:49.444722: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fadb0700 next 319 of size 2359296\n","2020-03-26 07:50:49.444730: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8faff0700 next 324 of size 9437184\n","2020-03-26 07:50:49.444739: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fb8f0700 next 325 of size 9437184\n","2020-03-26 07:50:49.444747: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fc1f0700 next 326 of size 2359296\n","2020-03-26 07:50:49.444756: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fc430700 next 328 of size 9437184\n","2020-03-26 07:50:49.444764: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fcd30700 next 329 of size 2359296\n","2020-03-26 07:50:49.444772: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fcf70700 next 331 of size 2359296\n","2020-03-26 07:50:49.444781: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fd1b0700 next 333 of size 2359296\n","2020-03-26 07:50:49.444789: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fd3f0700 next 338 of size 2359296\n","2020-03-26 07:50:49.444798: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fd630700 next 341 of size 2359296\n","2020-03-26 07:50:49.444806: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fd870700 next 342 of size 9437184\n","2020-03-26 07:50:49.444814: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fe170700 next 343 of size 2359296\n","2020-03-26 07:50:49.444823: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fe3b0700 next 344 of size 2359296\n","2020-03-26 07:50:49.445084: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fe5f0700 next 345 of size 2359296\n","2020-03-26 07:50:49.445105: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fe830700 next 346 of size 2359296\n","2020-03-26 07:50:49.445114: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fea70700 next 350 of size 2359296\n","2020-03-26 07:50:49.445123: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb0700 next 622 of size 256\n","2020-03-26 07:50:49.445132: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb0800 next 623 of size 256\n","2020-03-26 07:50:49.445140: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb0900 next 624 of size 256\n","2020-03-26 07:50:49.445148: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb0a00 next 625 of size 256\n","2020-03-26 07:50:49.445157: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb0b00 next 626 of size 256\n","2020-03-26 07:50:49.445165: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb0c00 next 627 of size 256\n","2020-03-26 07:50:49.445174: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb0d00 next 628 of size 256\n","2020-03-26 07:50:49.445182: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb0e00 next 629 of size 256\n","2020-03-26 07:50:49.445191: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb0f00 next 630 of size 256\n","2020-03-26 07:50:49.445199: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb1000 next 631 of size 256\n","2020-03-26 07:50:49.445208: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb1100 next 632 of size 256\n","2020-03-26 07:50:49.445216: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb1200 next 633 of size 256\n","2020-03-26 07:50:49.445224: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb1300 next 634 of size 256\n","2020-03-26 07:50:49.445233: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb1400 next 635 of size 256\n","2020-03-26 07:50:49.445241: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb1500 next 636 of size 256\n","2020-03-26 07:50:49.445249: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb1600 next 637 of size 256\n","2020-03-26 07:50:49.445258: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb1700 next 638 of size 256\n","2020-03-26 07:50:49.445266: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb1800 next 639 of size 256\n","2020-03-26 07:50:49.445275: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb1900 next 640 of size 256\n","2020-03-26 07:50:49.445283: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb1a00 next 641 of size 256\n","2020-03-26 07:50:49.445681: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb1b00 next 642 of size 256\n","2020-03-26 07:50:49.445751: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb1c00 next 643 of size 256\n","2020-03-26 07:50:49.445789: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb1d00 next 644 of size 256\n","2020-03-26 07:50:49.445819: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb1e00 next 645 of size 256\n","2020-03-26 07:50:49.445848: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb1f00 next 646 of size 256\n","2020-03-26 07:50:49.445911: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb2000 next 647 of size 256\n","2020-03-26 07:50:49.445941: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb2100 next 648 of size 256\n","2020-03-26 07:50:49.445956: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb2200 next 649 of size 256\n","2020-03-26 07:50:49.445970: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb2300 next 650 of size 256\n","2020-03-26 07:50:49.445984: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb2400 next 651 of size 8192\n","2020-03-26 07:50:49.445998: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb4400 next 652 of size 256\n","2020-03-26 07:50:49.446012: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb4500 next 653 of size 256\n","2020-03-26 07:50:49.446026: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb4600 next 654 of size 256\n","2020-03-26 07:50:49.446041: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb4700 next 655 of size 256\n","2020-03-26 07:50:49.446055: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb4800 next 656 of size 256\n","2020-03-26 07:50:49.446069: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb4900 next 657 of size 256\n","2020-03-26 07:50:49.446082: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb4a00 next 658 of size 256\n","2020-03-26 07:50:49.446096: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb4b00 next 659 of size 256\n","2020-03-26 07:50:49.446110: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb4c00 next 660 of size 256\n","2020-03-26 07:50:49.446123: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb4d00 next 661 of size 256\n","2020-03-26 07:50:49.446137: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb4e00 next 662 of size 256\n","2020-03-26 07:50:49.446150: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb4f00 next 663 of size 256\n","2020-03-26 07:50:49.446164: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb5000 next 664 of size 256\n","2020-03-26 07:50:49.446710: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb5100 next 665 of size 256\n","2020-03-26 07:50:49.446742: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb5200 next 666 of size 256\n","2020-03-26 07:50:49.446753: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb5300 next 667 of size 256\n","2020-03-26 07:50:49.446762: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb5400 next 668 of size 256\n","2020-03-26 07:50:49.446771: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb5500 next 669 of size 256\n","2020-03-26 07:50:49.446804: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb5600 next 670 of size 256\n","2020-03-26 07:50:49.446813: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb5700 next 671 of size 256\n","2020-03-26 07:50:49.446821: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb5800 next 672 of size 256\n","2020-03-26 07:50:49.446830: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb5900 next 673 of size 256\n","2020-03-26 07:50:49.446838: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb5a00 next 674 of size 256\n","2020-03-26 07:50:49.446847: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb5b00 next 675 of size 256\n","2020-03-26 07:50:49.446855: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb5c00 next 676 of size 256\n","2020-03-26 07:50:49.446864: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb5d00 next 677 of size 256\n","2020-03-26 07:50:49.446873: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb5e00 next 708 of size 512\n","2020-03-26 07:50:49.446882: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb6000 next 709 of size 256\n","2020-03-26 07:50:49.446890: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb6100 next 710 of size 512\n","2020-03-26 07:50:49.446899: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb6300 next 712 of size 512\n","2020-03-26 07:50:49.446907: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb6500 next 732 of size 3072\n","2020-03-26 07:50:49.446916: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb7100 next 713 of size 5120\n","2020-03-26 07:50:49.446925: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecb8500 next 714 of size 8192\n","2020-03-26 07:50:49.446933: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecba500 next 715 of size 256\n","2020-03-26 07:50:49.446942: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecba600 next 716 of size 256\n","2020-03-26 07:50:49.446950: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecba700 next 717 of size 256\n","2020-03-26 07:50:49.446959: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecba800 next 719 of size 16384\n","2020-03-26 07:50:49.446968: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecbe800 next 741 of size 3072\n","2020-03-26 07:50:49.446976: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecbf400 next 743 of size 3072\n","2020-03-26 07:50:49.446985: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecc0000 next 748 of size 3072\n","2020-03-26 07:50:49.446993: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecc0c00 next 750 of size 3072\n","2020-03-26 07:50:49.447002: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8fecc1800 next 352 of size 2289408\n","2020-03-26 07:50:49.447011: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8feef0700 next 354 of size 2359296\n","2020-03-26 07:50:49.447019: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ff130700 next 355 of size 2359296\n","2020-03-26 07:50:49.447028: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ff370700 next 356 of size 9437184\n","2020-03-26 07:50:49.447037: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ffc70700 next 357 of size 3072\n","2020-03-26 07:50:49.447045: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ffc71300 next 358 of size 12288\n","2020-03-26 07:50:49.447063: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ffc74300 next 359 of size 3072\n","2020-03-26 07:50:49.447071: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ffc74f00 next 360 of size 12288\n","2020-03-26 07:50:49.447080: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ffc77f00 next 361 of size 3072\n","2020-03-26 07:50:49.447088: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ffc78b00 next 362 of size 2359296\n","2020-03-26 07:50:49.447096: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ffeb8b00 next 363 of size 12288\n","2020-03-26 07:50:49.447107: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe8ffebbb00 next 364 of size 9437184\n","2020-03-26 07:50:49.447119: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9007bbb00 next 365 of size 3072\n","2020-03-26 07:50:49.447130: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9007bc700 next 366 of size 3072\n","2020-03-26 07:50:49.447141: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9007bd300 next 367 of size 3072\n","2020-03-26 07:50:49.447153: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9007bdf00 next 368 of size 9437184\n","2020-03-26 07:50:49.447162: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9010bdf00 next 369 of size 2359296\n","2020-03-26 07:50:49.447170: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9012fdf00 next 370 of size 2359296\n","2020-03-26 07:50:49.447179: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90153df00 next 371 of size 3072\n","2020-03-26 07:50:49.447187: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90153eb00 next 372 of size 2359296\n","2020-03-26 07:50:49.447195: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90177eb00 next 373 of size 3072\n","2020-03-26 07:50:49.447204: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90177f700 next 374 of size 3072\n","2020-03-26 07:50:49.447443: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe901780300 next 375 of size 3072\n","2020-03-26 07:50:49.447463: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe901780f00 next 376 of size 3072\n","2020-03-26 07:50:49.447472: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe901781b00 next 377 of size 6144\n","2020-03-26 07:50:49.447480: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe901783300 next 378 of size 12288\n","2020-03-26 07:50:49.447489: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe901786300 next 379 of size 3072\n","2020-03-26 07:50:49.447498: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe901786f00 next 380 of size 3072\n","2020-03-26 07:50:49.447507: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe901787b00 next 381 of size 2359296\n","2020-03-26 07:50:49.447515: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9019c7b00 next 382 of size 3072\n","2020-03-26 07:50:49.447524: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9019c8700 next 383 of size 2359296\n","2020-03-26 07:50:49.447532: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe901c08700 next 384 of size 2359296\n","2020-03-26 07:50:49.447541: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe901e48700 next 385 of size 9437184\n","2020-03-26 07:50:49.447549: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe902748700 next 386 of size 3072\n","2020-03-26 07:50:49.447558: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe902749300 next 387 of size 3072\n","2020-03-26 07:50:49.447566: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe902749f00 next 388 of size 3072\n","2020-03-26 07:50:49.447575: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90274ab00 next 389 of size 2359296\n","2020-03-26 07:50:49.447583: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90298ab00 next 390 of size 3072\n","2020-03-26 07:50:49.447592: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90298b700 next 391 of size 2359296\n","2020-03-26 07:50:49.447600: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe902bcb700 next 392 of size 3072\n","2020-03-26 07:50:49.447608: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe902bcc300 next 393 of size 3072\n","2020-03-26 07:50:49.447616: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe902bccf00 next 394 of size 3072\n","2020-03-26 07:50:49.447624: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe902bcdb00 next 395 of size 9437184\n","2020-03-26 07:50:49.447633: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9034cdb00 next 396 of size 2359296\n","2020-03-26 07:50:49.447641: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90370db00 next 397 of size 2359296\n","2020-03-26 07:50:49.447649: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90394db00 next 398 of size 2359296\n","2020-03-26 07:50:49.447657: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe903b8db00 next 399 of size 12288\n","2020-03-26 07:50:49.447666: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe903b90b00 next 400 of size 3072\n","2020-03-26 07:50:49.447674: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe903b91700 next 401 of size 2359296\n","2020-03-26 07:50:49.447682: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe903dd1700 next 402 of size 2359296\n","2020-03-26 07:50:49.447690: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe904011700 next 403 of size 12288\n","2020-03-26 07:50:49.447801: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe904014700 next 404 of size 3072\n","2020-03-26 07:50:49.447814: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe904015300 next 405 of size 2359296\n","2020-03-26 07:50:49.447822: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe904255300 next 406 of size 3072\n","2020-03-26 07:50:49.447831: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe904255f00 next 407 of size 3072\n","2020-03-26 07:50:49.447839: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe904256b00 next 408 of size 3072\n","2020-03-26 07:50:49.448035: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe904257700 next 409 of size 3072\n","2020-03-26 07:50:49.448052: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe904258300 next 410 of size 3072\n","2020-03-26 07:50:49.448061: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe904258f00 next 411 of size 3072\n","2020-03-26 07:50:49.448069: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe904259b00 next 412 of size 12288\n","2020-03-26 07:50:49.448078: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90425cb00 next 413 of size 2359296\n","2020-03-26 07:50:49.448086: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90449cb00 next 414 of size 3072\n","2020-03-26 07:50:49.448095: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90449d700 next 415 of size 3072\n","2020-03-26 07:50:49.448103: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90449e300 next 416 of size 12288\n","2020-03-26 07:50:49.448112: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9044a1300 next 417 of size 3072\n","2020-03-26 07:50:49.448120: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9044a1f00 next 418 of size 3072\n","2020-03-26 07:50:49.448129: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9044a2b00 next 419 of size 3072\n","2020-03-26 07:50:49.448137: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9044a3700 next 420 of size 3072\n","2020-03-26 07:50:49.448146: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9044a4300 next 421 of size 2359296\n","2020-03-26 07:50:49.448154: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9046e4300 next 422 of size 9437184\n","2020-03-26 07:50:49.448162: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe904fe4300 next 423 of size 9437184\n","2020-03-26 07:50:49.448170: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9058e4300 next 424 of size 3072\n","2020-03-26 07:50:49.448179: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9058e4f00 next 425 of size 3072\n","2020-03-26 07:50:49.448187: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9058e5b00 next 426 of size 2359296\n","2020-03-26 07:50:49.448195: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe905b25b00 next 427 of size 3072\n","2020-03-26 07:50:49.448203: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe905b26700 next 428 of size 3072\n","2020-03-26 07:50:49.448211: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe905b27300 next 429 of size 3072\n","2020-03-26 07:50:49.448220: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe905b27f00 next 430 of size 3072\n","2020-03-26 07:50:49.448228: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe905b28b00 next 431 of size 3072\n","2020-03-26 07:50:49.448236: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe905b29700 next 432 of size 2359296\n","2020-03-26 07:50:49.448381: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe905d69700 next 433 of size 3072\n","2020-03-26 07:50:49.448399: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe905d6a300 next 434 of size 2359296\n","2020-03-26 07:50:49.448408: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe905faa300 next 435 of size 3072\n","2020-03-26 07:50:49.448416: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe905faaf00 next 436 of size 3072\n","2020-03-26 07:50:49.448583: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe905fabb00 next 437 of size 2359296\n","2020-03-26 07:50:49.448597: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9061ebb00 next 438 of size 3072\n","2020-03-26 07:50:49.448606: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9061ec700 next 439 of size 3072\n","2020-03-26 07:50:49.448614: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9061ed300 next 440 of size 3072\n","2020-03-26 07:50:49.448623: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9061edf00 next 441 of size 3072\n","2020-03-26 07:50:49.448631: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9061eeb00 next 442 of size 9437184\n","2020-03-26 07:50:49.448640: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe906aeeb00 next 443 of size 2359296\n","2020-03-26 07:50:49.448649: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe906d2eb00 next 444 of size 12288\n","2020-03-26 07:50:49.448657: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe906d31b00 next 445 of size 9437184\n","2020-03-26 07:50:49.448666: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe907631b00 next 446 of size 3072\n","2020-03-26 07:50:49.448674: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe907632700 next 447 of size 3072\n","2020-03-26 07:50:49.448683: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe907633300 next 448 of size 2359296\n","2020-03-26 07:50:49.448691: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe907873300 next 449 of size 3072\n","2020-03-26 07:50:49.448699: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe907873f00 next 450 of size 3072\n","2020-03-26 07:50:49.448708: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe907874b00 next 451 of size 3072\n","2020-03-26 07:50:49.448717: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe907875700 next 452 of size 3072\n","2020-03-26 07:50:49.448725: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe907876300 next 453 of size 2359296\n","2020-03-26 07:50:49.448733: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe907ab6300 next 454 of size 3072\n","2020-03-26 07:50:49.448741: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe907ab6f00 next 455 of size 3072\n","2020-03-26 07:50:49.448749: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe907ab7b00 next 456 of size 3072\n","2020-03-26 07:50:49.448873: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe907ab8700 next 457 of size 3072\n","2020-03-26 07:50:49.448888: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe907ab9300 next 458 of size 2359296\n","2020-03-26 07:50:49.448896: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe907cf9300 next 459 of size 2359296\n","2020-03-26 07:50:49.448904: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe907f39300 next 460 of size 3072\n","2020-03-26 07:50:49.449060: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe907f39f00 next 461 of size 3072\n","2020-03-26 07:50:49.449074: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe907f3ab00 next 462 of size 6144\n","2020-03-26 07:50:49.449082: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe907f3c300 next 463 of size 3072\n","2020-03-26 07:50:49.449091: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe907f3cf00 next 464 of size 9437184\n","2020-03-26 07:50:49.449099: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90883cf00 next 465 of size 2359296\n","2020-03-26 07:50:49.449108: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe908a7cf00 next 466 of size 3072\n","2020-03-26 07:50:49.449116: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe908a7db00 next 467 of size 2359296\n","2020-03-26 07:50:49.449125: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe908cbdb00 next 468 of size 2359296\n","2020-03-26 07:50:49.449133: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe908efdb00 next 469 of size 3072\n","2020-03-26 07:50:49.449142: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe908efe700 next 470 of size 9437184\n","2020-03-26 07:50:49.449150: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9097fe700 next 471 of size 2359296\n","2020-03-26 07:50:49.449159: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe909a3e700 next 472 of size 2359296\n","2020-03-26 07:50:49.449167: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe909c7e700 next 473 of size 3072\n","2020-03-26 07:50:49.449175: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe909c7f300 next 474 of size 3072\n","2020-03-26 07:50:49.449184: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe909c7ff00 next 475 of size 9437184\n","2020-03-26 07:50:49.449192: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90a57ff00 next 476 of size 2359296\n","2020-03-26 07:50:49.449201: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90a7bff00 next 477 of size 2359296\n","2020-03-26 07:50:49.449209: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90a9fff00 next 478 of size 3072\n","2020-03-26 07:50:49.449218: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90aa00b00 next 479 of size 3072\n","2020-03-26 07:50:49.449314: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90aa01700 next 480 of size 6144\n","2020-03-26 07:50:49.449603: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90aa02f00 next 481 of size 3072\n","2020-03-26 07:50:49.449624: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90aa03b00 next 482 of size 12288\n","2020-03-26 07:50:49.449633: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90aa06b00 next 483 of size 2359296\n","2020-03-26 07:50:49.449642: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90ac46b00 next 484 of size 2359296\n","2020-03-26 07:50:49.449651: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90ae86b00 next 485 of size 9437184\n","2020-03-26 07:50:49.449659: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90b786b00 next 486 of size 2359296\n","2020-03-26 07:50:49.449668: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90b9c6b00 next 487 of size 3072\n","2020-03-26 07:50:49.449676: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90b9c7700 next 488 of size 3072\n","2020-03-26 07:50:49.449707: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90b9c8300 next 489 of size 9437184\n","2020-03-26 07:50:49.449715: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90c2c8300 next 490 of size 2359296\n","2020-03-26 07:50:49.449724: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90c508300 next 491 of size 3072\n","2020-03-26 07:50:49.449732: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90c508f00 next 492 of size 9437184\n","2020-03-26 07:50:49.449741: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90ce08f00 next 493 of size 3072\n","2020-03-26 07:50:49.449749: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90ce09b00 next 494 of size 2359296\n","2020-03-26 07:50:49.449757: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90d049b00 next 495 of size 2359296\n","2020-03-26 07:50:49.449766: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90d289b00 next 496 of size 3072\n","2020-03-26 07:50:49.449774: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90d28a700 next 497 of size 12288\n","2020-03-26 07:50:49.449783: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90d28d700 next 498 of size 3072\n","2020-03-26 07:50:49.449792: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90d28e300 next 499 of size 2359296\n","2020-03-26 07:50:49.450033: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90d4ce300 next 500 of size 9437184\n","2020-03-26 07:50:49.450053: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90ddce300 next 501 of size 9437184\n","2020-03-26 07:50:49.450062: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90e6ce300 next 502 of size 3072\n","2020-03-26 07:50:49.450071: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90e6cef00 next 503 of size 3072\n","2020-03-26 07:50:49.450080: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90e6cfb00 next 504 of size 2359296\n","2020-03-26 07:50:49.450088: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90e90fb00 next 505 of size 3072\n","2020-03-26 07:50:49.450097: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90e910700 next 506 of size 3072\n","2020-03-26 07:50:49.450105: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90e911300 next 507 of size 3072\n","2020-03-26 07:50:49.450114: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90e911f00 next 508 of size 3072\n","2020-03-26 07:50:49.450122: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90e912b00 next 509 of size 2359296\n","2020-03-26 07:50:49.450130: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90eb52b00 next 510 of size 2359296\n","2020-03-26 07:50:49.450139: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90ed92b00 next 511 of size 2359296\n","2020-03-26 07:50:49.450147: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90efd2b00 next 512 of size 12288\n","2020-03-26 07:50:49.450156: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90efd5b00 next 513 of size 9437184\n","2020-03-26 07:50:49.450164: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90f8d5b00 next 514 of size 12288\n","2020-03-26 07:50:49.450173: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90f8d8b00 next 515 of size 3072\n","2020-03-26 07:50:49.450181: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe90f8d9700 next 516 of size 9437184\n","2020-03-26 07:50:49.450190: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9101d9700 next 517 of size 3072\n","2020-03-26 07:50:49.450198: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9101da300 next 518 of size 9437184\n","2020-03-26 07:50:49.450207: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe910ada300 next 519 of size 2359296\n","2020-03-26 07:50:49.450215: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe910d1a300 next 520 of size 3072\n","2020-03-26 07:50:49.450223: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe910d1af00 next 521 of size 9437184\n","2020-03-26 07:50:49.450232: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe91161af00 next 522 of size 3072\n","2020-03-26 07:50:49.450512: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe91161bb00 next 523 of size 2359296\n","2020-03-26 07:50:49.450535: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe91185bb00 next 524 of size 3072\n","2020-03-26 07:50:49.450544: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe91185c700 next 525 of size 3072\n","2020-03-26 07:50:49.450575: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe91185d300 next 526 of size 2359296\n","2020-03-26 07:50:49.450584: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe911a9d300 next 527 of size 3072\n","2020-03-26 07:50:49.450592: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe911a9df00 next 528 of size 2359296\n","2020-03-26 07:50:49.450601: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe911cddf00 next 529 of size 9437184\n","2020-03-26 07:50:49.450609: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9125ddf00 next 530 of size 2359296\n","2020-03-26 07:50:49.450618: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe91281df00 next 531 of size 3072\n","2020-03-26 07:50:49.450626: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe91281eb00 next 532 of size 3072\n","2020-03-26 07:50:49.450634: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe91281f700 next 533 of size 3072\n","2020-03-26 07:50:49.450643: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe912820300 next 534 of size 3072\n","2020-03-26 07:50:49.450652: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe912820f00 next 535 of size 3072\n","2020-03-26 07:50:49.450660: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe912821b00 next 536 of size 2359296\n","2020-03-26 07:50:49.450668: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe912a61b00 next 537 of size 3072\n","2020-03-26 07:50:49.450677: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe912a62700 next 538 of size 3072\n","2020-03-26 07:50:49.450685: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe912a63300 next 539 of size 2359296\n","2020-03-26 07:50:49.450693: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe912ca3300 next 540 of size 3072\n","2020-03-26 07:50:49.450702: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe912ca3f00 next 541 of size 3072\n","2020-03-26 07:50:49.450710: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe912ca4b00 next 542 of size 2359296\n","2020-03-26 07:50:49.450719: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe912ee4b00 next 543 of size 3072\n","2020-03-26 07:50:49.450727: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe912ee5700 next 544 of size 12288\n","2020-03-26 07:50:49.450735: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe912ee8700 next 545 of size 3072\n","2020-03-26 07:50:49.450744: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe912ee9300 next 546 of size 3072\n","2020-03-26 07:50:49.450982: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe912ee9f00 next 547 of size 3072\n","2020-03-26 07:50:49.451001: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe912eeab00 next 548 of size 3072\n","2020-03-26 07:50:49.451010: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe912eeb700 next 549 of size 3072\n","2020-03-26 07:50:49.451018: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe912eec300 next 550 of size 3072\n","2020-03-26 07:50:49.451027: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe912eecf00 next 551 of size 3072\n","2020-03-26 07:50:49.451035: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe912eedb00 next 552 of size 3072\n","2020-03-26 07:50:49.451044: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe912eee700 next 553 of size 3072\n","2020-03-26 07:50:49.451052: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe912eef300 next 554 of size 198400\n","2020-03-26 07:50:49.451060: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe912f1fa00 next 555 of size 3072\n","2020-03-26 07:50:49.451069: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe912f20600 next 556 of size 12288\n","2020-03-26 07:50:49.451077: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe912f23600 next 557 of size 9437184\n","2020-03-26 07:50:49.451086: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe913823600 next 558 of size 3072\n","2020-03-26 07:50:49.451094: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe913824200 next 559 of size 3072\n","2020-03-26 07:50:49.451102: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe913824e00 next 560 of size 3072\n","2020-03-26 07:50:49.451111: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe913825a00 next 561 of size 3072\n","2020-03-26 07:50:49.451119: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe913826600 next 562 of size 3072\n","2020-03-26 07:50:49.451127: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe913827200 next 563 of size 3072\n","2020-03-26 07:50:49.451135: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe913827e00 next 564 of size 3072\n","2020-03-26 07:50:49.451144: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe913828a00 next 565 of size 3072\n","2020-03-26 07:50:49.451152: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe913829600 next 566 of size 9437184\n","2020-03-26 07:50:49.451161: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe914129600 next 567 of size 2359296\n","2020-03-26 07:50:49.451169: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe914369600 next 568 of size 2359296\n","2020-03-26 07:50:49.451177: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9145a9600 next 569 of size 3072\n","2020-03-26 07:50:49.451468: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9145aa200 next 570 of size 3072\n","2020-03-26 07:50:49.451494: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9145aae00 next 571 of size 3072\n","2020-03-26 07:50:49.451503: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9145aba00 next 572 of size 9437184\n","2020-03-26 07:50:49.451512: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe914eaba00 next 573 of size 3072\n","2020-03-26 07:50:49.451521: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe914eac600 next 574 of size 3072\n","2020-03-26 07:50:49.451529: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe914ead200 next 575 of size 9437184\n","2020-03-26 07:50:49.451538: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9157ad200 next 576 of size 2359296\n","2020-03-26 07:50:49.451546: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9159ed200 next 577 of size 2359296\n","2020-03-26 07:50:49.451555: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe915c2d200 next 578 of size 3072\n","2020-03-26 07:50:49.451564: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe915c2de00 next 579 of size 1572864\n","2020-03-26 07:50:49.451572: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe915dade00 next 580 of size 3072\n","2020-03-26 07:50:49.451581: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe915daea00 next 581 of size 3072\n","2020-03-26 07:50:49.451589: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe915daf600 next 582 of size 3072\n","2020-03-26 07:50:49.451598: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe915db0200 next 583 of size 3072\n","2020-03-26 07:50:49.451606: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe915db0e00 next 584 of size 2359296\n","2020-03-26 07:50:49.451615: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe915ff0e00 next 585 of size 3072\n","2020-03-26 07:50:49.451623: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe915ff1a00 next 586 of size 2359296\n","2020-03-26 07:50:49.451632: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe916231a00 next 587 of size 3072\n","2020-03-26 07:50:49.451640: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe916232600 next 588 of size 3072\n","2020-03-26 07:50:49.451649: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe916233200 next 589 of size 2359296\n","2020-03-26 07:50:49.451657: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe916473200 next 590 of size 3072\n","2020-03-26 07:50:49.451665: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe916473e00 next 591 of size 3072\n","2020-03-26 07:50:49.451905: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe916474a00 next 592 of size 3072\n","2020-03-26 07:50:49.451923: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe916475600 next 593 of size 2359296\n","2020-03-26 07:50:49.451932: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9166b5600 next 594 of size 3072\n","2020-03-26 07:50:49.451941: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9166b6200 next 595 of size 256\n","2020-03-26 07:50:49.451950: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9166b6300 next 596 of size 12288\n","2020-03-26 07:50:49.451958: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9166b9300 next 597 of size 12288\n","2020-03-26 07:50:49.451967: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9166bc300 next 598 of size 3072\n","2020-03-26 07:50:49.451975: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9166bcf00 next 599 of size 2359296\n","2020-03-26 07:50:49.451983: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9168fcf00 next 600 of size 3072\n","2020-03-26 07:50:49.451992: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9168fdb00 next 601 of size 9437184\n","2020-03-26 07:50:49.452000: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9171fdb00 next 602 of size 2359296\n","2020-03-26 07:50:49.452009: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe91743db00 next 603 of size 152189952\n","2020-03-26 07:50:49.452017: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe920561700 next 604 of size 3072\n","2020-03-26 07:50:49.452025: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe920562300 next 605 of size 3072\n","2020-03-26 07:50:49.452034: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe920562f00 next 606 of size 3072\n","2020-03-26 07:50:49.452042: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe920563b00 next 607 of size 9437184\n","2020-03-26 07:50:49.452051: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe920e63b00 next 608 of size 9437184\n","2020-03-26 07:50:49.452059: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe921763b00 next 609 of size 9437184\n","2020-03-26 07:50:49.452067: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe922063b00 next 610 of size 2359296\n","2020-03-26 07:50:49.452076: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9222a3b00 next 611 of size 3072\n","2020-03-26 07:50:49.452084: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9222a4700 next 612 of size 3072\n","2020-03-26 07:50:49.452093: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9222a5300 next 613 of size 3072\n","2020-03-26 07:50:49.452101: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9222a5f00 next 614 of size 1572864\n","2020-03-26 07:50:49.452370: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe922425f00 next 615 of size 2359296\n","2020-03-26 07:50:49.452395: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe922665f00 next 616 of size 3072\n","2020-03-26 07:50:49.452405: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe922666b00 next 617 of size 6144\n","2020-03-26 07:50:49.452413: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe922668300 next 618 of size 3072\n","2020-03-26 07:50:49.452422: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe922668f00 next 619 of size 3072\n","2020-03-26 07:50:49.452430: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe922669b00 next 620 of size 3072\n","2020-03-26 07:50:49.452439: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe92266a700 next 621 of size 3072\n","2020-03-26 07:50:49.452447: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe92266b300 next 680 of size 6291456\n","2020-03-26 07:50:49.452456: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe922c6b300 next 684 of size 6291456\n","2020-03-26 07:50:49.452464: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe92326b300 next 688 of size 6291456\n","2020-03-26 07:50:49.452472: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe92386b300 next 692 of size 6291456\n","2020-03-26 07:50:49.452481: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe923e6b300 next 696 of size 6291456\n","2020-03-26 07:50:49.452489: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe92446b300 next 1226 of size 6291456\n","2020-03-26 07:50:49.452498: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe924a6b300 next 1227 of size 6291456\n","2020-03-26 07:50:49.452506: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe92506b300 next 1228 of size 6291456\n","2020-03-26 07:50:49.452515: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe92566b300 next 1229 of size 6291456\n","2020-03-26 07:50:49.452523: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe925c6b300 next 1230 of size 6291456\n","2020-03-26 07:50:49.452532: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe92626b300 next 1231 of size 6291456\n","2020-03-26 07:50:49.452779: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe92686b300 next 703 of size 6291456\n","2020-03-26 07:50:49.452799: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe926e6b300 next 699 of size 50331648\n","2020-03-26 07:50:49.452808: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe929e6b300 next 700 of size 50331648\n","2020-03-26 07:50:49.452816: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe92ce6b300 next 701 of size 50331648\n","2020-03-26 07:50:49.452825: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe92fe6b300 next 702 of size 50331648\n","2020-03-26 07:50:49.452833: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe932e6b300 next 1221 of size 50331648\n","2020-03-26 07:50:49.452843: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe935e6b300 next 18446744073709551615 of size 68766976\n","2020-03-26 07:50:49.452852: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 536870912\n","2020-03-26 07:50:49.452861: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe93a000000 next 148 of size 9437184\n","2020-03-26 07:50:49.452870: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe93a900000 next 153 of size 2359296\n","2020-03-26 07:50:49.452879: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe93ab40000 next 154 of size 9437184\n","2020-03-26 07:50:49.452887: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe93b440000 next 157 of size 2359296\n","2020-03-26 07:50:49.452895: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe93b680000 next 159 of size 2359296\n","2020-03-26 07:50:49.452904: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe93b8c0000 next 165 of size 2359296\n","2020-03-26 07:50:49.452912: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe93bb00000 next 173 of size 2359296\n","2020-03-26 07:50:49.452921: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe93bd40000 next 175 of size 2359296\n","2020-03-26 07:50:49.452929: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe93bf80000 next 178 of size 2359296\n","2020-03-26 07:50:49.452937: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe93c1c0000 next 179 of size 2359296\n","2020-03-26 07:50:49.452946: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe93c400000 next 186 of size 2359296\n","2020-03-26 07:50:49.452954: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe93c640000 next 187 of size 9437184\n","2020-03-26 07:50:49.452963: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe93cf40000 next 189 of size 9437184\n","2020-03-26 07:50:49.452971: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe93d840000 next 191 of size 2359296\n","2020-03-26 07:50:49.452980: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe93da80000 next 199 of size 2359296\n","2020-03-26 07:50:49.453225: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe93dcc0000 next 205 of size 2359296\n","2020-03-26 07:50:49.453245: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe93df00000 next 207 of size 2359296\n","2020-03-26 07:50:49.453254: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe93e140000 next 212 of size 9437184\n","2020-03-26 07:50:49.453263: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe93ea40000 next 218 of size 2359296\n","2020-03-26 07:50:49.453272: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe93ec80000 next 220 of size 2359296\n","2020-03-26 07:50:49.453280: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe93eec0000 next 225 of size 9437184\n","2020-03-26 07:50:49.453289: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe93f7c0000 next 227 of size 2359296\n","2020-03-26 07:50:49.453297: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe93fa00000 next 232 of size 2359296\n","2020-03-26 07:50:49.453305: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe93fc40000 next 235 of size 9437184\n","2020-03-26 07:50:49.453314: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe940540000 next 236 of size 9437184\n","2020-03-26 07:50:49.453352: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe940e40000 next 238 of size 9437184\n","2020-03-26 07:50:49.453366: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe941740000 next 240 of size 9437184\n","2020-03-26 07:50:49.453378: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe942040000 next 242 of size 9437184\n","2020-03-26 07:50:49.453387: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe942940000 next 246 of size 2359296\n","2020-03-26 07:50:49.453395: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe942b80000 next 247 of size 2359296\n","2020-03-26 07:50:49.453662: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe942dc0000 next 249 of size 9437184\n","2020-03-26 07:50:49.453683: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9436c0000 next 250 of size 1572864\n","2020-03-26 07:50:49.453692: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe943840000 next 253 of size 2359296\n","2020-03-26 07:50:49.453701: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe943a80000 next 260 of size 2359296\n","2020-03-26 07:50:49.453710: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe943cc0000 next 262 of size 2359296\n","2020-03-26 07:50:49.453718: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe943f00000 next 263 of size 2359296\n","2020-03-26 07:50:49.453727: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe944140000 next 270 of size 2359296\n","2020-03-26 07:50:49.453735: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe944380000 next 272 of size 2359296\n","2020-03-26 07:50:49.453744: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9445c0000 next 274 of size 2359296\n","2020-03-26 07:50:49.453752: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe944800000 next 275 of size 9437184\n","2020-03-26 07:50:49.453761: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe945100000 next 276 of size 9437184\n","2020-03-26 07:50:49.453770: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe945a00000 next 278 of size 9437184\n","2020-03-26 07:50:49.453778: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe946300000 next 279 of size 2359296\n","2020-03-26 07:50:49.453786: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe946540000 next 280 of size 9437184\n","2020-03-26 07:50:49.453795: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe946e40000 next 285 of size 2359296\n","2020-03-26 07:50:49.453804: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe947080000 next 288 of size 9437184\n","2020-03-26 07:50:49.453812: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe947980000 next 289 of size 2359296\n","2020-03-26 07:50:49.453821: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe947bc0000 next 295 of size 2359296\n","2020-03-26 07:50:49.453829: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe947e00000 next 296 of size 2359296\n","2020-03-26 07:50:49.453838: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe948040000 next 297 of size 9437184\n","2020-03-26 07:50:49.453864: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe948940000 next 301 of size 2359296\n","2020-03-26 07:50:49.453873: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe948b80000 next 306 of size 2359296\n","2020-03-26 07:50:49.453882: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe948dc0000 next 308 of size 9437184\n","2020-03-26 07:50:49.454136: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9496c0000 next 18446744073709551615 of size 278134784\n","2020-03-26 07:50:49.454157: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 268435456\n","2020-03-26 07:50:49.454167: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe95a000000 next 131 of size 9437184\n","2020-03-26 07:50:49.454176: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe95a900000 next 18446744073709551615 of size 258998272\n","2020-03-26 07:50:49.454184: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 134217728\n","2020-03-26 07:50:49.454194: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe96a000000 next 67 of size 2359296\n","2020-03-26 07:50:49.454202: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe96a240000 next 68 of size 9437184\n","2020-03-26 07:50:49.454211: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe96ab40000 next 72 of size 2359296\n","2020-03-26 07:50:49.454219: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe96ad80000 next 74 of size 2359296\n","2020-03-26 07:50:49.454227: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe96afc0000 next 76 of size 2359296\n","2020-03-26 07:50:49.454236: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe96b200000 next 77 of size 9437184\n","2020-03-26 07:50:49.454244: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe96bb00000 next 79 of size 9437184\n","2020-03-26 07:50:49.454253: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe96c400000 next 81 of size 2359296\n","2020-03-26 07:50:49.454261: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe96c640000 next 82 of size 2359296\n","2020-03-26 07:50:49.454270: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe96c880000 next 85 of size 2359296\n","2020-03-26 07:50:49.454278: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe96cac0000 next 88 of size 2359296\n","2020-03-26 07:50:49.454286: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe96cd00000 next 92 of size 2359296\n","2020-03-26 07:50:49.454295: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe96cf40000 next 93 of size 2359296\n","2020-03-26 07:50:49.454303: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe96d180000 next 100 of size 9437184\n","2020-03-26 07:50:49.454312: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe96da80000 next 101 of size 9437184\n","2020-03-26 07:50:49.454347: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe96e380000 next 108 of size 2359296\n","2020-03-26 07:50:49.454602: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe96e5c0000 next 109 of size 2359296\n","2020-03-26 07:50:49.454623: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe96e800000 next 111 of size 9437184\n","2020-03-26 07:50:49.454632: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe96f100000 next 113 of size 2359296\n","2020-03-26 07:50:49.454641: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe96f340000 next 114 of size 9437184\n","2020-03-26 07:50:49.454650: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe96fc40000 next 120 of size 9437184\n","2020-03-26 07:50:49.454658: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe970540000 next 123 of size 2359296\n","2020-03-26 07:50:49.454667: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe970780000 next 125 of size 9437184\n","2020-03-26 07:50:49.454675: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe971080000 next 126 of size 2359296\n","2020-03-26 07:50:49.454684: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9712c0000 next 128 of size 2359296\n","2020-03-26 07:50:49.454692: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe971500000 next 129 of size 2359296\n","2020-03-26 07:50:49.454701: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe971740000 next 132 of size 2359296\n","2020-03-26 07:50:49.454709: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe971980000 next 143 of size 2359296\n","2020-03-26 07:50:49.454719: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe971bc0000 next 18446744073709551615 of size 4456448\n","2020-03-26 07:50:49.454728: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 67108864\n","2020-03-26 07:50:49.454737: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe972000000 next 30 of size 2359296\n","2020-03-26 07:50:49.454745: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe972240000 next 33 of size 2359296\n","2020-03-26 07:50:49.454754: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe972480000 next 34 of size 2359296\n","2020-03-26 07:50:49.454762: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9726c0000 next 35 of size 2359296\n","2020-03-26 07:50:49.454771: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe972900000 next 36 of size 2359296\n","2020-03-26 07:50:49.454779: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe972b40000 next 41 of size 9437184\n","2020-03-26 07:50:49.454788: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe973440000 next 43 of size 2359296\n","2020-03-26 07:50:49.455038: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe973680000 next 45 of size 9437184\n","2020-03-26 07:50:49.455059: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe973f80000 next 48 of size 2359296\n","2020-03-26 07:50:49.455068: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9741c0000 next 54 of size 2359296\n","2020-03-26 07:50:49.455077: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe974400000 next 55 of size 2359296\n","2020-03-26 07:50:49.455085: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe974640000 next 56 of size 2359296\n","2020-03-26 07:50:49.455094: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe974880000 next 57 of size 2359296\n","2020-03-26 07:50:49.455102: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe974ac0000 next 60 of size 9437184\n","2020-03-26 07:50:49.455112: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9753c0000 next 18446744073709551615 of size 12845056\n","2020-03-26 07:50:49.455121: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 33554432\n","2020-03-26 07:50:49.455130: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe976000000 next 19 of size 2359296\n","2020-03-26 07:50:49.455138: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe976240000 next 23 of size 2359296\n","2020-03-26 07:50:49.455146: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe976480000 next 24 of size 2359296\n","2020-03-26 07:50:49.455169: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe9766c0000 next 25 of size 2359296\n","2020-03-26 07:50:49.455178: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe976900000 next 27 of size 9437184\n","2020-03-26 07:50:49.455187: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe977200000 next 18446744073709551615 of size 14680064\n","2020-03-26 07:50:49.455195: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 16777216\n","2020-03-26 07:50:49.455204: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fe978000000 next 18446744073709551615 of size 16777216\n","2020-03-26 07:50:49.455213: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 1048576\n","2020-03-26 07:50:49.455222: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea00000 next 1 of size 1280\n","2020-03-26 07:50:49.455230: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea00500 next 2 of size 3072\n","2020-03-26 07:50:49.455239: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea01100 next 3 of size 3072\n","2020-03-26 07:50:49.455248: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea01d00 next 4 of size 3072\n","2020-03-26 07:50:49.455599: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea02900 next 5 of size 3072\n","2020-03-26 07:50:49.455632: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea03500 next 7 of size 3072\n","2020-03-26 07:50:49.455647: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea04100 next 8 of size 3072\n","2020-03-26 07:50:49.455662: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea04d00 next 11 of size 3072\n","2020-03-26 07:50:49.455676: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea05900 next 13 of size 3072\n","2020-03-26 07:50:49.455690: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea06500 next 14 of size 3072\n","2020-03-26 07:50:49.455704: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea07100 next 15 of size 3072\n","2020-03-26 07:50:49.455718: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea07d00 next 16 of size 3072\n","2020-03-26 07:50:49.455732: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea08900 next 17 of size 3072\n","2020-03-26 07:50:49.455745: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea09500 next 20 of size 3072\n","2020-03-26 07:50:49.455759: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea0a100 next 21 of size 12288\n","2020-03-26 07:50:49.455773: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea0d100 next 22 of size 12288\n","2020-03-26 07:50:49.455787: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea10100 next 26 of size 12288\n","2020-03-26 07:50:49.455801: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea13100 next 28 of size 12288\n","2020-03-26 07:50:49.455843: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea16100 next 31 of size 3072\n","2020-03-26 07:50:49.455938: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea16d00 next 32 of size 12288\n","2020-03-26 07:50:49.456502: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea19d00 next 37 of size 12288\n","2020-03-26 07:50:49.456532: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea1cd00 next 38 of size 12288\n","2020-03-26 07:50:49.456543: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea1fd00 next 39 of size 3072\n","2020-03-26 07:50:49.456552: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea20900 next 40 of size 3072\n","2020-03-26 07:50:49.456561: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea21500 next 42 of size 3072\n","2020-03-26 07:50:49.456570: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea22100 next 44 of size 3072\n","2020-03-26 07:50:49.456578: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea22d00 next 46 of size 3072\n","2020-03-26 07:50:49.456587: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea23900 next 47 of size 3072\n","2020-03-26 07:50:49.456595: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea24500 next 49 of size 3072\n","2020-03-26 07:50:49.456603: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea25100 next 50 of size 12288\n","2020-03-26 07:50:49.456612: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea28100 next 51 of size 256\n","2020-03-26 07:50:49.456621: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea28200 next 52 of size 256\n","2020-03-26 07:50:49.456629: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea28300 next 53 of size 3072\n","2020-03-26 07:50:49.456638: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea28f00 next 58 of size 3072\n","2020-03-26 07:50:49.456646: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0x7fea3ea29b00 next 59 of size 256\n","2020-03-26 07:50:49.456655: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea29c00 next 61 of size 3072\n","2020-03-26 07:50:49.456663: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea2a800 next 62 of size 3072\n","2020-03-26 07:50:49.456691: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea2b400 next 63 of size 3072\n","2020-03-26 07:50:49.456701: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea2c000 next 64 of size 3072\n","2020-03-26 07:50:49.456709: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea2cc00 next 65 of size 3072\n","2020-03-26 07:50:49.456718: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea2d800 next 69 of size 3072\n","2020-03-26 07:50:49.456726: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea2e400 next 70 of size 3072\n","2020-03-26 07:50:49.456735: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea2f000 next 71 of size 3072\n","2020-03-26 07:50:49.457029: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea2fc00 next 73 of size 3072\n","2020-03-26 07:50:49.457050: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea30800 next 75 of size 3072\n","2020-03-26 07:50:49.457059: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea31400 next 78 of size 12288\n","2020-03-26 07:50:49.457068: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea34400 next 80 of size 12288\n","2020-03-26 07:50:49.457076: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea37400 next 83 of size 3072\n","2020-03-26 07:50:49.457085: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea38000 next 84 of size 3072\n","2020-03-26 07:50:49.457093: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea38c00 next 86 of size 3072\n","2020-03-26 07:50:49.457102: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea39800 next 87 of size 3072\n","2020-03-26 07:50:49.457110: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea3a400 next 89 of size 3072\n","2020-03-26 07:50:49.457118: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea3b000 next 90 of size 3072\n","2020-03-26 07:50:49.457127: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea3bc00 next 91 of size 3072\n","2020-03-26 07:50:49.457135: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea3c800 next 94 of size 3072\n","2020-03-26 07:50:49.457143: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea3d400 next 95 of size 3072\n","2020-03-26 07:50:49.457152: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea3e000 next 96 of size 3072\n","2020-03-26 07:50:49.457160: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea3ec00 next 97 of size 3072\n","2020-03-26 07:50:49.457168: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea3f800 next 98 of size 3072\n","2020-03-26 07:50:49.457177: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea40400 next 99 of size 3072\n","2020-03-26 07:50:49.457185: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea41000 next 102 of size 3072\n","2020-03-26 07:50:49.457194: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea41c00 next 103 of size 3072\n","2020-03-26 07:50:49.457202: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea42800 next 104 of size 3072\n","2020-03-26 07:50:49.457210: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea43400 next 105 of size 3072\n","2020-03-26 07:50:49.457219: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea44000 next 106 of size 3072\n","2020-03-26 07:50:49.457227: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea44c00 next 107 of size 3072\n","2020-03-26 07:50:49.457235: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea45800 next 110 of size 3072\n","2020-03-26 07:50:49.457244: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea46400 next 112 of size 3072\n","2020-03-26 07:50:49.457252: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea47000 next 115 of size 3072\n","2020-03-26 07:50:49.457260: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea47c00 next 116 of size 3072\n","2020-03-26 07:50:49.457269: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea48800 next 117 of size 3072\n","2020-03-26 07:50:49.457277: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea49400 next 118 of size 3072\n","2020-03-26 07:50:49.457285: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea4a000 next 119 of size 3072\n","2020-03-26 07:50:49.457596: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea4ac00 next 121 of size 3072\n","2020-03-26 07:50:49.457619: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea4b800 next 122 of size 3072\n","2020-03-26 07:50:49.457628: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea4c400 next 124 of size 3072\n","2020-03-26 07:50:49.457637: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea4d000 next 127 of size 3072\n","2020-03-26 07:50:49.457645: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea4dc00 next 133 of size 3072\n","2020-03-26 07:50:49.457654: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea4e800 next 134 of size 3072\n","2020-03-26 07:50:49.457663: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea4f400 next 135 of size 3072\n","2020-03-26 07:50:49.457671: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea50000 next 136 of size 3072\n","2020-03-26 07:50:49.457679: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea50c00 next 137 of size 3072\n","2020-03-26 07:50:49.457688: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea51800 next 138 of size 3072\n","2020-03-26 07:50:49.457696: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea52400 next 139 of size 3072\n","2020-03-26 07:50:49.457705: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea53000 next 140 of size 3072\n","2020-03-26 07:50:49.457713: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea53c00 next 141 of size 3072\n","2020-03-26 07:50:49.457722: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea54800 next 142 of size 3072\n","2020-03-26 07:50:49.457730: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea55400 next 144 of size 3072\n","2020-03-26 07:50:49.457739: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea56000 next 145 of size 3072\n","2020-03-26 07:50:49.457747: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea56c00 next 146 of size 3072\n","2020-03-26 07:50:49.457756: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea57800 next 149 of size 3072\n","2020-03-26 07:50:49.457764: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea58400 next 150 of size 3072\n","2020-03-26 07:50:49.457773: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea59000 next 151 of size 3072\n","2020-03-26 07:50:49.457781: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea59c00 next 152 of size 3072\n","2020-03-26 07:50:49.457790: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea5a800 next 155 of size 3072\n","2020-03-26 07:50:49.457798: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea5b400 next 156 of size 3072\n","2020-03-26 07:50:49.457806: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea5c000 next 158 of size 3072\n","2020-03-26 07:50:49.457815: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea5cc00 next 160 of size 3072\n","2020-03-26 07:50:49.458073: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea5d800 next 161 of size 12288\n","2020-03-26 07:50:49.458092: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea60800 next 162 of size 3072\n","2020-03-26 07:50:49.458102: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea61400 next 163 of size 3072\n","2020-03-26 07:50:49.458110: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea62000 next 164 of size 3072\n","2020-03-26 07:50:49.458119: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea62c00 next 166 of size 3072\n","2020-03-26 07:50:49.458127: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea63800 next 167 of size 3072\n","2020-03-26 07:50:49.458136: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea64400 next 168 of size 3072\n","2020-03-26 07:50:49.458144: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea65000 next 169 of size 3072\n","2020-03-26 07:50:49.458153: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea65c00 next 170 of size 3072\n","2020-03-26 07:50:49.458161: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea66800 next 171 of size 3072\n","2020-03-26 07:50:49.458169: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea67400 next 172 of size 3072\n","2020-03-26 07:50:49.458178: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea68000 next 174 of size 3072\n","2020-03-26 07:50:49.458186: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea68c00 next 176 of size 3072\n","2020-03-26 07:50:49.458194: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea69800 next 177 of size 3072\n","2020-03-26 07:50:49.458203: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea6a400 next 180 of size 3072\n","2020-03-26 07:50:49.458211: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea6b000 next 181 of size 3072\n","2020-03-26 07:50:49.458220: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea6bc00 next 182 of size 3072\n","2020-03-26 07:50:49.458228: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea6c800 next 183 of size 3072\n","2020-03-26 07:50:49.458237: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea6d400 next 184 of size 3072\n","2020-03-26 07:50:49.458245: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea6e000 next 185 of size 3072\n","2020-03-26 07:50:49.458253: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea6ec00 next 188 of size 3072\n","2020-03-26 07:50:49.458262: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea6f800 next 190 of size 3072\n","2020-03-26 07:50:49.458270: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea70400 next 192 of size 3072\n","2020-03-26 07:50:49.458279: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea71000 next 193 of size 3072\n","2020-03-26 07:50:49.458287: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea71c00 next 194 of size 3072\n","2020-03-26 07:50:49.458590: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ea72800 next 195 of size 198400\n","2020-03-26 07:50:49.458613: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaa2f00 next 196 of size 3072\n","2020-03-26 07:50:49.458622: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaa3b00 next 197 of size 3072\n","2020-03-26 07:50:49.458631: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaa4700 next 198 of size 6144\n","2020-03-26 07:50:49.458640: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaa5f00 next 200 of size 3072\n","2020-03-26 07:50:49.458648: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaa6b00 next 201 of size 3072\n","2020-03-26 07:50:49.458657: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaa7700 next 202 of size 3072\n","2020-03-26 07:50:49.458665: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaa8300 next 203 of size 3072\n","2020-03-26 07:50:49.458673: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaa8f00 next 204 of size 3072\n","2020-03-26 07:50:49.458682: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaa9b00 next 206 of size 3072\n","2020-03-26 07:50:49.458690: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaaa700 next 208 of size 3072\n","2020-03-26 07:50:49.458698: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaab300 next 209 of size 3072\n","2020-03-26 07:50:49.458707: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaabf00 next 210 of size 3072\n","2020-03-26 07:50:49.458715: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaacb00 next 211 of size 6144\n","2020-03-26 07:50:49.458724: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaae300 next 213 of size 12288\n","2020-03-26 07:50:49.458732: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eab1300 next 214 of size 3072\n","2020-03-26 07:50:49.458741: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eab1f00 next 215 of size 3072\n","2020-03-26 07:50:49.458749: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eab2b00 next 216 of size 3072\n","2020-03-26 07:50:49.458757: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eab3700 next 217 of size 3072\n","2020-03-26 07:50:49.458766: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eab4300 next 219 of size 3072\n","2020-03-26 07:50:49.458774: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eab4f00 next 221 of size 3072\n","2020-03-26 07:50:49.458782: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eab5b00 next 222 of size 3072\n","2020-03-26 07:50:49.458791: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eab6700 next 223 of size 3072\n","2020-03-26 07:50:49.458799: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eab7300 next 224 of size 3072\n","2020-03-26 07:50:49.458807: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eab7f00 next 226 of size 3072\n","2020-03-26 07:50:49.458816: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eab8b00 next 228 of size 12288\n","2020-03-26 07:50:49.458824: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eabbb00 next 229 of size 3072\n","2020-03-26 07:50:49.458833: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eabc700 next 230 of size 3072\n","2020-03-26 07:50:49.458841: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eabd300 next 231 of size 3072\n","2020-03-26 07:50:49.458849: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eabdf00 next 233 of size 3072\n","2020-03-26 07:50:49.458868: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eabeb00 next 234 of size 3072\n","2020-03-26 07:50:49.459102: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eabf700 next 237 of size 12288\n","2020-03-26 07:50:49.459120: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eac2700 next 239 of size 12288\n","2020-03-26 07:50:49.459129: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eac5700 next 241 of size 12288\n","2020-03-26 07:50:49.459137: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eac8700 next 243 of size 3072\n","2020-03-26 07:50:49.459146: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eac9300 next 244 of size 3072\n","2020-03-26 07:50:49.459154: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eac9f00 next 245 of size 3072\n","2020-03-26 07:50:49.459163: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eacab00 next 248 of size 3072\n","2020-03-26 07:50:49.459171: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eacb700 next 251 of size 3072\n","2020-03-26 07:50:49.459179: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eacc300 next 252 of size 3072\n","2020-03-26 07:50:49.459188: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaccf00 next 254 of size 3072\n","2020-03-26 07:50:49.459196: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eacdb00 next 255 of size 3072\n","2020-03-26 07:50:49.459205: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eace700 next 256 of size 3072\n","2020-03-26 07:50:49.459213: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eacf300 next 257 of size 3072\n","2020-03-26 07:50:49.459221: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eacff00 next 258 of size 3072\n","2020-03-26 07:50:49.459230: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ead0b00 next 259 of size 3072\n","2020-03-26 07:50:49.459238: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ead1700 next 261 of size 3072\n","2020-03-26 07:50:49.459247: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ead2300 next 264 of size 3072\n","2020-03-26 07:50:49.459255: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ead2f00 next 265 of size 3072\n","2020-03-26 07:50:49.459264: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ead3b00 next 266 of size 3072\n","2020-03-26 07:50:49.459275: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ead4700 next 267 of size 3072\n","2020-03-26 07:50:49.459610: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ead5300 next 268 of size 3072\n","2020-03-26 07:50:49.459633: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ead5f00 next 269 of size 3072\n","2020-03-26 07:50:49.459642: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ead6b00 next 271 of size 3072\n","2020-03-26 07:50:49.459651: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ead7700 next 273 of size 3072\n","2020-03-26 07:50:49.459660: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ead8300 next 277 of size 3072\n","2020-03-26 07:50:49.459668: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ead8f00 next 281 of size 3072\n","2020-03-26 07:50:49.459677: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ead9b00 next 282 of size 3072\n","2020-03-26 07:50:49.459685: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eada700 next 283 of size 3072\n","2020-03-26 07:50:49.459694: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eadb300 next 284 of size 12288\n","2020-03-26 07:50:49.459702: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eade300 next 286 of size 12288\n","2020-03-26 07:50:49.459711: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eae1300 next 287 of size 3072\n","2020-03-26 07:50:49.459719: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eae1f00 next 290 of size 3072\n","2020-03-26 07:50:49.459728: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eae2b00 next 291 of size 3072\n","2020-03-26 07:50:49.459736: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eae3700 next 292 of size 3072\n","2020-03-26 07:50:49.459744: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eae4300 next 293 of size 3072\n","2020-03-26 07:50:49.459753: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eae4f00 next 294 of size 3072\n","2020-03-26 07:50:49.459761: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eae5b00 next 298 of size 3072\n","2020-03-26 07:50:49.459770: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eae6700 next 299 of size 3072\n","2020-03-26 07:50:49.459778: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eae7300 next 300 of size 3072\n","2020-03-26 07:50:49.459786: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eae7f00 next 302 of size 3072\n","2020-03-26 07:50:49.459795: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eae8b00 next 303 of size 3072\n","2020-03-26 07:50:49.459803: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eae9700 next 304 of size 3072\n","2020-03-26 07:50:49.459812: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaea300 next 305 of size 3072\n","2020-03-26 07:50:49.459820: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaeaf00 next 307 of size 3072\n","2020-03-26 07:50:49.459828: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaebb00 next 309 of size 3072\n","2020-03-26 07:50:49.459837: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaec700 next 310 of size 3072\n","2020-03-26 07:50:49.459845: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaed300 next 311 of size 3072\n","2020-03-26 07:50:49.459854: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaedf00 next 315 of size 3072\n","2020-03-26 07:50:49.459876: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaeeb00 next 316 of size 3072\n","2020-03-26 07:50:49.459885: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaef700 next 320 of size 3072\n","2020-03-26 07:50:49.459893: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaf0300 next 321 of size 3072\n","2020-03-26 07:50:49.459902: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaf0f00 next 322 of size 3072\n","2020-03-26 07:50:49.460077: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaf1b00 next 323 of size 12288\n","2020-03-26 07:50:49.460093: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaf4b00 next 327 of size 3072\n","2020-03-26 07:50:49.460102: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaf5700 next 330 of size 3072\n","2020-03-26 07:50:49.460110: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaf6300 next 332 of size 3072\n","2020-03-26 07:50:49.460119: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaf6f00 next 334 of size 3072\n","2020-03-26 07:50:49.460127: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaf7b00 next 335 of size 3072\n","2020-03-26 07:50:49.460136: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaf8700 next 336 of size 3072\n","2020-03-26 07:50:49.460144: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaf9300 next 337 of size 3072\n","2020-03-26 07:50:49.460153: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaf9f00 next 339 of size 3072\n","2020-03-26 07:50:49.460161: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eafab00 next 340 of size 3072\n","2020-03-26 07:50:49.460169: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eafb700 next 347 of size 3072\n","2020-03-26 07:50:49.460178: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eafc300 next 348 of size 3072\n","2020-03-26 07:50:49.460186: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eafcf00 next 349 of size 3072\n","2020-03-26 07:50:49.460194: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eafdb00 next 351 of size 3072\n","2020-03-26 07:50:49.460203: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eafe700 next 353 of size 3072\n","2020-03-26 07:50:49.460232: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3eaff300 next 18446744073709551615 of size 3328\n","2020-03-26 07:50:49.460241: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 4194304\n","2020-03-26 07:50:49.460378: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3ee00000 next 18446744073709551615 of size 4194304\n","2020-03-26 07:50:49.460397: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 4194304\n","2020-03-26 07:50:49.460407: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea3f200000 next 18446744073709551615 of size 4194304\n","2020-03-26 07:50:49.460415: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 16777216\n","2020-03-26 07:50:49.460680: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7fea55000000 next 18446744073709551615 of size 16777216\n","2020-03-26 07:50:49.460701: I tensorflow/core/common_runtime/bfc_allocator.cc:914]      Summary of in-use Chunks by size: \n","2020-03-26 07:50:49.460717: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 66 Chunks of size 256 totalling 16.5KiB\n","2020-03-26 07:50:49.460727: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 3 Chunks of size 512 totalling 1.5KiB\n","2020-03-26 07:50:49.460736: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 1280 totalling 1.2KiB\n","2020-03-26 07:50:49.460745: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 568 Chunks of size 3072 totalling 1.66MiB\n","2020-03-26 07:50:49.460755: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 3328 totalling 3.2KiB\n","2020-03-26 07:50:49.460763: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 5120 totalling 5.0KiB\n","2020-03-26 07:50:49.460773: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 12 Chunks of size 6144 totalling 72.0KiB\n","2020-03-26 07:50:49.460782: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 40 Chunks of size 8192 totalling 320.0KiB\n","2020-03-26 07:50:49.460791: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 60 Chunks of size 12288 totalling 720.0KiB\n","2020-03-26 07:50:49.460801: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 16384 totalling 16.0KiB\n","2020-03-26 07:50:49.460810: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 5 Chunks of size 198400 totalling 968.8KiB\n","2020-03-26 07:50:49.460819: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 5 Chunks of size 1572864 totalling 7.50MiB\n","2020-03-26 07:50:49.460828: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 2289408 totalling 2.18MiB\n","2020-03-26 07:50:49.460837: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 297 Chunks of size 2359296 totalling 668.25MiB\n","2020-03-26 07:50:49.460846: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 3 Chunks of size 4194304 totalling 12.00MiB\n","2020-03-26 07:50:49.460855: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 4456448 totalling 4.25MiB\n","2020-03-26 07:50:49.460875: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 126 Chunks of size 6291456 totalling 756.00MiB\n","2020-03-26 07:50:49.460885: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 140 Chunks of size 9437184 totalling 1.23GiB\n","2020-03-26 07:50:49.460894: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 11530752 totalling 11.00MiB\n","2020-03-26 07:50:49.461130: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 12845056 totalling 12.25MiB\n","2020-03-26 07:50:49.461149: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 14680064 totalling 14.00MiB\n","2020-03-26 07:50:49.461159: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 15853312 totalling 30.24MiB\n","2020-03-26 07:50:49.461169: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 16777216 totalling 32.00MiB\n","2020-03-26 07:50:49.461178: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 45 Chunks of size 25165824 totalling 1.05GiB\n","2020-03-26 07:50:49.461187: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 39 Chunks of size 50331648 totalling 1.83GiB\n","2020-03-26 07:50:49.461196: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 51904512 totalling 49.50MiB\n","2020-03-26 07:50:49.461206: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 68766976 totalling 65.58MiB\n","2020-03-26 07:50:49.461215: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 69206016 totalling 66.00MiB\n","2020-03-26 07:50:49.461224: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 76519680 totalling 72.97MiB\n","2020-03-26 07:50:49.461234: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 4 Chunks of size 152189952 totalling 580.56MiB\n","2020-03-26 07:50:49.461243: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 258998272 totalling 247.00MiB\n","2020-03-26 07:50:49.461252: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 278134784 totalling 265.25MiB\n","2020-03-26 07:50:49.461261: I tensorflow/core/common_runtime/bfc_allocator.cc:921] Sum Total of in-use chunks: 6.95GiB\n","2020-03-26 07:50:49.461270: I tensorflow/core/common_runtime/bfc_allocator.cc:923] total_region_allocated_bytes_: 7470045440 memory_limit_: 7470045594 available bytes: 154 curr_region_allocation_bytes_: 8589934592\n","2020-03-26 07:50:49.461284: I tensorflow/core/common_runtime/bfc_allocator.cc:929] Stats: \n","Limit:                  7470045594\n","InUse:                  7457756672\n","MaxInUse:               7457758976\n","NumAllocs:                    1692\n","MaxAllocSize:            278134784\n","\n","2020-03-26 07:50:49.461396: W tensorflow/core/common_runtime/bfc_allocator.cc:424] ***********************************************************************************************x****\n","2020-03-26 07:50:49.461697: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at softmax_op_gpu.cu.cc:157 : Resource exhausted: OOM when allocating tensor with shape[4,12,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n","ERROR:tensorflow:Error recorded from training_loop: 2 root error(s) found.\n","  (0) Resource exhausted: OOM when allocating tensor with shape[4,12,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n","\t [[node bert/encoder/layer_9/attention/self/Softmax (defined at /tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/ops.py:1748) ]]\n","Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n","\n","\t [[add_1/_4993]]\n","Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n","\n","  (1) Resource exhausted: OOM when allocating tensor with shape[4,12,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n","\t [[node bert/encoder/layer_9/attention/self/Softmax (defined at /tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/ops.py:1748) ]]\n","Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n","\n","0 successful operations.\n","0 derived errors ignored.\n","\n","Original stack trace for 'bert/encoder/layer_9/attention/self/Softmax':\n","  File \"drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/run_pretraining.py\", line 493, in <module>\n","    tf.app.run()\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n","    sys.exit(main(argv))\n","  File \"drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/run_pretraining.py\", line 466, in main\n","    estimator.train(input_fn=train_input_fn, max_steps=FLAGS.num_train_steps)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 3030, in train\n","    saving_listeners=saving_listeners)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\n","    loss = self._train_model(input_fn, hooks, saving_listeners)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\n","    return self._train_model_default(input_fn, hooks, saving_listeners)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1191, in _train_model_default\n","    features, labels, ModeKeys.TRAIN, self.config)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 2857, in _call_model_fn\n","    config)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1149, in _call_model_fn\n","    model_fn_results = self._model_fn(features=features, **kwargs)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 3126, in _model_fn\n","    features, labels, is_export_mode=is_export_mode)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 1663, in call_without_tpu\n","    return self._call_model_fn(features, labels, is_export_mode=is_export_mode)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 1994, in _call_model_fn\n","    estimator_spec = self._model_fn(features=features, **kwargs)\n","  File \"drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/run_pretraining.py\", line 137, in model_fn\n","    use_one_hot_embeddings=use_one_hot_embeddings)\n","  File \"/content/drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/modeling.py\", line 216, in __init__\n","    do_return_all_layers=True)\n","  File \"/content/drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/modeling.py\", line 844, in transformer_model\n","    to_seq_length=seq_length)\n","  File \"/content/drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/modeling.py\", line 720, in attention_layer\n","    attention_probs = tf.nn.softmax(attention_scores)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n","    return func(*args, **kwargs)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_ops.py\", line 2958, in softmax\n","    return _softmax(logits, gen_nn_ops.softmax, axis, name)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_ops.py\", line 2891, in _softmax\n","    return compute_op(logits, name=name)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/gen_nn_ops.py\", line 11376, in softmax\n","    \"Softmax\", logits=logits, name=name)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n","    op_def=op_def)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n","    return func(*args, **kwargs)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n","    attrs, op_def, compute_device)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n","    op_def=op_def)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n","    self._traceback = tf_stack.extract_stack()\n","\n","E0326 07:50:52.561890 140646457186176 error_handling.py:75] Error recorded from training_loop: 2 root error(s) found.\n","  (0) Resource exhausted: OOM when allocating tensor with shape[4,12,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n","\t [[node bert/encoder/layer_9/attention/self/Softmax (defined at /tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/ops.py:1748) ]]\n","Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n","\n","\t [[add_1/_4993]]\n","Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n","\n","  (1) Resource exhausted: OOM when allocating tensor with shape[4,12,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n","\t [[node bert/encoder/layer_9/attention/self/Softmax (defined at /tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/ops.py:1748) ]]\n","Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n","\n","0 successful operations.\n","0 derived errors ignored.\n","\n","Original stack trace for 'bert/encoder/layer_9/attention/self/Softmax':\n","  File \"drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/run_pretraining.py\", line 493, in <module>\n","    tf.app.run()\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n","    sys.exit(main(argv))\n","  File \"drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/run_pretraining.py\", line 466, in main\n","    estimator.train(input_fn=train_input_fn, max_steps=FLAGS.num_train_steps)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 3030, in train\n","    saving_listeners=saving_listeners)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\n","    loss = self._train_model(input_fn, hooks, saving_listeners)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\n","    return self._train_model_default(input_fn, hooks, saving_listeners)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1191, in _train_model_default\n","    features, labels, ModeKeys.TRAIN, self.config)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 2857, in _call_model_fn\n","    config)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1149, in _call_model_fn\n","    model_fn_results = self._model_fn(features=features, **kwargs)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 3126, in _model_fn\n","    features, labels, is_export_mode=is_export_mode)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 1663, in call_without_tpu\n","    return self._call_model_fn(features, labels, is_export_mode=is_export_mode)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 1994, in _call_model_fn\n","    estimator_spec = self._model_fn(features=features, **kwargs)\n","  File \"drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/run_pretraining.py\", line 137, in model_fn\n","    use_one_hot_embeddings=use_one_hot_embeddings)\n","  File \"/content/drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/modeling.py\", line 216, in __init__\n","    do_return_all_layers=True)\n","  File \"/content/drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/modeling.py\", line 844, in transformer_model\n","    to_seq_length=seq_length)\n","  File \"/content/drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/modeling.py\", line 720, in attention_layer\n","    attention_probs = tf.nn.softmax(attention_scores)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n","    return func(*args, **kwargs)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_ops.py\", line 2958, in softmax\n","    return _softmax(logits, gen_nn_ops.softmax, axis, name)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_ops.py\", line 2891, in _softmax\n","    return compute_op(logits, name=name)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/gen_nn_ops.py\", line 11376, in softmax\n","    \"Softmax\", logits=logits, name=name)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n","    op_def=op_def)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n","    return func(*args, **kwargs)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n","    attrs, op_def, compute_device)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n","    op_def=op_def)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n","    self._traceback = tf_stack.extract_stack()\n","\n","INFO:tensorflow:training_loop marked as finished\n","I0326 07:50:52.569368 140646457186176 error_handling.py:101] training_loop marked as finished\n","WARNING:tensorflow:Reraising captured error\n","W0326 07:50:52.569533 140646457186176 error_handling.py:135] Reraising captured error\n","Traceback (most recent call last):\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n","    return fn(*args)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n","    target_list, run_metadata)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n","    run_metadata)\n","tensorflow.python.framework.errors_impl.ResourceExhaustedError: 2 root error(s) found.\n","  (0) Resource exhausted: OOM when allocating tensor with shape[4,12,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n","\t [[{{node bert/encoder/layer_9/attention/self/Softmax}}]]\n","Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n","\n","\t [[add_1/_4993]]\n","Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n","\n","  (1) Resource exhausted: OOM when allocating tensor with shape[4,12,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n","\t [[{{node bert/encoder/layer_9/attention/self/Softmax}}]]\n","Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n","\n","0 successful operations.\n","0 derived errors ignored.\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/run_pretraining.py\", line 493, in <module>\n","    tf.app.run()\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n","    sys.exit(main(argv))\n","  File \"drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/run_pretraining.py\", line 466, in main\n","    estimator.train(input_fn=train_input_fn, max_steps=FLAGS.num_train_steps)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 3035, in train\n","    rendezvous.raise_errors()\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/tpu/error_handling.py\", line 136, in raise_errors\n","    six.reraise(typ, value, traceback)\n","  File \"/usr/local/lib/python3.6/dist-packages/six.py\", line 693, in reraise\n","    raise value\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 3030, in train\n","    saving_listeners=saving_listeners)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\n","    loss = self._train_model(input_fn, hooks, saving_listeners)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\n","    return self._train_model_default(input_fn, hooks, saving_listeners)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1195, in _train_model_default\n","    saving_listeners)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1494, in _train_with_estimator_spec\n","    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/training/monitored_session.py\", line 754, in run\n","    run_metadata=run_metadata)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/training/monitored_session.py\", line 1259, in run\n","    run_metadata=run_metadata)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/training/monitored_session.py\", line 1360, in run\n","    raise six.reraise(*original_exc_info)\n","  File \"/usr/local/lib/python3.6/dist-packages/six.py\", line 693, in reraise\n","    raise value\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/training/monitored_session.py\", line 1345, in run\n","    return self._sess.run(*args, **kwargs)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/training/monitored_session.py\", line 1418, in run\n","    run_metadata=run_metadata)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/training/monitored_session.py\", line 1176, in run\n","    return self._sess.run(*args, **kwargs)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/client/session.py\", line 956, in run\n","    run_metadata_ptr)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/client/session.py\", line 1180, in _run\n","    feed_dict_tensor, options, run_metadata)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n","    run_metadata)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/client/session.py\", line 1384, in _do_call\n","    raise type(e)(node_def, op, message)\n","tensorflow.python.framework.errors_impl.ResourceExhaustedError: 2 root error(s) found.\n","  (0) Resource exhausted: OOM when allocating tensor with shape[4,12,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n","\t [[node bert/encoder/layer_9/attention/self/Softmax (defined at /tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/ops.py:1748) ]]\n","Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n","\n","\t [[add_1/_4993]]\n","Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n","\n","  (1) Resource exhausted: OOM when allocating tensor with shape[4,12,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n","\t [[node bert/encoder/layer_9/attention/self/Softmax (defined at /tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/ops.py:1748) ]]\n","Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n","\n","0 successful operations.\n","0 derived errors ignored.\n","\n","Original stack trace for 'bert/encoder/layer_9/attention/self/Softmax':\n","  File \"drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/run_pretraining.py\", line 493, in <module>\n","    tf.app.run()\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n","    sys.exit(main(argv))\n","  File \"drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/run_pretraining.py\", line 466, in main\n","    estimator.train(input_fn=train_input_fn, max_steps=FLAGS.num_train_steps)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 3030, in train\n","    saving_listeners=saving_listeners)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\n","    loss = self._train_model(input_fn, hooks, saving_listeners)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\n","    return self._train_model_default(input_fn, hooks, saving_listeners)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1191, in _train_model_default\n","    features, labels, ModeKeys.TRAIN, self.config)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 2857, in _call_model_fn\n","    config)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1149, in _call_model_fn\n","    model_fn_results = self._model_fn(features=features, **kwargs)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 3126, in _model_fn\n","    features, labels, is_export_mode=is_export_mode)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 1663, in call_without_tpu\n","    return self._call_model_fn(features, labels, is_export_mode=is_export_mode)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 1994, in _call_model_fn\n","    estimator_spec = self._model_fn(features=features, **kwargs)\n","  File \"drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/run_pretraining.py\", line 137, in model_fn\n","    use_one_hot_embeddings=use_one_hot_embeddings)\n","  File \"/content/drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/modeling.py\", line 216, in __init__\n","    do_return_all_layers=True)\n","  File \"/content/drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/modeling.py\", line 844, in transformer_model\n","    to_seq_length=seq_length)\n","  File \"/content/drive/My Drive/Colab Notebooks/BERT/src/make_bert_model/modeling.py\", line 720, in attention_layer\n","    attention_probs = tf.nn.softmax(attention_scores)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n","    return func(*args, **kwargs)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_ops.py\", line 2958, in softmax\n","    return _softmax(logits, gen_nn_ops.softmax, axis, name)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_ops.py\", line 2891, in _softmax\n","    return compute_op(logits, name=name)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/gen_nn_ops.py\", line 11376, in softmax\n","    \"Softmax\", logits=logits, name=name)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n","    op_def=op_def)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n","    return func(*args, **kwargs)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n","    attrs, op_def, compute_device)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n","    op_def=op_def)\n","  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n","    self._traceback = tf_stack.extract_stack()\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rSRRbSgqTmnB"},"source":["\n","```bash\n","function ClickConnect() {\n","    var buttons = document.querySelectorAll(\"colab-dialog.yes-no-dialog paper-button#cancel\");\n","    buttons.forEach(function(btn) {\n","        btn.click();\n","    });\n","    console.log(\"1분마다 자동 재연결\");\n","    document.querySelector(\"colab-toolbar-button#connect\").click();\n","}\n","setInterval(ClickConnect, 1000 * 60);\n","\n","```"]},{"cell_type":"markdown","metadata":{"id":"hPX_Npp8rIFe"},"source":["## 5. Fine-Tuning1 - KorQuAD 학습\n","- BERT run_squad.py\n","- 데이터 : KorQuAD 1.0 데이터\n","- output : KorQuAD/output/\n","- 파라미터 : do_train=True, do_predict=True,<br>\n","train_batch_size=16, learning_rate=2e-5,<br>\n","num_train_epochs=1.0, max_seq_length=128,<br>\n","doc_stride=128, do_lower_case=False\n"]},{"cell_type":"code","metadata":{"id":"lNjyQjIF18I0","colab":{"base_uri":"https://localhost:8080/","height":694},"executionInfo":{"status":"ok","timestamp":1585634722073,"user_tz":-540,"elapsed":55151,"user":{"displayName":"Minkyung Park","photoUrl":"","userId":"13181002600298228191"}},"outputId":"7f7ce0f4-3956-4303-f0c6-98b7cb2c52ce"},"source":["pip install tensorflow==1.14.0"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==1.14.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n","\u001b[K     |████████████████████████████████| 109.2MB 1.2MB/s \n","\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.27.2)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n","Collecting tensorboard<1.15.0,>=1.14.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 52.9MB/s \n","\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.9.0)\n","Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.18.2)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.3)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n","Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n","\u001b[K     |████████████████████████████████| 491kB 54.4MB/s \n","\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.34.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (46.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n","Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n","  Found existing installation: tensorboard 2.1.1\n","    Uninstalling tensorboard-2.1.1:\n","      Successfully uninstalled tensorboard-2.1.1\n","  Found existing installation: tensorflow-estimator 2.2.0rc0\n","    Uninstalling tensorflow-estimator-2.2.0rc0:\n","      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n","  Found existing installation: tensorflow 2.2.0rc1\n","    Uninstalling tensorflow-2.2.0rc1:\n","      Successfully uninstalled tensorflow-2.2.0rc1\n","Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bvxHPh8rrPGD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607073600680,"user_tz":-540,"elapsed":4798,"user":{"displayName":"김정인","photoUrl":"","userId":"08669711361714769540"}},"outputId":"368d5632-d695-4046-ee55-f11eff1f348c"},"source":["!python drive/MyDrive/BERT/src/make_bert_model/run_squad.py \\\n","--vocab_file=drive/MyDrive/BERT/rsc/conf/vocab.txt \\\n","--bert_config_file=drive/MyDrive/BERT/rsc/conf/bert_config.json \\\n","--init_checkpoint=drive/MyDrive/BERT/rsc/pretrained_model/model_output_512_model.ckpt-200000 \\\n","--do_train=True \\\n","--train_file=drive/MyDrive/BERT/rsc/KorQuAD/KorQuAD_v1.0_train.json \\\n","--do_predict=True \\\n","--predict_file=drive/MyDrive/BERT/rsc/KorQuAD/KorQuAD_v1.0_dev.json \\\n","--train_batch_size=16 \\\n","--learning_rate=2e-5 \\\n","--num_train_epochs=1.0 \\\n","--max_seq_length=128 \\\n","--doc_stride=128 \\\n","--output_dir=drive/MyDrive/BERT/BERT/rsc/KorQuAD/output \\\n","  --do_lower_case=False"],"execution_count":23,"outputs":[{"output_type":"stream","text":["/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","WARNING:tensorflow:From /content/drive/MyDrive/BERT/src/make_bert_model/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From drive/MyDrive/BERT/src/make_bert_model/run_squad.py:1283: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From drive/MyDrive/BERT/src/make_bert_model/run_squad.py:1127: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n","\n","W1204 09:19:58.480099 140499336632192 deprecation_wrapper.py:119] From drive/MyDrive/BERT/src/make_bert_model/run_squad.py:1127: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n","\n","WARNING:tensorflow:From drive/MyDrive/BERT/src/make_bert_model/run_squad.py:1127: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n","\n","W1204 09:19:58.480329 140499336632192 deprecation_wrapper.py:119] From drive/MyDrive/BERT/src/make_bert_model/run_squad.py:1127: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/BERT/src/make_bert_model/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W1204 09:19:58.480530 140499336632192 deprecation_wrapper.py:119] From /content/drive/MyDrive/BERT/src/make_bert_model/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","WARNING:tensorflow:From drive/MyDrive/BERT/src/make_bert_model/run_squad.py:1133: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n","\n","W1204 09:19:58.482975 140499336632192 deprecation_wrapper.py:119] From drive/MyDrive/BERT/src/make_bert_model/run_squad.py:1133: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n","\n","I1204 09:19:59.245843 140499336632192 utils.py:141] NumExpr defaulting to 2 threads.\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","W1204 09:19:59.599643 140499336632192 lazy_loader.py:50] \n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From drive/MyDrive/BERT/src/make_bert_model/run_squad.py:229: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W1204 09:19:59.600261 140499336632192 deprecation_wrapper.py:119] From drive/MyDrive/BERT/src/make_bert_model/run_squad.py:229: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","Traceback (most recent call last):\n","  File \"drive/MyDrive/BERT/src/make_bert_model/run_squad.py\", line 1283, in <module>\n","    tf.app.run()\n","  File \"/root/.local/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 300, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 251, in _run_main\n","    sys.exit(main(argv))\n","  File \"drive/MyDrive/BERT/src/make_bert_model/run_squad.py\", line 1159, in main\n","    input_file=FLAGS.train_file, is_training=True)\n","  File \"drive/MyDrive/BERT/src/make_bert_model/run_squad.py\", line 230, in read_squad_examples\n","    input_data = json.load(reader)[\"data\"]\n","  File \"/usr/lib/python3.6/json/__init__.py\", line 299, in load\n","    parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n","  File \"/usr/lib/python3.6/json/__init__.py\", line 354, in loads\n","    return _default_decoder.decode(s)\n","  File \"/usr/lib/python3.6/json/decoder.py\", line 339, in decode\n","    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n","  File \"/usr/lib/python3.6/json/decoder.py\", line 357, in raw_decode\n","    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n","json.decoder.JSONDecodeError: Expecting value: line 7 column 1 (char 6)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"P1xLEPVP8x14"},"source":["## 결과"]},{"cell_type":"code","metadata":{"id":"d0GLaG-N8z7M","colab":{"base_uri":"https://localhost:8080/","height":87},"executionInfo":{"status":"ok","timestamp":1585619692618,"user_tz":-540,"elapsed":3629,"user":{"displayName":"Minkyung Park","photoUrl":"","userId":"13181002600298228191"}},"outputId":"4946ff6a-ec4e-46b6-e986-5707c433dd9b"},"source":["!python drive/My\\ Drive/Colab\\ Notebooks/BERT/rsc/KorQuAD/evaluate-v1.0.py \\\n","drive/My\\ Drive/Colab\\ Notebooks/BERT/rsc/KorQuAD/KorQuAD_v1.0_dev.json \\\n","drive/My\\ Drive/Colab\\ Notebooks/BERT/rsc/KorQuAD/output/predictions.json"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Traceback (most recent call last):\n","  File \"drive/My Drive/Colab Notebooks/BERT/rsc/KorQuAD/evaluate-v1.0.py\", line 119, in <module>\n","    with open(args.prediction_file) as prediction_file:\n","FileNotFoundError: [Errno 2] No such file or directory: 'drive/My Drive/Colab Notebooks/BERT/rsc/KorQuAD/output/predictions.json'\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0Vk1aHLe9KKW"},"source":["## 6. Fine-Tuning2 - 네이버영화 리뷰 감정분류\n","- BERT run_classfication.py\n","- 데이터 : 네이버 영화리뷰(https://github.com/e9t/nsmc)\n","- output : nsmc/output/\n","- 파라미터 : task_name=nsmc, do_train=true,<br>\n","do_eval=true, max_seq_length=128,<br>\n","train_batch_size=32, num_train_epochs=1.0<br>\n","learning_rate=3e-5, do_lower_case=false\n"]},{"cell_type":"code","metadata":{"id":"OlMoVML99JuW"},"source":["!python drive/My\\ Drive/Colab\\ Notebooks/BERT/src/make_bert_model/run_classifier.py \\\n","--task_name=nsmc \\\n","--do_train=true \\\n","--do_eval=true \\\n","--data_dir=drive/My\\ Drive/Colab\\ Notebooks/BERT/rsc/nsmc \\\n","--vocab_file=drive/My\\ Drive/Colab\\ Notebooks/BERT/rsc/conf/vocab.txt \\\n","--bert_config_file=drive/My\\ Drive/Colab\\ Notebooks/BERT/rsc/conf/bert_config.json \\\n","--init_checkpoint=drive/My\\ Drive/Colab\\ Notebooks/BERT/rsc/pretrained_model/model_output_512_model.ckpt-200000 \\\n","--max_seq_length=128 \\\n","--train_batch_size=32 \\\n","--num_train_epochs=1.0 \\\n","--learning_rate=3e-5 \\\n","--do_lower_case=false \\\n","--output_dir=drive/My\\ Drive/Colab\\ Notebooks/BERT/rsc/nsmc/output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aJGH2enMARPl"},"source":["## 7. Fine-Tuning3 - 카이스트 데이터셋 관계추출\n","- BERT run_multi_lassfication.py\n","- 데이터 : 카이스트 관계추출 데이터셋 (https://github.com/machinereading/kor-re-gold)\n","- output : relation_extract/output/\n","- 파라미터 : task_name=kent, do_train=true,<br>\n","do_eval=true, max_seq_length=128,<br>\n","train_batch_size=32, num_train_epochs=1.0<br>\n","learning_rate=2e-5, do_lower_case=false\n"]},{"cell_type":"code","metadata":{"id":"SXGqUFJGAs-d"},"source":["!python drive/My\\ Drive/Colab\\ Notebooks/BERT/src/make_bert_model/run_multi_classifier.py \\\n","--task_name=kent \\\n","--do_train=true \\\n","--do_eval=true \\\n","--data_dir=drive/My\\ Drive/Colab\\ Notebooks/BERT/rsc/relation_extract \\\n","--vocab_file=drive/My\\ Drive/Colab\\ Notebooks/BERT/rsc/conf/vocab.txt \\\n","--bert_config_file=drive/My\\ Drive/Colab\\ Notebooks/BERT/rsc/conf/bert_config.json \\\n","--init_checkpoint=drive/My\\ Drive/Colab\\ Notebooks/BERT/rsc/pretrained_model/model_output_512_model.ckpt-200000 \\\n","--max_seq_length=128 \\\n","--train_batch_size=32 \\\n","--num_train_epochs=1.0 \\\n","--learning_rate=2e-5 \\\n","--do_lower_case=false \\\n","--output_dir=drive/My\\ Drive/Colab\\ Notebooks/BERT/rsc/relation_extract/output"],"execution_count":null,"outputs":[]}]}