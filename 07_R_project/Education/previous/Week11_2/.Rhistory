q()
setwd("D:/R_project/library")
install.packages("rvest")
library(rvest)
# 도서관 대출상황 확인
url <- "http://www.bobaedream.co.kr/cyber/CyberCar.php?gubun=K&page=1"
usedCar <- read_html(url) #해당 url 페이지의 html tag를 가져와서 parsing함. usedCar
출처: https://insightteller.tistory.com/entry/R로-크롤링하기-보배드림-예제 [Be a Insight teller]
usedCar
View(usedCar)
carInfos <- html_nodes(usedCar, css='.carinfo')
head(carInfos)
head(carInfos)
View(carInfos)
View(usedCar)
carInfos <- html_nodes(usedCar, css='.carinfo')
head(carInfos)
# 도서관 대출상황 확인
library(rvest)
url <- "http://www.bobaedream.co.kr/cyber/CyberCar.php?gubun=K&page=1"
usedCar <- read_html(url) #해당 url 페이지의 html tag를 가져와서 parsing함.
usedCar
carInfos <- html_nodes(usedCar, css='.carinfo')
head(carInfos)
# 도서관 대출상황 확인
urlNews <- "http://news.naver.com/main/ranking/popularDay.nhn?mid=etc&sid1=111&date=20180804"   # 웹 스크래핑을 할 url을 입력합니다.
newsData <- read_html(urlNews)   # 입력된 url에서 html을 읽어옵니다.
# 도서관 대출상황 확인
urlNews <- "http://news.naver.com/main/ranking/popularDay.nhn?mid=etc&sid1=111&date=20180804"   # 웹 스크래핑을 할 url을 입력합니다.
newsData <- read_html(urlNews)   # 입력된 url에서 html을 읽어옵니다.
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
setwd("D:/R_project/Education/week10_2")
setwd("D:/R_project/Education/week10-3")
# install the MASS package for LDA
install.packages("MASS")
library(MASS)
# install.packages("gmodels") #crosstable
library(gmodels)
# read csv file
iris<-read.csv("iris.csv")
attach(iris)
# training/ test data : n=150
set.seed(1000)
N=nrow(iris)
tr.idx=sample(1:N, size=N*2/3, replace=FALSE)
# attributes in training and test
iris.train<-iris[tr.idx,-5]
iris.test<-iris[-tr.idx,-5]
# target value in training and test
trainLabels<-iris[tr.idx,5]
testLabels<-iris[-tr.idx,5]
train<-iris[tr.idx,]
test<-iris[-tr.idx,]
# Linear Discriminant Analysis (LDA) with training data n=100
iris.lda <- lda(Species ~ ., data=train, prior=c(1/3,1/3,1/3))
iris.lda
# predict test data set n=50
testpred <- predict(iris.lda, test)
testpred
# accuracy of LDA
CrossTable(x=testLabels,y=testpred$class, prop.chisq=FALSE)
# read csv file
iris<-read.csv("iris.csv")
attach(iris)
# training/ test data : n=150
set.seed(1000)
N=nrow(iris)
tr.idx=sample(1:N, size=N*2/3, replace=FALSE)
# attributes in training and test
iris.train<-iris[tr.idx,-5]
iris.test<-iris[-tr.idx,-5]
# target value in training and test
trainLabels<-iris[tr.idx,5]
testLabels<-iris[-tr.idx,5]
train<-iris[tr.idx,]
test<-iris[-tr.idx,]
# Linear Discriminant Analysis (LDA) with training data n=100
iris.lda <- lda(Species ~ ., data=train, prior=c(1/2,1/4,1/4))
iris.lda
# predict test data set n=50
testpred <- predict(iris.lda, test)
testpred
# accuracy of LDA
CrossTable(x=testLabels,y=testpred$class, prop.chisq=FALSE)
View(test)
View(train)
setwd("D:/R_project/Education/week10-4")
# MASS package for LDA
# install.packages("MASS")
library(MASS)
# install.packages("gmodels") #crosstable
library(gmodels)
# read csv file
iris<-read.csv("iris.csv")
attach(iris)
# training/ test data : n=150
set.seed(1000)
N=nrow(iris)
tr.idx=sample(1:N, size=N*2/3, replace=FALSE)
# attributes in training and test
iris.train<-iris[tr.idx,-5]
iris.test<-iris[-tr.idx,-5]
# target value in training and test
trainLabels<-iris[tr.idx,5]
testLabels<-iris[-tr.idx,5]
train<-iris[tr.idx,]
test<-iris[-tr.idx,]
# Box's M-test for Homogenity of Covariance Matrices
install.packages("biotools")
library(biotools)
boxM(iris[1:4], iris$Species)
# Quadratic Discriminant Analysis (QDA)
iris.qda <- qda(Species ~ ., data=train, prior=c(1/3,1/3,1/3))
iris.qda
# predict test data set n=50
testpredq <- predict(iris.qda, test)
testpredq
# accuracy of QDA
CrossTable(x=testLabels,y=testpredq$class, prop.chisq=FALSE)
# partimat() function for LDA & QDA
install.packages("klaR")
library(klaR)
partimat(as.factor(iris$Species) ~ ., data=iris, method="lda")
partimat(as.factor(iris$Species) ~ ., data=iris, method="qda")
library (e1071)
setwd("D:/R_project/Education/Week11-1")
# read data
iris<-read.csv("iris.csv")
attach(iris)
## classification
# 1. use all data
m1<- svm(Species ~., data = iris, kernel="linear")
summary(m1)
# classify all data using svm result (m1)
# first 4 variables as attribute variables
x<-iris[, -5]
pred <- predict(m1, x)
# Check accuracy (compare predicted class(pred) and true class(y))
# y <- Species or y<-iris[,5]
y<-iris[,5]
table(pred, y)
# visualize classes by color
plot(m1, iris,  Petal.Width~Petal.Length, slice=list(Sepal.Width=3, Sepal.Length=4))
## classification
# 1. use all data
m1<- svm(Species ~., data = iris)
summary(m1)
# classify all data using svm result (m1)
# first 4 variables as attribute variables
x<-iris[, -5]
pred <- predict(m1, x)
# Check accuracy (compare predicted class(pred) and true class(y))
# y <- Species or y<-iris[,5]
y<-iris[,5]
table(pred, y)
# visualize classes by color
plot(m1, iris,  Petal.Width~Petal.Length, slice=list(Sepal.Width=3, Sepal.Length=4))
setwd("D:/R_project/Education/Week11_2")
# install package for confusionMatrix
install.packages("caret")
library(caret)
# read data
iris<-read.csv("iris.csv")
attach(iris)
# training (100) & test set (50)
set.seed(1000, sample.kind="Rounding")
N=nrow(iris)
tr.idx=sample(1:N, size=N*2/3, replace=FALSE)
# target variable
y=iris[,5]
# split train data and test data
train=iris[tr.idx,]
test=iris[-tr.idx,]
m1<-svm(Species~., data = train)
summary(m1)
m2<-svm(Species~., data = train,kernel="polynomial")
summary(m2)
m3<-svm(Species~., data = train,kernel="sigmoid")
summary(m3)
m4<-svm(Species~., data = train,kernel="linear")
summary(m4)
View(m1)
#measure accuracy
pred11<-predict(m1,test) # radial basis
confusionMatrix(pred11, test$Species)
pred12<-predict(m2,test) # polynomial
confusionMatrix(pred12, test$Species)
pred13<-predict(m3,test) # simoid
confusionMatrix(pred13, test$Species)
pred14<-predict(m4,test) # linear
confusionMatrix(pred14, test$Species)
CrossTable(test$Species, pred14)
