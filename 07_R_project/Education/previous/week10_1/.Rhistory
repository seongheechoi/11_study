q()
setwd("D:/R_project/Education/week9-1")
# autompg data
car<-read.csv("autompg.csv")
head(car)
str(car)
attach(car)
# multiple regression : 1st full model
r1 <- lm(mpg ~ disp+hp+wt+accler, data=car)
View(r1)
summary(r1)
# pariwise plot - Explanatory Data Analysis
var1<-c("mpg","disp","hp","wt", "accler" )
pairs(car[var1], main ="Autompg",cex=1, col=as.integer(car$cyl))
# 2rd model using variable selection method
# step(r1, direction="forward")
# step(r1, direction="backward")
# stepwise selection
step(r1, direction="both")
# final multiple regression
r2<-lm(mpg ~ disp+wt+accler, data=car)
summary(r2)
# residual diagnostic plot
layout(matrix(c(1,2,3,4),2,2)) # optional 4 graphs/page
plot(r2)
# autompg data
car<-read.csv("autompg.csv")
head(car)
str(car)
attach(car)
# multiple regression : 1st full model
r1<-lm(mpg ~ disp+hp+wt+accler, data=car)
summary(r1)
# pariwise plot - Explanatory Data Analysis
var1<-c("mpg","disp","hp","wt", "accler" )
pairs(car[var1], main ="Autompg",cex=1, col=as.integer(car$cyl))
# pariwise plot - Explanatory Data Analysis
var1<-c("mpg","disp","hp","wt", "accler" )
pairs(car[var1], main ="Autompg",cex=1, col=as.integer(car$cyl))
# 2rd model using variable selection method
# step(r1, direction="forward")
# step(r1, direction="backward")
# stepwise selection
step(r1, direction="both")
# final multiple regression
r2<-lm(mpg ~ disp+wt+accler, data=car)
summary(r2)
# residual diagnostic plot
layout(matrix(c(1,2,3,4),2,2)) # optional 4 graphs/page
plot(r2)
# check correlation between independent variables
var2<-c("disp","hp","wt", "accler" )
cor(car[var2])
# check multicollinearity
# variance inflation factor(VIF)
install.packages("car")
library(car)
vif(lm(mpg ~ disp+hp+wt+accler, data=car))
# compare R-sqaured in regression
# which one is the most important variable?
summary(lm(mpg ~ disp))
summary(lm(mpg ~ hp))
summary(lm(mpg ~ wt))
summary(lm(mpg ~ accler))
# more checking point
plot(hp, mpg, col="blue")
## 2nd model : data split
# subset data hp<50
par(mfrow=c(1,1))
car_s1<-subset(car, hp<50)
plot(car_s1$hp, car_s1$mpg,col=10,  main="hp<50")
# regression for hp<50
summary(lm(car_s1$mpg ~ car_s1$hp))
# subset data hp>=50
car_s2<-subset(car, hp>=50)
plot(car_s2$hp, car_s2$mpg, col="coral", main="hp>=50")
# regression for hp>=50
summary(lm(car_s2$mpg ~ car_s2$hp))
# model for autompg data (hp<50)
car_s1<-subset(car, hp<50)
rf1<-lm(mpg ~ disp+hp+wt+accler, data=car_s1)
summary(rf1)
# residual diagnostic plot
layout(matrix(c(1,2,3,4),2,2)) # optional 4 graphs/page
plot(rf1)
setwd("D:/R_project/Education/Week_9-4")
# read csv file
iris<-read.csv(file="iris.csv")
# read csv file
iris<-read.csv(file="iris.csv")
View(iris)
head(iris)
str(iris)
attach(iris)
# training/ test data : n=150
set.seed(1000, sample.kind="Rounding") #시드 넘버를 지정하지 않으면 다른 성능비교 힘들어서 줌)
N=nrow(iris)
tr.idx=sample(1:N, size=N*2/3, replace=FALSE)
tr.idx
# attributes in training and test
iris.train<-iris[tr.idx,-5]
iris.test<-iris[-tr.idx,-5]
View(iris.train)
# target value in training and test
trainLabels<-iris[tr.idx,5]
testLabels<-iris[-tr.idx,5]
# to get frequency of class in test set
table(testLabels)
# training/ test data : n=150
set.seed(100, sample.kind="Rounding") #시드 넘버를 지정하지 않으면 다른 성능비교 힘들어서 줌)
N=nrow(iris)
tr.idx=sample(1:N, size=N*2/3, replace=FALSE)
tr.idx
# attributes in training and test
iris.train<-iris[tr.idx,-5]
iris.test<-iris[-tr.idx,-5]
# target value in training and test
trainLabels<-iris[tr.idx,5]
testLabels<-iris[-tr.idx,5]
# to get frequency of class in test set
table(testLabels)
# training/ test data : n=150
set.seed(1000, sample.kind="Rounding") #시드 넘버를 지정하지 않으면 다른 성능비교 힘들어서 줌)
N=nrow(iris)
tr.idx=sample(1:N, size=N*2/3, replace=FALSE)
tr.idx
# attributes in training and test
iris.train<-iris[tr.idx,-5]
iris.test<-iris[-tr.idx,-5]
# target value in training and test
trainLabels<-iris[tr.idx,5]
testLabels<-iris[-tr.idx,5]
# to get frequency of class in test set
table(testLabels)
setwd("D:/R_project/Education/week10_1")
# packages
install.packages("class")#no weighted value knn
install.packages("gmodels")#crosstable
install.packages("scales")#for graph
library(class)
library(gmodels)
library(scales)
# read csv file
iris<-read.csv("iris.csv")
# read csv file
iris<-read.csv("iris.csv")
# head(iris)
# str(iris)
attach(iris)
# training/ test data : n=150
set.seed(1000)
N=nrow(iris)
tr.idx=sample(1:N, size=N*2/3, replace=FALSE)
# attributes in training and test
iris.train<-iris[tr.idx,-5]
iris.test<-iris[-tr.idx,-5]
# target value in training and test
trainLabels<-iris[tr.idx,5]
testLabels<-iris[-tr.idx,5]
train <- iris[tr.idx,]
test <- iris[-tr.idx,]
# knn (5-nearest neighbor)
md1<-knn(train=iris.train,test=iris.test,cl=trainLabels,k=5)
md1
# accuracy of 5-nearest neighbor classification
CrossTable(x=testLabels,y=md1, prop.chisq=FALSE)
