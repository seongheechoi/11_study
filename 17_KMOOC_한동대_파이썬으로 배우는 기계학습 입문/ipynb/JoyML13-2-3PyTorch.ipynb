{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파이썬으로 배우는 기계학습\n",
    "# Machine Learning with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제 13-2 강: 기계학습 오픈 프레임워크 - PyTorch\n",
    "\n",
    "\n",
    "## 학습 목표\n",
    "- 기계학습을 위한 오픈 프레임워크는 무엇이 있는지 알아본다.\n",
    "- TensorFlow, Keras, PyTorch가 무엇인지 이해한다.\n",
    "- CNN을 이용한 MNIST 데이터를 3가지 프레임워크로 학습하는 것을 이해한다. \n",
    "\n",
    "## 학습 내용\n",
    "- 신경망 구현을 위한 패키지\n",
    "- PyTorch 란?\n",
    "- PyTorch 환경 구축\n",
    "- PyTorch 를 이용한 MNIST 데이터 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 신경망 구현을 위한 패키지\n",
    "\n",
    "이번 강의에서는 PyTorch 를 소개하겠습니다. PyTorch 를 사용한다면 간단하게 신경망을 구성할 수 있습니다. 데이터를 읽어드린 다음, 신경망을 구성하고 학습시켜 결과를 예측하는 것을 보여드리겠습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PyTorch 란?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/pytorch.png?raw=true\" width=\"300\">\n",
    "<br><center>그림 1: Pytorch [출처](https://pytorch.org/)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lua 언어로 개발된 Torch라는 딥러닝 라이브러리가 있었습니다. 머신러닝 라이브러리이자 Scientific Computing 프레임 워크 였습니다. 하지만, Lua 기반이라 다른 라이브러리에 비해 업데이트 속도도 느리고 사용자도 적었습니다. 그런데 이 Torch 를 Facebook에서 Python API로 개발하였습니다. 그러면서 폭발적인 인기를 얻게 되었고, 오늘 여러분들께 소개해 드리게 된 딥러닝 라이브러리 PyTorch입니다.\n",
    "\n",
    "디버깅이 쉬운 직관적인 코드로 구성되어있다.\n",
    "모델 그래프가 고정 상태가 아니기 때문에 언제든지 데이터에 따라 모델 조정 작업이 가능하다. (모델을 feed 하면서 정의하기 때문에 언제든 수정이 가능)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PyTorch 환경 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch를 사용하기 위해서는 Python이 설치되어 있어야 합니다. 이전에, 우리는 Tensorflow를 설치하면서 아나콘다를 이용했으므로, Python을 설치할 필요도 없으며, 이미 아나콘다가 설치되어 있다고 가정하에 설명드리겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Anaconda 설치\n",
    "\n",
    "Anaconda3 를 설치하세요. 이 [링크](https://www.continuum.io/downloads)를 통해 설치하시면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 PyTorch 설치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anaconda 까지 설치되어 있으면 PyTorch를 설치하는 것은 간단합니다. conda command를 이용하는 방법과, pip을 이용하는 방법 2가지가 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```conda install pytorch torchvision -c pytorch```\n",
    "\n",
    "\n",
    "```sudo pip install torch torchvision```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch가 제대로 설치되어있는지를 알아보기 위해 다음의 코드를 실행시켜보시길 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7647, 0.3304, 0.6325],\n",
      "        [0.1758, 0.8955, 0.6468],\n",
      "        [0.4148, 0.8790, 0.1989],\n",
      "        [0.0852, 0.3862, 0.1473],\n",
      "        [0.0085, 0.1239, 0.4428]])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 설치중에 어려움이 있다면, 아래 링크를 참고하도록 합니다.\n",
    "\n",
    "- [Anaconda 설치](https://www.continuum.io/downloads)\n",
    "- [Pytorch 설치](https://pytorch.org/get-started/locally/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. PyTorch 를 이용한 MNIST 데이터 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 PyTorch 를 사용할 환경이 구축되었습니다. PyTorch 를 이용해서 MNIST 데이터를 분석해보도록 합시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 MNIST 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch 에는 datasets 라는 모듈이 있으며, 사람들이 많이 사용하는 데이터를 쉽게 사용할 수 있도록 만들어져 있습니다. MNIST 데이터를 읽어오기 위해서는 datasets.MNIST를 이용하면 됩니다. torch.utils.data 에 있는 DataLoader 클래스에서 생성자 메소드를 호출하면 MNIST 데이터의 학습 데이터와 테스트 데이터를 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "use_cuda = not False and torch.cuda.is_available()\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=True, download=True,\n",
    "                    transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])),\n",
    "        batch_size=64, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=False, \n",
    "                    transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])),\n",
    "        batch_size=64, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLoader 클래스의 객체인 train_loader와 test_loader 안에 있는 dataset에 관한 내용은 다음과 같습니다. \n",
    "\n",
    "train_loader는 60000개의 데이터가 들어있으며, 각각에 데이터에 대한 평균과 분산에 대해서도 정리가 되어 있습니다.\n",
    "test_loader는 10000개의 데이터가 들어있으며, train_loader와 마찬가지로 평균과 분산 값이 들어있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Split: train\n",
      "    Root Location: ../data\n",
      "    Transforms (if any): Compose(\n",
      "                             ToTensor()\n",
      "                             Normalize(mean=(0.1307,), std=(0.3081,))\n",
      "                         )\n",
      "    Target Transforms (if any): None\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Split: test\n",
      "    Root Location: ../data\n",
      "    Transforms (if any): Compose(\n",
      "                             ToTensor()\n",
      "                             Normalize(mean=(0.1307,), std=(0.3081,))\n",
      "                         )\n",
      "    Target Transforms (if any): None\n"
     ]
    }
   ],
   "source": [
    "print(train_loader.dataset)\n",
    "print(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 신경망 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 신경망을 구축합니다. 이번에는 Tensorflow와 Keras와 다르게 클래스로 구현해보도록 하겠습니다. \n",
    "총 3개의 Convolutional Layer를 사용하며 마지막에는 10개의 출력값을 가지는 레이어를 구축합니다. 3개의 Convolutional Layer에는 kernel size가 2인, fitter가 들어가며 Dropout ratio는 0.2를 유지하도록 합니다.\n",
    "\n",
    "마지막 층은 10개의 뉴런을 사용하며, 각각의 뉴런은 0부터 9까지의 숫자를 예측하는 역할을 합니다. \n",
    "\n",
    "또한, 순전파를 위해 forward 메소드도 구현해주도록 합니다. 여기서, 각각의 Convolutional Layer에서 사용할 활성화 함수를 지정해주도록 합니다. 3개의 Layer모두 relu 함수를 활성화 함수로 지정했습니다. \n",
    "\n",
    "마지막 층에서는 softmax 함수를 구현하여, 결과를 조금 더 명확히 알 수 있도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=2)\n",
    "        self.conv1_drop = nn.Dropout2d(0.2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=2)\n",
    "        self.conv2_drop = nn.Dropout2d(0.2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=2)\n",
    "        self.conv3_drop = nn.Dropout2d(0.2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1_drop(self.conv1(x)), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv3_drop(self.conv3(x)), 2))\n",
    "        x = x.view(-1, 256)\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 하이퍼 파라미터 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자, 이제 신경망을 구축했으니 신경망에서 사용할 하이퍼파라미터 값을 설정해주도록 합니다.\n",
    "반복횟수는 10회로, 학습률은 0.01, random seed를 b값이 랜덤으로 설정되도록 합니다. 또한 RMSprop을 최적화 함수로 사용하도록 지정합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "learning_rate = 0.01\n",
    "random_seed = 1\n",
    "log_interval = 10\n",
    "\n",
    "network = Net()\n",
    "optimizer = optim.RMSprop(network.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 train 메소드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 모델을 학습시키는 단계입니다. network.train()은 우리가 구현하지는 않았지만, torch.nn.Module에 있는 메소드입니다. 이를 이용하여 학습을 위한 준비를 하고, train_loader에 있는 데이터들을 하나하나 학습시켜나갑니다. 이때, 손실함수로 Cross Entropy를 사용하고 있는 것을 알 수 있네요. \n",
    "\n",
    "또, 주목해 볼만한 것은 PyTorch에서 역전파는 `loss.backward()`만으로 수행될 수 있다는 점입니다. 일일이 구현을 안해도되니 매우 편하지요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 test 메소드\n",
    "\n",
    "이제 학습된 모델을 테스트하는 단계입니다. network.eval() 도 마찬가지로, torch.nn.Module에 있는 메소드입니다. 평가를 위한 준비를 마친 다음, test_loader에 있는데이터 하나하나에 대해 반복하며 모델이 올바른 결과를 내는지 확인합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        output = network(data)\n",
    "        test_loss += F.cross_entropy(output, target, size_average=False).item()\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "    print('Test Accuracy {}%\\n'.format(100.*correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.334411\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.294427\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.287363\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.188863\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 1.772631\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 1.619825\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 1.604931\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 1.338034\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 1.369627\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.936478\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.093312\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 1.139393\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.800295\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.828252\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.724024\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.590776\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.715705\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.613140\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.836331\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.506106\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.755633\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.488995\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.384932\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 1.050210\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.672261\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.549577\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.449842\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.261024\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.533016\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.285692\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.550318\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.745755\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.637204\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.667985\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.717866\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.467654\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.579569\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.294432\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.471447\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.353370\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.612982\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.674477\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.423966\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.523700\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.224742\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.357188\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.579741\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.180053\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.343833\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.309191\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.580767\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.763291\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.515650\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.465625\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.544690\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.246075\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.240006\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.309581\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.303818\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.369439\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.356537\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.303717\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.121931\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.382595\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.312552\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.264882\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.491115\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.129421\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.247640\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.268467\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.589417\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.302993\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.193523\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.425020\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.379427\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.215964\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.267928\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.208362\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.282164\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.182069\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.315300\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.316884\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.221763\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.116831\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.327696\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.258844\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.167004\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.420129\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.200892\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.212499\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.307058\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.286280\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.463082\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.147937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy 96%\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.170682\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.209871\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.225171\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.336706\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.395491\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.285216\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.230774\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.192664\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.233209\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.083432\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.315345\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.187431\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.340239\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.428680\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.337271\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.201456\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.230920\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.456971\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.210482\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.093373\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.199786\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.236190\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.543962\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.259940\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.349427\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.146760\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.184372\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.305945\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.687407\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.119667\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.096674\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.067106\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.438348\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.326344\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.211525\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.308068\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.462168\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.151646\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.091830\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.548296\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.232543\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.356959\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.195599\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.096438\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.209732\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.240290\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.185609\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.272744\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.193279\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.405858\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.381323\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.512945\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.088030\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.145882\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.216796\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.186899\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.504554\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.229439\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.145720\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.189088\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.337593\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.033638\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.347664\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.168422\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.470489\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.253868\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.301987\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.207718\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.278690\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.333692\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.283508\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.318742\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.400907\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.421909\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.222540\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.275375\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.234783\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.225548\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.330937\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.193890\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.356914\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.090012\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.230569\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.301030\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.087181\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.435530\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.199882\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.104088\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.238744\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.254094\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.165793\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.248447\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.178624\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.268052\n",
      "Test Accuracy 96%\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.455335\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.185468\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.310622\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.092837\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.220432\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.151844\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.346851\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.231830\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.125329\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.080142\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.166071\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.091756\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.129013\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.097959\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.148032\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.274334\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.159714\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.174305\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.238829\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.123763\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.284069\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.206197\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.244540\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.125472\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.287321\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.272601\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.167369\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.094793\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.134119\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.475559\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.249327\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.215575\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.420247\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.279614\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.168801\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.410459\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.140629\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.252248\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.103764\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.267929\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.164637\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.280762\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.354263\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.334377\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.233627\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.491811\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.237859\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.296041\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.131968\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.256571\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.221596\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.106367\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.274557\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.202710\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.116495\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.274217\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.157630\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.184804\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.048359\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.368856\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.227118\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.341883\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.170507\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.403920\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.090416\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.278631\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.196933\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.149070\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.430098\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.430742\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.054512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.161274\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.083485\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.758969\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.339093\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.167012\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.381515\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.126423\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.201586\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.165129\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.050831\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.227145\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.312054\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.221599\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.226790\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.317033\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.229453\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.099558\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.158682\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.166258\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.356148\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.164055\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.211237\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.388727\n",
      "Test Accuracy 96%\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.277867\n",
      "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.159020\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.266315\n",
      "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.167091\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.093065\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.248055\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.145165\n",
      "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.552064\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.191930\n",
      "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.095625\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.220972\n",
      "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.234407\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.225631\n",
      "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.297598\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.175651\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.386905\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.109880\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.332870\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.111851\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.262103\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.179417\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.263540\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.303787\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.248497\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.366837\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.167535\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.165043\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.134477\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.441422\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.502630\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.108471\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.126162\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.233295\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.363137\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.132692\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.352536\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.227222\n",
      "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.113815\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.086915\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.061514\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.422726\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.220246\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.343922\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.509977\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.369188\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.168665\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.150904\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.248382\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.391763\n",
      "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.281113\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.196937\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.137566\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.124976\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.142654\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.177744\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.312936\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.147963\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.184119\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.271068\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.231956\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.105234\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.127434\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.088726\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.229629\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.353267\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.154006\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.176822\n",
      "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.242369\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.240658\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.195636\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.278919\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.228771\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.120171\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.213639\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.118622\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.196054\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.069083\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.296893\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.033744\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.259455\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.323584\n",
      "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.139627\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.223775\n",
      "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.172980\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.102344\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.282381\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.299780\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.471655\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.283700\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.136697\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.286480\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.367760\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.257778\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.410679\n",
      "Test Accuracy 96%\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.339763\n",
      "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.103357\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.368331\n",
      "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.194286\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.253399\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.409608\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.315440\n",
      "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.131408\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.230649\n",
      "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.413770\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.130647\n",
      "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.103799\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.327590\n",
      "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.167229\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.367601\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.237544\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.222565\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.382013\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.189077\n",
      "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.246284\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.082177\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.118270\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.084002\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.249601\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.247091\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.049966\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.171386\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.106865\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.273233\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.524839\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.041522\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.254053\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.102065\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.253436\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.090055\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.085599\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.192819\n",
      "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.422221\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.135117\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.099512\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.382790\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.243523\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.156122\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.319439\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.335896\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.087175\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.135520\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.198541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.258536\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.105414\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.259861\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.242120\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.320441\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.321954\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.182505\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.162547\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.238584\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.226176\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.140342\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.138878\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.448307\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.097634\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.093226\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.201360\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.051196\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.337927\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.467320\n",
      "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.284328\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.398125\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.124719\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.255098\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.274401\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.080853\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.238199\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.258408\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.157305\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.419070\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.211075\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.156684\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.140969\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.248773\n",
      "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.237739\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.239286\n",
      "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.113977\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.101342\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.139351\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.043046\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.486158\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.268852\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.136422\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.222113\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.274229\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.107807\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.159652\n",
      "Test Accuracy 95%\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.183188\n",
      "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.172309\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.158738\n",
      "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.193841\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.135763\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.174154\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.061386\n",
      "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.280451\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.038608\n",
      "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.272771\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.134166\n",
      "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.227029\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.179214\n",
      "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.188898\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.238162\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.167494\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.122994\n",
      "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.104633\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.351336\n",
      "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.162978\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.478870\n",
      "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.067996\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.234458\n",
      "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.229880\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.038713\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.141579\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.097110\n",
      "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.209343\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.153641\n",
      "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.153654\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.209430\n",
      "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.372515\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.121185\n",
      "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.201456\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.358103\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.079303\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.109209\n",
      "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.180036\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.175760\n",
      "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.183566\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.203920\n",
      "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.126480\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.118469\n",
      "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.298393\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.387015\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.301517\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.125800\n",
      "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.156222\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.220391\n",
      "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.168378\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.199548\n",
      "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.074954\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.287455\n",
      "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.343682\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.332088\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.237096\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.085741\n",
      "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.139344\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.278817\n",
      "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.101503\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.074102\n",
      "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.170738\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.237319\n",
      "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.161824\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.318458\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.191189\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.301669\n",
      "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.105339\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.141402\n",
      "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.169578\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.408520\n",
      "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.106891\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.183056\n",
      "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.032615\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.468044\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.243914\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.242773\n",
      "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.230942\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.208215\n",
      "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.143228\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.043984\n",
      "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.098389\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.284663\n",
      "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.256215\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.117502\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.226087\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.145848\n",
      "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.108211\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.376800\n",
      "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.063954\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.448396\n",
      "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.186892\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.104757\n",
      "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.254458\n",
      "Test Accuracy 96%\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.062987\n",
      "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.210277\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.112971\n",
      "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.180237\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.239360\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.187612\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.192979\n",
      "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.160115\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.156815\n",
      "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.250101\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.130415\n",
      "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.128143\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.161617\n",
      "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.147162\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.104543\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.126637\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.120687\n",
      "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.485252\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.123452\n",
      "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.024185\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.281056\n",
      "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.185327\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.268906\n",
      "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.141251\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.115883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.216840\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.188179\n",
      "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.180027\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.295811\n",
      "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.082677\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.280433\n",
      "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.089761\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.182818\n",
      "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.304592\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.246981\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.197804\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.206023\n",
      "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.136560\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.203592\n",
      "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.209005\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.119652\n",
      "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.159837\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.105320\n",
      "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.164969\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.316077\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.372764\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.075178\n",
      "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.276661\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.247072\n",
      "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.188541\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.288885\n",
      "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.121332\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.125699\n",
      "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.259152\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.156550\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.357217\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.067595\n",
      "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.311110\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.129751\n",
      "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.261623\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.156479\n",
      "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.244393\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.132527\n",
      "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.229993\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.277672\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.217141\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.101373\n",
      "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.082334\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.117119\n",
      "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.135258\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.272350\n",
      "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.508979\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.148610\n",
      "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.209399\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.247341\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.147301\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.132839\n",
      "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.342275\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.099950\n",
      "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.159004\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.189105\n",
      "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.066201\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.326026\n",
      "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.173789\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.162024\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.175036\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.212783\n",
      "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.147552\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.179991\n",
      "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.223853\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.268992\n",
      "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.144938\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.257710\n",
      "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.172706\n",
      "Test Accuracy 95%\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.501408\n",
      "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.176317\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.286544\n",
      "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.314120\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.276978\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.180701\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.237955\n",
      "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.203894\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.272021\n",
      "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.114438\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.429824\n",
      "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.200577\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.273285\n",
      "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.111898\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.166124\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.239657\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.421576\n",
      "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.315001\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.199725\n",
      "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.127846\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.213032\n",
      "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.210524\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.371979\n",
      "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.257857\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.098678\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.123892\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.088558\n",
      "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.268499\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.126821\n",
      "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.362636\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.166957\n",
      "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.104427\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.172040\n",
      "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.367197\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.234343\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.180919\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.292076\n",
      "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.112775\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.424100\n",
      "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.322961\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.240301\n",
      "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.080458\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.190858\n",
      "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.068999\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.174880\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.156743\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.292993\n",
      "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.217376\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.154363\n",
      "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.440407\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.212733\n",
      "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.107799\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.068600\n",
      "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.174487\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.084349\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.311031\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.146857\n",
      "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.166509\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.339776\n",
      "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.317708\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.217940\n",
      "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.208993\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.369722\n",
      "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.409726\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.350970\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.140039\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.451368\n",
      "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.159024\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.085513\n",
      "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.407219\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.098657\n",
      "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.143077\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.287437\n",
      "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.502845\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.183672\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.055236\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.131893\n",
      "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.258058\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.267964\n",
      "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.182929\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.088676\n",
      "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.133354\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.458104\n",
      "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.157810\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.208959\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.171566\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.394668\n",
      "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.309137\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.281415\n",
      "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.191268\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.305617\n",
      "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.538007\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.363004\n",
      "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.298797\n",
      "Test Accuracy 97%\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.294566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.616248\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.291383\n",
      "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.236659\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.312430\n",
      "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.382891\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.153971\n",
      "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.105250\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.238781\n",
      "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.419278\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.313787\n",
      "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.100430\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.120571\n",
      "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.085834\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.348447\n",
      "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.137886\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.015561\n",
      "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.084235\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.184196\n",
      "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.210975\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.062882\n",
      "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.189186\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.055629\n",
      "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.287846\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.224736\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.413293\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.367666\n",
      "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.235402\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.186479\n",
      "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.198831\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.175358\n",
      "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.133506\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.285944\n",
      "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.115815\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.251186\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.258713\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.156683\n",
      "Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.460816\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.104200\n",
      "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.266610\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.288855\n",
      "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.218331\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.243067\n",
      "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.264082\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.169373\n",
      "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.235127\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.264704\n",
      "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.110440\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.060799\n",
      "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.315339\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.202224\n",
      "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.206512\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.471361\n",
      "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.275274\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.380942\n",
      "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.219080\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.138906\n",
      "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.209834\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.145005\n",
      "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.278497\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.147905\n",
      "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.196367\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.151656\n",
      "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.264931\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.223461\n",
      "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.132932\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.023053\n",
      "Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.052682\n",
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.256909\n",
      "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.118074\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.109192\n",
      "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.071402\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.094631\n",
      "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.346019\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.349777\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.123427\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.095701\n",
      "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.302698\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.022751\n",
      "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.172836\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.157333\n",
      "Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.226434\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.064018\n",
      "Train Epoch: 9 [53120/60000 (88%)]\tLoss: 0.199258\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.273248\n",
      "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.185627\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.270786\n",
      "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.096814\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.117858\n",
      "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.351882\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.205762\n",
      "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.299510\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.299817\n",
      "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.211270\n",
      "Test Accuracy 97%\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.180567\n",
      "Train Epoch: 10 [640/60000 (1%)]\tLoss: 0.098701\n",
      "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 0.136705\n",
      "Train Epoch: 10 [1920/60000 (3%)]\tLoss: 0.260344\n",
      "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 0.222490\n",
      "Train Epoch: 10 [3200/60000 (5%)]\tLoss: 0.193856\n",
      "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 0.267479\n",
      "Train Epoch: 10 [4480/60000 (7%)]\tLoss: 0.169056\n",
      "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 0.123960\n",
      "Train Epoch: 10 [5760/60000 (10%)]\tLoss: 0.316067\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.060336\n",
      "Train Epoch: 10 [7040/60000 (12%)]\tLoss: 0.132142\n",
      "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 0.395817\n",
      "Train Epoch: 10 [8320/60000 (14%)]\tLoss: 0.294424\n",
      "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 0.181530\n",
      "Train Epoch: 10 [9600/60000 (16%)]\tLoss: 0.070951\n",
      "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.154760\n",
      "Train Epoch: 10 [10880/60000 (18%)]\tLoss: 0.235839\n",
      "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 0.238121\n",
      "Train Epoch: 10 [12160/60000 (20%)]\tLoss: 0.258944\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.227580\n",
      "Train Epoch: 10 [13440/60000 (22%)]\tLoss: 0.092175\n",
      "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 0.207825\n",
      "Train Epoch: 10 [14720/60000 (25%)]\tLoss: 0.132402\n",
      "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 0.099268\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.100835\n",
      "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 0.456057\n",
      "Train Epoch: 10 [17280/60000 (29%)]\tLoss: 0.150618\n",
      "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 0.214103\n",
      "Train Epoch: 10 [18560/60000 (31%)]\tLoss: 0.157532\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.093855\n",
      "Train Epoch: 10 [19840/60000 (33%)]\tLoss: 0.144669\n",
      "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.300450\n",
      "Train Epoch: 10 [21120/60000 (35%)]\tLoss: 0.128354\n",
      "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 0.089929\n",
      "Train Epoch: 10 [22400/60000 (37%)]\tLoss: 0.308939\n",
      "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 0.193489\n",
      "Train Epoch: 10 [23680/60000 (39%)]\tLoss: 0.307054\n",
      "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 0.359309\n",
      "Train Epoch: 10 [24960/60000 (42%)]\tLoss: 0.128032\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.332960\n",
      "Train Epoch: 10 [26240/60000 (44%)]\tLoss: 0.251167\n",
      "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 0.067405\n",
      "Train Epoch: 10 [27520/60000 (46%)]\tLoss: 0.114087\n",
      "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 0.205862\n",
      "Train Epoch: 10 [28800/60000 (48%)]\tLoss: 0.152748\n",
      "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 0.633554\n",
      "Train Epoch: 10 [30080/60000 (50%)]\tLoss: 0.173931\n",
      "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.057240\n",
      "Train Epoch: 10 [31360/60000 (52%)]\tLoss: 0.251682\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.105833\n",
      "Train Epoch: 10 [32640/60000 (54%)]\tLoss: 0.126308\n",
      "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 0.101106\n",
      "Train Epoch: 10 [33920/60000 (57%)]\tLoss: 0.166630\n",
      "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 0.058597\n",
      "Train Epoch: 10 [35200/60000 (59%)]\tLoss: 0.137763\n",
      "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 0.106830\n",
      "Train Epoch: 10 [36480/60000 (61%)]\tLoss: 0.150519\n",
      "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 0.116167\n",
      "Train Epoch: 10 [37760/60000 (63%)]\tLoss: 0.341268\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.079433\n",
      "Train Epoch: 10 [39040/60000 (65%)]\tLoss: 0.152580\n",
      "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 0.160861\n",
      "Train Epoch: 10 [40320/60000 (67%)]\tLoss: 0.342136\n",
      "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.155857\n",
      "Train Epoch: 10 [41600/60000 (69%)]\tLoss: 0.099880\n",
      "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 0.234323\n",
      "Train Epoch: 10 [42880/60000 (71%)]\tLoss: 0.245202\n",
      "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 0.513231\n",
      "Train Epoch: 10 [44160/60000 (74%)]\tLoss: 0.023130\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.027981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [45440/60000 (76%)]\tLoss: 0.111028\n",
      "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 0.088748\n",
      "Train Epoch: 10 [46720/60000 (78%)]\tLoss: 0.168245\n",
      "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 0.186785\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.226959\n",
      "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 0.073061\n",
      "Train Epoch: 10 [49280/60000 (82%)]\tLoss: 0.206084\n",
      "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 0.297060\n",
      "Train Epoch: 10 [50560/60000 (84%)]\tLoss: 0.061064\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.285747\n",
      "Train Epoch: 10 [51840/60000 (86%)]\tLoss: 0.254455\n",
      "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 0.227160\n",
      "Train Epoch: 10 [53120/60000 (88%)]\tLoss: 0.106087\n",
      "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 0.188184\n",
      "Train Epoch: 10 [54400/60000 (91%)]\tLoss: 0.286405\n",
      "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 0.349108\n",
      "Train Epoch: 10 [55680/60000 (93%)]\tLoss: 0.332064\n",
      "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 0.440225\n",
      "Train Epoch: 10 [56960/60000 (95%)]\tLoss: 0.265202\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.193010\n",
      "Train Epoch: 10 [58240/60000 (97%)]\tLoss: 0.231994\n",
      "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 0.468878\n",
      "Train Epoch: 10 [59520/60000 (99%)]\tLoss: 0.077902\n",
      "Test Accuracy 96%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs+1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 참고자료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Udacity 강의 'Artificial Intelligence Nanodegree - Convolutional Neural Networks' [aind2-cnn Jupyter Notebook 파일](https://github.com/udacity/aind2-cnn/blob/master/mnist-mlp/mnist_mlp.ipynb)\n",
    "- Keras Documentation https://keras.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "Rejoice in the Lord always. I will say it again: Rejoice! (Ph4:4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
